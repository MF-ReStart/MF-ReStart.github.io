{"meta":{"title":"荒原饮露","subtitle":"可能是未来的架构师，也可能送外卖。","description":"","author":"荒原饮露","url":"https://www.missf.top","root":"/"},"pages":[{"title":"","date":"2020-06-02T02:12:04.533Z","updated":"2020-04-13T10:37:41.000Z","comments":false,"path":"tags/index.html","permalink":"https://www.missf.top/tags/index.html","excerpt":"","text":""},{"title":"","date":"2020-09-11T10:56:09.202Z","updated":"2020-09-11T10:56:09.202Z","comments":false,"path":"categories/index.html","permalink":"https://www.missf.top/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"MariaDB 主从复制和 Maxscale 中间件实现读写分离及故障切换","slug":"MariaDB 主从复制和 Maxscale 中间件实现读写分离及故障切换","date":"2020-09-14T03:20:58.000Z","updated":"2020-09-25T09:13:11.719Z","comments":true,"path":"post/2c9da2f4.html","link":"","permalink":"https://www.missf.top/post/2c9da2f4.html","excerpt":"","text":"环境准备system version: CentOS Linux release 7.7.1908 mariadb version: 10.5.2 maxscale version: 2.5.3 GA client: 10.10.110.84 mariadb master: 10.10.110.80 mariadb slave1: 10.10.110.81 mariadb slave2: 10.10.110.82 maxscale proxy: 10.10.110.83 主从复制原理当 mariadb master 服务器上的数据发生改变时(增、删、改)，则将其改变写入 binlog 二进制日志中。slave 服务器会在一定时间间隔内对 master 二进制日志进行探测其是否发生改变，如果发生改变，则开启一个 I/O 线程请求 master 二进制事件，同时主节点为每个 I/O 线程启动一个 dump 线程，用于向其发送二进制事件，并保存至从库本地的中继日志中，从库将启动 SQL 线程从中继日志中读取二进制日志，在本地回放，使得从库数据和主库的数据保持一致，最后 IO 线程和 SQL 线程将进入睡眠状态，等待下一次被唤醒 主从复制的前提条件 master 一定要开启 binlog 二进制日志，并且授予 slave 远程连接的权限 主从复制至少需要两个 mysql 实例，可以分布在不同服务器，也可以在同一台服务器 master 实例和 slave 实例的 mysql 版本最好相同(如果不同，那么 master 实例版本需要低于 slave 实例) master 实例和 slave 实例之间时间同步 配置 MariaDB Master 节点# 安装MariaDB tee /etc/yum.repos.d/Mariadb.repo &lt;&lt; EOF # mariadb 10.5 CentOS repository list - created 2020-09-14 10:57 UTC # http://downloads.mariadb.org/mariadb/repositories/ [mariadb] name=mariadb baseurl=https://mirrors.aliyun.com/mariadb/yum/10.5/centos7-amd64/ gpgkey=https://mirrors.aliyun.com/mariadb/yum/RPM-GPG-KEY-MariaDB gpgcheck=1 EOF yum clean all &amp;&amp; yum makecache yum install -y MariaDB-server MariaDB-client # 配置文件 cat /etc/my.cnf.d/server.cnf ... [mysqld] log-bin=mariadb-bin server_id=180 port=53306 ... # 启动mariadb systemctl start mariadb # 添加用户slave授予远程连接的权限,供从节点复制binlog GRANT REPLICATION SLAVE ON *.* TO 'slave'@'10.10.110.%' IDENTIFIED BY '123456'; # 查看主库的binlog记录日志信息偏移量position mariadb [(none)]> show master status; +--------------------+----------+--------------+------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +--------------------+----------+--------------+------------------+ | mariadb-bin.000001 | 529 | | | +--------------------+----------+--------------+------------------+ 1 row in set (0.000 sec) 配置 MariaDB Slave 节点mariadb 10.0.2开始，GTID 是默认打开的。因为 maxscale 故障切换功能需要 mariadb 开启基于 GTID 的主从复制，而且是以 master_use_gtid=current_pos 的方式。因为 master_use_gtid=slave_pos 的方式，master 将从最后一个 GTID 开始给 slave 复制 binlog，通过 @@gtid_slave_pos 这个变量来查看目前最后一个 GTID 的位置，如果A节点 (master) 故障了之后由B节点成为了 master，当A节点以 slave 的身份加入到集群时，由于A节点之前从未成为过 slave，那么A节点的 @@gtid_slave_pos 是空的。为了能让故障的 master 节点故障之后能够重新以 slave 的身份加入到集群，我们需要使用 master_use_gtid=current_pos 的 GTID 方式开启主从复制 # 指定主库信息(master信息会存到/var/lib/mysql/master.info文件) mariadb [(none)]> change master to master_host='10.10.110.80', -> master_user='slave', -> master_password='123456', -> master_port=53306, -> master_use_gtid=current_pos, -> master_connect_retry=30; Query OK, 0 rows affected (0.017 sec) # 启动slave线程,若要更改指定的主库信息,需先执行stop slave,修改完成后执行start slave mariadb [(none)]> start slave; Query OK, 0 rows affected (0.003 sec) # 查看slave状态(slave_IO_Running和slave_SQL_Running都为Yes状态) mariadb [(none)]> show slave status\\G *************************** 1. row *************************** slave_IO_State: Waiting for master to send event master_Host: 10.10.110.80 master_User: slave master_Port: 53306 Connect_Retry: 30 master_Log_File: mariadb-bin.000001 Read_master_Log_Pos: 529 Relay_Log_File: localhost-relay-bin.000002 Relay_Log_Pos: 830 Relay_master_Log_File: mariadb-bin.000001 slave_IO_Running: Yes slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_master_Log_Pos: 529 Relay_Log_Space: 1143 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 master_SSL_Allowed: No master_SSL_CA_File: master_SSL_CA_Path: master_SSL_Cert: master_SSL_Cipher: master_SSL_Key: Seconds_Behind_master: 0 master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: master_Server_Id: 80 master_SSL_Crl: master_SSL_Crlpath: Using_Gtid: Current_Pos Gtid_IO_Pos: 0-80-1 Replicate_Do_Domain_Ids: Replicate_Ignore_Domain_Ids: Parallel_Mode: optimistic SQL_Delay: 0 SQL_Remaining_Delay: NULL slave_SQL_Running_State: slave has read all relay log; waiting for more updates slave_DDL_Groups: 1 slave_Non_Transactional_Groups: 0 slave_Transactional_Groups: 0 1 row in set (0.001 sec) 验证主从复制在 mariadb master上创建测试数据，然后在 mariadb slave 上查看数据是否已经同步过来 create database mariadb; use mariadb; create table mariadb(name varchar(25),city varchar(30),age int); insert into mariadb.mariadb values(\"mariadb\",\"china\",11); MariaDB 开启并行复制mariadb的复制通过三步完成: 1.从库的IO线程去主库上读取binlog日志变更，并把读取的事件按顺序存放到relay log 2.从库的SQL线程一次读取relay log中的一个事件 3.SQL线程依次执行relay log中的事件 mariadb 10之前的版本中，第三步是通过SQL线程来执行的，这意味着一次只能执行一个事件，复制本质上是单线程的。mariadb 10之后的版本中，第三步可以由一个单独的复制工作线程池执行，从而通过并行应用多个事件来提高复制性能 cat /etc/my.cnf.d/server.cnf ... [mysqld] slave-parallel-threads=8 # 在工作线程池中创建8个线程 ... 查看工作线程的数量 MariaDB [(none)]> SHOW PROCESSLIST; +----+-------------+-----------+------+--------------+------+--------------------------------------------------------+------------------+----------+ | Id | User | Host | db | Command | Time | State | Info | Progress | +----+-------------+-----------+------+--------------+------+--------------------------------------------------------+------------------+----------+ | 5 | system user | | NULL | Slave_IO | 27 | Waiting for master to send event | NULL | 0.000 | | 7 | system user | | NULL | Slave_worker | 27 | Waiting for work from SQL thread | NULL | 0.000 | | 8 | system user | | NULL | Slave_worker | 27 | Waiting for work from SQL thread | NULL | 0.000 | | 9 | system user | | NULL | Slave_worker | 27 | Waiting for work from SQL thread | NULL | 0.000 | | 10 | system user | | NULL | Slave_worker | 27 | Waiting for work from SQL thread | NULL | 0.000 | | 11 | system user | | NULL | Slave_worker | 27 | Waiting for work from SQL thread | NULL | 0.000 | | 12 | system user | | NULL | Slave_worker | 27 | Waiting for work from SQL thread | NULL | 0.000 | | 13 | system user | | NULL | Slave_worker | 27 | Waiting for work from SQL thread | NULL | 0.000 | | 14 | system user | | NULL | Slave_worker | 27 | Waiting for work from SQL thread | NULL | 0.000 | | 6 | system user | | NULL | Slave_SQL | 27 | Slave has read all relay log; waiting for more updates | NULL | 0.000 | | 15 | root | localhost | NULL | Query | 0 | starting | SHOW PROCESSLIST | 0.000 | +----+-------------+-----------+------+--------------+------+--------------------------------------------------------+------------------+----------+ 11 rows in set (0.000 sec) 判断主从复制延迟Seconds_Behind_Master 是通过 sql_thread 执行的事件的时间戳和 io_thread 复制好的事件的时间戳进行比较，而得到的一个差值 NULL：表示 io_thread 或是 sql_thread 有任何一个发生故障，也就是该线程的 Running 状态是 No 而非 Yes 0：该值为零，是我们极为渴望看到的情况，表示主从复制良好，可以认为 lag 不存在 正值：表示主从已经出现延时，数字越大表示从库落后主库越多 负值：几乎很少见，其实这是一个 BUG 值，该参数是不应该出现负值的 仅仅依靠 Seconds_Behind_Master 的值来监测主从同步数据是否延迟是绝对不可靠的，如果网络存在延迟，即使我们看到 Seconds_Behind_Master 的值为零，也会存在很大的偏差。更加严谨的判断主从延时的做法是： 对 master 和 slave 同时发起 SHOW BINARY LOGS 请求，判断二者 binlog 的差异 对 slave 发起 SHOW slave STATUS\\G 的请求，查看 Read_Master_Log_Pos 和 Exec_Master_Log_Pos 是否一致 读写分离和故障切换的实现数据写入操作在主库执行，数据读取操作在从库执行，在一定程度上减轻了数据库的压力，主从复制保证了数据的安全 Maxscale 概述maxscale 是由 mariadb 团队开发的一个数据库代理工具，将数据库语句转发到一个或多个数据库服务器，转发是使用基于对数据库语句的语义理解和后端数据库集群中服务器角色的规则来执行的，设计目的是为应用程序提供透明的负载平衡和高可用性功能。mariadb maxscale 具有可扩展和灵活的架构，通过插件组件支持不同的协议和路由方法 安装 Maxscalewget https://downloads.mariadb.com/MaxScale/2.5.3/rhel/7/x86_64/maxscale-2.5.3-2.rhel.7.x86_64.rpm yum -y install maxscale-2.5.3-2.rhel.7.x86_64.rpm MariaDB Master 主库上创建相关的账户在开始配置之前，需要在 mariadb master 中为 maxscale 创建两个用户，用于 maxscale 的监控模块和路由模块 monitor_user：该账号监控集群状态，如果发现某个从服务器复制线程停掉了，那么就不向其转发请求了 # 创建监控用户,用于[MariaDB-Monitor]配置 CREATE USER 'monitor_user'@'%' IDENTIFIED BY '123456'; GRANT REPLICATION CLIENT ON *.* TO 'monitor_user'@'%'; # 如果使用 MariaDB Monitor 的自动故障转移，用户将需要额外的授权 GRANT SUPER, RELOAD ON *.* TO 'monitor_user'@'%'; routing_user：该账号将不同的请求分发到不同的节点上，当客户端连接到 maxscale 这个节点上时，maxscale 节点会使用该账号去查后端数据库，检查客户端登陆的用户是否有权限或密码是否正确等等 # 创建routing user,用于[Read-Write-Service]配置 CREATE USER 'routing_user'@'%' IDENTIFIED BY '123456'; GRANT SELECT ON mysql.user TO 'routing_user'@'%'; GRANT SELECT ON mysql.db TO 'routing_user'@'%'; GRANT SELECT ON mysql.tables_priv TO 'routing_user'@'%'; GRANT SELECT ON mysql.columns_priv TO 'routing_user'@'%'; GRANT SELECT ON mysql.proxies_priv TO 'routing_user'@'%'; GRANT SELECT ON mysql.roles_mapping TO 'routing_user'@'%'; GRANT SHOW DATABASES ON *.* TO 'routing_user'@'%'; 配置加密密码我们创建的数据库用户信息需要填写到 maxscale 配置文件中，为了防止配置文件出现明文密码，我们可以使用秘钥为密码加密，然后将加密后的字符串填写在 maxscale 配置文件中 # 生成秘钥,密钥将保存到/var/lib/maxscale/.secrets maxkeys # 基于秘钥生成123456加密后的字符串(记录下来) maxpasswd /var/lib/maxscale/ 123456 Maxscale 配置文件[root@localhost ~]# grep -v \"^#\" /etc/maxscale.cnf [maxscale] threads=auto admin_host=0.0.0.0 admin_port=8080 admin_secure_gui=false # 关闭GUI安全验证,不然需要配置ssl [server1] # 不需要指定哪个是master和slave,maxscale会自动识别 type=server address=10.10.110.80 port=53306 protocol=MariaDBBackend [server2] type=server address=10.10.110.81 port=53306 protocol=MariaDBBackend [server3] type=server address=10.10.110.82 port=53306 protocol=MariaDBBackend [MariaDB-Monitor] type=monitor module=mariadbmon servers=server1,server2,server3 user=monitor_user password=EA25B20FBB2B3EF4562F9D585DE8826B64B328C08571D8F656424252F9560A62 monitor_interval=2000 [Read-Write-Service] type=service router=readwritesplit # 配置读写分离的路由 servers=server1,server2,server3 user=routing_user password=EA25B20FBB2B3EF4562F9D585DE8826B64B328C08571D8F656424252F9560A62 [Read-Write-Listener] type=listener service=Read-Write-Service # 监听读写分离的服务 protocol=MariaDBClient port=4006 # maxscale代理的端口 启动 Maxscale 服务systemctl start maxscale.service Maxctrl 管理工具的使用maxctrl 如果不指定 COMMAND 将会进入交互式模式，在交互式中可以直接输入 COMMAND，以表格格式显示基础信息 # 显示所有后端服务器 maxctrl -h 10.10.110.83:8080 list servers ┌─────────┬──────────────┬───────┬─────────────┬─────────────────┬─────────┐ │ Server │ Address │ Port │ Connections │ State │ GTID │ ├─────────┼──────────────┼───────┼─────────────┼─────────────────┼─────────┤ │ server1 │ 10.10.110.80 │ 53306 │ 0 │ Master, Running │ 0-80-15 │ ├─────────┼──────────────┼───────┼─────────────┼─────────────────┼─────────┤ │ server2 │ 10.10.110.81 │ 53306 │ 0 │ Slave, Running │ 0-80-15 │ ├─────────┼──────────────┼───────┼─────────────┼─────────────────┼─────────┤ │ server3 │ 10.10.110.82 │ 53306 │ 0 │ Slave, Running │ 0-80-15 │ └─────────┴──────────────┴───────┴─────────────┴─────────────────┴─────────┘ list services # 显示所有服务，例如读写分离服务等 list monitors # 显示所有监控信息 list listeners # 显示监听信息 # 更多的命令可以去官网自行了解... 登录 Maxscale 仪表板默认情况下用户名是 admin，密码是 mariadb 仪表板界面可以看到以下资源的概览信息：按 monitor 分组的所有服务器，当前会话和所有服务。这些资源的信息每10秒更新一次。监视器、服务器和服务资源都有自己的详细信息页面。可以通过单击仪表板页面上的资源名称来访问它，在详细信息页中，可以修改部分资源参数的值 Maxscale 测试读写分离验证读写分离的 “读” 操作是否在从库上 # 分别在两个从库上创建数据 create database slave; use slave; create table info(name varchar(25),ip int); insert into slave.info values(\"slave\",inet_aton('10.10.110.81')); create database slave; use slave; create table info(name varchar(25),ip int); insert into slave.info values(\"slave\",inet_aton('10.10.110.82')); # 在主库上创建测试用户 grant all on *.* to 'check'@'%' identified by '123456'; # 连接maxscale查询数据验证读写分离(读操作自动负载均衡) mysql -ucheck -p123456 -P4006 -h 10.10.110.83 MariaDB [(none)]> select name,inet_ntoa(ip) from slave.info; +-------+---------------+ | name | inet_ntoa(ip) | +-------+---------------+ | slave | 10.10.110.82 | +-------+---------------+ 1 row in set (0.002 sec) MariaDB [(none)]> select name,inet_ntoa(ip) from slave.info; +-------+---------------+ | name | inet_ntoa(ip) | +-------+---------------+ | slave | 10.10.110.81 | +-------+---------------+ 1 row in set (0.001 sec) 验证读写分离的 “写” 操作是否在主库上 # 连接maxscale往里写数据,看slave上数据有没有同步过来 create database test; use test; create table test(name varchar(25),city varchar(30),age int); insert into test.test values(\"mariadb\",\"china\",11); Maxscale 配置故障切换编辑 maxscale 的配置文件，配置故障切换参数 [root@localhost ~]# grep -v \"^#\" /etc/maxscale.cnf [maxscale] threads=auto admin_host=0.0.0.0 admin_port=8080 admin_secure_gui=false [server1] type=server address=10.10.110.80 port=53306 protocol=MariaDBBackend [server2] type=server address=10.10.110.81 port=53306 protocol=MariaDBBackend [server3] type=server address=10.10.110.82 port=53306 protocol=MariaDBBackend [MariaDB-Monitor] type=monitor module=mariadbmon servers=server1,server2,server3 user=monitor_user password=EA25B20FBB2B3EF4562F9D585DE8826B64B328C08571D8F656424252F9560A62 monitor_interval=2000 replication_user=slave # 复制用户 replication_password=EA25B20FBB2B3EF4562F9D585DE8826B64B328C08571D8F656424252F9560A62 auto_failover=true # 开启自动故障转移 auto_rejoin=true # 自动重新连接 failcount=3 # 故障次数 failover_timeout=90 # 故障转移超时 switchover_timeout=90 # 故障切换超时 verify_master_failure=true # 自动故障转移启用额外的主故障验证 master_failure_timeout=10 # [Read-Write-Service] type=service router=readwritesplit servers=server1,server2,server3 user=routing_user password=EA25B20FBB2B3EF4562F9D585DE8826B64B328C08571D8F656424252F9560A62 [Read-Write-Listener] type=listener service=Read-Write-Service protocol=MariaDBClient port=4006 手动关闭 master 节点，使用 maxctrl 查看 master 状态，可以看到 master 节点会自动切换。当 master节点修复之后会自动重新加入集群 [root@localhost ~]# maxctrl -h 10.10.110.83:8080 list servers ┌─────────┬──────────────┬───────┬─────────────┬────────────────┬─────────┐ │ Server │ Address │ Port │ Connections │ State │ GTID │ ├─────────┼──────────────┼───────┼─────────────┼────────────────┼─────────┤ │ server1 │ 10.10.110.80 │ 53306 │ 0 │ Down │ 0-80-26 │ ├─────────┼──────────────┼───────┼─────────────┼────────────────┼─────────┤ │ server2 │ 10.10.110.81 │ 53306 │ 0 │ Slave, Running │ 0-81-27 │ ├─────────┼──────────────┼───────┼─────────────┼────────────────┼─────────┤ │ server3 │ 10.10.110.82 │ 53306 │ 0 │ Slave, Running │ 0-82-27 │ └─────────┴──────────────┴───────┴─────────────┴────────────────┴─────────┘ [root@localhost ~]# maxctrl -h 10.10.110.83:8080 list servers ┌─────────┬──────────────┬───────┬─────────────┬─────────────────┬─────────┐ │ Server │ Address │ Port │ Connections │ State │ GTID │ ├─────────┼──────────────┼───────┼─────────────┼─────────────────┼─────────┤ │ server1 │ 10.10.110.80 │ 53306 │ 0 │ Down │ 0-80-26 │ ├─────────┼──────────────┼───────┼─────────────┼─────────────────┼─────────┤ │ server2 │ 10.10.110.81 │ 53306 │ 0 │ Master, Running │ 0-81-27 │ ├─────────┼──────────────┼───────┼─────────────┼─────────────────┼─────────┤ │ server3 │ 10.10.110.82 │ 53306 │ 0 │ Slave, Running │ 0-82-27 │ └─────────┴──────────────┴───────┴─────────────┴─────────────────┴─────────┘","categories":[{"name":"MariaDB","slug":"MariaDB","permalink":"https://www.missf.top/categories/MariaDB/"},{"name":"Maxscale","slug":"MariaDB/Maxscale","permalink":"https://www.missf.top/categories/MariaDB/Maxscale/"}],"tags":[{"name":"MariaDB","slug":"MariaDB","permalink":"https://www.missf.top/tags/MariaDB/"},{"name":"数据库","slug":"数据库","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"读写分离","slug":"读写分离","permalink":"https://www.missf.top/tags/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/"}]},{"title":"Elastic 收集 Java 日志","slug":"Elastic 收集 Java 日志","date":"2020-09-08T10:20:14.000Z","updated":"2020-09-28T03:32:36.845Z","comments":true,"path":"post/5a1ae96.html","link":"","permalink":"https://www.missf.top/post/5a1ae96.html","excerpt":"","text":"安装 TomcatTomcat 属于 Java 应用，这里收集 Tomcat 日志作为示例 # 下载软件包 wget -P /server/tools/https://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.53/bin/apache-tomcat-8.5.53.tar.gz # 解压 tar xf apache-tomcat-8.5.53.tar.gz -C /usr/local/ &amp;&amp; mv /usr/local/apache-tomcat-8.5.53/ /usr/local/tomcat # 启动tomcat /usr/local/tomcat/bin/startup.sh 编写 Filebeat pipelinefilebeat 获取所有不以 “[“ 开头的行，并将它们合并到上一行以 “[“ 开头的行之后 filebeat.inputs: - type: log enabled: true paths: - /usr/local/tomcat/logs/catalina.out tags: [\"catalina\"] fields: server: tomcat type: tomcat-catalina fields_under_root: true multiline: pattern: '^\\[' negate: true match: after #output.console: output.redis: hosts: [\"10.10.110.194:56379\"] password: \"123456\" key: \"tomcat\" db: 0 datatype: list 模拟 Tomcat 报错日志往 Tomcat 的日志写入错误信息，模拟报错信息 cat > /usr/local/tomcat/logs/catalina.out &lt;&lt; EOF Sep 09, 2020 5:50:33 PM org.apache.catalina.startup.Catalina stopServer SEVERE: Catalina.stop: org.xml.sax.SAXParseException; systemId: file:/usr/local/tomcat/conf/server.xml; lineNumber: 22; columnNumber: 45; Attribute name \"dda\" associated with an element type \"Server\" must be followed by the ' = ' character. at java.xml/com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.parse(AbstractSAXParser.java:1243) at java.xml/com.sun.org.apache.xerces.internal.jaxp.SAXParserImpl$JAXPSAXParser.parse(SAXParserImpl.java:635) at org.apache.tomcat.util.digester.Digester.parse(Digester.java:1495) at org.apache.catalina.startup.Catalina.stopServer(Catalina.java:485) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.apache.catalina.startup.Bootstrap.stopServer(Bootstrap.java:389) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:479) EOF 编写 Logstash pipelineinput { redis { host => \"10.10.110.194\" port => 56379 password => \"123456\" db => \"0\" data_type => \"list\" key => \"tomcat\" } } output { if [type] == \"tomcat-catalina\" { if [tags][0] == \"catalina\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-tomcat-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Kibana 展示数据这里展示数据是不显示完全的，我们可以指定字段查看更详细的信息 指定 message 字段，查看被合并成一行的 Tomcat 报错日志","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic 收集 Nginx 日志","slug":"Elastic 收集 Nginx 日志","date":"2020-08-25T06:27:22.000Z","updated":"2020-09-28T03:33:53.780Z","comments":true,"path":"post/baa98a96.html","link":"","permalink":"https://www.missf.top/post/baa98a96.html","excerpt":"","text":"Nginx 配置 Json 格式日志修改 Nginx 配置文件，定义输出 json 格式的日志，便于 filebeat 和 logstash 收集 http { log_format main '{\"@timestamp\": \"$time_iso8601\", ' '\"clientRealIp\": \"$remote_addr\", ' '\"scheme\": \"$scheme\", ' '\"method\": \"$request_method\", ' '\"host\": \"$host\", ' '\"url\": \"$request_uri\", ' '\"size\": $body_bytes_sent, ' '\"referrer\": \"$http_referer\", ' '\"agent\": \"$http_user_agent\", ' '\"upstream_addr\": \"$upstream_addr\", ' '\"request_time\": $request_time, ' '\"request_length\": $request_length, ' '\"upstream_connect_time\": \"$upstream_connect_time\", ' '\"upstream_response_time\": \"$upstream_response_time\", ' '\"upstream_status\": \"$upstream_status\", ' '\"status\": \"$status\"}'; } Filebeat 配置文件编写 filebeat 配置文件，收集 Nginx 的 access.log 和 error.log，并且添加自定义字段和标签存储到 redis cat /etc/filebeat/filebeat-nginx.yml filebeat.inputs: - type: log enabled: true json.keys_under_root: true paths: - /usr/local/nginx/logs/access.log tags: [\"access\"] fields: server: nginx type: nginx-access fields_under_root: true - type: log enabled: true json.keys_under_root: true paths: - /usr/local/nginx/logs/error.log tags: [\"error\"] fields: server: nginx type: nginx-error fields_under_root: true processors: - drop_fields: fields: [\"input_type\", \"ecs.version\", \"host.name\", \"agent\", \"log.offset\"] #output.console: output.redis: hosts: [\"10.10.110.194:56379\"] password: \"123456\" key: \"nginx\" db: 0 datatype: list 控制台调试 Filebeat 输出的日志数据通过 drop_fields 去控制我们想要输出的字段，得到精简的日志数据 { \"@timestamp\": \"2020-09-07T18:08:49.000Z\", \"@metadata\": { \"beat\": \"filebeat\", \"type\": \"_doc\", \"version\": \"7.9.0\" }, \"server\": \"nginx\", \"ecs\": {}, \"host\": {}, \"log\": { \"file\": { \"path\": \"/usr/local/nginx/logs/access.log\" } }, \"json\": {}, \"input\": { \"type\": \"log\" }, \"type\": \"nginx-access\", \"message\": \"10.10.110.194 - - [08/Sep/2020:02:08:41 +0800] \\\"GET /848dd HTTP/1.1\\\" 404 153 \\\"-\\\" \\\"curl/7.29.0\\\"\", \"tags\": [\"access\"] } Logstash 读取 Redis 中的日志数据logstash 读取 redis 中的日志数据，并且在 Kibana展示 Nginx 日志 # logstash配置文件通过我们定义的fields字段和标签匹配数据,将不同的数据存储到不同的index input { redis { host => \"10.10.110.194\" port => 56379 password => \"123456\" db => \"0\" data_type => \"list\" key => \"nginx\" } } output { # 通过字段和标签判断日志数据,存储到不同的index if [type] == \"nginx-access\" { if [tags][0] == \"access\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-nginx-access%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } if [type] == \"nginx-error\" { if [tags][0] == \"error\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-nginx-error%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Kibana 展示 Nginx 日志我们可以在 kibana 上创建索引，查看 Nginx 日志，通过字段去统计和展示日志数据","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic 引入 Filebeat","slug":"Elastic 引入 Filebeat","date":"2020-08-20T03:58:57.000Z","updated":"2020-09-28T03:35:18.064Z","comments":true,"path":"post/9482a90c.html","link":"","permalink":"https://www.missf.top/post/9482a90c.html","excerpt":"","text":"引入 Filebeat 架构简介filebeat 代替 logstash 去收集日志数据，然后将收集到的日志数据存储到 redis 或者 kafka，再由 logstash 去消费数据。filebeat 是非常轻量级单用途的日志采集器，属于Beats 家族。早期的 elk 架构使用 logstash 收集、解析日志，但是 logstash 对内存、CPU、IO等资源消耗比较高(因为 logstash 是使用 java 语言编写的)，后来出现了使用golang 编写的 filebeat 日志收集器，可以不依赖任何环境安装即可使用，同时对资源的占用可以忽略不计，使用 filebeat 替代 logstash 去收集日志是非常好的方案 安装 Filebeat# 下载filebeat wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.9.0-x86_64.rpm # 安装 yum install -y filebeat-7.9.0-x86_64.rpm 编写 Filebeat 配置文件filebeat 配置文件负责收集日志，然后将数据存到 redis cat /etc/filebeat/filebeat.yml filebeat.inputs: - type: log enabled: true paths: - /var/log/messages tags: [\"messages\",\"syslog\"] #include_lines: ['sometext'] Filebeat仅导出与列表中的正则表达式匹配的行 #exclude_lines: ['^DBG'] Filebeat会删除列表中与正则表达式匹配的所有行 fields: # 可以指定字段向输出添加附加信息 type: system # fields_under_root: true # 如果为true,则自定义字段将作为顶级字段而不是作为fields字段的子字典 - type: log enabled: true paths: - /var/log/audit/audit.log tags: [\"audit\",\"syslog\"] fields: type: system # fields_under_root: true output.console: # 将收集到的日志数据输出到控制台,可以查看fields定义的字段 output.redis: # filebeat将收集到的日志存储到redis hosts: [\"10.10.110.194:56379\"] password: \"123456\" key: \"filebeat\" db: 0 timeout: 5 查看 Filebeat 输出的 Json 数据我们在调试日志格式时使用命令去启动 filebeat，使用 systemctl 的方式去调试会出现很多转义符，不便于查看 /usr/bin/filebeat -c /etc/filebeat/filebeat.yml # 这里需要将控制台输出的数据json格式化 { \"@timestamp\": \"2020-09-07T16:17:42.615Z\", \"@metadata\": { \"beat\": \"filebeat\", \"type\": \"_doc\", \"version\": \"7.9.0\" }, \"ecs\": { \"version\": \"1.5.0\" }, \"host\": { \"name\": \"localhost.localdomain\" }, \"agent\": { \"ephemeral_id\": \"660a2bfb-9a56-43a8-ae93-788060f5d243\", \"id\": \"6a8ff370-52b5-4f89-ad9c-b6feecf938a9\", \"name\": \"localhost.localdomain\", \"type\": \"filebeat\", \"version\": \"7.9.0\", \"hostname\": \"localhost.localdomain\" }, \"log\": { \"offset\": 997322, \"file\": { \"path\": \"/var/log/messages\" } }, \"message\": \"Sep 8 00:01:01 localhost systemd: Started Session 7 of user root.\", \"tags\": [\"messages\", \"syslog\"], \"fields\": { # 这里由于filebeat配置文件中没有开启fields_under_root: true这个选项,所以我们定义的字段会在fields里面 \"type\": \"system\" }, \"input\": { \"type\": \"log\" } } 定义 Filebeat 输出的 Json 数据我们除了可以自己自定义字段，还可以删除一些 filebeat 默认输出的字段，让日志数据更加易于查看 # 定义filebeat配置文件,过滤不需要的json数据 filebeat.inputs: - type: log enabled: true # json.keys_under_root: true 开始json解析,不是json格式的日志不要开启此选项 paths: - /var/log/messages tags: [\"messages\",\"syslog\"] fields: type: system fields_under_root: true - type: log enabled: true paths: - /var/log/audit/audit.log tags: [\"audit\",\"syslog\"] fields: type: system fields_under_root: true processors: - drop_fields: fields: [\"input_type\", \"ecs.version\", \"host.name\", \"agent\", \"log.offset\"] # 将这些字段丢弃 output.console: 查看自定义之后的 json 数据 { \"@timestamp\": \"2020-09-07T17:37:59.500Z\", \"@metadata\": { \"beat\": \"filebeat\", \"type\": \"_doc\", \"version\": \"7.9.0\" }, \"tags\": [\"messages\", \"syslog\"], \"input\": { \"type\": \"log\" }, \"type\": \"system\", # fields_under_root: true 将作为顶级字段 \"ecs\": {}, \"host\": {}, \"log\": { \"file\": { \"path\": \"/var/log/messages\" } }, \"message\": \"Sep 8 01:35:28 localhost systemd-logind: Removed session 4.\" } Logstash 消费 Redis 中的数据filebeat 将日志数据存储到 redis 之后，logstash 从 redis 读取日志数据就是非常简单的事情了 cat /etc/logstash/conf.d/sys-from-redis.conf input { redis { host => \"10.10.110.194\" port => 56379 password => \"123456\" db => \"0\" data_type => \"list\" batch_count => \"1\" key => \"filebeat\" } } filter { } output { if [type] == \"system\" { # 这里的匹配由filebeat输出的json数据格式来定义 if [tags][0] == \"messages\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-fromredis-messages-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } else if [tags][0] == \"audit\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-fromredis-audit-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Elasticsearch 查看数据索引的命名根据我们在 logstash 处理数据时的定义格式","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic 引入 Redis","slug":"Elastic 引入 Redis","date":"2020-08-17T10:48:56.000Z","updated":"2020-09-28T03:37:04.849Z","comments":true,"path":"post/23bc2fbc.html","link":"","permalink":"https://www.missf.top/post/23bc2fbc.html","excerpt":"","text":"引入 Redis 架构简介logstash 分为 shipper(负责收集日志数据)和 indexer(负责对日志做过滤存储到ES)两个角色。当日志量达到一个量级之后，我们就不能继续使用 logstash 去收集和处理数据，由于 ES 的 HTTP API 处理能力有限，在日志写入频繁的情况下可能会超时、丢失，所以用队列来做缓冲在两个 logstash 角色之间可以引入 redis 或者 kafka。使用消息队列的方式可减少 ES 压力，队列起到缓冲作用，也可以一定程度保护数据不丢失。同时我们还能将所有收集到的日志统一在 logstash indexer 进行处理 环境准备logstash 10.10.110.195 # logstash shipper生产数据,将获取到的数据存到redis logstash + redis 10.10.110.194 # logstash indexer消费redis中的日志数据 生产日志数据编写 logstash pipeline 配置文件，将收集到的日志数据存储到 redis input { file { path => [\"/var/log/messages\"] type => \"syslog\" tags => [\"messages\",\"log\"] start_position => \"beginning\" } file { path => [\"/var/log/audit/audit.log\"] type => \"syslog\" tags => [\"audit\",\"log\"] start_position => \"beginning\" } } filter { } output { redis { host => [\"10.10.110.194:56379\"] password => \"123456\" db => \"0\" data_type => \"list\" key => \"logstash\" } } 启动 logstash 进行收集日志存储到 redis /usr/share/logstash/bin/logstash -rf /etc/logstash/conf.d/syslog-toredis.conf Redis查看日志数据logstash 在收集到日志数据并且添加上标签和类型然后存储到 redis，我们可以返回列表的长度来得知日志数据是否被存储到 redis 消费日志数据编写 logstash pipeline 配置文件，将 redis 中的日志数据存储到 ES input { redis { host => \"10.10.110.194\" port => 56379 password => \"123456\" db => \"0\" data_type => \"list\" key => \"logstash\" } } filter { } output { if [type] == \"syslog\" { if [tags][0] == \"messages\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"syslog-fromredis-messages-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } else if [tags][0] == \"audit\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"syslog-fromredis-audit-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Redis 查看消费的数据日志数据被消费完之后就代表已经写入到 ES # redis中的key会全部存到ES中(日志数据被消费完) 127.0.0.1:56379> llen logstash (integer) 7041 127.0.0.1:56379> llen logstash (integer) 5791 127.0.0.1:56379> llen logstash (integer) 4541 127.0.0.1:56379> llen logstash (integer) 3041 127.0.0.1:56379> llen logstash (integer) 1666 127.0.0.1:56379> llen logstash (integer) 0 127.0.0.1:56379>","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Kibana 展示系统日志","slug":"Elastic Kibana 展示系统日志","date":"2020-08-16T10:39:44.000Z","updated":"2020-09-28T03:37:59.036Z","comments":true,"path":"post/c802a07c.html","link":"","permalink":"https://www.missf.top/post/c802a07c.html","excerpt":"","text":"编写 logstash pipeline 配置文件定义日志收集、过滤、存储的方式 input { file { path => [\"/var/log/messages\"] type => \"syslog\" tags => [\"messages\",\"log\"] start_position => \"beginning\" # 从文件开头读取 } file { path => [\"/var/log/audit/audit.log\"] type => \"syslog\" tags => [\"audit\",\"log\"] start_position => \"beginning\" } } filter { } output { if [type] == \"syslog\" { if [tags][0] == \"messages\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] # 存储带ES index => \"syslog-messages-%{+YYYY.MM.dd}\" # index的命名格式 } stdout { codec=> rubydebug } } else if [tags][0] == \"audit\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"syslog-audit-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Logstash 收集日志存储到 ES# 启动logstash,systemctl启动方式可以指定配置文件 /usr/share/logstash/bin/logstash -rf /etc/logstash/conf.d/syslog.conf # logstash常用参数 -n 指定logstash实例的名称,默认为当前主机名 -f 指定启动配置文件 -e 指定直接执行的配置文件内容,可以不指定-f参数了 -r 检测配置文件变化,自动重新加载 -t 检查配置的语法是否正确并退出 Elasticsearch 查看数据索引的命名格式按日期去分割 将 ES 的日志索引到 KibanaKibana 的配置文件指定 ES 的地址，使用正则匹配去创建索引 配置时间过滤器字段 Kibana 展示日志数据可以根据日志数据的字段去查看指定的信息","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Kibana","slug":"Elastic Kibana","date":"2020-08-14T07:56:54.000Z","updated":"2020-09-28T03:38:46.361Z","comments":true,"path":"post/e26112db.html","link":"","permalink":"https://www.missf.top/post/e26112db.html","excerpt":"","text":"Kibana 简述Kibana 是一个针对 Elasticsearch 的开源分析及可视化平台，用来搜索、查看交互存储在 Elasticsearch 索引中的数据。使用 Kibana，可以通过各种图表进行高级数据分析及展示。Kibana 让海量数据更容易理解，它操作简单，基于浏览器的用户界面可以快速创建仪表板(dashboard)实时显示 Elasticsearch 查询动态。设置 Kibana 非常简单，无需编码或者额外的基础架构，就可以完成 Kibana 安装并启动 Elasticsearch 索引监测 Kibana 安装配置# 下载Kibana wget https://artifacts.elastic.co/downloads/kibana/kibana-7.8.1-x86_64.rpm # 安装 shasum -a 512 kibana-7.8.1-x86_64.rpm rpm --install kibana-7.8.1-x86_64.rpm # 修改Kibana配置文件 grep -v \"^#\" /etc/kibana/kibana.yml server.port: 5601 server.host: \"127.0.0.1\" elasticsearch.hosts: [\"http://10.10.110.191:9200\"] i18n.locale: \"zh-CN\" # 启动Kibana systemctl start kibana.service 配置 Nginx 代理 Kibana配置 Nginx 反向代理实现鉴权 vim /usr/local/nginx/conf/nginx.conf server { listen 9090; server_name localhost; location / { auth_basic \"Restricted Access\"; auth_basic_user_file /usr/local/nginx/conf/passwd.db; # 账号密码文件 proxy_pass http://127.0.0.1:5601; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 配置验证登录账号密码 # 需要安装httpd-tools工具,文件里的密码是密文的 htpasswd -c /usr/local/nginx/conf/passwd.db admin # 连续输入两次密码 # 测试本机kibana能否连接,如果本机都不能连接,那么Nginx代理就没有意义 curl -L -u admin:12345678 http://127.0.0.1:5601 登录 Kibana登录 kibana 的地址 http://10.10.110.194:9090/ Nginx 账号密码 kibana web 页面","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Logstash","slug":"Elastic Logstash","date":"2020-08-11T07:04:57.000Z","updated":"2020-09-28T03:50:24.049Z","comments":true,"path":"post/fe947601.html","link":"","permalink":"https://www.missf.top/post/fe947601.html","excerpt":"","text":"Logstash 概述logstash 是 elasticsearch 的数据管道，负责对数据源进行处理。工作原理分别是输入、过滤、输出。其中 input(负责从数据源采集数据)和 output(将数据传输到目的地)是必要的，filter(将数据修改为你指定的格式或内容)是非必要的。logstash 是插件式管理模式，在输入、过滤、输出以及编码过程中都可以使用插件进行定制，Logstash 社区有超过 200 种可用插件 Logstash 安装这里使用 yum 是因为二进制安装的 jdk，在 Logstash 启动时会报 could not find java # 安装jdk yum install -y java-11-openjdk java-11-openjdk-devel java-11-openjdk-headless # 下载logstash wget https://artifacts.elastic.co/downloads/logstash/logstash-7.8.1.rpm # 安装logstash yum install -y logstash-7.8.1.rpm # 修改启动分配内存 vim /etc/logstash/jvm.options -Xms512m -Xmx512m # 第一个logstash示例 cd logstash Installation directory bin/logstash -e 'input { stdin { } } output { stdout {} }' 执行结果如下 Logstash 配置详解Logstash 的配置有两个必须元素(input和output)和一个可选元素(filter) input { # 输入 stdin { ... # 标准输入 } } filter { # 过滤 ... # 对数据进行分割、截取等处理 } output { # 输出 stdout { ... # 标准输出 } } 输入 采集各种样式、大小和来源的数据，数据往往以各种各样的形式，或分散或集中地存在于不同的系统中 Logstash支持各种输入选择 ，可以在同一时间从众多常用来源捕捉事件 能够以连续的流式传输方式，轻松地从您的日志、指标、Web 应用、数据存储以及各种AWS服务采集数据 过滤 实时解析和转换数据，Logstash过滤器能够解析各个事件 识别已命名的字段以构建结构，并将它们转换成通用格式，以便更轻松更快速地分析和实现商业价值 输出 Logstash提供众多输出选择，你可以将数据发送到指定的地方，并且能够灵活地解锁众多下游用例 输入插件 Stdin 示例从标准输入读取数据输出到标准输出 input { stdin { } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 mwj { \"host\" => \"localhost.localdomain\", \"@timestamp\" => 2020-08-12T18:36:32.683Z, \"message\" => \"mwj\", \"@version\" => \"1\" } test data { \"host\" => \"localhost.localdomain\", \"@timestamp\" => 2020-08-12T18:36:47.691Z, \"message\" => \"test data\", \"@version\" => \"1\" } 输入插件 File 示例从文件中读取数据，输出到标准输出 input { file { # 调用file这个插件,logstash社区有非常多的插件可以供我们使用 path =>\"/var/log/messages\" # 数据源来自这个文件的内容 tags =>\"messages\" # 打标签 type =>\"syslog\" } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 { \"type\" => \"syslog\", \"@timestamp\" => 2020-08-13T11:41:45.031Z, \"@version\" => \"1\", \"path\" => \"/var/log/messages\", \"host\" => \"localhost.localdomain\", \"tags\" => [ [0] \"messages\" ], \"message\" => \"Aug 13 19:41:44 localhost yum[86466]: Installed: 1:nginx-mod-http-image-filter-1.16.1-1.el7.x86_64\" } { \"type\" => \"syslog\", \"@timestamp\" => 2020-08-13T11:41:45.032Z, \"@version\" => \"1\", \"path\" => \"/var/log/messages\", \"host\" => \"localhost.localdomain\", \"tags\" => [ [0] \"messages\" ], \"message\" => \"Aug 13 19:41:44 localhost yum[86466]: Installed: 1:nginx-all-modules-1.16.1-1.el7.noarch\" } 输入插件 TCP 示例logstash 从本机端口读取数据，其他机器通过 nc 工具发送数据到 logstash 指定的端口 input { tcp { port =>12345 # 监听12345端口 type =>\"nc\" # 通过nc工具使用tcp/udp连接去发送网络数据给logstash } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 { \"@version\" => \"1\", \"type\" => \"nc\", \"@timestamp\" => 2020-08-13T06:28:13.448Z, \"host\" => \"10.10.110.191\", \"port\" => 35228, \"message\" => \"we\" # logstash接收到其他机器nc工具发送过来的信息(nc 10.10.110.194 12345) } { \"@version\" => \"1\", \"type\" => \"nc\", \"@timestamp\" => 2020-08-13T06:28:40.148Z, \"host\" => \"10.10.110.191\", \"port\" => 35228, \"message\" => \"test\" } 编解码插件 Json 示例只有输入 json 格式的数据才会被成功编解码，不是 json 格式的数据 logstash 不处理 input { stdin { codec => json { charset => [\"UTF-8\"] } } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 {\"name\":\"孙七\",\"age\": 24,\"mail\": \"555@qq.com\",\"hobby\":\"听音乐、看电影\"} { \"hobby\" => \"听音乐、看电影\", \"name\" => \"孙七\", \"mail\" => \"555@qq.com\", \"age\" => 24, \"@version\" => \"1\", \"host\" => \"localhost.localdomain\", \"@timestamp\" => 2020-09-01T14:27:24.066Z } 编解码插件 Multline 示例multline 会将不是以字母开头的行合并到上一行(next是合并到下一行)，下面模拟 java 日志报错 input { stdin { codec => multiline { pattern => \"^\\s\" what => \"previous\" } } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 [INFO] 2020-08-13 15:56:53,195 --AsyncResolver-bootstrap-executor-0-- # 模拟java报错信息 at com.curre at org.sprin at org.sprin { \"@timestamp\" => 2020-09-01T14:36:50.642Z, \"tags\" => [ [0] \"multiline\" ], \"@version\" => \"1\", \"message\" => \"[INFO] 2020-08-13 15:56:53,195 --AsyncResolver-bootstrap-executor-0--\\n at com.curre\\n at org.sprin\\n at org.sprin\", \"host\" => \"localhost.localdomain\" } 过滤插件 Json 示例将 json 数据做过滤放在 content 字段里面 input { stdin { } } filter { json { source => \"message\" target => \"content\" } } output { stdout { codec => rubydebug } } 执行结果如下 {\"request\":\"get\", \"status\":\"404\", \"bytes\":\"563\"} # 数据源 { \"host\" => \"localhost.localdomain\", \"@timestamp\" => 2020-08-13T09:28:26.702Z, \"content\" => { \"request\" => \"get\", \"bytes\" => \"563\", \"status\" => \"404\" }, \"message\" => \"{\\\"request\\\":\\\"get\\\", \\\"status\\\":\\\"404\\\", \\\"bytes\\\":\\\"563\\\"}\", \"@version\" => \"1\" } 过滤插件 Kv 示例以 &amp; 和 ? 作为分隔符，得到 key=value 形式的数据 input { stdin { } } filter { kv { field_split => \"&amp;?\" # 以&amp;和?作为分隔符,得到key=value的形式 field_split_pattern => \":+\" # 以一个或者多个:作为分隔符 } } output { stdout { codec => rubydebug } } 执行结果如下 pin=12345~0&amp;d=123&amp;e=foo@bar.com&amp;oq=bo?oi=bo&amp;ss=12345: # 数据源 { \"d\" => \"123\", \"pin\" => \"12345~0\", \"ss\" => \"12345:\", \"oq\" => \"bo\", \"oi\" => \"bo\", \"e\" => \"foo@bar.com\", \"@timestamp\" => 2020-08-13T09:31:41.881Z, \"host\" => \"localhost.localdomain\", \"message\" => \"pin=12345~0&amp;d=123&amp;e=foo@bar.com&amp;oq=bo?oi=bo&amp;ss=12345:\", \"@version\" => \"1\" } 输出插件 ES 示例logstash 将日志输出到 ES 节点，存储到 missf 这个 index 并且以时间去命名 output { elasticsearch { hosts => \"localhost:9200\" index => \"missf-%{+YYYY.MM.dd}\" } }","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Elasticsearch","slug":"Elastic Elasticsearch","date":"2020-08-05T10:26:09.000Z","updated":"2020-09-28T03:49:11.115Z","comments":true,"path":"post/1abc58c4.html","link":"","permalink":"https://www.missf.top/post/1abc58c4.html","excerpt":"","text":"Elasticsearch 简介Elasticsearch 是一个基于 Lucene 的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于 RESTful web 接口。Elasticsearch 是用 Java 语言开发，并作为 Apache 许可条款下的开放源代码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索、稳定、可靠、快速、使用方便 我们建立一个网站或应用程序，并要添加搜索功能，但是想要完成搜索工作的创建是非常困难的。我们希望搜索解决方案要运行速度快，我们希望能有一个零配置和一个完全免费的搜索模式，我们希望能够简单地使用 JSON 通过 HTTP 来索引数据，我们希望搜索服务器始终可用，我们希望能够从一台开始并扩展到数百台，我们要实时搜索，我们要简单的多用户，我们希望建立一个云的解决方案。因此我们利用 Elasticsearch 来解决所有这些问题及可能出现的更多其它问题 Elasticsearch 集群部署Elasticsearch 的发展是非常快速的，所以在 ES5.0 之前，ELK 的各个版本都不统一，出现了版本号混乱的状态，所以从 5.0 开始，所有 Elastic Stack 中的项目全部统一版本号。目前最新版本是 7.8.1 # 环境准备 ES1 10.10.110.191 ES2 10.10.110.192 ES3 10.10.110.193 # 下载elasticsearch和校验文件 wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.1-x86_64.rpm wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.1-x86_64.rpm.sha512 # 安装elasticsearch shasum -a 512 -c elasticsearch-7.8.1-x86_64.rpm.sha512 yum install -y elasticsearch-7.8.1-x86_64.rpm # 修改jvm启动参数,根据自己机器决定 vim /etc/elasticsearch/jvm.options -Xms512m # 确保Xmx和Xms的大小是相同的，其目的是为了能够在java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源 -Xmx512m # 修改进程在VMAs(虚拟内存区域)创建内存映射最大数量 echo \"vm.max_map_count=655360\" >> /etc/sysctl.conf &amp;&amp; sysctl -p # 修改elasticsearch配置文件 grep -v '^#' /etc/elasticsearch/elasticsearch.yml cluster.name: elk-cluster # 集群名称,所有节点一样 node.name: node-1 # 不同节点,分别用node-1/node-2/node-3... path.data: /var/lib/elasticsearch # 数据目录,如果加入集群失败可以清空数据目录再重启服务 path.logs: /var/log/elasticsearch # 日志目录 network.host: 10.10.110.191 # 不同节点,分别用10.10.110...... http.port: 9200 # 监听端口 discovery.seed_hosts: [\"10.10.110.191\", \"10.10.110.192\", \"10.10.110.193\"] # 集群发现,可以写成10.10.110.191:9200 cluster.initial_master_nodes: [\"node-1\", \"node-2\", \"node-3\"] # 指定可以成为master的节点,此参数只有在初始化集群时生效 # 启动elasticsearch服务 systemctl start elasticsearch.service Elasticsearch 集群常用查询查看集群状态 curl -X GET http://10.10.110.191:9200/_cluster/health?pretty # 响应 { \"cluster_name\" : \"elk-cluster\", \"status\" : \"green\", # 集群状态红绿灯,绿:健康,黄:亚健康,红:病态 \"timed_out\" : false, \"number_of_nodes\" : 3, \"number_of_data_nodes\" : 3, \"active_primary_shards\" : 0, \"active_shards\" : 0, \"relocating_shards\" : 0, \"initializing_shards\" : 0, \"unassigned_shards\" : 0, \"delayed_unassigned_shards\" : 0, \"number_of_pending_tasks\" : 0, \"number_of_in_flight_fetch\" : 0, \"task_max_waiting_in_queue_millis\" : 0, \"active_shards_percent_as_number\" : 100.0 } 查看节点状态 curl -X GET 'http://10.10.110.191:9200/_cat/nodes?v' ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name 10.10.110.191 62 93 0 0.00 0.01 0.05 dilmrt - node-1 10.10.110.193 62 74 0 0.00 0.01 0.05 dilmrt * node-3 # *代表当前节点是master 10.10.110.192 70 75 0 0.00 0.01 0.05 dilmrt - node-2 查询节点所有索引 curl -X GET 'http://10.10.110.191:9200/_cat/indices?v' health status index uuid pri rep docs.count docs.deleted store.size pri.store.size green open data njHuT0XvSOa2NHPJM3Aj-g 1 1 3 0 19.5kb 9.7kb 查询一个索引所有数据 curl -X GET 'http://10.10.110.191:9200/data/_search/?pretty' Elasticsearch-head 安装由于 ES 官方并没有为 ES 提供界面管理工具，仅仅是提供了后台的服务。elasticsearch-head 是一个为 ES 开发的一个页面客户端工具，其源码托管于 GitHub，地址为：https://github.com/mobz/elasticsearch-head elasticsearch-head 提供了四种安装方式： 源码安装通过npm run start启动(不推荐) 通过docker安装(推荐) 通过chrome插件安装(推荐) 通过ES的plugin方式安装(不推荐) 通过 Docker 安装 # 拉取镜像 docker pull mobz/elasticsearch-head:5 # 启动容器 docker run -itd --name \"elasticsearch-head\" -p 9100:9100 -v elasticsearch_head:/usr/src/app --restart always mobz/elasticsearch-head:5 # 由于前后端分离开发,所以会存在跨域问题,需要在服务端做CORS的配置 vim /etc/elasticsearch/elasticsearch.yml http.cors.enabled: true http.cors.allow-origin: \"*\" # Web访问 http://10.10.110.191:9100/ Elasticsearch Head 数据浏览不显示数据，使用浏览器按 F12 查看发现 406 Not Acceptable 错误，出现这个错误是因为后台返回的数据是 json 格式前台无法解析，解决方法如下： # 找到docker数据卷在宿主机上的目录 docker volume inspect elasticsearch_head # 修改数据卷目录下_site/vendor.js文件 contentType: \"application/x-www-form-urlencoded\" 修改为 contentType: \"application/json;charset=UTF-8\" var inspectData = s.contentType === \"application/x-www-form-urlencoded\" &amp;&amp; 修改为 var inspectData = s.contentType === \"application/json;charset=UTF-8\" &amp;&amp; Elasticsearch 基本概念索引(index)是 Elasticsearch 存放数据的地方，可以理解为关系型数据库的数据库。我们的数据被存储和索引在分片(shards)中，索引只是一个把一个或多个分片分组在一起的逻辑空间。索引的结构是为快速有效的全文索引准备的，索引名称必须是小写，并且不能用下划线开头 类型(type)用于区分同一个索引下不同的数据类型，相当于关系型数据库中的表。在 Elasticsearch 中，我们使用相同类型的文档表示相同的 “事物”，因为他们的数据结构也是相同的。每个类型都有自己的映射(mapping)或者结构定义，就像传统数据库表中的列一样。所有类型下的文档被存储在同一个索引下，但是类型的映射会告诉 Elasticsearch 不同的文档如何被索引(ES6.0之后一个索引只能存在一种类型) 文档(document)是 ElasticSearch 中存储的实体数据，一个文档相当于数据库表中的一行记录。在 Elasticsearch 中，文档这个术语有着特殊含义。它特指最顶层结构或者根对象(root object)序列化成的 JSON 数据(以唯一ID标识并存储于Elasticsearch中) 关系型数据库与 Elasticsearch 的概念类比如下 Relational DB Databases Tables Rows Columns Elasticsearch Indices Types Documents Fields RESTful API在 Elasticsearch 中，提供了功能丰富的 RESTful API 的操作，包括基本的 CRUD、创建索引、删除索引等操作。RESTful 是统一规范的 http 接口，任何语言都可以使用。我们可以直接使用 web 客户端(postman)来测试，甚至还可以使用 Linux 上的 curl 工具测试，不需要自己写程序来调用 Elasticsearch 服务 # Elasticsearch RESTful操作数据的风格 curl -X &lt;verb> '&lt;protocol>://&lt;host>:&lt;port>/&lt;path>?&lt;query_string> -d &lt;body>' verb：HTTP 方法，如 GET、POST、PUT、HEAD、DELETE host：ES 集群中的任意节点主机名 port：ES HTTP 服务端口默认 9200 path：索引路径 query_string：可选的查询请求参数，例如 ?pretty 参数将格式化输出 JSON 数据 -d：一个 GET 的 JSON 格式请求主体 body：自己写的 JSON 格式的请求主体 创建索引在 Lucene 中创建索引是需要定义字段名称以及字段的类型，在 Elasticsearch 中提供了非结构化的索引，就是不需要创建索引结构，即可写入数据到索引中，实际上在 Elasticsearch 底层会进行结构化操作，此操作对用户是透明的 # 创建一个data的空索引 curl -X PUT '10.10.110.191:9200/data' # 删除索引 curl -X DELETE '10.10.110.191:9200/data' 插入数据URL 规则：POST /索引/类型/id # 往data这个索引下的user类型中插入一条ID为1的数据,?pretty是以json格式返回数据 curl -X POST '10.10.110.191:9200/data/user/1?pretty' -H \"Content-Type:application/json\" -d ' { \"name\": \"mowenjie\", \"job\": \"DevOps\", \"base\": \"sz\" }' # 响应 { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"1\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : { \"total\" : 2, \"successful\" : 1, \"failed\" : 0 }, \"_seq_no\" : 0, \"_primary_term\" : 1 } # 不指定ID插入数据会自动生成ID curl -X POST '10.10.110.191:9200/data/user/?pretty' -H \"Content-Type:application/json\" -d ' { \"name\": \"missf\", \"job\": \"linux\", \"base\": \"sz\" }' # 响应 { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"-J1PMXQBkHjO2vDovLJx\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : { \"total\" : 2, \"successful\" : 2, \"failed\" : 0 }, \"_seq_no\" : 1, \"_primary_term\" : 1 } 更新数据在 Elasticsearch 中可以通过覆盖的方式对数据进行更新 # 对ID为1的这条数据进行更新 curl -X PUT '10.10.110.191:9200/data/user/1?pretty' -H \"Content-Type:application/json\" -d ' { \"name\": \"fan\", \"job\": \"java\", \"base\": \"bj\" }' # 查询更新结果 curl -X GET '10.10.110.191:9200/data/user/1?pretty' { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"1\", \"_version\" : 2, # 更新之后的数据版本进行了+1 \"_seq_no\" : 2, \"_primary_term\" : 1, \"found\" : true, \"_source\" : { \"name\" : \"fan\", \"job\" : \"java\", \"base\" : \"bj\" } } # 上面是更新整条数据,下面是局部更新一条数据的某些字段,需要使用_update标识 curl -X POST '10.10.110.191:9200/data/user/1/_update?pretty' -H \"Content-Type:application/json\" -d ' { \"doc\":{ \"name\": \"aaa\" } }' 删除数据在 Elasticsearch 中，删除文档数据只需要发起 DELETE 请求即可 # 删除ID为1的这条数据 curl -X DELETE 'http://10.10.110.191:9200/data/user/1?pretty' # 响应,看到返回\"result\" : \"deleted\"就表示删除成功,如果删除一条不存在的数据会返回404 { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"1\", \"_version\" : 2, \"result\" : \"deleted\", \"_shards\" : { \"total\" : 2, \"successful\" : 2, \"failed\" : 0 }, \"_seq_no\" : 1, \"_primary_term\" : 1 } 删除一个文档也不会立即从磁盘上移除，它只是被标记成已删除。Elasticsearch 将会在你之后添加更多索引的时候才在后台进行删除内容的清理 搜索数据根据 id 搜索数据 curl -X GET '10.10.110.191:9200/data/user/003?pretty' 搜索全部数据 curl -X GET '10.10.110.191:9200/data/user/_search?pretty' # 响应默认只返回10条数据 关键字搜素数据 # 查询base等于sz的用户数据 curl -X GET '10.10.110.191:9200/data/user/_search?q=base:sz' DSL 搜索Elasticsearch 提供基于 JSON 的完整查询语言 DSL(Query DSL) 来定义查询，它允许你构建更加复杂、强大的查询 # 查询base等于sz的用户 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { # 请求体 \"query\" : { \"match\" : { \"base\" : \"sz\" } } } ' # 查询age大于16且job等于Linux的用户 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"bool\": { \"filter\": { \"range\": { \"age\": { \"gt\": 16 } } }, \"must\": { \"match\": { \"job\": \"Linux\" } } } } } ' # 全文搜索 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"match\": { \"name\": \"miss lisi\" } } } ' 高亮显示查询得到需要高亮的数据，再使用 highlight 将需要高亮的字段写在 fields 里面 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"match\": { \"name\": \"miss lisi\" } }, \"highlight\": { \"fields\": { \"name\": {} } } } ' 聚合在 Elasticsearch 中支持聚合操作，类似 SQL 中的 group by 操作 # 根据字段值分组聚合 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"aggs\": { \"age_terms\": { \"terms\": { \"field\": \"age\" } } } } ' # 响应,age字段值为16的有1条数据,age字段值为25的有2条数据 \"aggregations\" : { \"age_terms\" : { \"doc_count_error_upper_bound\" : 0, \"sum_other_doc_count\" : 0, \"buckets\" : [ { \"key\" : 16, \"doc_count\" : 1 }, { \"key\" : 25, \"doc_count\" : 2 }, { \"key\" : 36, \"doc_count\" : 1 } ] } } 文档一个文档不只有数据，它还包含了元数据(metadata)——关于文档的信息。三个必须的元数据节点是 节点 说明 _index 文档存储的地方 _type 文档代表的对象的类 _id 文档的唯一标识 索引(index)类似于关系型数据库里的 “数据库” ——它是我们存储和索引关联数据的地方 _type(类型)，在关系型数据库中，我们经常将相同类的对象存储在一个表里，因为它们有着相同的结构。同理，在 Elasticsearch 中我们使用相同类型(type)的文档表示相同的 “事物”，因为他们的数据结构也是相同的 id 仅仅是一个字符串，它与 _index 和 _type 组合时，就可以在 Elasticsearch 中唯一标识一个文档。当创建一个文档时你可以自定义 _id ，也可以让 Elasticsearch 帮你自动生成 响应查询指定响应字段 # 只响应_source下的name,job字段 curl -X GET '10.10.110.191:9200/data/user/001/?_source=name,job' 不返回元数据，仅仅返回原始数据 curl -X GET '10.10.110.191:9200/data/user/001/_source' 判断文档存在如果我们只需要判断文档是否存在，而不查询文档内容 # 如果文档存在,Elasticsearch将返回HTTP/1.1 200 OK,如果不存在就返回HTTP/1.1 404 Not Found curl -i -X HEAD 'http://10.10.110.191:9200/data/user/001' 当然，这只表示你在查询的那一刻文档不存在，但并不表示几毫秒后依旧不存在，另一个进程在这期间可能创建新文档 批量操作有些情况下可以通过批量操作以减少网络请求，如：批量查询、批量插入数据 # 批量查询 curl -X POST '10.10.110.191:9200/data/user/_mget?pretty' -H \"Content-Type:application/json\" -d ' { \"ids\": [\"001\", \"002\"] }' # 响应 { \"docs\" : [ { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"001\", \"_version\" : 1, \"_seq_no\" : 0, \"_primary_term\" : 1, \"found\" : true, \"_source\" : { \"name\" : \"lisi\", \"job\" : \"Python\", \"base\" : \"sh\", \"age\" : 16 } }, { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"002\", \"_version\" : 1, \"_seq_no\" : 1, \"_primary_term\" : 1, \"found\" : true, \"_source\" : { \"name\" : \"mowenjie\", \"job\" : \"Linux\", \"base\" : \"sz\", \"age\" : 36 } } ] } 分页和 SQL 使用 LIMIT 关键字返回只有一页的结果一样，Elasticsearch 接受 from 和 size 参数 size: 结果数,默认10 from: 从第n条数据之后开始,默认0 查询一个区间的数据 # 导入官方测试数据 curl -H \"Content-Type: application/x-ndjson\" -XPOST \"10.10.110.191:9200/bank/account/_bulk?pretty\" --data-binary @accounts.json # 将数据的account_number字段进行排序之后再取数据 curl -X GET \"http://10.10.110.191:9200/bank/account/_search?pretty\" -H \"Content-Type:application/json\" -d ' { \"query\": {\"match_all\": {} }, \"sort\": [{\"account_number\": \"asc\"}], \"from\": 10, # 从第10条数据之后开始 \"size\": 30 # 一共返回30条数据,就是account_number为10-39的数据 }' # 取1000到2000这个区间的随机数据 curl -X GET \"http://10.10.110.191:9200/bank/account/_search?pretty\" -H \"Content-Type:application/json\" -d' { \"query\": { \"bool\": { \"must\": { \"match_all\": {} }, \"filter\": { \"range\": { \"balance\": { \"gte\": 1000, \"lte\": 2000 } } } } } }' 映射前面我们创建的索引以及插入数据，都是由 Elasticsearch 进行自动判断类型，有些时候我们是需要进行明确字段类型的，否则自动判断的类型和实际需求是不相符的。每个字段都有一个数据类型，可以是一个简单的类型：text、keyword、date、long、double、boolean、ip，或者一个支持 JSON 层次结构的类型：例如 object、nested，或者是一种特殊的类型：geo_point、geo_shape、completion 创建明确类型的索引 curl -X PUT '10.10.110.191:9200/itcast' -H \"Content-Type:application/json\" -d ' { \"settings\": { \"index\": { \"number_of_shards\": \"2\", \"number_of_replicas\": \"0\" } }, \"mappings\": { \"properties\": { \"name\": { \"type\": \"text\" }, \"age\": { \"type\": \"integer\" }, \"mail\": { \"type\": \"keyword\" }, \"hobby\": { \"type\": \"text\" } } } }' 查看索引映射 curl -X GET '10.10.110.191:9200/itcast/_mapping' # 响应 { \"itcast\" : { \"mappings\" : { \"properties\" : { \"age\" : { \"type\" : \"integer\" }, \"hobby\" : { \"type\" : \"text\" }, \"mail\" : { \"type\" : \"keyword\" }, \"name\" : { \"type\" : \"text\" } } } } } 批量插入数据 # 如果插入的数据类型与我们字段定义的类型不同,那么就无法插入 curl -X POST '10.10.110.191:9200/itcast/_bulk' -H \"Content-Type:application/json\" --data-binary @itcast.json {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"1\"}} {\"name\":\"张三\",\"age\": 20,\"mail\": \"111@qq.com\",\"hobby\":\"羽毛球、乒乓球、足球\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"2\"}} {\"name\":\"李四\",\"age\": 21,\"mail\": \"222@qq.com\",\"hobby\":\"羽毛球、乒乓球、足球、篮球\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"3\"}} {\"name\":\"王五\",\"age\": 22,\"mail\": \"333@qq.com\",\"hobby\":\"羽毛球、篮球、游泳、听音乐\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"4\"}} {\"name\":\"赵六\",\"age\": 23,\"mail\": \"444@qq.com\",\"hobby\":\"跑步、游泳\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"5\"}} {\"name\":\"孙七\",\"age\": 24,\"mail\": \"555@qq.com\",\"hobby\":\"听音乐、看电影\"} 查询插入的数据 curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' 结构化查询term 主要用于精确匹配某些值，比如数字、日期、布尔值或 not_analyzed 的字符串(未经分析的文本数据类型) curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\" : { \"term\" : { \"age\" : 20 } } }' range 过滤允许我们按照指定范围查询一批数据 # 查询age大于等于20小于等于22范围的数据(gt:大于,gte:大于等于,lt:小于,lte:小于等于) curl -X POST '10.10.110.191:9200/bank/account/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\" : { \"range\": { \"age\": { \"gte\": 20, \"lte\": 22 } } } }' exists 查询可以用于查找文档中是否包含指定字段或没有某个字段，类似于 SQL 语句中的 IS_NULL 条件 # 查询原始数据中含有address字段的文档 curl -X POST '10.10.110.191:9200/bank/account/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\" : { \"exists\": { \"field\": \"address\" } } }' match 是一个模糊查询，需要指定字段名，但是会进行分词(中英文分词不一样) # 查询hobby字段是乒乓球的记录,在查询之前会进行分词(只要记录包含[乒/乓/球]都会被匹配成功) curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"match\": { \"hobby\": \"乒乓球\" } } }' bool 查询可以用来合并多个条件查询结果的布尔逻辑，它包含以下操作符： must: 多个查询条件的完全匹配，相当于and must_not: 多个查询条件的相反匹配，相当于not should: 至少有一个查询条件匹配，相当于or filter: 必须匹配，但它不会对匹配的数据进行评分 # 只要包含\"乒乓 游泳\"的数据都会被匹配 curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"bool\": { \"must\": [ { \"match\": { \"hobby\": \"乒乓 游泳\" } } ] } } }' # hobby包含乒乓但是age不等于21的数据 curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"bool\": { \"must\": [ { \"match\": { \"hobby\": \"乒乓\" } } ], \"must_not\": [ { \"match\": { \"age\": \"21\" } } ] } } }' 中文分词中文分词的难点在于在汉语中没有明显的词汇分界点，如在英语中空格可以作为分隔符，如果分隔不正确就会造成歧义。常用中文分词器有 IK、jieba、THULAC 等，推荐使用 IK 分词器 IK Analyzer是一个开源的，基于java语言开发的轻量级的中文分词工具包。从2006年12月推出1.0版开始，IKAnalyzer已经推出了3个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。新版本的IK Analyzer 3.0则发展为面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。采用了特有的”正向迭代最细粒度切分算法”，具有80万字/秒的高速处理能力 采用了多子处理器分析模式，支持：英文字母（IP地址、Email、URL）、数字（日期，常用中文数量词，罗马数字，科学计数法），中文词汇（姓名、地名处理）等分词处理。 优化的词典存储，更小的内存占用 安装 ik 中文分词器 # 下载对应es版本的ik分词器 https://github.com/medcl/elasticsearch-analysis-ik # 创建目录 cd your-es-root/plugins/ &amp;&amp; mkdir ik # 解压 unzip plugin to folder your-es-root/plugins/ik # 重启es(集群环境每一台都要配置) 分词测试 curl -X POST '10.10.110.191:9200/_analyze?pretty' -H \"Content-Type:application/json\" -d ' { \"analyzer\": \"ik_max_word\", \"text\": \"我是中国人\" }' 结果 { \"tokens\" : [ { \"token\" : \"我\", \"start_offset\" : 0, \"end_offset\" : 1, \"type\" : \"CN_CHAR\", \"position\" : 0 }, { \"token\" : \"是\", \"start_offset\" : 1, \"end_offset\" : 2, \"type\" : \"CN_CHAR\", \"position\" : 1 }, { \"token\" : \"中国人\", \"start_offset\" : 2, \"end_offset\" : 5, \"type\" : \"CN_WORD\", \"position\" : 2 }, { \"token\" : \"中国\", \"start_offset\" : 2, \"end_offset\" : 4, \"type\" : \"CN_WORD\", \"position\" : 3 }, { \"token\" : \"国人\", \"start_offset\" : 3, \"end_offset\" : 5, \"type\" : \"CN_WORD\", \"position\" : 4 } ] }","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Stack","slug":"Elastic Stack","date":"2020-08-05T06:19:27.000Z","updated":"2020-09-28T03:50:06.982Z","comments":true,"path":"post/cb83e724.html","link":"","permalink":"https://www.missf.top/post/cb83e724.html","excerpt":"","text":"Elastic Stack 简介ELK 日志收集分析平台相信所有的运维工程师都听说过，实际上 ELK 不是一门技术，而是三个软件的简称。它们分别是由 Elasticsearch、Logstash、Kibana 组成，在ELK发展的过程中，又有新成员 Beats 的加入，所以就形成了 Elastic Stack Elastic Stack 的组成 ElasticsearchElasticsearch 基于 java 语言开发，是个开源分布式搜索引擎，它的特点有:分布式、零配置、自动发现、索引自动分片、索引副本机制、RESTful 风格接口、多数据源、自动搜索负载等 LogstashLogstash 基于 java 语言开发，是一个开源的用于收集，分析和存储日志的工具 KibanaKibana 基于 nodejs，也是一个开源和免费的工具，Kibana 可以为 Logstash 和 ElasticSearch 提供的日志分析的友好 Web 界面，可以汇总、分析和搜索重要数据日志 BeatsBeats 是 elastic 公司开源的一款采集系统监控数据的代理 agent，是在被监控服务器上以客户端形式运行的数据收集器的统称，可以直接把数据发送给 Elasticsearch 或者通过 Logstash 发送给 Elasticsearch，然后进行后续的数据分析活动 Beats由如下组成： Packetbeat：一个网络数据包分析器，用于监控、收集网络流量信息，Packetbeat 嗅探服务器之间的流量，解析应用层协议，并关联到消息的处理，其支持ICMP(v4 and v6)、DNS、HTTP、Mysql、PostgreSQL、Redis、MongoDB、Memcache 等协议 Filebeat：用于监控、收集服务器日志文件，其已取代 logstash forwarder Metricbeat：可定期获取外部系统的监控指标信息，其可以监控、收集 Apache、HAProxy、MongoDB、MySQL、Nginx、PostgreSQL、Redis、System、Zookeeper 等服务 Winlogbeat：用于监控、收集 Windows 系统的日志信息","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Prometheus pushgateway工具(8)","slug":"Prometheus pushgateway 工具","date":"2020-08-04T10:05:33.000Z","updated":"2020-09-28T03:55:04.931Z","comments":true,"path":"post/5cf39589.html","link":"","permalink":"https://www.missf.top/post/5cf39589.html","excerpt":"","text":"PushGateway 部署prometheus 基于 http 的 pull 方式去采集时间序列数据，但是由于业务需求，prometheus 和 exporter 可能不在一个子网或者防火墙原因，导致 prometheus 无法直接拉取各个 target 数据，或者需要将不同的数据进行汇总，这时候就可以使用 prometheus 的自带组件 pushgateway 进行数据的汇总，将默认的 pull 方式改为 push 方式进行数据的采集 # 下载pushgateway wget https://github.com/prometheus/pushgateway/releases/download/v1.2.0/pushgateway-1.2.0.linux-amd64.tar.gz # 解压 tar xf pushgateway-1.2.0.linux-amd64.tar.gz &amp;&amp; mv pushgateway-1.2.0.linux-amd64 /usr/local/pushgateway # 创建pushgateway启动文件 vim /usr/lib/systemd/system/pushgateway.service [Unit] Documentation=pushgateway exporter After=local-fs.target network-online.target network.target Wants=local-fs.target network-online.target network.target [Service] Restart=on-failure ExecStart=/usr/local/pushgateway/pushgateway # 需要修改监听端口可以自行添加参数 [Install] WantedBy=multi-user.target # 启动pushgateway systemctl start pushgateway.service Prometheus 添加 PushGateway在我们的 prometheus 配置文件添加 pushgateway 的地址 vim /usr/local/prometheus/prometheus.yml scrape_configs: - job_name: 'pushgateway' static_configs: - targets: ['49.233.200.185:9091'] # 这个是安装了pushgateway的服务器地址 labels: instance: pushgateway 重启 prometheus 服务 systemctl restart prometheus.service pushgateway 其实是一个中转站，我们可以使用任何高级语言发送 post 请求到 pushgateway，然后对数据进行增加删除等操作，pushgateway 再把数据实时推送到 prometheus 推送数据到 PushGatewayecho \"missf 123456\" | curl --data-binary @- http://49.233.200.185:9091/metrics/job/prometheus # 数据:missf,值:123456 # --data-binary 表示发送二进制数据(post方式) # http://49.233.200.185:9091 pushgateway的地址 查看 pushgateway 推送到 prometheus上的数据，这可以看到有 exported_job=”prometheus” 和 job=”prometheus” 两个指标，我们推送数据时指定的 job 是 prometheus，为什么这里的 job 会显示 pushgateway 呢？这里需要修改一个 honor_labels 的参数 修改 prometheus 的配置文件，开启 honor_labels 参数(默认为false) scrape_configs: - job_name: 'pushgateway' honor_labels: true static_configs: - targets: ['49.233.200.185:9091'] labels: instance: pushgateway 重启 prometheus 再次推送数据到 pushgateway，然后查看 prometheus 上的数据 echo \"mwj 123456\" | curl --data-binary @- http://49.233.200.185:9091/metrics/job/prometheus/instance/missf 这里说明一下 honor_labels 的作用：因为 prometheus 配置 pushgateway 的时候，也会指定 job 和 instance，但是它只表示 pushgateway 实例本身，不能真正表达收集数据的含义。所以配置 pushgateway 需要添加 honor_labels：true 参数，避免收集到的数据本身的 job 和 instance 被覆盖。具体参考官网 在 PushGateway 删除数据curl -X DELETE http://49.233.200.185:9091/metrics/job/prometheus/instance/missf","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus 业务监控","slug":"Prometheus 业务监控","date":"2020-08-03T02:26:26.000Z","updated":"2020-09-28T03:57:18.458Z","comments":true,"path":"post/f261c617.html","link":"","permalink":"https://www.missf.top/post/f261c617.html","excerpt":"","text":"Blackbox_exporter 部署Blackbox_exporter 是 prometheus 官方提供的 exporter 之一，可以提供 http、dns、tcp、icmp 的监控数据采集 # 下载 wget https://github.com/prometheus/blackbox_exporter/releases/download/v0.17.0/blackbox_exporter-0.17.0.linux-amd64.tar.gz # 解压 tar xf blackbox_exporter-0.17.0.linux-amd64.tar.gz &amp;&amp; mv blackbox_exporter-0.17.0.linux-amd64 /usr/local/blackbox # 创建blackbox启动文件 vim /usr/lib/systemd/system/blackbox.service [Unit] Documentation=Blackbox exporter After=local-fs.target network-online.target network.target Wants=local-fs.target network-online.target network.target [Service] Restart=on-failure ExecStart=/usr/local/blackbox/blackbox_exporter --config.file=/usr/local/blackbox/blackbox.yml [Install] WantedBy=multi-user.target # 启动blackbox systemctl daemon-reload systemctl restart blackbox.service 配置 TCP 端口检测及告警传统的端口检测方式，调用命令的方式去实现 ncat -vz 47.100.107.121 80 # 返回seconds而不是timeout那么端口就是通的 telnet ...... zabbix监控端口可以通过模板或者自定义key写脚本实现 修改 prometheus 配置文件，配置 TCP 端口检测 vim /usr/local/prometheus/prometheus.yml scrape_configs: - job_name: 'nginx_port_check' metrics_path: /probe params: module: [tcp_connect] file_sd_configs: - files: - check/port/nginx.json relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 47.100.107.121:9115 # 这个是blackbox所在主机以及端口 编写监控 TCP 端口的告警规则 vim /usr/local/prometheus/rules/nginx_port_check.yml groups: - name: nginx port check rules: - alert: nginx_port_check failed for: 5s expr: probe_success{job=\"nginx_port_check\"} == 0 labels: serverity: critical annotations: description: \"{{ $labels.group }} port connection fail,{{ $labels.group }} value is:{{ $value }}\" summary: \"{{ $labels.group }} port connection failed\" 修改 prometheus 配置文件需要重启 prometheus 服务 systemctl restart prometheus.service 关闭 Nginx 测试当 80 端口无法访问之后的告警结果 业务接口检测及告警基于现在 Java + Vue 前后端分离的开发模式下，我们很多时候需要去检测 Java 的接口是否正常。传统的手动检测可以使用 postman，或者写 shell 脚本也可以实现，但是prometheus 可以通过 blackbox 去更好的检测业务接口 修改 prometheus 配置文件，添加监控业务接口的 job scrape_configs: - job_name: 'get_mysite' scrape_interval: 5s metrics_path: /probe params: module: [http_2xx] file_sd_configs: - files: - check/url/*.json relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 47.100.107.121:9115 编写监控 url 链接的告警规则文件 vim /usr/local/prometheus/rules/get_mysite.yml groups: - name: get mysite check rules: - alert: get_mysite_check failed for: 5s expr: probe_success{group=\"get_mysite\",instance=\"https://www.missf.top\",job=\"get_mysite\"} == 0 labels: serverity: critical annotations: description: \"{{ $labels.group }} failed, {{ $labels.group }} value is:{{ $value }}\" summary: \"{{ $labels.group }} website not accessible\" 修改 prometheus 配置文件之后记得重启 prometheus 服务 systemctl restart prometheus.service 如果 https://www.missf.top 这个链接的 http 请求不是返回 2xx 的状态码就会告警 我们在监控业务接口时，只监控到接口的返回状态(2xx状态码)，假如我们想要监控业务接口的返回内容该如何实现呢？那就需要修改 blackbox 的配置文件 modules: http_2xx: prober: http # 下面这段是需要添加的内容 http: method: GET headers: Host: www.missf.top Accept-Language: en-US Origin: missf.top fail_if_body_matches_regexp: # 如果我get的url地址返回的正文中有\"apache\",那么就会失败,则probe_success值为0 - \"apache\" fail_if_body_not_matches_regexp: - \"nginx\" # 如果我get的url地址返回的正文中没有\"nginx\",那么就会失败,则probe_success值为0 http_post_2xx: prober: http http: method: POST tcp_connect: prober: tcp pop3s_banner: prober: tcp tcp: query_response: - expect: \"^+OK\" tls: true tls_config: insecure_skip_verify: false ssh_banner: prober: tcp tcp: query_response: - expect: \"^SSH-2.0-\" irc_banner: prober: tcp tcp: query_response: - send: \"NICK prober\" - send: \"USER prober prober prober :prober\" - expect: \"PING :([^ ]+)\" send: \"PONG ${1}\" - expect: \"^:[^ ]+ 001\" icmp: prober: icmp 修改了 blackbox 配置文件需要重启 blackbox 服务 systemctl restart blackbox.service 上面所配置的匹配返回内容是在http_2xx这个模块下添加的，我们需要修改prometheus配置文件对应的http_2xx模块的规则文件，配置我们监控业务接口的返回内容的url地址 vim /usr/local/prometheus/check/url/get_mysite.json [ { \"targets\": [ \"47.100.107.121\" # 这个url返回的是默认的Nginx页面,对应我上面的匹配规则(nginx/apache) ], \"labels\": { \"group\": \"get_mysite\" } } ] 查看 blackbox 的采集数据 probe_success 的值是根据我们在 blackbox 配置文件的正则去决定的 这时候我们 get_mysite.json 这个规则文件的 job 的 probe_success 值就是通过 get 获取一个 url 的返回值去确定的，我们这样就可以去监控接口的返回内容了 配置网络监控我们可以让服务器使用 icmp 协议去请求 www.baidu.com 或者是一个公网 IP，测试服务器的网络是否正常 修改 prometheus 配置文件，添加网络监控的 job scrape_configs: - job_name: 'icmp_check_network' scrape_interval: 5s metrics_path: /probe params: module: [icmp] file_sd_configs: - files: - check/icmp/*.json relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 47.100.107.121:9115 编写网络监控的规则文件 vim /usr/local/prometheus/rules/check_network.yml groups: - name: icmp check network rules: - alert: icmp check network failed for: 10s expr: probe_success{group=\"icmp_check_network\",instance=\"www.baidu.com\",job=\"icmp_check_network\"} == 0 labels: serverity: critical annotations: description: \"{{ $labels.group }} icmp connection failed, {{ $labels.group }} value is: {{ $value }}\" summary: \"{{ $labels.group }} connection failed, instance: {{ $labels.instance }}\" 修改 prometheus 配置文件之后记得重启 prometheus 服务 systemctl restart prometheus.service","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus 告警","slug":"Prometheus 告警","date":"2020-07-23T03:53:03.000Z","updated":"2020-09-28T04:00:18.741Z","comments":true,"path":"post/615f0093.html","link":"","permalink":"https://www.missf.top/post/615f0093.html","excerpt":"","text":"Alertmanager 概述prometheus 发出告警时分为两部分，首先 prometheus 按告警规则(rule_files配置)向 alertmanager 发送告警，即告警规则是在 prometheus 上定义的，然后由 alertmanager 去管理这些告警，包括去重(deduplicating)、分组(grouping)、静音(silencing)、抑制(inhibition)、聚合(aggregation)，最终通过丰富的告警通知渠道(电话、微信、短信、邮件)将告警通知路由给对应的联系人。prometheus 的大部分组件都是 go 语言开发的，zabbix 到4.4之后的客户端才是 go 编写 Alertmanager 二进制安装# 下载 wget https://github.com/prometheus/alertmanager/releases/download/v0.21.0/alertmanager-0.21.0.linux-amd64.tar.gz # 解压 tar xf alertmanager-0.21.0.linux-amd64.tar.gz &amp;&amp; mv alertmanager-0.21.0.linux-amd64 /usr/local/alertmanager # 创建alertmanager启动文件 vim /usr/lib/systemd/system/alertmanager.service [Unit] Documentation=alertmanager [Service] Restart=on-failure ExecStart=/usr/local/alertmanager/alertmanager --config.file=/usr/local/alertmanager/alertmanager.yml --storage.path=/usr/local/alertmanager/data [Install] WantedBy=multi-user.target # 启动 systemctl daemon-reload systemctl start alertmanager.service Alertmanager 配置文件详解vim /usr/local/alertmanager/alertmanager.yml global: resolve_timeout: 5m # 恢复的超时时间,这个跟告警恢复通知有关,此参数并不是说在这个时间没有收到告警就会恢复 route: group_by: ['alertname'] # 默认以告警名进行分组,就是rule文件的alert值进行分组 group_wait: 10s # 发送警报前，至少等待多少秒才会发送(为了收集同组更多的警报信息一起发送) group_interval: 10s # 如果警报1已经发送,这时又出现同组的警报2,由于组状态发生变化,警报会在group_interval这个时间内发送,不会被repeat_interval这个时间收敛 repeat_interval: 20m # 报警信息已发送，但事件并没有恢复,则等待多久时间再重新发送(生产环境一般设成20min或者30min) receiver: 'web.hook' # 发送警报的接收者名称,如果一个报警没有被一个route匹配,则发送给默认的接收器 receivers: # 发送告警信息给那个接收者 - name: 'web.hook' # 这个需要和上面定义的接收者名称一致 webhook_configs: - url: 'http://127.0.0.1:5001/' inhibit_rules: # 抑制规则,防止告警风暴 - source_match: severity: 'critical' target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] 检查 Alertmanager 配置文件# 提示SUCCESS,则配置文件没有问题 ./amtool check-config alertmanager.yml # 修改配置文件之后重启alertmanager systemctl restart alertmanager.service 配置邮件告警修改 alertmanager 配置文件，填写邮箱的验证信息，定义路由的收件人，配置发送告警邮件到那个邮箱 cat /usr/local/alertmanager/alertmanager.yml global: resolve_timeout: 3m smtp_smarthost: 'smtp.qq.com:465' smtp_from: '1173354099@qq.com' smtp_auth_username: '1173354099@qq.com' smtp_auth_password: '' # 授权码 smtp_require_tls: false route: group_by: ['alertname'] group_wait: 10s group_interval: 10s repeat_interval: 20m receiver: 'devops.mail' receivers: - name: 'devops.mail' email_configs: - to: 'mf_2013@163.com' headers: { Subject: \"[WARN] Prometheus 报警邮件\" } send_resolved: true # 发送告警恢复通知 #inhibit_rules: # - source_match: # severity: 'critical' # target_match: # severity: 'warning' # equal: ['alertname', 'dev', 'instance'] 配置 prometheus 与 alertmanager 通信，设置规则文件的路径和正则匹配 # 修改prometheus配置文件 vim /usr/local/prometheus/prometheus.yml alerting: alertmanagers: - static_configs: - targets: - 127.0.0.1:9093 # 这里由于alertmanager是和prometheus部署在同一台机器上,所以写本机地址 rule_files: - \"rules/*.yml\" # rules这个目录是在prometheus上的,指当前配置文件的同级目录,这个目录需要自己创建 # 检查prometheus配置文件 ./promtool check config prometheus.yml systemctl restart prometheus.service 编写 rules 文件，根据 rules 文件中的表达式去告警，这个规则文件的路径是 prometheus 配置文件中定义的 # 监控节点的状态 cat /usr/local/prometheus/rules/node.yml groups: - name: node_alert rules: - alert: Node_InstanceDown expr: up == 0 # 表达式 for: 5s labels: serverity: error annotations: summary: \"Instance {{ $labels.instance }} down\" description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes\" 在 prometheus 的 web 控制台查看配置的规则 关闭 node_exporter.service 节点，查看告警邮件 配置微信告警修改 alertmanager 配置文件，定义路由规则 cat /usr/local/alertmanager/alertmanager.yml global: resolve_timeout: 3m smtp_smarthost: 'smtp.qq.com:465' smtp_from: '1173354099@qq.com' smtp_auth_username: '1173354099@qq.com' smtp_auth_password: '' # 授权码 smtp_require_tls: false templates: - /usr/local/alertmanager/template/wechat.temp route: group_by: ['alertname'] group_wait: 10s group_interval: 10s repeat_interval: 20m #receiver: 'devops.mail' receiver: 'devops.mailwechat' routes: # 为node_exporter、docker、mysqld_exporter定义匹配路由,每个路由有自己的分组在微信告警时信息就会单独发送 - receiver: 'devops.mailwechat' # 每个服务可以定义自己的接收者,这样在发送时就可以发送给不同的人,不同的服务对应不同的处理人员 group_wait: 10s group_by: ['node_exporter'] match_re: job: node_exporter - receiver: 'devops.mailwechat' group_wait: 10s group_by: ['docker'] match_re: job: docker - receiver: 'devops.mailwechat' group_wait: 10s group_by: ['mysqld_exporter'] match_re: job: mysqld_exporter receivers: - name: 'devops.mailwechat' # 将这个告警同时发送到邮件和微信 email_configs: - to: 'mf_2013@163.com' headers: { Subject: \"[WARN] Prometheus 报警邮件\" } send_resolved: true wechat_configs: - api_secret: '' agent_id: '' corp_id: '' to_party: '' send_resolved: true #inhibit_rules: # - source_match: # severity: 'critical' # target_match: # severity: 'warning' # equal: ['alertname', 'dev', 'instance'] 编写 rules 文件，为了每个服务单独报警，这里将 node_exporter、docker、mysqld_exporter 分开去写匹配规则 cat /usr/local/prometheus/rules/node.yml groups: - name: node_exporter rules: - alert: node_exporter_Down expr: up{job=\"node_exporter\"} == 0 for: 5s labels: serverity: error annotations: summary: \"Instance {{ $labels.instance }} down\" description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes\" - name: mysqld_exporter rules: - alert: mysqld_exporter_Down expr: up{job=\"mysqld_exporter\"} == 0 for: 5s labels: serverity: error annotations: summary: \"Instance {{ $labels.instance }} down\" description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes\" - name: docker rules: - alert: docker_Down expr: up{job=\"docker\"} == 0 for: 5s labels: serverity: error annotations: summary: \"Instance {{ $labels.instance }} down\" description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes\" 配置完成之后重启 alertmanager systemctl restart alertmanager.service 关闭 node_exporter 和 docker_cadvisor 服务，这时候会每个服务单独发送告警信息，由于将全部服务 group_by 在一个组里面，在发送恢复信息时会出现服务混乱的情况，所以我将每个服务做了路由，每一个服务都有自己的 group_by，这样在发送信息时才会单独去发送 配置钉钉告警先去创建一个钉钉机器人，具体过程这里就不详细说明了 prometheus 配置钉钉告警需要使用到 prometheus-webhook-dingtalk 插件，我们先使用二进制安装钉钉插件，dingtalk 服务默认启动的端口是 8060 prometheus-webhook-dingtalk插件下载地址 # 下载prometheus-webhook-dingtalk wget https://github.com/timonwong/prometheus-webhook-dingtalk/releases/download/v1.4.0/prometheus-webhook-dingtalk-1.4.0.linux-amd64.tar.gz # 解压prometheus-webhook-dingtalk tar xf prometheus-webhook-dingtalk-1.4.0.linux-amd64.tar.gz &amp;&amp; mv prometheus-webhook-dingtalk-1.4.0.linux-amd64 /usr/local/dingtalk # 编写dingtalk启动文件 vim /usr/lib/systemd/system/dingtalk.service [Unit] Description=prometheus-webhook-dingtalk After=network-online.target [Service] Restart=on-failure ExecStart=/usr/local/dingtalk/prometheus-webhook-dingtalk \\ --ding.profile=Prometheus告警=https://oapi.dingtalk.com/robot/send?access_token=xxxxxx [Install] WantedBy=multi-user.target # 启动dingtalk.service systemctl daemon-reload systemctl restart dingtalk.service # 查看dingtalk的webhook地址 journalctl -fu dingtalk.service Jul 29 18:38:01 iZuf6fpaicz5jt7kep555qZ prometheus-webhook-dingtalk[5504]: ts=2020-07-29T10:38:01.655Z caller=main.go:133 component=configuration msg=\"Webhook urls for prometheus alertmanager\" urls=http://localhost:8060/dingtalk/Prometheus告警/send 修改 prometheus 的 alertmanager 配置，更改告警的路由和接收者 route: receiver: 'devops_dingtalk' # 接收者必须和下面的一致 receivers: - name: 'devops_dingtalk' webhook_configs: - url: 'http://localhost:8060/dingtalk/Prometheus告警/send' # 这个URL是dingtalk的webhook地址 send_resolved: true 关闭 docker 收集器查看告警效果 告警状态prometheus 的告警状态有三种，我们可以在 prometheus 的控制台页面上查看告警的状态 inactive 没有触发任何阈值，这个是根据 scrape_interval 参数(采集数据周期)和 evaluation_interval 参数(对比规则周期)去决定的 pending 已触发阈值但未满足告警持续时间，告警进入 pending 状态之后，需要等待规则配置的 for 时间，如果在这个时间内触发阈值的表达式一直成立，才会进入 firing 状 态 firing 已触发阈值且满足告警持续时间，将告警从 prometheus 发送给 alertmanager，在 alertmanager 收到告警之后并不会立刻发送，还需要等待一个 group_wait 时间，直到某个计算周期表达式为假，告警状态变更为 inactive，发送一个 resolve 给 altermanger，说明此告警已解决 告警收敛alertmanager 在收到 prometheus 发送的告警之后，并不是把收到的信息简单的直接发送出去，而是通过一系列的收敛机制(分组、抑制、静默)去筛选出需要发送的信息，如果 alertmanager 收到信息就直接发送出去，会导致告警信息过多，运维人员会被告警信息淹没，错过重要的告警信息 分组 将类似性质的告警分类为单个通知，减少告警消息数量 将类似性质的告警进行聚合发送，帮助运维更好的排查问题 抑制 当告警发出后，停止重复发送由此告警而引起的其他告警，帮助运维第一时间掌握最核心的告警信息 inhibit_rules: - source_match: severity: 'critical' # 当发生critical级别的告警时,就会抑制下面warning级别的告警 target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] # 已发送的告警与新产生的告警中equal定义的标签完全相同,则启动抑制机制 静默 是一种简单的特定时间静音的提醒机制，在发布新版本时我们需要停掉某些进程，这时候告警肯定会触发的，由于这是我们已经预知的现象，我们可以打开 prometheus 主机的 9093 端口暂时将告警设置成静音 Prometheus一条告警是怎么触发的1.采集数据 scrape_interval: 15s 2.比对采集到的数据是否触发阈值 evaluation_interval: 15s 3.判断是否超出持续时间(在这个时间内一直处于触发阈值状态)for: 5s 4.告警到达alertmanager然后进行分组、抑制、静默 5.通过分组、抑制、静默一系列机制的信息将会被发送，但是会延迟发送group_wait: 10s 编写告警规则案例groups: - name: general.rules rules: - alert: node_FileSystemUsage # 监控磁盘使用率 expr: 100 - node_filesystem_free_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"} / node_filesystem_size_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"} * 100 > 80 for: 5s labels: serverity: warning annotations: summary: \"Instance {{ $labels.instance }} : {{ $labels.mountpoint }} Partition utilization is too high\" description: \"{{ $labels.instance }} : {{ $labels.mountpoint }} Partition utilization is greater than 80% (Currently: {{ $value }})\" - alert: node_MemoryUsage # 监控内存使用率 expr: 100 - (node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) / node_memory_MemTotal_bytes * 100 > 80 for: 5s labels: serverity: warning annotations: summary: \"Instance {{ $labels.instance }} High memory usage\" description: \"{{ $labels.instance }} Memory usage greater than 80% (Currently: {{ $value }})\" - alert: node_cpuUsage # 监控CPU使用率 expr: 100 - irate(node_cpu_seconds_total{mode=\"idle\",job=\"node_exporter\",instance=\"47.100.107.121:9100\"}[5m]) * 100 > 80 for: 5s labels: serverity: warning annotations: summary: \"Instance {{ $labels.instance }} High cpu usage\" description: \"{{ $labels.instance }} Memory usage greater than 60% (Currently: {{ $value }})\"","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus 监控案例","slug":"Prometheus 监控案例","date":"2020-07-16T07:43:16.000Z","updated":"2020-09-28T04:03:32.474Z","comments":true,"path":"post/ba827699.html","link":"","permalink":"https://www.missf.top/post/ba827699.html","excerpt":"","text":"监控 Linux 服务器部署 node_exporter prometheus 官方提供 Node_exporter 来让我们收集机器的系统数据，除 node_exporter 外，官方还提供 consul、memcached、haproxy、mysqld 等 exporter。exporter类似于 zabbix 写好的监控模板，但是这些 exporter 都是需要在被监控节点安装 # 下载node_exporter wget https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz # 解压 tar xf node_exporter-1.0.1.linux-amd64.tar.gz &amp;&amp; mv node_exporter-1.0.1.linux-amd64 /usr/local/node_exporter # 编写启动文件 vim /usr/lib/systemd/system/node_exporter.service [Unit] Description=prometheus [Service] Restart=on-failure ExecStart=/usr/local/node_exporter/node_exporter [Install] WantedBy=multi-user.target # 启动node_exporter systemctl daemon-reload systemctl start node_exporter.service # 访问node_exporter的数据接口 http://10.10.110.23:9100/metrics # 默认端口是9100,默认接口是metrics 配置监控 # 修改prometheus配置文件 vim /usr/local/prometheus/prometheus.yml - job_name: 'node_exporter' file_sd_configs: - files: ['/usr/local/prometheus/sd_config/node/*.yaml'] refresh_interval: 5s # 创建服务发现的文件 vim /usr/local/prometheus/sd_config/node/*.yaml - targets: - '10.10.110.23:9100' # 这个地址是被监控节点的IP地址 promSQL监控CPU、内存、硬盘CPU监控 # 计算CPU五分钟内平均的使用率表达式 100 - irate(node_cpu_seconds_total{mode=\"idle\",instance=\"10.10.110.23:9100\",job=\"node_exporter\"}[5m]) * 100 # node_cpu_seconds_total{mode=\"idle\",instance=\"10.10.110.23:9100\",job=\"node_exporter\"}[5m]:取CPU五分钟之内的空闲值 # irate函数:将会用于计算某个指标在一定时间间隔内的变化速率 # 将得到的空闲值乘以100再得到CPU百分比的空闲值,再以100减去CPU百分比的空闲值,就得到CPU五分钟内平均的使用率 内存监控 # 计算内存使用率表达式 100 - (node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) / node_memory_MemTotal_bytes * 100 # (node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes)是内存剩余的总量 在系统层面来考虑:buff和cache是已经被使用的内存 在程序层面来考虑:buff和cache是剩余的内存 # 内存剩余的总量除以内存总量得到内存剩余率,再以100减去内存剩余率得到内存使用率 硬盘监控 # 计算硬盘使用率表达式 100 - node_filesystem_free_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"} / node_filesystem_size_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"} * 100 # node_filesystem_free_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"}是根分区硬盘剩余容量,只计算ext4|xfs类型的文件系统 # node_filesystem_size_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"}是根分区的硬盘总量 # 根分区硬盘剩余容量除以根分区的硬盘总量得到根分区硬盘的剩余率,再以100减去硬盘的剩余率得到硬盘使用率 监控系统服务状态修改 node_exporter 的启动参数 vim /usr/lib/systemd/system/node_exporter.service [Unit] Description=prometheus [Service] Restart=on-failure ExecStart=/usr/local/node_exporter/node_exporter --collector.systemd --collector.systemd.unit-whitelist=(docker|sshd).service # 利用正则匹配监控systemd的docker|sshd这三个服务 [Install] WantedBy=multi-user.target 重启 node_exporter systemctl daemon-reload systemctl restart node_exporter.service 查看监控服务的数据指标 node_systemd_unit_state{name=\"docker.service\"} 在 activating、active、deactivating、failed、inactive 五个状态中 value 为 1 的状态，就是服务当前的状态 使用 Grafana 图表展示监控数据安装 Grafana # 下载软件包 wget https://dl.grafana.com/oss/release/grafana-7.1.0-1.x86_64.rpm # 安装 yum install grafana-7.1.0-1.x86_64.rpm -y # 启动 systemctl enable grafana-server.service systemctl start grafana-server.service # Grafana默认端口为3000,账号密码都为admin,初次登录会提示需要修改密码 Grafana 配置数据源 填写 prometheus 主机的地址，在配置数据源时我们还可以配置验证、定义 HTTP 头部、以及其他的一些信息 Grafana 导入仪表盘我们可以自己编写仪表盘，也可以使用官方网站上别人已经写好的仪表盘模板直接导入使用，这里我们没有必要自己去编写(重复造轮子而且还没有人家专业…)。我们先去Grafana Labs上找到监控 Linux 主机的仪表盘，然后将仪表盘的 ID 号导入到 Grafana 查看仪表盘Grafana 监控 Linux 主机的仪表盘数据是从 prometheus 的数据源获取的，就是被监控主机上的 node_exporter 获取到的数据 监控 Docker 服务器部署 cadvisor 想要监控 Docker 容器，需要在被监控主机安装 cadvisor 插件，暴露一个 HTTP 端口，为 prometheus 提供容器的监控数据 # 由于国内无法连接到gcr.io,这里使用张馆长仓库的镜像地址 docker run \\ --volume=/:/rootfs:ro \\ --volume=/var/run:/var/run:ro \\ --volume=/sys:/sys:ro \\ --volume=/var/lib/docker/:/var/lib/docker:ro \\ --volume=/dev/disk/:/dev/disk:ro \\ --publish=8080:8080 \\ --detach=true \\ --name=cadvisor \\ --privileged \\ --device=/dev/kmsg \\ registry.aliyuncs.com/k8sxio/cadvisor:latest 配置 Prometheus 监控 cadvisor cadvisor 可以搜集一台机器上所有运行的容器信息，还提供基础查询界面和 http 接口，供其他组件如 prometheus 拉取数据 vim /usr/local/prometheus/prometheus.yml # 在prometheus配置文件加入监控主机的cadvisor端口(拉取容器数据) - job_name: 'docker' static_configs: - targets: ['10.10.110.23:8080'] systemctl daemon-reload systemctl restart prometheus.service Grafana 导入仪表盘 我们去 Grafana Labs 网站寻找一个监控 Docker 主机的仪表盘，在 Grafana 进行导入 查看Docker主机仪表盘 监控 MySQL 服务器监控 MySQL 主机和监控 Linux 主机一样，都是需要导出器去获取数据，这里我们去 prometheus 官网下载 mysqld_exporter，然后在 mysql 主机上安装(监控那台 mysql 主机就在那台主机安装mysqld_exporter) MySQL 主机安装 mysqld_exporter # 下载 wget https://github.com/prometheus/mysqld_exporter/releases/download/v0.12.1/mysqld_exporter-0.12.1.linux-amd64.tar.gz # 解压 tar xf mysqld_exporter-0.12.1.linux-amd64.tar.gz &amp;&amp; mv mysqld_exporter-0.12.1.linux-amd64 /usr/local/mysqld_exporter # 创建启动文件 vim /usr/lib/systemd/system/mysqld_exporter.service [Unit] Documentation=https://prometheus.io/ [Service] Restart=on-failure Environment=DATA_SOURCE_NAME=exporter:Missf.top123@(localhost:3306)/ # 连接数据库的账号密码,也可以指定.my.cnf文件 ExecStart=/usr/local/mysqld_exporter/mysqld_exporter [Install] WantedBy=multi-user.target # 被监控数据库添加mysql用户及监控权限 CREATE USER 'exporter'@'localhost' IDENTIFIED BY 'Missf.top123' WITH MAX_USER_CONNECTIONS 3; GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'exporter'@'localhost'; FLUSH PRIVILEGES; # 启动mysqld_exporter systemctl start mysqld_exporter # 获取监控数据 curl [IP]:9104/metrics 配置Prometheus监控mysqld_exporter # 修改配置文件 vim /usr/local/prometheus/prometheus.yml - job_name: 'mysqld_exporter' # 添加监控mysqld_exporter static_configs: - targets: ['47.100.107.121:9104'] # 重启 systemctl restart prometheus.service 导入 MySQL 仪表盘 导入 ID 为 7362 的 MySQL 仪表盘，查看 MySQL 的监控数据","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus 配置文件与核心功能","slug":"Prometheus 配置文件与核心功能","date":"2020-07-15T11:06:15.000Z","updated":"2020-09-28T04:04:16.449Z","comments":true,"path":"post/521f1005.html","link":"","permalink":"https://www.missf.top/post/521f1005.html","excerpt":"","text":"全局配置文件介绍global: # 全局默认的数据拉取间隔,默认每隔1m拉取一次监控数据 [ scrape_interval: &lt;duration> | default = 1m ] # 全局默认的单次数据拉取超时 [ scrape_timeout: &lt;duration> | default = 10s ] # 对告警规则做定期计算的间隔时间,每隔1m对比一次我采集到的数据跟我设置的告警规则,符合告警规则的事件就会被发送到alertmanager,由alertmanager做路由匹配然后进行告警处理 [ evaluation_interval: &lt;duration> | default = 1m ] # 监控告警的规则设置 rule_files: [ - &lt;filepath_glob> ... ] # 配置被监控指标 scrape_configs: [ - &lt;scrape_config> ... ] # 指定告警和告警管理器相关的设置 alerting: alert_relabel_configs: [ - &lt;relabel_config> ... ] alertmanagers: [ - &lt;alertmanager_config> ... ] scrape_configs配置数据源，拉取数据的对象称为 Targets，每个 Targets 用 job_name 命名，添加数据源又分为静态配置和服务发现 # 定义job名称,是一个拉取单元,每个job_name都会自动引入默认配置如: # scrape_interval 依赖全局配置 # scrape_timeout 依赖全局配置 # metrics_path 默认为'/metrics' # scheme 默认为'http' job_name: &lt;job_name> # 数据拉取间隔 [ scrape_interval: &lt;duration> | default = &lt;global_config.scrape_interval> ] # 数据拉取超时时间 [ scrape_timeout: &lt;duration> | default = &lt;global_config.scrape_timeout> ] # 拉取数据指标的地址 [ metrics_path: &lt;path> | default = /metrics ] 基于文件的服务发现基于文件的服务发现不需要依赖其他平台与第三方服务，用户只需将要更新的 target 信息以 yaml 或 json 文件格式添加到 target 文件中，prometheus 会定期的从指定文件中读取 target 信息并更新。给我们带来的好处就是不需要一个个 target 去添加，只需要一个 yaml 或者 json 文件，便于管理 编写配置文件 vim prometheus.yml # my global config 全局配置文件 global: scrape_interval: 5s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration 告警管理 alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093 # Load rules once and periodically evaluate them according to the global 'evaluation_interval'. rule_files: # - \"first_rules.yml\" # - \"second_rules.yml\" # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs: # The job name is added as a label `job=&lt;job_name>` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. # scrape_interval: 5s # static_configs: # - targets: ['localhost:9090'] file_sd_configs: # 文件服务发现 - files: ['/usr/local/prometheus/sd_config/*.yaml'] # 指定服务发现的文件路径 refresh_interval: 5s # 每过5秒动态发现服务配置 创建目录及文件 vim /usr/local/prometheus/sd_config/test.yaml # 需要监控那一台主机就在那一台主机上创建 - targets: - '10.10.110.150:9090' # 这个是填写prometheus主机的地址,如果prometheus启动时监听的是8080端口,那么这里就需要和prometheus端口一致,不然获取不到数据 labels: group: prometheus 重载配置文件 ps -ef | grep prometheus root 1774 1 0 Jul15 ? 00:02:21 /usr/local/prometheus/prometheus --config.file=/usr/local/prometheus/prometheus.yml root 2741 1702 0 14:13 pts/1 00:00:00 grep --color=auto prometheus kill -hup 1774","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus 部署","slug":"Prometheus 部署","date":"2020-07-15T09:11:11.000Z","updated":"2020-09-28T04:04:47.406Z","comments":true,"path":"post/d26dfcbe.html","link":"","permalink":"https://www.missf.top/post/d26dfcbe.html","excerpt":"","text":"Prometheus 二进制部署# 下载二进制安装包 wget https://github.com/prometheus/prometheus/releases/download/v2.19.2/prometheus-2.19.2.linux-amd64.tar.gz # 解压 tar xf prometheus-2.19.2.linux-amd64.tar.gz &amp;&amp; mv prometheus-2.19.2.linux-amd64 /usr/local/prometheus # 创建启动文件 cp /usr/lib/systemd/system/sshd.service /usr/lib/systemd/system/prometheus.service # 编写启动文件 tee /usr/lib/systemd/system/prometheus.service &lt;&lt; EOF [Unit] Description=http://prometheus.io [Service] Restart=on-failure ExecStart=/usr/local/prometheus/prometheus --config.file=/usr/local/prometheus/prometheus.yml [Install] WantedBy=multi-user.target EOF # 启动prometheus systemctl daemon-reload systemctl restart prometheus.service 修改配置文件vim /usr/local/prometheus/prometheus # my global config global: scrape_interval: 5s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093 # Load rules once and periodically evaluate them according to the global 'evaluation_interval'. rule_files: # - \"first_rules.yml\" # - \"second_rules.yml\" # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs: # The job name is added as a label `job=&lt;job_name>` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['127.0.0.1:9090'] Docker 部署docker run -d --name \"prometheus\" -p 9090:9090 \\ --mount src=prometheus,dst=/etc/prometheus \\ --mount type=bind,src=/prometheus/prometheus.yml,dst=/etc/prometheus/prometheus.yml prom/prometheus 启动常用命令行参数./prometheus -h --config.file=\"prometheus.yml\" # 指定配置文件 --web.listen-address=\"0.0.0.0:9090\" # 指定端口 --log.level=info # 指定日志级别","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus 概述","slug":"Prometheus 概述","date":"2020-07-14T06:48:33.000Z","updated":"2020-09-28T04:06:47.253Z","comments":true,"path":"post/ef0b21f0.html","link":"","permalink":"https://www.missf.top/post/ef0b21f0.html","excerpt":"","text":"Prometheus 简介Prometheus (普罗米修斯)是一个最初在 SoundCloud 上构建的监控系统。自2012年成为社区开源项目，拥有非常活跃的开发人员和用户社区。为强调开源及独立维护，Prometheus 于2016年加入云原生云计算基金会(CNCF)，成为继 Kubernetes 之后的第二个托管项目 可能有些运维小伙伴不知道 Prometheus，但是你们一定用过 zabbix。现在由于 Docker 和 Kubernetes 的兴起，zabbix 渐渐的失去了监控的优势，现在 Prometheus 是用来监控容器的最好实现，只有用到 Docker 和 Kubernetes 就离不开Prometheus提供监控支持。以前刚接触 zabbix 时，配置的微信告警让我开心了一整天，那时候觉得 zabbix 是世界上最好的监控软件，但是现在却觉得 Prometheus 才是。可能人总是需要不断向前看、不断向前奔跑的吧 prometheus官网 Prometheus 特点 多维数据模型(由时序列数据metric和一组key/value组成) 使用多维度数据完成复杂的语言查询，为 prometheus 的后期发展奠定基础(PromSQL) 不依赖分布式存储，单个服务器节点可直接工作 通过 pushgateway 进行时序列数据推送(pushing) 可以通过服务发现或者静态配置去获取要采集的目标服务器 多种可视化图表及仪表盘支持 基于 HTTP 的 pull 方式采集时间序列数据 Prometheus 组成及架构Prometheus 根据配置定时去拉取各个节点的数据，默认使用的拉取方式是 pull，也可以使用 pushgateway 提供的 push 方式获取各个监控节点的数据。将获取到的数据存入TSDB(时序型数据库)，此时 prometheus 已经获取到监控数据，可以使用内置的 promSQL 进行查询。它的报警功能使用 alertmanager 提供，alertmanager 是prometheus的告警管理和发送报警的一个组件。prometheus 原生的图表结构过于简单，prometheus 的图表展示功能一般由 grafana 进行统一管理 Prometheus 数据模型Prometheus 将所有数据存储为时间序列，具有相同度量名称以及标签属于同一个指标。每个时间序列都由度量标准名称和一组键值对(也成为标签)唯一标识 # 时间序列格式示例 &lt;metric name>{&lt;label name>=&lt;label value>, ...} api_http_requests_total{method=\"POST\", handler=\"/messages\"} Prometheus 指标类型Counter：递增的计数器 Gauge：可以任意变化的数值 Histogram：对一段时间范围内数据进行采样，并对所有数值求和与统计数量 Summary：与Histogram类似 不同的指标类型用于渲染不同的图表 Prometheus 作业和实例实例：可以抓取的目标称为实例(Instances) 作业：具有相同目标的实例集合称为作业(Job) scrape_configs: - job_name: 'prometheus' # prometheus这个job作用于localhost:9090这个目标 static_configs: - targets: ['localhost:9090'] - job_name: 'node' # node这个job作用于192.168.1.10:9090这个目标 static_configs: - targets: ['192.168.1.10:9090']","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus 监控的意义","slug":"Prometheus 监控的意义","date":"2020-07-13T17:28:39.000Z","updated":"2020-09-28T04:07:32.353Z","comments":true,"path":"post/ded057ed.html","link":"","permalink":"https://www.missf.top/post/ded057ed.html","excerpt":"","text":"监控目的监控分为白盒监控和黑盒监控。白盒监控: 通过监控内部的运行状态及指标判断接下来可能会发生的问题，从而做出预判或应对的方法。黑盒监控: 监控系统或服务，在发生异常时做出相应的措施。prometheus 属于黑盒监控，是在服务发生异常时，我们通过告警信息得知，才去处理异常问题 监控的目的主要分为以下方面: 根据历史监控数据，对未来做出预测 发生异常时即使告警，或做出相应措施 根据监控报警及时定位问题根源，记录问题出现的证据(记录网络波动) 通过可视化图表展示，便于直观获取信息 领导查看数据图表(PV、UV、订单趋势图) 运维人员能够提前预知风险，避免故障的产生或者在故障发生时能够迅速处理 怎么监控使用传统监控工具，直接调用 Linux 系统命令去获取服务状态和信息 # free # vmstat # df # top # ss # iftop ... 使用监控系统去监控系统和服务，能够整体监控每一项数据 # zabbix # nagios # prometheus # open-falcon 监控流程监控的大概流程分为：数据采集、数据存储、数据分析、以及展示和告警 监控什么 监控类型 具体参数 硬件监控 硬件参数、温度、故障等 系统监控 CPU，内存，硬盘，网卡流量，TCP状态，进程数 应用监控 Nginx、Tomcat、PHP、MySQL、Redis等 日志监控 系统日志、服务日志、访问日志、错误日志 安全监控 WAF，敏感文件监控 API监控 可用性，接口请求，响应时间 业务监控 例如电商网站，每分钟产生多少订单、注册多少用户、多少活跃用户、推广活动效果 流量分析 根据流量获取用户相关信息，例如用户地理位置、某页面访问状况、页面停留时间等","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Docker Compose 单机编排利器","slug":"Docker Compose 单机编排利器","date":"2020-07-10T06:27:09.000Z","updated":"2020-09-28T03:28:39.275Z","comments":true,"path":"post/34699079.html","link":"","permalink":"https://www.missf.top/post/34699079.html","excerpt":"","text":"Docker Compose 概述Compose 是用于定义和运行多容器的工具，通过 Compose 可以使用 YAML 文件来配置容器。然后使用一个命令就可以从配置中创建并启动所有服务。其实在刚学习Docker 时我就想过，如果我是 LNMP 架构容器化项目，因为每次都要一个个容器的启动，是否有必要将启停多个容器的命令写成一个 shell 脚本呢。现在学到 Docker Compose，才知道根本没有这个必要，我们现在所有能想到的东西，其实早就有人帮我们实现了。这里不得不敬佩那些为开源项目做出贡献的伟大开发者们 使用 Compose 大概分为三个步骤： 定义 Dockerfile，以便可以在任意环境运行 定义应用程序启动配置文件 docker-compose.yml docker-compose 启动并管理整个应用程序生命周期 Linux 安装 Compose其实前面我们在学习 Harbor 时已经安装过 docker-compose，这是一个使用 python 开发的编排工具，国内下载可能会比较慢(你应该知道怎么做了吧…) curl -L \"https://github.com/docker/compose/releases/download/1.26.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/bin/docker-compose chmod +x /usr/bin/docker-compose docker-compose.yaml 配置文件参数build 使用 docker-compose 启动容器服务除了可以基于指定的镜像，还可以基于一份 Dockerfile，在使用 up 启动时执行构建镜像的任务，这个构建标签就是 build。Compose 将会利用它自动构建这个镜像，然后使用这个镜像启动服务容器 version:\"3.7\" services: web: context:./web dockerfile:Dockerfile context context 选项可以是 Dockerfile 的文件路径，也可以是到链接到 git 仓库的 url。当提供的值是相对路径时，它被解析为相对于撰写文件的路径，此目录也是发送到 Docker守护进程的 context build: context:./dir dockerfile 使用此 dockerfile 文件来构建，必须使用 context 指定构建路径 build: context:. # 知道dockerfile必须要有构建路径,.表示当前路径 dockerfile:Dockerfile-alternate image 指定 docker-compose 启动容器服务的镜像，可以是存储仓库、标签以及镜像 ID，如果镜像不存在，Compose 会自动拉去镜像 image: redis image: ubuntu:14.04 image: tutum/influxdb image: example-registry.com:4000/postgresql image: a4bc65fd command 覆盖容器启动后默认执行的命令 command:bundle exec thin -p 3000 command:[\"bundle\",\"exec\",\"thin\",\"-p\",\"3000\"] container_name 指定容器名称，由于容器名称是唯一的，如果指定自定义名称，则无法使用 scale container_name:my-web-container environment 添加环境变量，可以使用数组或字典。这个标签的作用是设置镜像变量，它可以保存变量到镜像里面，类似 ENV 指令一样会把变量一直保存在镜像、容器中 environment: RACK_ENV:development SHOW:'true' SESSION_SECRET: environment: -RACK_ENV=development -SHOW=true -SESSION_SECRET networks 加入指定网络 networks: - lnmp ports 映射端口 ports: -\"3000\" -\"3000-3005\" -\"8000:8000\" -\"9090-9091:8080-8081\" -\"49100:22\" -\"127.0.0.1:8001:8001\" -\"127.0.0.1:5000-5010:5000-5010\" # 指定IP+端口的话只会监听ipv4的地址 -\"6060:6060/udp\" expose 暴露端口，但不映射到宿主机，只被连接的服务访问。这个标签与 Dockerfile 中的 EXPOSE 指令一样，用于指定暴露的端口，实际上 docker-compose.yml 的端口映射还得 ports 这样的标签 extra_hosts 添加主机名的标签，就是往 /etc/hosts 文件中添加一些记录，与 Docker 客户端中的 –add-host 类似 extra_hosts: -\"www.missf.top:124.156.205.241\" -\"mf_missf.gitee.io:212.64.62.174\" volumes 挂载一个目录或者一个已存在的数据卷容器 volumes: - /opt/data:/var/lib/mysql # 挂载宿主机的/opt/data目录到容器的/var/lib/mysql - datavolume:/var/lib/mysq # 将容器的/var/lib/mysq挂载到datavolume数据卷 restart 默认值为 no ，即在任何情况下都不会重新启动容器。当值为 always 时，容器总是重新启动。当值为 on-failure 时，当出现 on-failure 报错容器退出时，容器重新启动 restart: \"no\" restart: always restart: on-failure restart: unless-stopped hostname 定义容器主机名 hostname: foo Compose 常用选项与命令up 命令：该命令十分强大，它将尝试自动完成包括构建镜像、创建服务、启动服务、并关联服务相关容器的一系列操作 -d：在后台运行服务容器 –force-recreate：强制重新创建容器，不能与 –no-recreate 同时使用 –no-recreate：如果容器已经存在了，则不重新创建，不能与 –force-recreate 同时使用 -no-build：不自动构建缺失的服务镜像 –no-deps：不启动服务所链接的容器 build 命令：可以随时在项目目录下运行 docker-compose build 来重新构建服务 –force-rm：删除构建过程中的临时容器 –no-cache：构建镜像过程中不使用 cache(这将加长构建过程) –pull：始终尝试通过 pull 来获取更新版本的镜像 ps 命令：列出项目中目前的所有容器 -q：只打印容器的 ID 信息 logs 命令：查看服务容器的输出，默认情况下，docker-compose 将对不同的服务输出使用不同的颜色来区分 docker-compose logs [选项] rm命令：删除所有(停止状态的)服务容器，推荐先执行 docker-compose stop 命令来停止容器 -f/–force：强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项 -v：删除容器所挂载的数据卷 scale 命令：设置指定服务运行的容器个数 docker-compose scale web=3 db=2 down 命令：删除容器、网络 start/stop/restart 命令：启动/停止/重启服务 docker-compose 编排 lnmp 环境docker-compose 目录设计 tree /docker-compose_lnmp/ /docker-compose_lnmp/ ├── docker-compose.yaml ├── mysql │ └── start ├── nginx │ ├── Dockerfile │ ├── nginx-1.16.1.tar.gz │ ├── nginx.conf │ ├── php.conf │ └── start └── php ├── Dockerfile ├── php-7.4.0.tar.gz ├── php-fpm.conf ├── php.ini ├── start └── www.conf 编写 docker-compose.yaml version: '3' services: php: hostname: php build: context: ./php dockerfile: Dockerfile networks: - \"lnmp\" volumes: - \"nginx:/usr/local/nginx/html\" nginx: hostname: nginx build: context: ./nginx dockerfile: Dockerfile ports: - \"80:80\" - \"443:443\" networks: - \"lnmp\" volumes: - \"nginx:/usr/local/nginx/html/\" mysql: hostname: mysql image: mysql:5.7 ports: - \"53306:3306\" networks: - \"lnmp\" volumes: - \"mysql:/var/lib/mysql/\" command: --character-set-server=utf8mb4 environment: MYSQL_ROOT_PASSWORD: mwj123456 MYSQL_DATABASE: wordpress networks: lnmp: {} volumes: nginx: {} # 把php代码放到这个数据卷的目录下 mysql: {} docker-compose 编排 nginx 反向代理 tomcat 集群docker-compose 目录设计 tree /docker-compose_lnmt/ /docker-compose_lnmt/ ├── docker-compose.yaml ├── nginx │ ├── Dockerfile │ ├── nginx-1.16.1.tar.gz │ ├── nginx.conf │ ├── start │ └── tomcat.conf └── tomcat ├── apache-tomcat-8.5.57.tar.gz ├── Dockerfile ├── jdk-8u211-linux-x64.tar.gz └── start 编写 docker-compose.yaml cat docker-compose.yaml version: '3' services: nginx: hostname: nginx build: context: ./nginx dockerfile: Dockerfile ports: - \"80:80\" - \"443:443\" networks: - \"lnmt\" volumes: - \"webapps:/usr/local/tomcat/webapps/\" tomcat1: hostname: tomcat1 build: context: ./tomcat dockerfile: Dockerfile networks: - \"lnmt\" volumes: - \"webapps:/usr/local/tomcat/webapps/\" tomcat2: hostname: tomcat2 build: context: ./tomcat dockerfile: Dockerfile networks: - \"lnmt\" volumes: - \"webapps:/usr/local/tomcat/webapps/\" tomcat3: hostname: tomcat3 build: context: ./tomcat dockerfile: Dockerfile networks: - \"lnmt\" volumes: - \"webapps:/usr/local/tomcat/webapps/\" mysql: hostname: mysql image: mysql:5.7 ports: - \"53306:3306\" networks: - \"lnmt\" volumes: - \"mysql:/var/lib/mysql/\" command: --character-set-server=utf8mb4 environment: MYSQL_ROOT_PASSWORD: mwj123456 MYSQL_DATABASE: test volumes: webapps: {} # 把war包放到这个数据卷的目录下,就会自动解压 mysql: {} networks: lnmt: {} 监听 Nginx 容器访问日志 tail -f /usr/local/nginx/logs/access.log # 点击浏览器刷新页面,可以看到upstream_addr的IP变化,这样就实现了反向代理Tomcat集群 {\"@timestamp\": \"2020-07-14T08:03:19+08:00\", \"clientRealIp\": \"10.10.110.1\", \"scheme\": \"http\", \"method\": \"GET\", \"host\": \"10.10.110.150\", \"url\": \"/\", \"size\": 1056, \"referrer\": \"-\", \"agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36\", \"upstream_addr\": \"192.168.16.3:8080\", \"request_time\": 0.323, \"request_length\": 450, \"upstream_connect_time\": \"0.003\", \"upstream_response_time\": \"0.324\", \"upstream_status\": \"200\", \"status\": \"200\"} {\"@timestamp\": \"2020-07-14T08:03:28+08:00\", \"clientRealIp\": \"10.10.110.1\", \"scheme\": \"http\", \"method\": \"GET\", \"host\": \"10.10.110.150\", \"url\": \"/\", \"size\": 1056, \"referrer\": \"-\", \"agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36\", \"upstream_addr\": \"192.168.16.6:8080\", \"request_time\": 0.345, \"request_length\": 450, \"upstream_connect_time\": \"0.000\", \"upstream_response_time\": \"0.345\", \"upstream_status\": \"200\", \"status\": \"200\"} {\"@timestamp\": \"2020-07-14T08:03:29+08:00\", \"clientRealIp\": \"10.10.110.1\", \"scheme\": \"http\", \"method\": \"GET\", \"host\": \"10.10.110.150\", \"url\": \"/\", \"size\": 1056, \"referrer\": \"-\", \"agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36\", \"upstream_addr\": \"192.168.16.4:8080\", \"request_time\": 0.355, \"request_length\": 450, \"upstream_connect_time\": \"0.000\", \"upstream_response_time\": \"0.354\", \"upstream_status\": \"200\", \"status\": \"200\"}","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker 图形化页面管理","slug":"Docker 图形化页面管理","date":"2020-07-10T02:03:55.000Z","updated":"2020-09-28T03:22:54.348Z","comments":true,"path":"post/92368be2.html","link":"","permalink":"https://www.missf.top/post/92368be2.html","excerpt":"","text":"Portainer 概述Portainer 是 Docker 的图形化管理工具，portainer 通过连接 /var/run/docker.sock 文件去管理容器，可让你轻松管理不同的 Docker 环境 (Docker主机或Swarm群集)。Portainer 提供状态显示面板、应用模板快速部署、容器镜像网络数据卷、事件日志显示、容器控制台操作、登录用户管理和控制等功能。Docker 图形化管理界面有很多实现的工具，但生态一直不温不火，这是由于 Docker 的很多操作都是直接在命令行进行，再加上 Docker 的操作也比较简单。一般这样的图形化管理平台都是交给开发和测试人员去使用的 Portainer 安装docker run -d -p 8000:8000 -p 9000:9000 --name \"portainer\" --restart=always \\ -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer # 这里portainer通过连接/var/run/docker.sock文件去管理容器,所以需要把宿主机的docker.sock文件挂载到portainer 登录 Portainer 页面 Portainer 连接容器的方式 Local：管理 Portainer 所在主机上的 Docker 主机，需要将宿主机的 docker.sock 文件挂载到 Portainer 容器内 Remote：管理远程主机上的 Docker 主机，但是要开启远程的 Docker 主机的 Docker API，允许 Portainer 通过 TCP 连接 Agent：直接连接到在 Swarm 集群中运行的 Portainer 代理 Azure：连接到 Microsoft Azure 这里我们先使用 Local 的方式连接到 Portainer 所在的主机 Portainer 管理界面通过下图可以看到 Portainer 提供了对容器、镜像、网络、数据卷、变量、主机的操作，App templates 是一些供我们下载的公共镜像，我们还可以看到正在运行的容器状态、日志、基于镜像、创建时间、映射端口等 Portainer 连接远程 Docker 主机首先需要在远程 Docker 主机上开启 Docker API vim /usr/lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 # 表示所有地址都能连接到Docker API,也可以指定IP连接,默认端口是2375 systemctl daemon-reload systemctl restart docker.service 然后在 Portainer 再创建一个连接远程 Docker 主机 API 的节点 这时候我们可以使用 Portainer 去管理本地和远程主机上的 Docker 资源了","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker 企业级镜像仓库Harbor","slug":"Docker 企业级镜像仓库 Harbor","date":"2020-07-08T05:33:50.000Z","updated":"2020-09-28T03:09:26.120Z","comments":true,"path":"post/d46af348.html","link":"","permalink":"https://www.missf.top/post/d46af348.html","excerpt":"","text":"Harbor 概述Harbor 是由 VMWare 公司开源的容器镜像仓库。事实上，Harbor 是在 Docker Registry 上进行了相应的企业级扩展，从而获得了更加广泛的应用，这些新的企业级特性包括：管理用户界面，基于角色的访问控制 ，AD/LDAP 集成以及审计日志等，足以满足基本企业需求 Harbor 官网 Harbor GitHub 地址 Harbor 部署条件服务器硬件配置 最低要求：CPU2核/内存4G/硬盘40GB 推荐：CPU4核/内存8G/硬盘160GB 软件 Docker 17.06 版本+ Docker Compose 1.18 版本+ 安装方式 在线安装：从 Docker Hub 下载 Harbor 相关镜像，因此安装软件包非常小 离线安装：安装包包含部署的相关镜像，因此安装包比较大 docker-compose 安装下载二进制文件 https://github.com/docker/compose/releases # docker-compose下载地址 # 下载docker-compose-Linux-x86_64这个二进制文件 配置二进制文件 mv docker-compose-Linux-x86_64 /usr/bin/docker-compose chmod +x /usr/bin/docker-compose docker-compose --help # 安装完成 Harbor HTTP部署下载 Harbor 安装包 wget https://github.com/goharbor/harbor/releases/download/v2.0.1/harbor-offline-installer-v2.0.1.tgz 解压安装包 tar xf harbor-offline-installer-v2.0.1.tgz 修改配置文件 cp harbor.yml.tmpl harbor.yml vim harbor.yml hostname: reg.missf.com # 修改Harbor默认域名 https: # 先注释https相关配置 harbor_admin_password: MF-yihan # 修改Harbor的密码 部署 Harbor ./prepare # 做一系列的准备工作 ./install.sh # 利用docker-compose拉取一系列的镜像,安装好之后就会直接启动 访问 Harbor # 通过本地电脑配置hosts,然后在浏览器访问我们的域名reg.missf.com 登录 Harbor vim /etc/hosts # 添加解析,登录时可以直接访问域名 10.10.110.151 reg.missf.com vim /etc/docker/daemon.json # 配置域名可信任,因为现在没有配置https,而docker默认是使用https协议去连接的,不配置不能登录成功 { \"registry-mirrors\": [\"https://265wemgl.mirror.aliyuncs.com\"], \"insecure registries\": [\"reg.missf.com\"] } systemctl restart docker.service # 修改了daemon.json需要重启docker docker-compose down &amp;&amp; docker-compose up -d # 重启docker之后容器有些会退出,重启harbor重启把容器拉起来 docker login reg.missf.com # 登录成功 Username: admin Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded 推送镜像到 Harbor 仓库 docker tag nginx:1.0 reg.missf.com/library/nginx:1.0 # 推送之前修改镜像的标签(镜像中心/项目/镜像:标签) docker push reg.missf.com/library/nginx:1.0 # 推送镜像，pull拉取镜像也是使用这个标签去拉取 The push refers to repository [reg.missf.com/library/nginx] b1b653ec37ba: Pushed fe503a975c26: Pushed 60165efe909a: Pushed e098d2f9f0dd: Pushed ae9b67129281: Pushed d2039520c249: Pushed 034f282942cd: Pushed 1.0: digest: sha256:a4c155ecb6b7eee5d332764057c29a74d8965de19f9d739f1792cf479c2bf030 size: 1786 查看 Harbor 上推送成功的镜像 Harbor HTTPS部署由于 Harbor 不附带任何证书，它默认使用 HTTP 来提供注册表请求。但是强烈建议为生产环境配置 ssl 证书。这里我们由于是实验测试，使用自签名证书，到时候生产环境配置可以去阿里云购买 ssl 证书 生成自签名 ssl 证书，由于 kubernetes 使用 cfssl 自签证书，这里我们也使用 cfssl 生成自签证书 # 执行这个脚本,安装cfssl并将命令放到/usr/bin/下供我们直接使用 cat cfssl.sh wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 chmod +x cfssl* mv cfssl_linux-amd64 /usr/bin/cfssl mv cfssljson_linux-amd64 /usr/bin/cfssljson mv cfssl-certinfo_linux-amd64 /usr/bin/cfssl-certinfo # 执行这个脚本,生成两个json的ca配置文件并自动生成证书,cfssl是根据json的配置文件去生成ca证书的 cat certs.sh cat > ca-config.json &lt;&lt;EOF { \"signing\": { \"default\": { \"expiry\": \"87600h\" }, \"profiles\": { \"kubernetes\": { \"expiry\": \"87600h\", \"usages\": [ \"signing\", \"key encipherment\", \"server auth\", \"client auth\" ] } } } } EOF cat > ca-csr.json &lt;&lt;EOF { \"CN\": \"kubernetes\", \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"Beijing\", \"ST\": \"Beijing\" } ] } EOF cfssl gencert -initca ca-csr.json | cfssljson -bare ca - # 初始化ca配置文件 cat > reg.missf.com-csr.json &lt;&lt;EOF { \"CN\": \"reg.missf.com\", \"hosts\": [], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"BeiJing\", \"ST\": \"BeiJing\" } ] } EOF cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes reg.missf.com-csr.json | cfssljson -bare reg.missf.com # 生成ca证书 # 执行完上面两个脚本之后我们会得到下面这两个文件 reg.missf.com-key.pem reg.missf.com.pem Harbor 启用 HTTPS https: # https port for harbor, default is 443 port: 443 # The path of cert and key files for nginx certificate: /root/ssh/reg.missf.com.pem private_key: /root/ssh/reg.missf.com-key.pem 重新配置并部署Harbor systemctl restart docker.service ./prepare docker-compose down docker-compose up –d # 重新打开Harbor页面会自动跳转到https,但是由于是自签证书,所以仍会显示不安全 其他 Docker 主机连接 Harbor 仓库 一般 Harbor 仓库都是自己公司内部使用,但是有时候也会开放给别的 Docker 主机去 pull 镜像，如果其他的 Docker 主机需要连接 Harbor，必须要有证书才能连接 # 复制Harbor主机的证书到需要连接Harbor仓库的Docker主机上 mkdir -p /etc/docker/certs.d/reg.missf.com/ # 在Docker主机上创建目录 cp reg.missf.com.pem /etc/docker/certs.d/reg.missf.com/reg.missf.com.crt # 将Harbor主机的证书复制到Docker主机 echo \"10.10.110.151 reg.missf.com\" >> /etc/hosts # 这里由于是实验环境,需要配置域名解析 docker login reg.missf.com # 在其他的docker主机登录到Harbor,就可以pull拉取Harbor仓库的镜像了 Username: admin Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded Harbor主从复制的三种方式学习过 MySQL 主从的同学可以看出，其实 Harbor 的主从复制和 MySQL 的主从复制方式非常相似 主节点的仓库管理新建目标 新建一个目标，就代表本地 Harbor 可以连接到这个远程 Harbor，当我们配置复制管理的目的 Registry 时，可以从新建目标里面填写复制镜像到那个 Harbor 节点 主节点的复制管理新建规则 配置复制模式和目的 Registry，将本地 Harbor 主节点上的镜像(可以使用过滤器进行选择性推送)推送到备用 Harbor 节点上 推送验证 这时候只有有镜像被推送到 Harbor 的主节点，那么 Harbor 主节点就会把镜像 push 到 Harbor 的备用节点，可以查看复制记录 Harbor 运行维护Harbor 容器功能介绍 容器 功能 harbor-core 配置管理中心 harbor-jobservice 负责镜像复制 harbor-log 记录操作日志 harbor-portal Web管理页面和API harbor-db PG数据库 registryctl 镜像存储 nginx 前端代理，负责前端页面和镜像上传/下载转发 redis 会话 Harbor 容器数据持久化目录：/data (这个目录需要定时备份) 日志文件目录：/var/log/harbor","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Dockerfile 定制容器镜像","slug":"Dockerfile 定制容器镜像","date":"2020-06-30T05:33:50.000Z","updated":"2020-09-28T02:59:16.805Z","comments":true,"path":"post/44241b5a.html","link":"","permalink":"https://www.missf.top/post/44241b5a.html","excerpt":"","text":"Dockerfile 介绍Dockerfile 是由一行一行的命令语句组成，并且从上到下执行，支持以#注释行。一般 Dockerfile 的内容分为四个部分，基础镜像信息、维护者信息、镜像操作指令、容器启动时执行指令 Dockerfile 常用指令 指令 描述 FROM 指定构建新镜像时是基于那个镜像，Dockerfile的第一条指令必须为FROM指令，如果在同一个Dockerfile中创建多个镜像可以使用多个FROM指令 LABEL 为镜像添加标签 RUN 每条RUN指令将在当前镜像的基础上执行指定shell命令，并提交为新的镜像 COPY 拷贝宿主机(Dockerfile所在目录的相对路径)的文件或目录到镜像中 ADD 复制指定的&lt;src&gt;到容器中的&lt;dest&gt;，&lt;src&gt;可以是Dockerfile所在目录的文件或目录，可以是一个URL，还可以是一个tar文件(自动解压缩) ENV 指定一个环境变量，会被后续RUN指令使用，并在容器运行时保持 USER 指定运行容器时的用户名或UID，后续的RUN也会使用指定用户 EXPOSE 声明容器运行的服务端口，启动容器时可以将这些端口转发到宿主机或者指定宿主机那个端口映射过来 WORKDIR 为后续的RUN、CMD、ENTRYPOINT指令配置工作目录 VOLUME 在镜像中创建挂载点，这样只要通过该镜像创建的容器都有了挂载点，查看容器详细信息可以看到容器挂载点映射到宿主机的目录 CMD 容器启动时执行指令，每个Dockerfile只能有一条CMD指令，如果有多个CMD指令只有最后一个生效 ENTRYPOINT ENTRYPOINT如果与CMD一起使用，CMD将作为ENTRYPOINT的默认参数，如果有多个ENTRYPOINT指令只有最后一个生效 构建镜像Dockerfile demo # This dockerfile demo for project build to docker images FROM centos:7 LABEL maintainer www.missf.top USER root RUN yum install -y nginx EXPOSE 80 443 VOLUME [\"/usr/local/nginx/\"] CMD [\"/usr/local/nginx/bin\"] Docker build构建镜像 # 在Dockerfile所在的目录下构建镜像,后面的\".\"表示当前目录 docker build -t demo:1.0 . # 构建过程如下 Sending build context to Docker daemon 2.048kB Step 1/8 : FROM centos:7 7: Pulling from library/centos 524b0c1e57f8: Pull complete Digest: sha256:e9ce0b76f29f942502facd849f3e468232492b259b9d9f076f71b392293f1582 Status: Downloaded newer image for centos:7 ---> b5b4d78bc90c Step 2/8 : LABEL maintainer mownejie ---> Running in 7dbcab7ef3ce Removing intermediate container 7dbcab7ef3ce ---> 4db1e9da6977 Step 3/8 : ENV JAVA_HOME /usr/local/java ---> Running in b896cedee458 Removing intermediate container b896cedee458 ---> f8991838d97e Step 4/8 : USER root ---> Running in 8252457198f0 Removing intermediate container 8252457198f0 ---> 96ef213928ad Step 5/8 : RUN yum install -y nginx ---> Running in 8807973810c5...... # -t 指定这个镜像的tag # -f 指定这个Dockerfile文件的位置 CMD 与 ENTRYPOINT 区别CMD用法 # exec形式,首选形式,传参不支持引用变量 CMD [\"executable\", \"param1\", \"param2\"] # CMD作为ENTRYPOINT的默认参数 CMD [\"param1\", \"param2\"] # Shell形式 CMD command param1 param2 ENTRYPOINT用法 ENTRYPOINT [\"executable\", \"param1\", \"param2\"] # 假如配合CMD一起使用,那么[\"param1\", \"param2\"]可以写在CMD作为ENTRYPOINT的默认参数 ENTRYPOINT command param1 param2 总结 1. CMD和ENTRYPOINT指令都可以用来定义运行容器时所使用的命令 2. Dockerfile至少指定一个CMD或ENTRYPOINT 3. CMD可以用作ENTRYPOINT默认参数，或者用作容器的默认命令 4. docker run启动容器时指定&lt;command>，将会覆盖dockerfile定义的CMD 构建 Nginx 容器镜像Dockerfile 内容 FROM centos:7.7.1908 LABEL maintainer www.missf.top RUN yum install -y gcc gcc-c++ make \\ openssl-devel pcre-devel gd-devel \\ iproute net-tools telnet wget curl && \\ yum clean all && rm -rf /var/cache/yum/* ADD nginx-1.16.1.tar.gz / RUN cd nginx-1.16.1 && \\ ./configure --user=nginx --group=nginx \\ --prefix=/usr/local/nginx \\ --with-http_stub_status_module \\ --with-http_ssl_module \\ --with-http_gzip_static_module \\ --with-http_sub_module && \\ make -j4 && make install && \\ mkdir /usr/local/nginx/conf/vhost && \\ cd / && rm -rf nginx* && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime RUN useradd -s /sbin/nologin nginx ENV PATH $PATH:/usr/local/nginx/sbin ENV LANG=\"en_US.utf8\" COPY nginx.conf /usr/local/nginx/conf/nginx.conf COPY php.conf /usr/local/nginx/conf/vhost/php.conf WORKDIR /usr/local/nginx EXPOSE 80 443 CMD [\"nginx\", \"-g\", \"daemon off;\"] 目录结构 [root@localhost /Dockerfile/nginx]# ll total 1028 -rw-r--r-- 1 root root 890 Jul 6 18:58 Dockerfile -rw-r--r-- 1 root root 1032630 Jan 14 09:53 nginx-1.16.1.tar.gz -rw-r--r-- 1 root root 3297 Jul 6 18:46 nginx.conf -rw-r--r-- 1 root root 362 Jul 6 20:13 php.conf -rw-r--r-- 1 root root 128 Jul 6 18:51 start 构建PHP容器镜像Dockerfile 内容 FROM centos:7.7.1908 LABEL maintainer www.missf.top RUN yum install -y epel-release && \\ yum install -y sqlite-devel libmcrypt-devel mhash-devel libxslt-devel \\ libjpeg-devel libpng libpng-devel freetype freetype-devel \\ libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel libjpeg \\ glib2 glib2-develbzip2 bzip2-devel ncurses ncurses-devel \\ curl-devel e2fsprogs e2fsprogs-devel krb5 gcc krb5-devel libidn \\ openssl-devel libsqlite3x-devel oniguruma-devel openssl libidn-devel \\ iproute net-tools telnet wget curl && \\ yum clean all && rm -rf /var/cache/yum/* ADD php-7.4.0.tar.gz / RUN cd /php-7.4.0 && \\ ./configure --prefix=/usr/local/php \\ --with-config-file-path=/usr/local/php/etc \\ --enable-opcache --with-curl --enable-fpm \\ --enable-gd --with-iconv --enable-mbstring \\ --with-mysqli --with-openssl --enable-static \\ --enable-sockets --enable-inline-optimization \\ --with-zlib --disable-ipv6 --disable-fileinfo \\ --with-mcrypt --enable-hash --with-jpeg-dir --with-png-dir \\ --with-freetype-dir --with-pdo-mysql --disable-debug && \\ make -j 4 && make install && \\ cp /php-7.4.0/php.ini-production /usr/local/php/etc/php.ini && \\ cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf && \\ cp /usr/local/php/etc/php-fpm.d/www.conf.default /usr/local/php/etc/php-fpm.d/www.conf && \\ sed -i \"90a \\daemonize = no\" /usr/local/php/etc/php-fpm.conf && \\ mkdir /usr/local/php/log && \\ cd / && rm -rf php* && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime ENV PATH $PATH:/usr/local/php/sbin ENV LANG=\"en_US.utf8\" COPY php.ini /usr/local/php/etc/ COPY php-fpm.conf /usr/local/php/etc/ COPY www.conf /usr/local/php/etc/php-fpm.d/ WORKDIR /usr/local/php EXPOSE 9000 CMD [\"php-fpm\"] 目录结构 [root@localhost /Dockerfile/php]# ll total 16144 -rw-r--r-- 1 root root 1758 Jul 6 18:53 Dockerfile -rw-r--r-- 1 root root 16418792 Jul 1 10:39 php-7.4.0.tar.gz -rw-r--r-- 1 root root 5394 Jul 1 21:51 php-fpm.conf -rw-r--r-- 1 root root 72953 Jul 1 22:09 php.ini -rw-r--r-- 1 root root 93 Jul 6 18:56 start -rw-r--r-- 1 root root 19616 Jul 6 18:53 www.conf 容器化搭建个人博客自定义网络 docker network create lnmp # 将多个容器加入到一个自定义网络 创建 MySQL 容器 docker volume create mysql docker run -e MYSQL_ROOT_PASSWORD=mwj123456 -e MYSQL_DATABASE=wordpress -p 53306:3306 --name \"mysql\" --network lnmp --mount src=mysql,dst=/var/lib/mysql/ -d mysql:5.7 # 将MySQL数据库的数据持久化到mysql这个数据卷 创建 PHP 容器 docker volume create nginx docker run --name php --network lnmp --mount src=nginx,dst=/usr/local/nginx/html/ -d php:1.0 # 这里先启动PHP容器再启动Nginx容器,因为Nginx要去连接PHP容器,如果PHP容器没有启动,那Nginx就因为无法连接到PHP所有退出了 # 这里需要把Nginx代码也挂载到PHP容器内,而且容器内的路径要与Nginx配置文件路径一致 # 因为Nginx配置文件将所有*.php的请求都通过fastcgi_pass代理到PHP容器去处理,所有需要把代码也挂载到PHP容器内,不然访问php文件会提示未找到文件 创建 Nginx 容器 docker container run --name \"nginx\" --mount src=nginx,dst=/usr/local/nginx/html --network lnmp -p 80:80 -p 443:443 -d nginx:1.0 部署 WordPress 代码 docker volume inspect nginx # 先查看数据卷在宿主机上的目录,然后把代码解压到对应的目录下 tar xf wordpress-5.4.2-zh_CN.tar.gz -C /var/lib/docker/volumes/nginx/_data/ # 这时候通过访问宿主机的IP就能看到WordPress的安装页面了,如果无法对wp-config.php文件写入,就手动创建并写入 构建 Tomcat 容器镜像Dockerfile 内容 FROM centos:7.7.1908 LABEL maintainer www.missf.top ADD jdk-8u211-linux-x64.tar.gz /usr/local/ ADD apache-tomcat-8.5.57.tar.gz /usr/local/ RUN mv /usr/local/jdk1.8.0_211 /usr/local/jdk && \\ mv /usr/local/apache-tomcat-8.5.57 /usr/local/tomcat && \\ rm -rf /usr/local/tomcat/webapps/* ENV JAVA_HOME /usr/local/jdk ENV CLASSPATH ${JAVA_HOME}/lib/dt.jar:${JAVA_HOME}/lib/tools.jar ENV CATALINA_HOME /usr/local/tomcat ENV PATH $PATH:${JAVA_HOME}/bin:${CATALINA_HOME}/lib:${CATALINA_HOME}/bin RUN sed -i '1a JAVA_OPTS=\"-Djava.security.egd=file:/dev/./urandom\"' ${CATALINA_HOME}/bin/catalina.sh && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime WORKDIR ${CATALINA_HOME} EXPOSE 8080 CMD [\"catalina.sh\", \"run\"] 目录结构 [root@localhost /Dockerfile/tomcat]# ll total 200568 -rw-r--r-- 1 root root 10379806 Jul 7 11:19 apache-tomcat-8.5.57.tar.gz -rw-r--r-- 1 root root 728 Jul 7 19:41 Dockerfile -rw-r--r-- 1 root root 194990602 Jul 2 2019 jdk-8u211-linux-x64.tar.gz 部署测试代码 docker volume inspect tomcat # 查看Tomcat容器代码目录持久化到宿主机的目录 ll /var/lib/docker/volumes/tomcat/_data # 放到这个目录的war包会被自动解压 total 17840 drwxr-x--- 4 root root 37 Jul 7 21:34 ROOT -rw-r--r-- 1 root root 18265402 Jun 20 13:08 ROOT.war 构建 Java 微服务项目镜像Dockerfile 内容 # 一个容器内只跑一个jar包 FROM java:8-jdk-alpine LABEL maintainer www.missf.top ENV JAVA_OPTS=\"$JAVA_OPTS -Dfile.encoding=UTF8 -Duser.timezone=GMT+08 -Xms128m -Xmx128m\" RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories && \\ apk add -U tzdata && \\ mkdir /projects && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime COPY hello.jar /projects/ EXPOSE 8888 CMD [\"/bin/sh\", \"-c\", \"java -jar $JAVA_OPTS /projects/hello.jar\"] Dockerfile 最佳实践减少镜像层：一次 RUN 指令形成新的一层镜像，shell 命令尽量写在一行，减少镜像层 优化镜像大小：在形成新的一层镜像之后，如果没有在同一层删除缓存或者没用的文件，那么这些文件都会被带到下一层，所有要在每一层清理对应的残留数据，减少镜像大小 减少网络传输：例如镜像所需要下载的软件包，mvn 仓库 多阶段构建：代码编译、部署在一个 Dockerfile 完成，只会保留部署阶段产生的数据 选择最小的基础镜像：例如 alpine","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker 容器网络","slug":"Docker 容器网络","date":"2020-06-23T01:49:44.000Z","updated":"2020-09-28T02:52:35.605Z","comments":true,"path":"post/bc1d2f66.html","link":"","permalink":"https://www.missf.top/post/bc1d2f66.html","excerpt":"","text":"bridge 模式当启动 Docker 进程之后，Docker 会默认创建一个名为 docker0 的虚拟网桥，创建容器时如果不指定网络，默认就是添加到这个网桥中。这样 Docker 主机上的所有容器都可以通过交换机的方式连接在一个二层网络中。创建容器时，Docker 会先创建容器的虚拟网卡，容器的虚拟网卡去连接 Docker 主机的 docker0 虚拟网桥，相当于用一根网线将容器和 Docker 主机连接起来。虚拟网卡连接到 docker0 子网后，由 docker0 虚拟网桥分配 IP 给容器的虚拟网卡使用，并设置 docker0 虚拟网桥的 IP 地址为容器的默认网关。除了 Docker 启动时默认创建的 bridge 默认网络，我们还可以自定义 bridge 网络。相比默认的具备内部 DNS 发现，bridge 网络模式还可以通过容器名去实现容器之间的网络通信 查看 Docker 宿主机上的 docker0 虚拟网桥，默认网段是 172.17.0.1，安装 Docker 之后默认创建的 ip a s docker0 3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default link/ether 02:42:9f:dc:ee:74 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:9fff:fedc:ee74/64 scope link valid_lft forever preferred_lft forever 查看默认定义好的网络模式，这里没有 container 模式是因为 container 是启动容器时直接指定的 docker network ls NETWORK ID NAME DRIVER SCOPE a42d2b0e12ec bridge bridge local 168bbf4b0447 host host local ec481d03e2a1 none null local 21be62f7b97e webserver bridge local 查看 bridge 网络模式的详细信息 docker network inspect bridge [ { \"Name\": \"bridge\", \"Id\": \"a42d2b0e12ec0e039e7c4686099468585b88c8df8b639eaa780700980adb9e1b\", \"Created\": \"2020-06-23T17:16:25.717600267+08:00\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [ { \"Subnet\": \"172.17.0.0/16\", \"Gateway\": \"172.17.0.1\" } ] }, \"Internal\": false, \"Attachable\": false, \"Ingress\": false, \"ConfigFrom\": { \"Network\": \"\" }, \"ConfigOnly\": false, \"Containers\": { \"253d0d8f196182eccaa52238068513cebfbf2abe69d2a7980e40d8c136b53960\": { \"Name\": \"nginx\", \"EndpointID\": \"7fd4576f90bc1d0fd966ed5794710dd43461d077ea32f99e54a8b3c56ba1de08\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" }, \"8652448b6f9a99d9b9a6c70277ea23924b21df57289d4deb29a146974ad4c4dd\": { \"Name\": \"centos7\", \"EndpointID\": \"e112927463f07a606a3a019f3af7400c711b9a903fec19c130b27c7d5f53d359\", \"MacAddress\": \"02:42:ac:11:00:03\", \"IPv4Address\": \"172.17.0.3/16\", \"IPv6Address\": \"\" } }, \"Options\": { \"com.docker.network.bridge.default_bridge\": \"true\", \"com.docker.network.bridge.enable_icc\": \"true\", \"com.docker.network.bridge.enable_ip_masquerade\": \"true\", \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\", \"com.docker.network.bridge.name\": \"docker0\", \"com.docker.network.driver.mtu\": \"1500\" }, \"Labels\": {} } ] 安装网桥管理工具包 yum install -y bridge-utils.x86_64 查看虚拟网桥上的接口信息 brctl show docker0 bridge name bridge id STP enabled interfaces docker0 8000.02429fdcee74 no veth81bdc19 vetha8f66a7 创建类型为 bridge 的自定义网桥 docker network create webserver 21be62f7b97ebfc9ce6f6a1aaaffd59a4a220c6b778f36a98c72162023b5c5e5 启动容器时指定使用自定义创建的 webserver 网桥(具备DNS发现) docker container run -itd --name \"app1\" --network webserver centos:7.7.1908 98efd7fb3c63c0bd487039b7ef00925d786e0499f10d76003afa2277cc93b404 docker container run -itd --name \"app2\" --network webserver centos:7.7.1908 c81e58db50ca74111d46f460ff322378b45414a36804738597559ec3c06cf542 docker container run -itd --name \"app3\" --network webserver centos:7.7.1908 41fb1a7dd161c03a158a104da54dcfa3b226035feceecabd003f7a18e91bff61 查看容器的 IP 地址 docker inspect --format='{{.NetworkSettings.Networks.webserver.IPAddress}}' app1 172.18.0.2 docker inspect --format='{{.NetworkSettings.Networks.webserver.IPAddress}}' app2 172.18.0.3 docker inspect --format='{{.NetworkSettings.Networks.webserver.IPAddress}}' app3 172.18.0.4 容器之间的通信测试，自定义的 bridge 网桥相比默认的 bridge 网桥具备内部 DNS 发现， IP 和主机名都是可以 PING 通 ping 172.18.0.2 PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data. 64 bytes from 172.18.0.2: icmp_seq=1 ttl=64 time=0.203 ms 64 bytes from 172.18.0.2: icmp_seq=2 ttl=64 time=0.085 ms ping 98efd7fb3c63 # 如果启动容器时不指定自定义的网桥,那就会使用默认的bridge模式,这样是不能PING通主机名的 PING 98efd7fb3c63 (172.18.0.2) 56(84) bytes of data. 64 bytes from app1.webserver (172.18.0.2): icmp_seq=1 ttl=64 time=0.402 ms 64 bytes from app1.webserver (172.18.0.2): icmp_seq=2 ttl=64 time=0.100 ms host模式如果启动容器时指定 host 模式，那么这个容器将不会获得一个独立的 Network namespace，而是和宿主机共用一个 Network namespace。容器不会虚拟出自己的网卡，而是使用宿主机的 IP 和端口。这种无需 NAT 转换的网络模式无需再映射容器与宿主机之间的端口，在提高网络传输性能的同时，造成了网络环境隔离性弱化。容器之间不再拥有隔离独立的网络，Docker host 上已使用的端口就不能再用了 启动一个 Nginx 容器，再查看宿主机上的 80 端口是否被使用 docker container run -itd --name \"host_nginx\" --network=host nginx:1.1 查看宿主机上的 80 端口是否被 Nginx 容器所使用 netstat -lntup | grep 80 tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 7358/nginx: master 查看宿主机上 Nginx 进程的父进程是否为 Docker ps -afx | grep containerd -A 1 1100 ? Ssl 1:18 /usr/bin/containerd 7341 ? Sl 0:00 \\_ containerd-shim -namespace moby -workdir /var/lib/containerd/io.containerd.runtime.v1.linux/moby/adf66250b1fcd95c2531f04f8504bea614dd90903f4f074e150ce6202895a023 -address /run/containerd/containerd.sock -containerd-binary /usr/bin/containerd -runtime-root /var/run/docker/runtime-runc 7358 pts/0 Ss+ 0:00 \\_ nginx: master process nginx -g daemon off; # 这个nginx进程是容器中启动的nginx进程,这也正如我们前面所说,使用host模式启动容器,容器会和宿主机共用一个Network namespace 进入容器中查看网卡信息，可以看到宿主机上的网卡也会显示，这就是共用了一个 Network namespace 的结果 ifconfig br-21be62f7b97e: flags=4099&lt;UP,BROADCAST,MULTICAST> mtu 1500 inet 172.18.0.1 netmask 255.255.0.0 broadcast 172.18.255.255 inet6 fe80::42:6fff:fe77:c9f0 prefixlen 64 scopeid 0x20&lt;link> ether 02:42:6f:77:c9:f0 txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 docker0: flags=4099&lt;UP,BROADCAST,MULTICAST> mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:9fff:fedc:ee74 prefixlen 64 scopeid 0x20&lt;link> ether 02:42:9f:dc:ee:74 txqueuelen 0 (Ethernet) RX packets 3 bytes 114 (114.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 8 bytes 677 (677.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ens32: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 10.10.110.150 netmask 255.255.255.0 broadcast 10.10.110.255 inet6 fe80::20c:29ff:fec4:cbac prefixlen 64 scopeid 0x20&lt;link> ether 00:0c:29:c4:cb:ac txqueuelen 1000 (Ethernet) RX packets 91694 bytes 118390130 (112.9 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 41857 bytes 2875558 (2.7 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73&lt;UP,LOOPBACK,RUNNING> mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host> loop txqueuelen 1000 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 none 模式容器启动时指定 none 模式是获取独立的 Network namespace，但不为容器进行任何网络配置。容器内部只有 loopback 网络设备不会再有其他的网络资源，将网络创建的责任完全交给用户。作为 Docker 开发者，才能在这基础做其他无限多可能的网络定制开发，这种方式可以实现更加灵活复杂的网络，同时也体现了Docker 设计理念的开放 启动一个 none 模式的容器 docker container run -itd --name \"none_centos\" --network=none centos:7.7.1908 进入容器查看网卡设备信息 docker container exec -it none_centos /bin/bash ifconfig # 这里只有一个回环口地址,因为none模式不会对容器进行任何网络配置 lo: flags=73&lt;UP,LOOPBACK,RUNNING> mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host> loop txqueuelen 1000 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 container 模式创建新的容器时指定和已存在的容器共享一个 Network namespace，这些容器之间共享 IP、端口范围等网络配置，容器之间传输效率高。两个容器除了网络资源共享之外，其他资源还是隔离的。虽然多个容器共享网络环境，但是多个容器形成的整体依然与宿主机以及其他容器形成网络隔离 启动一个名为 server1 的容器 docker container run -itd --name \"server1\" centos:7.7.1908 再启动两个容器，把它们加入到 server1 这个容器的 Network namespace docker container run -itd --name \"server2\" --network=container:server1 centos:7.7.1908 docker container run -itd --name \"server3\" --network=container:server1 centos:7.7.1908 查看各个容器的 IP 地址 docker inspect --format='{{.NetworkSettings.Networks.bridge.IPAddress}}' server1 172.17.0.3 docker inspect --format='{{.NetworkSettings.Networks.bridge.IPAddress}}' server2 &lt;no value> docker inspect --format='{{.NetworkSettings.Networks.bridge.IPAddress}}' server3 &lt;no value> 这里我们在查看 server2 和 server3 容器 IP 时，显示为 &lt;no value&gt;，其实它们是和 server1 共用一个 Network namespace 的 docker container exec -it server2 /bin/bash [root@41436b0be6f7 /]# ifconfig eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 172.17.0.3 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:03 txqueuelen 0 (Ethernet) RX packets 10969 bytes 20985758 (20.0 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 6234 bytes 344851 (336.7 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 docker container exec -it server3 /bin/bash [root@41436b0be6f7 /]# ifconfig eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 172.17.0.3 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:03 txqueuelen 0 (Ethernet) RX packets 10969 bytes 20985758 (20.0 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 6234 bytes 344851 (336.7 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 # 两个容器的IP、主机名都相同 容器虚拟网卡和 docker0 网桥的 veth pair 配对veth 是成对出现的虚拟网络设备， 发送到 veth 一端虚拟设备的请求会从另一端的虚拟设备中发出。创建一个容器的同时会为这个容器创建一对虚拟网卡 veth pair，这个成对出现的虚拟网卡 veth pair，分别放到宿主机和容器中，宿主机一端桥接到默认的 docker0 或者自定义的网桥上，容器一端放到新创建容器的 Network namespace 中，并把名字修改为 eth0。虚拟网卡 veth pair 就像是一根网线，将宿主机的 docker0 和容器连接起来 docker container run -itd --name \"server1\" centos:7.7.1908 # 创建容器 brctl show docker0 # 查看宿主机上的docker0网桥 bridge name bridge id STP enabled interfaces docker0 8000.02429fdcee74 no veth7459cf7 ip a s veth7459cf7 # 这是虚拟网卡veth pair在宿主机上的一端 34: veth7459cf7@if33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 86:54:3c:c6:70:6b brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::8454:3cff:fec6:706b/64 scope link valid_lft forever preferred_lft forever [root@ec94bfbd724f /]# ifconfig # 容器内部的eth0网卡是虚拟网卡veth pair在容器中的一端 eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 172.17.0.2 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:02 txqueuelen 0 (Ethernet) RX packets 5495 bytes 10346440 (9.8 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 3386 bytes 186731 (182.3 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 容器网络访问原理图 容器网络实现的核心技术: iptablesdocker 容器的跨网络隔离与通信，是使用 iptables 去实现的 源IP地址变换规则docker 在安装完成后，将默认在宿主机上增加一些 iptables 规则，以用于 docker 容器和容器之间的隔离与通信，可以使用使用 iptables-save 命令查看 iptables-save | grep docker -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE 参数说明: -s:源地址172.17.0.0/16 -o:指定数据报文流出接口为docker0 -j:动作为MASQUERADE(地址伪装) 上面这条规则关系着 Docker 容器和外界的通信，含义是源地址为 172.17.0.0/16 的数据包(即Docker容器发出的数据)，当不是从 docker0 网卡发出时做 SNAT(源地址转换)。这样使得 Docker 容器访问外网的流量，在外界看来就是从宿主机上发出的，外界感觉不到 Docker 容器的存在 目标IP地址变换规则从 Docker 容器访问外网的流量，在外部看来就是从宿主机上发出的，外部感觉不到 Docker 容器的存在。其实这也是由相应的 iptables 规则去实现的 docker container run -itd --name \"nginx\" -p 80:80 nginx:1.17 查看创建容器之后生成的 iptables 规则 iptables-save | grep docker -A DOCKER ! -i docker0 -p tcp -m tcp --dport 80 -j DNAT --to-destination 172.17.0.2:80 -A DOCKER -d 172.17.0.2/32 ! -i docker0 -o docker0 -p tcp -m tcp --dport 80 -j ACCEPT 这两条规则将访问宿主机的 80 端口的流量转发到了 172.17.0.2 的 80 端口上(即真正提供服务的 Docker 容器的IP+端口)，所以外界访问 Docker 容器是通过 iptables 做DNAT (目的地址转换)实现的 etcd 和 flannel 实现 docker 跨主机通信flannel 是一种基于 overlay 网络的跨主机容器网络解决方案，也就是将 TCP 数据包封装在另一种网络包里面进行路由转发和通信，flannel 是 CoreOS 团队针对Kubernetes 设计的一个网络规划服务，让集群中的不同节点主机创建的容器都具有全集群唯一的虚拟 ip 地址，flannel 使用 go 语言编写 实现原理 flannel 为每个 host 分配一个 subnet，容器从这个 subnet 中分配 ip，这些 ip 可以在 host 间路由，容器间无需使用 nat 和端口映射即可实现跨主机通信。每个 subnet 都是从一个更大的 ip 池中划分的，flannel 会在每个主机上运行一个叫 flanneld 的 agent，其职责就是从池子中分配 subnet。etcd 相当于一个数据库，flannel 使用 etcd 存放网络配置、已分配的 subnet、host 的 IP 等信息 实验环境 节点 安装软件 系统 内核版本 docker版本 10.10.110.150(master) etcd、flannel、docker CentOS7.7.1908 3.10.0-1062.el7.x86_64 19.03.12 10.10.110.151(slave) flannel、docker CentOS7.7.1908 3.10.0-1062.el7.x86_64 19.03.12 master节点配置安装配置 etcd yum install -y etcd # 安装etcd,由于不配置etcd集群,所以只在10.10.110.150节点安装etcd就行了 sed -i \"s/localhost/10.10.110.150/g\" /etc/etcd/etcd.conf # 修改etcd配置文件 systemctl start etcd.service # 启动etcd 安装配置 flannel yum install -y flannel sed -i \"s/127.0.0.1/10.10.110.150/g\" /etc/sysconfig/flanneld # flannel连接到etcd,slave连接也是填写master的IP etcdctl --endpoints=\"http://10.10.110.150:2379\" set /atomic.io/network/config '{ \"Network\":\"172.17.0.0/16\", \"Backend\": {\"Type\": \"vxlan\"}} ' # 配置etcd的子网,如果这一步不配置,那么etcd无法启动 systemctl start flanneld.service # 启动flannel slave节点配置安装配置 flannel yum install -y flannel sed -i \"s/127.0.0.1/10.10.110.150/g\" /etc/sysconfig/flanneld # 这里是填写master节点的IP,让slave连接到master的etcd,多slave也一样 systemctl start flanneld.service # 确保slave节点能连接到master节点的etcd,如果不关闭防火墙,那必须打开2379端口 配置 Docker 使用 flannel 的网络master 节点 vim /usr/lib/systemd/system/docker.service EnvironmentFile=/run/flannel/docker # 加载这个文件里面的变量,这个文件记录了flannel分配给master节点的子网信息(slave也会有自己的子网) ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock $DOCKER_NETWORK_OPTIONS # 这个变量是上面文件中定义的,意思是在启动容器时指定使用flannel分配的子网去配置容器的网络 iptables -P FORWARD ACCEPT # 开启iptables转发,如不开启即使配置成功也不能通信 systemctl daemon-reload systemctl restart flanneld.service # 这里必须先重启flannel再重启docker,这时候启动容器就会使用flannel去配置容器的网络 systemctl restart docker.service slave 节点配置 vim /usr/lib/systemd/system/docker.service EnvironmentFile=/run/flannel/docker # 查看slave节点上这个文件,网段是和master节点不一样的 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock $DOCKER_NETWORK_OPTIONS iptables -P FORWARD ACCEPT systemctl daemon-reload systemctl restart flanneld.service systemctl restart docker.service 查看宿主机的IP变化master 节点 ip a 3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:e3:89:96:4e brd ff:ff:ff:ff:ff:ff inet 172.17.98.1/24 brd 172.17.98.255 scope global docker0 valid_lft forever preferred_lft forever 4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default link/ether 02:6f:fa:71:67:f7 brd ff:ff:ff:ff:ff:ff inet 172.17.98.0/32 scope global flannel.1 valid_lft forever preferred_lft forever inet6 fe80::6f:faff:fe71:67f7/64 scope link valid_lft forever preferred_lft forever # docker0虚拟网卡和flannel虚拟网卡已经在同一网段，这时候说明配置成功 slave 节点 ip a 3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:f2:30:ba:34 brd ff:ff:ff:ff:ff:ff inet 172.17.75.1/24 brd 172.17.75.255 scope global docker0 valid_lft forever preferred_lft forever 4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default link/ether f6:ae:d1:c0:e1:a7 brd ff:ff:ff:ff:ff:ff inet 172.17.75.0/32 scope global flannel.1 valid_lft forever preferred_lft forever inet6 fe80::f4ae:d1ff:fec0:e1a7/64 scope link valid_lft forever preferred_lft forever 在两个节点创建容器相互 ping 验证master 节点 docker run -it busybox sh / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:62:02 inet addr:172.17.98.2 Bcast:172.17.98.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1450 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:656 (656.0 B) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # ping 172.17.75.2 PING 172.17.75.2 (172.17.75.2): 56 data bytes 64 bytes from 172.17.75.2: seq=0 ttl=62 time=0.492 ms 64 bytes from 172.17.75.2: seq=1 ttl=62 time=0.353 ms 64 bytes from 172.17.75.2: seq=2 ttl=62 time=0.342 ms slave 节点 docker run -it busybox sh / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:4B:02 inet addr:172.17.75.2 Bcast:172.17.75.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1450 Metric:1 RX packets:6 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:516 (516.0 B) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # ping 172.17.98.2 PING 172.17.98.2 (172.17.98.2): 56 data bytes 64 bytes from 172.17.98.2: seq=0 ttl=62 time=1.945 ms 64 bytes from 172.17.98.2: seq=1 ttl=62 time=0.344 ms 64 bytes from 172.17.98.2: seq=2 ttl=62 time=0.384 ms 注意：如果不能 ping 通，先重启 flannel 再重启 Docker 试试","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker 容器数据持久化","slug":"Docker 容器数据持久化","date":"2020-06-19T02:14:10.000Z","updated":"2020-09-28T02:42:33.940Z","comments":true,"path":"post/a7b8d397.html","link":"","permalink":"https://www.missf.top/post/a7b8d397.html","excerpt":"","text":"容器数据持久化的三种方式由于容器的镜像分层机制，我们在容器里面创建文件或者修改文件，结果都会保存在容器的可读写层中，一旦容器被销毁，那么这个读写层也会随着容器销毁而消失。而且当一个容器需要和其他容器的读写层进行数据交互时，也会显得非常困难。于是在将容器数据持久化到宿主机方面，Docker 为我们提供了三种持久化的方式 volumes 持久化方式 volumes 由 Docker 负责创建、管理。用户可以显式的调用命令 docker volume create 创建 volume，也可以通过 container、service 的启动隐式创建。Docker 创建的 volumes 本质上还是宿主机文件系统中的一个目录，一个 volumes 可以供多个容器使用，即使没有容器使用此 volumes，它也不会自动删除，除非用户明确删除它。如果用户显式创建 volumes 则需要给它一个名称，如果是隐式创建 volumes 则 Docker 会为它分配一个在宿主机范围内唯一的名字。通过使用第三方提供的 volume driver，用户可以将数据持久到远程主机或者云存储中，也就是说存储空间可以不由宿主机提供 # 创建volumes docker volume create nginx_volumes # 查看volumes docker volume ls # 查看卷详细信息 docker volume inspect nginx_volumes [ { \"CreatedAt\": \"2020-06-19T18:47:49+08:00\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/nginx_volumes/_data\", # 这是volumes在宿主机上的真实路径 \"Name\": \"nginx_volumes\", \"Options\": {}, \"Scope\": \"local\" } ] # 清理volumes docker volume rm nginx_volumes 将 Nginx 容器的 html 目录映射到宿主机的 nginx_volumes 目录 # 创建数据持久化的容器,如果卷不存在则自动创建 docker container run -itd --name \"nginx1\" -p 80:80 -v nginx_volumes:/usr/share/nginx/html nginx:1.17 # -v方式 docker container run -itd --name \"nginx1\" -p 80:80 --mount src=nginx_volumes,dst=/usr/share/nginx/html nginx:1.17 # --mount方式 # 查看nginx_volumes在宿主机的真实目录 ll /var/lib/docker/volumes/nginx_volumes/_data total 8 -rw-r--r-- 1 root root 494 Apr 14 22:19 50x.html # 这时候nginx容器内部的文件已经被映射到宿主机上了 -rw-r--r-- 1 root root 612 Apr 14 22:19 index.html # 修改宿主机上的index.html文件 echo \"nginx_volumes test\" > /var/lib/docker/volumes/nginx_volumes/_data/index.html # 访问宿主机的80端口(前面启动容器时将容器的80端口绑定到宿主机的80端了) curl 10.10.110.150 nginx_volumes test # nginx容器内的文件确实被修改成功 bind mounts 持久化方式 bind mounts 本质上是容器共享宿主机文件系统，比如 Docker 将宿主机的 /etc/resov.conf 文件 bind mount 到容器里，两者会使用相同的 dns 服务器 # 创建容器,将宿主机的/nginx/app绑定到容器的/usr/share/nginx/html目录 docker container run -itd --name \"nginx1\" --mount type=bind,src=/nginx/app,dst=/usr/share/nginx/html nginx:1.17 docker container run -itd --name \"nginx1\" -v /nginx/app:/usr/share/nginx/html nginx:1.17 # 查看宿主机和容器的目录 ls /nginx/app docker exec -it nginx1 ls /usr/share/nginx/html # 两个目录都为空,这是因为bind mounts是将宿主机的目录绑定到容器的目录,容器目录已有的内容会被隐藏(bind mounts以宿主机目录为主) 注意：如果源文件或源目录不存在，则不会自动创建。如果容器目录为非空目录，则容器目录现有内容会被宿主机目录内容所隐藏 tmpfs 持久化方式 出于安全原因，或者容器性能优化的原因有时候不需要容器的数据长久保存时可以使用这种方式。将容器数据挂载存储在宿主机的内存中，避免写入容器可写层，提高容器性能 volumes 和 bind mounts 的使用场景和区别volumes 适合多个容器需要共享数据、将数据保存到远程主机或云上等场景。bind mounts 适合将宿主机的系统配置文件共享给容器。volumes 是将容器内部的数据映射到宿主机对应的 volumes 目录，如果容器内部是一个非空目录，volumes 目录也是一个非空目录，那么两个目录的文件会合并。而 bind mounts 是将宿主机上任意位置的目录或文件挂载到容器中，如果宿主机的目录非空，那么容器目录的数据将会被宿主机目录的数据隐藏，容器内的数据要卸除挂载后才会恢复 bind mounts 和volumes 都可以通过使用标志 “-v” 或 “–volume” 来挂载到容器中，只是格式有些许不同。然而，在 Docker17.06 及其以上版本中，我们推荐使用 “–mount” 来对容器或服务进行这三种方式的挂载，因为这种格式更加清晰","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker 容器管理","slug":"Docker 容器管理","date":"2020-06-17T08:23:38.000Z","updated":"2020-09-28T02:39:54.868Z","comments":true,"path":"post/39a5b294.html","link":"","permalink":"https://www.missf.top/post/39a5b294.html","excerpt":"","text":"创建容器常用选项 选项 描述 -i, –interactive 交互式 -t, –tty 分配一个伪终端 -d, –detach 运行容器到后台 -e, –env 设置环境变量 -p, –publish list 发布容器端口到主机 -P, –publish-all 发布容器所有EXPOSE的端口到宿主机随机端口 –name string 指定容器名称 -h, –hostname 设置容器主机名 –ip string 指定容器IP,只能用于自定义网络 –network 连接容器到一个网络 –mount mount 将文件系统附加到容器 -v, –volume list 绑定挂载一个卷 –restart string 容器退出时重启策略,默认no,可选值:[always|on-failure] 创建容器示例 # 启动一个nginx容器,指定名字、映射端口、设置重启 # 如果不加-it分配一个交互式的伪终端,容器就会直接退出了,容器内的第一个程序必须一直处于前台运行(必须hang住) docker container run -itd --name \"nginx\" -p 80:80 --restart always nginx:1.17 容器资源限制 选项 描述 -m，–memory 容器可以使用的最大内存量 –memory-swap 允许交换到磁盘的内存量 –memory-swappiness=&lt;0-100&gt; 容器使用SWAP分区交换的百分比(0-100，默认为-1) –oom-kill-disable 禁用OOM Killer –cpus 可以使用的CPU数量 –cpuset-cpus 限制容器使用特定的CPU核心，如(0-3, 0,1) –cpu-shares CPU共享(相对权重) 内存限额示例 # 允许容器最多使用500M内存和600M的swap,并禁用OOM Killer docker container run -d --name \"nginx1\" --memory=\"500M\" --memory-swap=\"600M\" --oom-kill-disable nginx:1.17 CPU限额示例 # 允许容器最多使用两个的CPU docker container run -d --name \"nginx2\" --cpus=\"2\" nginx:1.17 # 允许容器最多使用50%的CPU docker container run -d --name \"nginx3\" --cpus=\".5\" nginx:1.17 容器资源配额扩容# 容器资源可更新选项 docker update --help Usage: docker update [OPTIONS] CONTAINER [CONTAINER...] Update configuration of one or more containers Options: --blkio-weight uint16 Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0) --cpu-period int Limit CPU CFS (Completely Fair Scheduler) period --cpu-quota int Limit CPU CFS (Completely Fair Scheduler) quota --cpu-rt-period int Limit the CPU real-time period in microseconds --cpu-rt-runtime int Limit the CPU real-time runtime in microseconds -c, --cpu-shares int CPU shares (relative weight) --cpus decimal Number of CPUs --cpuset-cpus string CPUs in which to allow execution (0-3, 0,1) --cpuset-mems string MEMs in which to allow execution (0-3, 0,1) --kernel-memory bytes Kernel memory limit -m, --memory bytes Memory limit --memory-reservation bytes Memory soft limit --memory-swap bytes Swap limit equal to memory plus swap: '-1' to enable unlimited swap --pids-limit int Tune container pids limit (set -1 for unlimited) --restart string Restart policy to apply when a container exits # 更新正在运行中的容器内存限额 docker update --memory=\"400M\" --memory-swap=\"500M\" --restart=\"on-failure\" 4e860294d239 管理容器常用命令 选项 描述 ls 列出容器 inspect 查看一个或多个容器详细信息 exec 在运行容器中执行命令 commit 创建一个新镜像来自一个容器 cp 拷贝文件/文件夹到一个容器 logs 获取一个容器日志 port 列出或指定容器端口映射 top 显示一个容器运行的进程 stats 显示容器资源使用统计 stop/start/restart 停止/启动一个或多个容器 rm 删除一个或多个容器 prune 移除已停止的容器 管理容器示例 # 列出真正运行的所有容器 docker container ls -a # 获取一个容器日志 docker container logs --tail=\"5\" nginx # 仅列出最新N条容器log信息 docker container logs -f nginx # 跟踪log信息输出 docker logs --since=\"2020-06-18\" --tail=\"10\" nginx # 显示某个时间之后的最新十条log信息 # 进入正在运行的容器中执行命令 docker container exec -it nginx /bin/bash # 显示一个容器运行的进程 docker container top nginx # 删除一个或删除全部容器 docker container rm -f nginx docker container rm -f $(docker container ls -q) 容器实现核心技术：Namespace在容器化中，一台物理计算机可以运行多个不同操作系统(一个容器就类似于一个系统)，那就需要解决 “隔离性”，让彼此感知不到对方的存在，出现问题也互不影响 Linux 内核从 2.4.19 版本开始引入了 namespace 概念，其目的是将特定的全局系统资源通过抽象方法使得 namespace 中的进程看起来拥有自己隔离的资源。Docker 就是借助这个机制实现了容器资源隔离 Linux 的 namespace 机制提供了6种不同的命名空间 IPC：隔离进程间通信 MOUNT：隔离文件系统挂载点 NET：隔离网络协议栈 PID：隔离进程号，容器命名空间对父进程空间可见 USER：隔离用户 UTS：隔离主机名和域名 容器实现核心技术：CGroupsDocker 利用 namespace 实现了容器之间资源隔离，但是 namespace 不能对容器资源限制，比如 CPU、内存。如果某一个容器属于 CPU 密集型任务，那么会影响其他容器使用 CPU，导致多个容器相互影响并且抢占资源。如何对多个容器的资源使用进行限制就成了容器化的主要问题。所以容器引入了 Control Groups(简称CGroups)，限制容器资源 CGroups 以某种标准讲一组进程为目标进行资源分配和控制，例如 CPU、内存、带宽等，并且可以动态配置 限制进程组使用的资源数量(Resource limitation )：可以为进程组设定资源使用上限，例如内存 进程组优先级控制(Prioritization)：可以为进程组分配特定 CPU、磁盘 IO 吞吐量 记录进程组使用的资源数量(Accounting)：例如使用记录某个进程组使用的 CPU 时间 进程组控制(Control)：可以将进程组挂起和恢复 查看cgroups可控制的资源 资源 描述 blkio 对块设备的IO进行限制 cpu 限制CPU时间片的分配，与cpuacct挂载同一目录 cpuacct 生成cgroup中的任务占用CPU资源的报告，与cpu挂载同一目录 cpuset 给cgroup中的任务分配独立的CPU(多核处理器)和内存节点 devices 允许或者拒绝 cgroup 中的任务访问设备 freezer 暂停/恢复 cgroup 中的任务 hugetlb 限制使用的内存页数量 memory 对cgroup中任务的可用内存进行限制，并自动生成资源占用报告 net_cls 使用等级识别符(classid)标记网络数据包，这让 Linux 流量控制程序(tc)可以识别来自特定从cgroup任务的数据包，并进行网络限制 net_prio 允许基于cgroup设置网络流量的优先级 perf_event 允许使用perf工具来监控cgroup pids 限制任务的数量 资源控制在容器中的实际位置 ll /sys/fs/cgroup/\"资源名\"/docker/\"容器ID\"/ Docker 核心组件之间关系我们使用 Docker client 运行一个容器，其实容器运行时底层是需要依赖一系列组件的，我们完全可以通过调用这些组件去启动一个容器，而不使用 Docker 引擎的方式去启动。主要的组件有 docker client、docker daemon、containerd、container-shim、runC docker client docker 客户端程序，负责发送用户的请求给 docker daemon docker daemon docker daemon守护进程，也称 docker engine，负责处理 docker client 的请求，并返回处理结果 containerd containerd 是一个工业级标准的容器运行时，它强调简单性、健壮性和可移植性。Containerd 可以在宿主机中管理完整的容器生命周期:容器镜像的传输和存储、容器的执行和管理、存储和网络等。为 docker daemon 提供接口去管理容器，Docker 对容器的管理和操作基本都是通过 containerd 完成的。但是要注意的是：containerd 被设计成嵌入到一个更大的系统中，而不是直接由开发人员或终端用户使用 container-shim container-shim 是 containerd 的组件，是容器的运行时载体，我们在 Docker 宿主机上看到的 shim 也正是代表着一个个通过调用containerd 启动的 Docker 容器 ps axf | grep docker -A 1 10191 ? Sl 0:01 \\_ containerd-shim -namespace moby -workdir /var/lib/containerd/io.containerd.runtime.v1.linux/moby/4dffa5d5861899400770d6470618e4e051c5f1bf0c53034999b13821fc3fe93f -address /run/containerd/containerd.sock -containerd-binary /usr/bin/containerd -runtime-root /var/run/docker/runtime-runc 10208 ? Ss 0:00 \\_ nginx: master process nginx -g daemon off; -- 4215 ? Ssl 2:06 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock runC RunC 是一个轻量级的工具，它是用来运行容器的。我们可以认为它就是个命令行小工具，可以不用通过 Docker 引擎，直接运行容器。事实上 runC 是标准化的产物，它根据 OCI 标准来创建和运行容器。而 OCI(Open Container Initiative) 组织，旨在围绕容器格式和运行时制定一个开放的工业化标准","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker 镜像管理","slug":"Docker 镜像管理","date":"2020-06-16T07:00:10.000Z","updated":"2020-09-28T02:34:42.174Z","comments":true,"path":"post/ce2c2968.html","link":"","permalink":"https://www.missf.top/post/ce2c2968.html","excerpt":"","text":"镜像概述 镜像是一个分层存储的文件 镜像就是一个软件的运行环境 一个镜像可以重复使用，创建无数个容器 一个不包含 Linux 内核而又精简的 Linux 操作系统 镜像是一种标准化的交付，镜像内包含代码以及软件的运行环境 配置镜像加速阿里云为每一个开通容器镜像服务的用户免费提供一个镜像加速地址 # 配置镜像加速 tee /etc/docker/daemon.json &lt;&lt; EOF { \"registry-mirrors\": [\"https://265wemgl.mirror.aliyuncs.com\"] } EOF systemctl daemon-reload systemctl restart docker.service 拉取镜像我们拉取镜像一般是默认从 Docker Hub 拉取的，但是国内访问 Docker Hub 速度很慢，所以我们在前面配置了阿里云的镜像加速。在拉取镜像时，直接从阿里云的 Docker 镜像仓库拉取。我们假如要拉取一个镜像，但是不知道仓库中是否有这个镜像时，我们可以先搜索这个镜像名字，看是否有对应的镜像 # 搜索镜像 docker search nginx # 拉取镜像,如果不指定版本号,默认拉取最新(latest) docker pull nginx:1.17 镜像拉取到宿主机本地之后，会以分层的文件形式存储，下面是镜像的存放目录 [root@localhost ~]# ll /var/lib/docker/overlay2/ total 0 drwx------ 4 root root 55 Jun 17 19:04 5f4badc01c88554e78d4aaec269a84fb5e2028d42278d5f131dda81c4209622c drwx------ 3 root root 47 Jun 17 19:04 658e3b564ce9017b0bd507f1853702f6cdda4642fdc6fbf4b4d06e34cf9a8c25 drwx------ 3 root root 30 Jun 17 19:09 6d57028d1a60a66afc6959b02e0005ea424182908fadf6aa5ac90f3868c014f7 brw------- 1 root root 253, 0 Jun 17 18:31 backingFsBlockDev drwx------ 4 root root 72 Jun 17 19:04 d56648ebd71c9bdb68226b4021ec008db3ed537072b3c4f9e77afc51f8108c07 drwx------ 2 root root 142 Jun 17 19:09 l 镜像与容器的联系当启动一个新容器时，Docker 只加载只读镜像，并在这个只读镜像上面添加一个读写层，即容器层。但我们需要修改容器里面的文件时，会先从镜像层把这个文件拷贝到读写层，然后再执行修改操作 镜像存储核心技术:联合文件系统(UnionFS)联合文件系统(UnionFS)是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(uniteseveral directories into a single virtual filesystem)。联合文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。另外，不同 Docker 容器就可以共享一些基础的文件系统层，同时再加上自己独有的改动层，大大提高了存储的效率 Docker 中使用的 AUFS (AnotherUnionFS)就是一种联合文件系统。 AUFS 支持为每一个成员目录(类似 Git 的分支)设定只读(readonly)、读写(readwrite)和写出（whiteout-able）权限, 同时 AUFS 里有一个类似分层的概念, 对只读权限的分支可以逻辑上进行增量地修改(不影响只读部分的) Docker 目前支持的联合文件系统包括 OverlayFS、AUFS、Btrfs、VFS、ZFS 和 DeviceMapper 镜像存储核心技术：写时复制(COW)Docker 镜像由多个只读层叠加而成，启动容器时，Docker 会加载只读镜像层并在镜像层顶部添加一个读写层。如果运行中的容器修改了一个已存在的文件，那么该文件将会从只读层复制到读写层，该文件的只读版本任然存在，只是已经被读写层中该文件的副本所隐藏，这就是写时复制机制 镜像常用管理命令# 列出镜像,-a显示所有镜像 docker image ls # 在当前目录通过Dockerfile构建镜像 docker build -t \"nginx_tomcat\" . # 查看镜像历史 docker image history nginx:1.17 # 显示镜像的详细信息 docker inspect nginx:1.17 # 从镜像仓库拉取镜像 docker pull nginx:1.17 # 推送镜像到镜像仓库 docker pull centos:7.6.1810 # 移除一个或多个镜像 docker image rm centos docker image rm $(docker image ls -q) # 删除全部镜像 # 删除没有被标记或没有被任何容器引用的镜像 docker image prune -af # 创建一个引用源镜像标记目标镜像 docker tag centos:latest coentos:v1 # 为centos:latest这个镜像打一个标签为coentos:v1 # 导出容器文件系统为tar归档文件 docker export -o centos-export.tar [CONTAINER ID] # 导入容器文件系统tar归档文件来创建镜像 docker import centos-export.tar # 保存一个或多个镜像到一个tar归档文件 docker save -o database.tar redis mysql # 加载镜像来自tar归档或标准输入 docker load -i database.tar 相信许多的初学者看到这里肯定有疑问，这里说明一下 export &amp; import 和 save &amp; load 的区别在哪里 export 和 import 区别export 的应用场景主要用来制作基础镜像，比如你从一个 CentOS 镜像启动一个容器，然后安装一些软件和进行一些设置后，使用 Docker export 保存为一个基础镜像。然后把这个镜像分发给其他人使用，比如作为基础的开发环境 export:将容器导出为tar归档文件,生成的是该容器的快照，复刻了容器当前的Linux系统环境 import:将tar归档文件导入为镜像 整个过程即:容器-->tar归档文件-->镜像 save 和 load 区别如果你的应用是使用 docker-compose.yml 编排的多个镜像组合，但你要部署的客户服务器并不能连外网。这时，你可以使用 docker save将用到的镜像打个包，然后拷贝到客户服务器上使用 docker load 载入 save:将镜像导出为tar归档文件,该命令也可以作用于容器,但导出的是容器背后的images load:将tar归档文件导入为镜像 注意：save 命令生成的 tar 包比 export 命令生成的 tar 包大很多，两组命令不可交叉互用","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker 核心概念与安装","slug":"Docker 核心概念与安装","date":"2020-06-15T02:56:03.000Z","updated":"2020-09-28T02:30:12.203Z","comments":true,"path":"post/f7aff4ce.html","link":"","permalink":"https://www.missf.top/post/f7aff4ce.html","excerpt":"","text":"为什么使用容器提供简单轻量的建模方式，非常容易上手，运行速度非常快 使开发和运维的职责分离，开发只需要关心容器中的程序，运维只需要管理容器 快速高效的开发生命周期，开发环境和生产环境一致，避免了额外的调试有效缩短上线时间 鼓励使用面向服务的架构，Docker 推荐单个容器只运行一个应用程序，使分布式扩展和调试变得简单 Docker 是什么容器技术 想要了解 Docker，首先要知道什么是容器。最早的容器技术来自于 BSD 的 jail 技术(jail一词是监狱的意思，这个技术的隔离思想来源于监狱的启发)，目的就是为了实现进程隔离，使得一个进程被攻陷后不会影响到其他进程，这是出于安全的目的 使用最为广泛的开源容器引擎 在近几年来，Docker 是一个非常火的名词。事实上 Docker 只是众多容器引擎其中一款优秀的容器引擎，但是它却几乎成为了容器的代名词。许多业外人士觉得 Docker 就是容器，这里大家要明白，Docker 只是属于容器技术的一种 容器是一种操作系统级别的虚拟化技术 使用 Docker 创建的容器，以特殊进程的方式在宿主机上运行，运行一个容器就像运行一个进程一样，宿主机上可以运行多个容器，容器间的资源是互相隔离的 依赖于 Linux 内核特性 Namespace &amp; Cgroups 容器之间运行的是一个隔离的环境，也可以理解类似于一个沙盒，使用 Namespace 进行资源的隔离，使用 Cgroups 进行资源的控制 Docker 基本组成Docker Client 客户端 docker 采用 C/S 架构 docker 客户端和 docker 服务器之间的通信访问可以是本地方式也可以是远程方式 docker 客户端向守护进程发送请求，守护进程的执行结果会传回给客户端 Docker Daemon 守护进程 docker 采用 C/S 架构 docker 客户端和 docker 服务器之间的通信访问可以是本地方式也可以是远程方式 docker 客户端向守护进程发送请求，守护进程的执行结果会传回给客户端 Docker Image 镜像 镜像是容器的基石，镜像包含了容器启动的一切条件，容器基于镜像去启动。镜像是层叠的只读文件系统，底层是bootfs引导文件系统，rootfs文件系统永远是只读状态，使用同一个镜像无论启动多少个容器，或者容器被如何修改，镜像都不会被改变。一个镜像可以放到一个镜像的顶部，最下面的镜像称为基础镜像，就是图中的centos/Ubuntu层。这里使用了写时复制技术(copy on write)，即通过一个镜像启动一个容器实例，这个镜像是以只读形式挂载的，即不允许任何修改操作，当在容器实例中修改一个文件时，会首先从镜像里把这个文件拷贝到可写层，然后执行更新操作。 Docker Container 容器 容器通过镜像启动 docker 守护进程执行命令就是在容器实例中执行 应用部署在容器中 在启动容器时会在镜像的最上层创建一个读写层，读写层加上下面的多个只读层从而构成一个容器 Docker Registry 仓库 随着我们项目的增加，我们构建的镜像也会越来越多。而镜像也是像代码一样的，需要一个镜像仓库来进行管理的，镜像仓库里面保存着我们构建的镜像。镜像仓库还分为公有仓库和私有仓库。公有仓库一般指 Docker Hub，Docker Hub 是一个由 Docker 公司运行和管理的基于云的存储库，它是一个在线存储库，Docker 镜像可以由其他用户发布和使用。而私有仓库一般是我们公司的组织内部拥有的一个私有仓库，仅允许公司内部用户使用 容器的关系图 容器 VS 虚拟机虚拟机是系统级别的虚拟化，而容器是进程级别的虚拟化，这是虚拟机和容器最核心的区别。虚拟机提供了物理机硬件级别的操作系统隔离，使用虚拟机部署应用，除了应用和应用依赖的库文件，还需要虚拟完整的操作系统，每个虚拟机拥有自己独立的内核，这会大量占用系统的硬件资源。而容器是进程级别的虚拟化，当我们运行 Docker 容器时，此时容器本身只是操作系统中的一个进程，利用了 Linux 系统的内核特性 (Namespace &amp; Cgroups) 实现了进程之间网络、空间、权限等隔离，使多个容器进程互相不知道彼此的存在。在这个追求速度的互联网时代，容器在许多方面要比虚拟机优秀。但是不意味着传统的虚拟机技术就过时了，虚拟机的操作系统级别隔离是容器无法替代的，容器的意义在于运行单个应用，如果在容器里面添加越来越多的功能，那不如一开始就直接使用虚拟机 虚拟技术的核心区别 容器 VS 虚拟机详细对比 Container VM 启动速度 秒级 分钟级 运行性能 接近原生 5%左右损失 磁盘占用 MB GB 数量 成百上千 一般几十台 隔离性 进程级 系统级(更彻底) 操作系统 主要支持Linux 几乎所有 封装程度 只打包项目代码和依赖关系，共享宿主机内核 完整的操作系统 Docker 应用场景应用程序打包和发布 应用程序环境隔离 持续集成 部署微服务 快速搭建测试环境 提供Pass产品(平台即服务) Linux 安装 Docker# 安装依赖包 yum install -y yum-utils device-mapper-persistent-data lvm2 # 添加Docker软件源 yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo # 安装Docker CE yum install -y docker-ce # 启动Docker服务并设置开机启动 systemctl start docker systemctl enable docker # 查看docker版本 docker --version Docker version 19.03.11, build 42e35e61f3 # 查看更详细的信息 docker info","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"CODING 持续集成 Java 项目","slug":"CODING 持续集成Java项目","date":"2020-06-11T06:16:18.000Z","updated":"2020-09-28T02:26:52.824Z","comments":true,"path":"post/1b979c3e.html","link":"","permalink":"https://www.missf.top/post/1b979c3e.html","excerpt":"","text":"CODING 介绍在说到持续集成这方面，相信所有做运维的小伙伴都知道 Jenkins，就是那个拿着托盘的老头子。但是说到 coding，可能很多人都没听说过。什么是 coding 呢？ coding 涵盖了软件开发从构想到交付的一切所需，使研发团队在云端高效协同，实践敏捷开发与 DevOps，提升软件交付质量与速度。这是来自官网的介绍，下面就让我们一起学习 coding 吧 注册 CODINGcoding 所有的东西都是在这个云平台上实现的，所谓的使研发团队在云端高效协同说的就是这个吧 创建项目选择 DevOps 项目模板 填写项目基本信息 下载若依的源码 若依源码gitee地址 配置若依数据库，将若依自带的两个 SQL 文件导入到 ry 数据库 初始化本地仓库 git init git add . git commit -m \"第一次提交\" 配置 CODING SSH 秘钥 在 Windows 电脑生成 SSH 密钥对，然后将 id_rsa.pub 公钥添加到 coding SSH 公钥 推送本地仓库到 coding 注意：如果已经在 coding 配置了 SSH 秘钥，git 添加远程仓库的时候不要使用 https 的地址，不然还是会提示需要输入 coding 的账号密码 git remote add origin git@e.coding.net:missf/RuoYi.git # 配置了SSH秘钥的，一定要填写项目的git地址 git push -u origin master # 这样推送时就不需要输入账号密码啦 持续集成创建持续集成任务 新建构建计划 在服务器生成SSH秘钥对，将私钥录入到coding的凭据管理，coding就能持续集成部署代码到服务器 编写静态配置的 Jenkinsfile 配置环境变量 这里附上完整 Jenkinsfile pipeline { agent any stages { stage('检出') { steps { checkout([$class: 'GitSCM', branches: [[name: env.GIT_BUILD_REF]], userRemoteConfigs: [[url: env.GIT_REPO_URL, credentialsId: env.CREDENTIALS_ID]]]) } } stage('构建') { steps { echo '构建中...' sh 'java -version' sh 'mvn package' echo '构建完成.' } } stage('压缩jar包') { steps { echo '压缩中...' sh 'cd /root/workspace/ruoyi-admin/target/ &amp;&amp; tar -zcf /tmp/ruoyi-admin.tar.gz ruoyi-admin.jar' echo '压缩完成.' } } stage('部署') { steps { echo '部署中...' script { def remote = [:] remote.name = 'java-server' remote.allowAnyHosts = true remote.host = \"${env.REMOTE_HOST}\" remote.port = 50312 remote.user = \"${env.REMOTE_USER_NAME}\" // 把「CODING 凭据管理」中的「凭据 ID」填入 credentialsId，而 id_rsa 无需修改 withCredentials([sshUserPrivateKey(credentialsId: \"${env.REMOTE_CRED}\", keyFileVariable: 'id_rsa')]) { remote.identityFile = id_rsa // SSH 上传文件到服务器 sshPut remote: remote, from: '/tmp/ruoyi-admin.tar.gz', into: '/tmp/' // 解压缩 sshCommand remote: remote, sudo: false, command: \"tar -zxf /tmp/ruoyi-admin.tar.gz -C /home/ruoyi/\" // 执行Java应用启停脚本 sshCommand remote: remote, sudo: true, command: \"sh /home/ruoyi/start.sh stop &amp;&amp; sh /home/ruoyi/start.sh start\" } } echo '部署完成' } } } } 本地仓库推送代码到 master 分支时就会自动触发持续集成任务 开启缓存目录后可以大大提升构建的速度 立即构建 查看构建过程，构建失败可以查看完整日志分析失败原因 服务器的启停脚本 [root@java-server ~]# cd /home/ruoyi/ [root@java-server ruoyi]# ll total 65080 drwxr-xr-x 2 root root 4096 May 18 10:18 logs -rw-r--r-- 1 root root 67 May 18 17:04 nohup.out -rw-r--r-- 1 root root 66627886 May 18 17:04 ruoyi-admin.jar -rwxr-xr-x 1 root root 760 May 18 14:29 start.sh [root@java-server ruoyi]# cat start.sh #!/bin/bash WORKSPACE=/home/ruoyi if [ -d \"${WORKSPACE}\" ]; then cd ${WORKSPACE} else echo \"${WORKSPACE} directory does not exist\" exit 1 fi APP_NAME='ruoyi-admin.jar' USE_JAVA_HOME='/usr/local/jdk1.8.0_211' JVM_OPTS='-Xms512m -Xmx512m' CONFIG_OPTS='' if [ $1 == 'start' ]; then echo 'start service '$APP_NAME nohup java -jar ${JVM_OPTS} ${APP_NAME} > ${WORKSPACE}/nohup.out 2>&amp;1 &amp; elif [ $1 == 'stop' ]; then echo 'stop service '$APP_NAME PID=$(ps -ef | grep -v grep | grep ${APP_NAME} | awk '{print $2}') if [ -z ${PID} ]; then echo ${APP_NAME} ' had stopped' else kill ${PID} sleep 2 if [ $? -ne 0 ]; then echo ${APP_NAME} ' stop failed' exit 1 fi fi fi 查看持续集成的效果","categories":[{"name":"CODING","slug":"CODING","permalink":"https://www.missf.top/categories/CODING/"}],"tags":[{"name":"CODING","slug":"CODING","permalink":"https://www.missf.top/tags/CODING/"},{"name":"持续集成","slug":"持续集成","permalink":"https://www.missf.top/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"}]},{"title":"Ansible jinja2 模板","slug":"Ansible jinja2 模板","date":"2020-06-10T12:16:53.000Z","updated":"2020-09-26T09:38:42.712Z","comments":true,"path":"post/347a3183.html","link":"","permalink":"https://www.missf.top/post/347a3183.html","excerpt":"","text":"Ansible jinja2 模板我们在多个管理节点部署服务时，很多服务的配置文件都是需要监听服务所在主机的 IP 地址，这时候就需要使用到 Ansible 的 jinja2 模板去分发动态的配置文件。我们先创建一份模板文件，将 IP 配置部分使用 Ansible 变量进行替换，然后使用 template 模块对模版文件进行渲染，将根据我们定义的变量而生成不同的配置文件发送到对应的管理节点 下面我们以安装 redis 为示例，为不同的管理节点分发动态配置文件 cat /etc/redis/conf/redis.conf bind {{ ansible_host }} # 将默认的127.0.0.1改为管理节点本机的IP，这样就能生成各自的管理节点的配置文件 准备模板配置文件之后，下面就来编写一个 Playbook，完成模板配置文件的渲染和分发 --- - hosts: all remote_user: root tasks: - template: src: /root/playbook/redis.conf # 控制节点上的模板文件,定义好变量,通过template模块进行渲染 dest: /etc/redis.conf # 管理节点上这个文件将被控制节点上的模板文件所替换 jinja2 语法Ansible 使用 Jinja2 模板来启用动态表达式和对变量的访问，就是说 Ansible 使用 Jinja 模板对含有动态表达式和变量的文件进行解析个渲染 变量&amp;表达式 可以使用点.来访问变量的属性，也可以使用下标语法 []，下面 2 种方式效果是一样的 {{ foo.bar }} {{ foo['bar'] }} # 如果变量或属性不存在，会返回一个未定义值。 除了变量， {{}} 中还可以包含一些表达式 {{ 1 == 1 }} {{ 2 != 3 }} {{ 2 > 3 }} {{ 4 &lt;= 3 }} # 根据对应的表达式返回true或false {{ 3 + 2 }} {{ 3 - 4 }} {{ 3 * 5 }} {{ 2 ** 3 }} # 2的3次方 # 根据算术运算返回结果 # 字符串、数值、列表、元组、字典、布尔值等数据类型均可在\"{{ }}\"使用 控制 用来装载控制语句，比如 if 控制结构，for循环控制结构 {% for item in seq %} ``` 注释 要把模板中一行的部分注释掉 ```yaml {# 这是被注释的内容 #} ``` 转义 简单的使用单引号('')进行转义，对于较大的段落，使用raw进行转义 ```yaml {% raw %} &lt;ul> {% for item in seq %} &lt;li>{{ item }}&lt;/li> {% endfor %} &lt;/ul> {% endraw %} 执行命令时传入变量 cat /root/test.j2 my blog is {{ site }} ansible dbserver -m template -e \"site=missf.top\" -a \"src=/root/test.j2 dest=/opt/test\" cat /opt/test my blog is missf.top if {% if num > 3 %} gtfr derew pllu {% endif %} 使用 template 模板进行渲染 ansible dbserver -m template -e \"num=4\" -a \"src=/root/test.j2 dest=/opt/test\" # 渲染后的输出结果 cat /opt/test gtfr derew pllu for jinja2 模板的 for 语法示例 {% if num > 3 %} {% for i in [5,65,7,23] %} {{ i }} {% endfor %} 使用 template 模板进行渲染 ansible dbserver -m template -a \"src=/root/test.j2 dest=/opt/test\" # 渲染后的输出结果 cat /opt/test 5 65 7 23 控制空白 从 for 循环的结果看出，使用 template 模板进行渲染时不会去处理空格或者换行符，在开始或结束放置一个减号(-)，可以移除块前或块后的空白 {% for i in [5,65,7,23] -%} {{ i }} # 这里可以使用{{ i }}{{' '}}定义分割符 {%- endfor %} ansible dbserver -m template -a \"src=/root/test.j2 dest=/opt/test\" cat /opt/test 565723 # 将换行符和空白都移除了 5 65 7 23 # 定义分割符的效果 ​ 我要去重新学习梳理 Docker了，Ansible 就先到这里吧！等到有空了，再重启吧","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible include","slug":"Ansible include","date":"2020-06-10T11:56:59.000Z","updated":"2020-09-26T09:35:19.165Z","comments":true,"path":"post/f03bbd11.html","link":"","permalink":"https://www.missf.top/post/f03bbd11.html","excerpt":"","text":"Ansible include在所有的编程语言中，在处理重复代码的时候，都会将重复的代码提取出来作为一个逻辑单元，这个逻辑单元通常被称为函数或者方法，这样可以让我们更加方便的、重复的调用这段代码。而且如果需要修改这段代码，只需要修改这段代码本身，那么在调用这段代码的地方的逻辑就会随之改变。同时，使用函数的方式编写代码，能让我们的逻辑更清晰，通过函数的名称，大概能推算出程序的主体作用和逻辑 在 Ansible 中，其实也有类似的功能，这种功能被称之为 include。通过 include，我们可以在 Playbook 中包含另一个文件，以便实现我们刚才所说的函数效果 在配置环境的时候，我们经常会有一些需要重复使用的 Playbook，就像下面的 LAMP 环境和 LNMP 环境 cat lamp.yaml --- - hosts: dbserver remote_user: root tasks: - name: install lamp yum: name: - mysql - php-fpm - httpd state: present cat lnmp.yaml --- - hosts: dbserver remote_user: root tasks: - name: install lnmp yum: name: - mysql - php-fpm - nginx state: present 我们可以把上面的两个 Playbook 改写层下面这样，便于我们直接调用 cat lamp.yaml - yum: name: - mysql - php-fpm - httpd state: present cat lnmp.yaml - yum: name: - mysql - php-fpm - nginx state: present 当我们需要执行这两个 Playbook 时，直接使用 include 调用，Playbook 中的任务就会在被调用处执行 cat lamp_lnmp.yaml - hosts: webserver remote_user: root tasks: - name: install lamp include_tasks: lamp.yaml # 这里执行的是lamp.yaml的内容 - hosts: dbserver remote_user: root tasks: - name: install lnmp include_tasks: lnmp.yaml 给 include 文件传参cat baidu.yaml - shell: ping -c 3 \"{{ baidu }}\" # 在include文件使用变量 cat include_baidu.yaml --- - hosts: dbserver remote_user: root vars: baidu: \"www.baidu.com\" # 定义include文件所需要的变量 tasks: - name: ping baidu include_tasks: baidu.yaml # 调用执行include文件 Import_playbook我们使用 include 关键字可以调用任务列表，但如果想要调用整个 Playbook，则需要 import_playbook 模块代替 include 模块 cat import_test.yaml --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"test task cat import_test.yaml\" - import_playbook: intest7.yaml # 调用intest7.yaml整个yaml cat intest7.yaml --- - hosts: webserver remote_user: root tasks: - debug: msg: \"test task cat intest7.yaml\"","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible lookups 插件","slug":"Ansible lookups 插件","date":"2020-06-10T11:46:58.000Z","updated":"2020-09-26T09:32:13.891Z","comments":true,"path":"post/8dfd5e56.html","link":"","permalink":"https://www.missf.top/post/8dfd5e56.html","excerpt":"","text":"Ansible 的 lookups 插件过滤器其实是 Ansible 中的一种插件，除了过滤器之外，Ansible 中还有很多其他种类的插件。而且我们一直都在使用这些插件，比如我们在配置 Ansible 的主机清单时，就用到了 Inventory 种类的插件。lookups 其实也是插件的一种，lookups 的所有操作都是在控制节点上进行的，与管理节点无关。Ansible 官网为我们总结了各个插件的作用，并且按照这些插件功能进行了分类 官网插件地址 lookups file 插件可以读取文件，插件的源码是使用 Python 读取文件然后把结果返回给变量 --- - hosts: dbserver remote_user: root vars: contents: \"{{ lookup('file','/etc/hostname') }}\" tasks: - name: debug lookup file debug: msg: \"the contents is {{ contents }}\" 如果不想将所有文件的内容变成一整个字符串，而是获取一个字符串列表，可以使用 wantlist 参数 --- - hosts: dbserver remote_user: root vars: contents: \"{{ lookup('file','/etc/hostname',wantlist=true) }}\" tasks: - name: debug lookup file debug: msg: \"the contents is {{ contents }}\" lookups password 插件会对传入的内容进行加密处理 --- - hosts: dbserver vars: contents: \"{{ lookup('password','ansible') }}\" # 将ansible这个字符串进行加密处理 tasks: - name: debug lookups debug: msg: \"the contents is {{ contents }}\" lookups pipe 插件运行命令并返回结果，pipe 这个插件底层是使用 Python 的 subprocess 库实现的 --- - hosts: dbserver remote_user: root vars: contents: \"{{ lookup('pipe','hostname') }}\" tasks: - name: debug lookup pipe debug: msg: \"the contents is {{ contents }}\" lookups redis_kv 插件是用来从本地 redis 中读取数据的 --- - hosts: dbserver remote_user: root vars: contents: \"{{ lookup('redis_kv', 'redis://127.0.0.1:6379,ansible') }}\" # 获取本地redis数据库ansible这个键的值 tasks: - name: debug lookup redis_kv debug: msg: \"the contents is {{ contents }}\" lookups dict 插件是用来获取变量的键值对 --- - hosts: dbserver vars: users: alice: female bob: male tasks: - debug: msg: \"{{ item.key }} = {{ item.value }}\" loop: \"{{ lookup('dict',users) }}\" lookups env 插件可以获取 Ansible 主机中指定变量的值 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ lookup('env','PATH') }}\" lookups first_found 插件可以获取列表中第一个找到的文件，如果列表中的所有文件都没有找到，可以添加 errors=ignore 忽略报错 - hosts: master remote_user: root tasks: - name: debug lookup first found debug: msg: \"{{ lookup('first_found',looklist,errors='ignore') }}\" vars: looklist: - \"/abc.txt\" - \"/tmp/str.txt\" lookups dig 插件可以获取指定域名的 IP 地址，需要 Python 安装 dnspython 库 --- - hosts: master remote_user: root tasks: - debug: msg: \"{{ lookup('dig','www.baidu.com',wantlist=true) }}\"","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible 过滤器","slug":"Ansible 过滤器","date":"2020-06-09T11:46:58.000Z","updated":"2020-09-26T07:32:22.192Z","comments":true,"path":"post/f254b261.html","link":"","permalink":"https://www.missf.top/post/f254b261.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 Ansible 的过滤器过滤器可以帮助我们对数据进行处理，例如将获取到的变量值中的所有字母都变成大写，过滤器能帮我们实现这样的需求 --- - hosts: dbserver remote_user: root vars: testvar: fesf1dEcd tasks: - debug: msg: \"{{ testvar | upper }}\" # 执行playbook ok: [dbserver] => { \"msg\": \"FESF1DECD\" } 过滤器是一种能够帮助我们处理数据的工具，Ansible中的过滤器功能来自于 jinja2 模板引擎，我们可以借助 jinja2 的过滤器功能在 Ansible 中对数据进行各种处理，而上例中的 upper 就是一种过滤器，这个过滤器的作用就是将小写字母变成大写。当然还有很多其他的过滤器，这些过滤器有些是 jinja2 内置的，有些是 Ansible 特有的，如果这些过滤器都不能满足你的需求，jinja2 也支持自定义过滤器 字符串操作相关的过滤器--- - hosts: dbserver remote_user: root vars: testvar: fesf1dEcd tasks: - debug: msg: \"{{ testvar | upper }}\" # 将全部字母转换成大写 - debug: msg: \"{{ testvar | lower }}\" # 将全部字母转换成小写 - debug: msg: \"{{ testvar | capitalize }}\" # 首字母大写,其他小写 - debug: msg: \"{{ testvar | reverse }}\" # 将字符串反转 - debug: msg: \"{{ testvar | first }}\" # 返回字符串的第一个字符 - debug: msg: \"{{ testvar | last }}\" # 返回字符串的最后一个字符 - debug: msg: \"{{ testvar | trim }}\" # 将字符串开头和结尾的空格去除 - debug: msg: \"{{ testvar | center(width=30) }}\" # 将字符串居中并设置字符串的长度为30,字符串两边用空格填充 - debug: msg: \"{{ testvar | length }}\" # 返回字符串长度,length与count等效,可以写为count - debug: msg: \"{{ testvar | list }}\" # 将字符串转换成列表,每个字符作为一个元素 - debug: msg: \"{{ testvar | shuffle }}\" # 将字符串转换成列表,每个字符作为一个元素,并且随机打乱顺序(洗牌) 数字操作相关的过滤器--- - hosts: dbserver remote_user: root vars: tes: -8 tasks: - debug: msg: \"{{ 5 + ('8' | int) }}\" # 把字符串类型的'8'转换为整形后再作计算 - debug: msg: \"{{ '9' | int(default=6) }}\" # 把字符串类型的'a'转换为整形,如果无法转换则返回6 - debug: msg: \"{{ '8' | float }}\" # 将对应的值转换为浮点型,如果无法转换则默认返回'0.0' - debug: msg: \"{{ 'a' | float(8.88) }}\" # 当对应的值无法返回时则返回指定的'8.88' - debug: msg: \"{{ tes | abs }}\" # 获取这个变量的绝对值 - debug: msg: \"{{ 15.2 | round }}\" # 四舍五入 - debug: msg: \"{{ 3.14159 | round(2) }}\" # 保留小数点后两位 - debug: msg: \"{{ 100 | random }}\" # 从0到100中返回一个随机数 - debug: msg: \"{{ 10 | random(start=5) }}\" # 从5到10中返回一个随机数 - debug: msg: \"{{ 15 | random(start=5,step=2) }}\" # 从5到15中返回一个随机数,步长为2 - debug: msg: \"{{ 15 | random(step=5) }}\" # 从0到10中返回一个随机数,这个数是5的倍数 列表操作相关的过滤器--- - hosts: dbserver remote_user: root tasks: vars: var1: [32,45,63,76,58] var2: [23,[34,65],34,80] var3: [23,'r',87] var4: ['fr',['po','qE'],'tT','IO'] var5: ['bc',1,5,'b','c'] var6: ['bc',5,'b','g'] tasks: - debug: msg: \"{{ var1 | length }}\" # 返回列表长度,length与count等效 - debug: msg: \"{{ var1 | first }}\" # 返回列表中的第一个值 - debug: msg: \"{{ var1 | last }}\" # 返回列表中的最后一个值 - debug: msg: \"{{ var1 | min }}\" # 返回列表中最小的值 - debug: msg: \"{{ var1 | max }}\" # 返回列表中最大的值 - debug: msg: \"{{ var1 | sort }}\" # 将列表升序排序输出 - debug: msg: \"{{ var1 | sort(reverse=true) }}\" # 将列表降序排序输出 - debug: msg: {{ var1 | sum }}\" # 返回纯数字非嵌套列表中所有数字的和 - debug: msg: \"{{ var2| flatten }}\" # 如果列表中包含列表,就把列表拉平为一个列表 - debug: msg: \"{{ var2 | flatten(levels=1) }}\" # 如果列表中嵌套了多层列表,就把第一层列表拉平 - debug: msg: \"{{ var2 | flatten | max }}\" # 将嵌套列表拉平之后取列表中的最大值 - debug: msg: \"{{ var3 | join }}\" # 将列表中的元素连接成一个字符串 - debug: msg: \"{{ var3 | join(',') }}\" # 将列表中的元素以','分割连接成一个字符串 - debug: msg: \"{{ var3 | random }}\" # 从列表中返回一个随机值 - debug: msg: \"{{ var3 | shuffle }}\" # 随机打乱列表元素的顺序 - debug: msg: \"{{ var4 | upper }}\" # 将列表中的每个元素变成纯大写 - debug: msg: \"{{ var4 | lower }}\" # 将列表中的每个元素变成纯小写 - debug: msg: \"{{ var5 | unique }}\" # 去掉列表中重复的元素,重复的元素只留一个 - debug: msg: \"{{ var5 | union(var6) }}\" # 合并列表,重复元素只留一个(并集) - debug: msg: \"{{ var5 | intersect(var6) }}\" # 取出两个列表的交集元素,重复的元素只留一个 变量未定义相关的过滤器--- - hosts: dbserver remote_user: root vars: var1: '' tasks: - debug: msg: \"{{ var0 | default('missf.top') }}\" # 如果变量没有定义则返回一个默认值,如果定义了变量即使变量值为空还是会输出变量值 - debug: msg: \"{{ var1 | default('coding',boolean=true) }}\" # 如果变量未定义或者变量值为空,则返回默认值 - debug: \"{{ var0 | mandatory }}\" # 如果变量未定义,则报出\"Mandatory variable 'var0' not defined\"错误而不是默认错误 常用过滤器--- - hosts: dbserver remote_user: root vars: users: - name: mj age: 15 hobby: - egm - book - name: mk age: 17 hobby: - pq - jk tasks: - debug: msg: \"{{ users | map(attribute='name') | list }}\" # 从users列表中获取到每个元素所共有的某个属性的值,并将这些值组成一个列表 - debug: msg: \"{{ (name == 'missf') | ternary('Mr','Ms') }}\" # 如果name变量的值是missf,那么对应的值则为Mr,否则则为Ms vars: name: 'missf' - debug: msg: \"{{ tg | basename }}\" # 可以获取到一个路径字符串中的文件名 vars: tg: \"/etc/hosts\" - debug: msg: \"{{ win | win_basename }}\" # 可以获取到windows路径字符串中的文件名 vars: win: \"C:\\studio\\missf\" - debug: msg: \"{{ path | realpath }}\" # 可以获取软链接文件所指向的真正文件 vars: path: \"/tmp/linkfile\" - debug: msg: \"{{ path | splitext }}\" # 可以将文件名后缀带有'.'的部分分开 vars: path: \"/etc/yum.conf\" - debug: msg: \"{{ path | splitext | last }}\" # 将字符串以'.'分开后取最后一个 vars: path: \"/etc/yum.conf\" - debug: msg: \"{{ vt | to_uuid }}\" # 为字符串生成uuid vars: vt: \"this is test\" - debug: msg: \"{{ sk | bool }}\" # 字符串内容为'yes','1','True','true'则返回true,内容为其他则返回false vars: sk: \"yes\" - debug: msg: \"{{ ('2016-08-16 12:00:49' | to_datetime) - ('2012-03-25 19:03:15' | to_datetime) }}\" # 使用to_datetime关键字计算时间差,默认转换的字符串的格式必须是'%Y-%m-%d %H:%M:%S' - debug: msg: \"{{ ('20160814'| to_datetime('%Y%m%d')) - ('2012-12-25 19:00:00' | to_datetime) }}\" # 如果对应的字符串不是这种格式,则需要在to_datetime中指定与字符串相同的时间格式,才能正确的转换为时间类型 - debug: msg: \"{{ '123456' | hash('sha1') }}\" # 使用sha1算法对字符串进行哈希 - debug: msg: \"{{ '123456' | password_hash('md5','ffsfsfsfsfscs') }}\" # 使用md5算法加密，指定字符串作为盐值 密码验证示例--- - hosts: dbserver remote_user: root vars_prompt: - name: username prompt: \"input username\" # 用户输入用户名 - name: password prompt: \"input password\" # 用户输入密码 tasks: - debug: msg: \"{{ username | hash('md5') }}\" # 将用户名hash register: username_md5 - debug: msg: \"{{ password | hash('md5') }}\" # 将密码hash register: password_md5 - debug: msg: \"username yes\" when: username_md5.msg == 'fac2db1a64bc2a16887e9bdf17e15f8e' # 通过比对(用户输入的用户名)和(剧本写死的MD5值)确认密码 - debug: msg: \"password yes\" when: password_md5.msg == 'e10adc3949ba59abbe56e057f20f883e'","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible 条件判断","slug":"Ansible 条件判断","date":"2020-06-08T10:27:28.000Z","updated":"2020-09-28T04:24:10.610Z","comments":true,"path":"post/87ce98f8.html","link":"","permalink":"https://www.missf.top/post/87ce98f8.html","excerpt":"","text":"Ansible 的条件判断绝大数语言中，都使用 if 作为条件判断的方法，而在 Ansible 中，条件判断使用关键字 when 简单示例使用 when 关键字指明条件是：ansible_distribution == “CentOS”，这里的 ansible_distribution 是 facts 信息中的一个 key，我们在调用 ansible_distribution 变量时并没有为它添加 { { % raw % } }，这是在 when 关键字中引用变量时，不需要加 { % raw % }。如果 ansible_distribution == “CentOS” 这个条件成立，那么就调用 debug 模块，打印 msg 的内容，如果不成立则不执行 debug 模块 # 简单示例 --- - hosts: dbserver remote_user: root tasks: - debug: msg: 'system release is centos' when: ansible_distribution == \"CentOS\" 配合循环进行判断定义条件为 item &gt; 1，只有条件成立时 item 才会被打印，而 with_items 会循环列表中的值，item 变量的值不断变化 --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_items: - 1 - 2 - 3 when: item > 1 条件判断通配符 运算符 条件 结果 == 两个值是否相等 相等则为真 != 两个值是否不相等 不等则为真 &gt; 左边的值大于右边的值 则为真 &lt; 左边的值小于右边的值 则为真 &gt;= 左边的值大于或等于右边的值 则为真 &lt;= 左边的值小于或等于右边的值 则为真 逻辑运算符 运算符 条件 结果 and 当左边与右边同时为真 则返回真 or 当左边与右边有任意一个为真 则返回真 not 对一个操作取反 () 将一组操作包装在一起 逻辑运算和分组示例--- - hosts: dbserver remote_user: root tasks: - debug: msg: 'System release is centos6 or centos7' when: ansible_distribution == \"CentOS\" and (ansible_distribution_major_version == \"6\" or ansible_distribution_major_version == \"7\") 判断模块执行返回的信息我们在执行 shell 命令时，通常需要获取命令的返回信息，这样才能够根据返回的信息，判断之后的操作如何进行下去 --- - hosts: dbserver remote_user: root tasks: - name: touch file1 shell: \"touch /file1\" register: returnmsg - name: debug file1 debug: msg: \"Command execution successful\" when: returnmsg.rc == 0 # 命令执行成功的返回值中rc的值为0 - name: debug file2 debug: msg: \"Command execution failed\" when: returnmsg.rc != 0 跳过执行遇到的错误有些时候我们的 tasks 执行到一半时，遇到错误之后就不再继续往下执行了，我们可以使用 ignore_errors 关键字去跳过这个错误，让剧本继续往下执行 --- - hosts: dbserver remote_user: root tasks: - name: touch file1 shell: \"ls /file123\" register: returnmsg ignore_errors: true - name: debug file1 debug: msg: \"Command execution successful\" when: returnmsg.rc == 0 - name: debug file2 debug: msg: \"Command execution failed\" when: returnmsg.rc != 0 条件判断与testsLinux 系统中可以使用一些常用的判断操作，例如使用 test 命令判断文件或者目录是否存在 test /etc/ echo $? 0 Ansible 中也有类似用于判断文件和目录的方法，注意这个是判断控制节点上的文件和目录，”is exists” | “is not exists” --- - hosts: dbserver remote_user: root vars: testpath: /etc tasks: - debug: msg: \"file exist\" when: testpath is exists # 判断testpath变量这个路径是否存在，存在则为真，打印msg内容 ok: [dbserver] => { \"msg\": \"file exist\" } 判断变量的 tests defined：判断变量是否已经定义，已经定义则返回真 undefind：判断变量是否已经定义，未定义则返回真 none：判断变量值是否为空，如果变量已经定义，但是变量值为空，则返回真 定义变量 f1 赋值为 test，定义 h2 但不赋值，debug 模块根据对应的条件是否为真打印具体 msg 内容 --- - hosts: dbserver remote_user: root tasks: vars: f1: 'test' h2: tasks: - debug: msg: 'varf1 is undefined' when: f1 is undefined - debug: msg: 'The variable is defined, but there is no value' when: h2 is none 判断执行结果的 tests success 或 succeeded：通过任务的返回信息判断任务的执行状态，任务执行成功则返回真 failure 或 failed：通过任务的返回信息判断任务的执行状态，任务执行失败则返回真 change 或 changed：通过任务的返回信息判断任务的执行状态，任务执行状态为 changed 则返回真 skip 或 skipped：通过任务的返回信息判断任务的执行状态，当任务没有满足条件而被跳过执行时，则返回真 使用 shell 模块执行一条命令，并且使用 register 将返回值存进 returnmsg 变量，如果命令执行报错就跳过继续往下执行，下面再判断这个变量的执行结果 --- - hosts: dbserver remote_user: root tasks: - shell: \"ls /etc/hosts\" register: returnmsg ignore_errors: true - debug: msg: \"success\" when: returnmsg is success - debug: msg: \"failed\" when: returnmsg is failure - debug: msg: \"changed\" when: returnmsg is changed - debug: msg: \"skip\" when: \"returnmsg is skip\" 判断路径的 tests file：判断路径是否是一个文件，如果是则返回真 directory：判断路径是否是一个目录，如果是则返回真 link：判断路径是否是一个软链接，如果是则返回真 mount：判断路径是否是一个挂载点，如果是则返回真 exists：判断路径是否存在，如果存在则返回真 判断字符串的 tests lower：判断包含字母的字符串中的字母是否是纯小写，如果是则返回真 upper：判断包含字母的字符串中的字母是否是纯大写，如果是则返回真 判断整除的 tests even：判断数值是否是偶数，如果是则返回真 odd：判断数值是否是奇数，如果是则返回真 divisibleby(num)：判断是否可以整除指定的数值，如果可以整除则返回真 条件判断与 block想要在条件成立时，执行多个任务，我们不需要在每个任务中都加入判断条件，我们可以使用 block 关键字将多个任务整合成一个块 --- - hosts: dbserver remote_user: root tasks: - shell: \"ls /loo\" ignore_errors: true - block: # 这个block块有两个任务 - debug: msg: \"run command failed\" - file: path: \"/oo\" state: touch when: 2 > 1 # 条件成立就执行block块的任务 block 与 rescue 的错误处理我们在处理某些复杂的任务时，需要使用到错误处理的判断，使我们的 Playbook 更加灵活。例如我需要执行多个任务，这多个任务中只要有一个执行失败，就会触发错误处理，执行我们提前定义好的救援任务进行补救 --- - hosts: dbserver remote_user: root tasks: - block: - shell: \"ls /123\" - debug: msg: \"tcodmf\" - file: path: \"/loo\" state: touch rescue: - debug: msg: \"error\" # 只要block块里面的三个任务有一个执行失败就会执行rescue定义好的任务 block 和 always 的错误处理如果 block 中的任务执行出错，那么就会执行 rescue 中的任务，如果 block 中的任务执行没有出错，那么 rescue 中的任务就不会执行，但是 always 中的任务是无论如何都会执行的，不管 block 中的内容是否出错 --- - hosts: dbserver remote_user: root tasks: - block: - debug: msg: \"echo 123\" - command: cat /etc/hosts | wc -l # command模块不能执行带特殊字符的命令，第一次出错 - debug: msg: \"echo 456\" rescue: - debug: msg: \"echo error1\" - command: cat /etc/hosts | wc -l # command模块不能执行带特殊字符的命令，第二次出错 always: - debug: msg: \"echo error2\" # 最后执行always 条件判断与错误处理我们有时候需要在判断条件成立时，执行退出的指令，使 Playbook 中断执行，这里我们需要使用到 fail 模块。我们知道，在执行 Playbook 时，如果 Playbook 中的任意一个任务执行失败，Playbook 都会终止执行，而 fail 模块就是天生用来执行失败的模块。只要Playbook 中执行fail模块，Playbook 就会认为有任务执行失败了 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"123\" - debug: msg: \"456\" - fail: # 执行fail模块中断playbook执行,后面的任务不再执行 - debug: msg: \"789\" 使用 fail 模块终止 Playbook，默认打印 “Failed as requested from task” 的错误提示，这个我们可以自定义 fail 模块的错误提示 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"123\" - debug: msg: \"456\" - fail: msg: \"stop operation playbook\" - debug: msg: \"789\" 利用条件判断去控制 fail 模块的执行 --- - hosts: dbserver remote_user: root tasks: - shell: \"echo 'This is a string for testing--error'\" register: return_value # 取到shell模块执行的返回值 - fail: msg: \"stop operation playbook\" when: \"'error' in return_value.stdout\" # 判断字符串是否存在于return_value.stdout这个输出信息 - debug: msg: \"playbook has stopped\" # 由于fail模块执行而中断playbook,这个将不会执行 failed_when 关键字 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"123456\" - shell: \"echo 'This is a string for testing--error'\" register: return_value failed_when: '\"error\" in return_value.stdout' # 如果条件成立,那么failed_when就会提示所对应的shell模块执行失败 - debug: msg: \"654321\" # 不会被打印 failed_changed 关键字 正常情况下，debug 模块正常执行的情况下只能是 “ok” 状态，我们可以使用 failed_changed 关键字改变执行后的状态定义为 changed --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"test message\" changed_when: 2 > 1 changed: [dbserver] => { \"msg\": \"test message\" }","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible 循环","slug":"Ansible 循环","date":"2020-06-01T02:47:20.000Z","updated":"2020-09-26T07:24:47.731Z","comments":true,"path":"post/b39a1b7d.html","link":"","permalink":"https://www.missf.top/post/b39a1b7d.html","excerpt":"","text":"Ansible 的循环我们在编写 Playbook 的时候，不可避免的要执行一些重复性操作，比如指定安装软件包，批量创建用户，操作某个目录下的所有文件等。Ansible 一门简单的自动化语言，所以流程控制、循环语句这些编程语言的基本元素它同样都具备。 Ansible 提供了两个用于创建循环的关键字: loop 和 with_，Ansible 2.5 中添加了 loop，但它还不是 with_ 的完全替代品。在官方推荐使用 loop，但我们现在还可以在大多数用例中使用 with_，但是随着 loop 语法的不断改进，with_ 以后可能会失效 标准循环使用 with_items 关键字创建一个循环的列表，with_items 会把列表的每一条信息，单独放到 item 变量里面，然后循环打印每次 item 变量的值 # 方式1 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" with_items: - 1 - 2 - 3 # 方式2 --- - hosts: dbserver remote_user: root tasks: - debug: msg={{ item }} with_items: [1,2,3] # 方式3 --- - hosts: dbserver remote_user: root vars: list: - a - b - c tasks: - debug: msg={{ item }} with_items: '{{ list }}' # 方式4 --- - hosts: dbserver remote_user: root vars: list: [1,2,3] tasks: - debug: msg={{ item }} with_items: '{{ list }}' # 添加多个用户 --- - hosts: dbserver remote_user: root tasks: - name: add server users user: name: \"{{ item }}\" state: present groups: server with_items: - server1 - server2 定义稍微复杂的列表自定义列表中的每一个键值对都是一个对象，我们可以通过对象的属性对应的 “键”，获取到对应的 “值”，执行下面的 Playbook 之后，mm 和 nn 都会被输出 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item.name }}\" with_items: - { name: mm, age: 23} - { name: nn, age: 24} ansible-playbook item.yaml # 执行playbook ok: [dbserver] => (item={u'age': 23, u'name': u'mm'}) => { \"msg\": \"mm\" } ok: [dbserver] => (item={u'age': 24, u'name': u'nn'}) => { \"msg\": \"nn\" } 利用循环创建多个文件# 没学习循环之前可能这样创建多个文件 --- - hosts: dbserver remote_user: root gather_facts: no tasks: - file: path: '/opt/a' state: touch - file: path: '/opt/b' state: touch - file: path: '/opt/c' state: touch - file: path: '/opt/d' state: touch # 使用循环的方式 --- - hosts: dbserver remote_user: root gather_facts: no vars: dirs: - '/opt/a' - '/opt/b' - '/opt/c' - '/opt/d' tasks: - file: path: '{{ item }}' state: touch with_items: '{{ dirs }}' 利用循环多次调用模块不使用循环的情况下调用模块，返回的信息是这样的 --- - hosts: dbserver remote_user: root tasks: - shell: 'ls /etc' register: returnvalue - debug: var: returnvalue ansible-playbook item.yaml ok: [dbserver] => { \"returnvalue\": { \"changed\": true, \"cmd\": \"ls /etc\", \"delta\": \"0:00:00.025062\", \"end\": \"2020-06-02 01:06:34.741709\", \"failed\": false, \"rc\": 0, \"start\": \"2020-06-02 01:06:34.716647\", \"stderr\": \"\", \"stderr_lines\": [],这里省略...... } 我们使用循环重复调用了 shell 模块两次，分别执行了两条命令，然后将 shell 模块的返回值存放到了 returnvalue 变量中，最后使用 debug 模块输出了 returnvalue 变量的值。当使用了循环之后，每次 shell 模块执行后的返回值都会放入一个名为 results 的序列中，其实，results 也是一个返回值，当模块中使用了循环时，模块每次执行的返回值都会追加存放到 results 这个返回值中，所以，我们可以通过 results 关键字获取到每次模块执行后的返回值 --- - hosts: dbserver remote_user: root tasks: - shell: '{{ item }}' with_items: - 'ls /etc' - 'ls /var' register: returnvalue - debug: var: returnvalue ansible-playbook item.yaml ok: [dbserver] => { \"returnvalue\": { \"changed\": true, \"msg\": \"All items completed\", \"results\": [ { \"ansible_loop_var\": \"item\", \"changed\": true, \"cmd\": \"ls /etc\", \"delta\": \"0:00:00.026532\", \"end\": \"2020-06-02 01:08:22.264277\", \"failed\": false, \"invocation\": { 这里省略...... } 先使用循环重复的调用了 shell 模块，然后将 shell 模块每次执行后的返回值注册到了变量 returnvalue 中，之后，在使用 debug 模块时，通过返回值 results 获取到了之前每次执行shell模块的返回值(shell 每次执行后的返回值已经被放入到 item 变量中)，最后又通过返回值 stdout 获取到了每次 shell 模块执行后的标准输出 --- - hosts: dbserver remote_user: root tasks: - shell: '{{ item }}' with_items: - 'ls /etc' - 'ls /var' register: returnvalue - debug: msg: '{{ item.stdout }}' with_items: '{{ returnvalue.results}}' 打印序列中的序列with_items 块序列下面有一个自定义列表 [1,2,3]，执行 Playbook 会循环打印 [1,2,3] 列表里的每一个值 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" with_items: [1,2,3] ok: [dbserver] => (item=1) => { \"msg\": 1 } ok: [dbserver] => (item=2) => { \"msg\": 2 } ok: [dbserver] => (item=3) => { \"msg\": 3 } with_items 块序列下面有两个自定义列表，执行 Playbook 还是会循环打印两个列表里的每一个值 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" with_items: - [1,2,3] - [4,5,6] ok: [dbserver] => (item=1) => { \"msg\": 1 } ok: [dbserver] => (item=2) => { \"msg\": 2 } ok: [dbserver] => (item=3) => { \"msg\": 3 } ok: [dbserver] => (item=4) => { \"msg\": 4 } ok: [dbserver] => (item=5) => { \"msg\": 5 } ok: [dbserver] => (item=6) => { \"msg\": 6 } 当 with_items 块序列下面有两个自定义的列表时，我们如何让 debug 模块将每个小列表作为一个小整体输出，而不应该输出小列表中的每个元素呢？我们可以使用 with_list 关键字，替换上例 Playbook 中的 with_items 关键字 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" with_list: - [1,2,3] - [4,5,6] ok: [dbserver] => (item=[1, 2, 3]) => { # with_list块序列只会循环最外层的每一项,而with_items则是循环处理每一个元素 \"msg\": [ 1, 2, 3 ] } ok: [dbserver] => (item=[4, 5, 6]) => { \"msg\": [ 4, 5, 6 ] } 元素对齐合并with_together 可以将两个列表中的元素对齐合并，如果两个列表元素不一致，缺少的元素值为 null --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_together: - [1,2,3] - [a,b,c] ok: [dbserver] => (item=[1, u'a']) => { \"msg\": [ 1, \"a\" ] } ok: [dbserver] => (item=[2, u'b']) => { \"msg\": [ 2, \"b\" ] } ok: [dbserver] => (item=[3, u'c']) => { \"msg\": [ 3, \"c\" ] } 元素两两组合需求：我们需要创建三个目录，这三个目录下面都有相同的子目录，我们使用 ansible-playbook 的方式去循环创建，需要用到 with_cartesian 这个关键字 # 需要创建的目录结构如下: dir1/sofm dir1/bin dir2/sofm dir2/bin dir3/sofm dir3/bin --- - hosts: dbserver remote_user: root tasks: - file: state: directory path: '/{{ item[0] }}/{{ item[1] }}' with_cartesian: - [dir1,dir2,dir3] - [sofm,bin] 执行 Playbook 会将两个列表的元素两两组合，使用 item[0] 和 item[1] 来获取每一次循环的值 PLAY [dbserver] ****************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] TASK [file] ********************************************************************************************************************** changed: [dbserver] => (item=[u'dir1', u'sofm']) changed: [dbserver] => (item=[u'dir1', u'bin']) changed: [dbserver] => (item=[u'dir2', u'sofm']) changed: [dbserver] => (item=[u'dir2', u'bin']) changed: [dbserver] => (item=[u'dir3', u'sofm']) changed: [dbserver] => (item=[u'dir3', u'bin']) PLAY RECAP *********************************************************************************************************************** dbserver : ok=2 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 列表元素添加索引编号使用 with_indexed_items 关键字可以为列表的每一个元素添加索引编号，索引编号从0开始，我们可以在出来列表每一项元素的时候获取到索引编号 --- - hosts: dbserver remote_user: root tasks: - debug: msg: 'index is {{ item[0] }},value is {{ item[1] }}' with_indexed_items: - index1 - index2 - index3 ok: [dbserver] => (item=[0, u'index1']) => { \"msg\": \"index is 0,value is index1\" } ok: [dbserver] => (item=[1, u'index2']) => { \"msg\": \"index is 1,value is index2\" } ok: [dbserver] => (item=[2, u'index3']) => { \"msg\": \"index is 2,value is index3\" } 生成数字序列假如需要在管理节点创建 dir2、dir4、dir6 这样的目录，我们该如何使用循环去创建呢，这里就需要使用到 with_sequence 这个关键字去生成数字序列。debug 模块被调用了4次，从2开始，到8结束，每一次增加2(步长)，看到这是不是有了 Python 的感觉呢 --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_sequence: start=2 end=8 stride=2 ok: [dbserver] => (item=2) => { \"msg\": \"2\" } ok: [dbserver] => (item=4) => { \"msg\": \"4\" } ok: [dbserver] => (item=6) => { \"msg\": \"6\" } ok: [dbserver] => (item=8) => { \"msg\": \"8\" } 创建 dir2、dir4、dir6 这样不连续的目录 --- - hosts: dbserver remote_user: root tasks: - file: path: /dir{{ item }} state: directory with_sequence: start=2 end=6 stride=2 输出更简单的连续序列--- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_sequence: count=5 注意：当我们不指定 start 的值时，start 的值默认为1，但是当 end 的值小于 start 时则必须指定 stride，而且 stride 的值必须是负数 返回一个随机值使用 with_random_choice 这个关键字可以让我们从一个列表的多个值中随机返回一个值 --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_random_choice: - qwe - rtd - fdv - oki ok: [dbserver] => (item=oki) => { \"msg\": \"oki\" # 随机返回列表中的一个值 } 使用循环去操作字典这里我们学习一个叫 with_dict 的字典关键字，下面来看看字典的使用场景 定义一个 users 变量，users 有两个用户，我们使用 with_dict 关键字处理这个字典格式的变量 --- - hosts: dbserver remote_user: root vars: users: alix: feom boo: mair tasks: - debug: msg: '{{ item }}' with_dict: '{{ users }}' ok: [dbserver] => (item={'value': u'feom', 'key': u'alix'}) => { \"msg\": { \"key\": \"alix\", # users变量经过with_dict处理之后，键值对分别被放入key和value关键字中 \"value\": \"feom\" } } ok: [dbserver] => (item={'value': u'mair', 'key': u'boo'}) => { \"msg\": { \"key\": \"boo\", # 我们可以通过key关键字和value关键字分别获取到字典中键值对的键和值 \"value\": \"mair\" } } 字典定义和取值--- - hosts: dbserver remote_user: root vars: users: alix: name: feom gender: female phone: 155464615 boo: name: mair gender: male phone: 179444684 tasks: - debug: msg: '{{ item }} alix phone is {{ item.value.phone }}' # 使用item.value.phone的方法取某一项的值 with_dict: '{{ users }}' ok: [dbserver] => (item={'value': {u'gender': u'female', u'name': u'feom', u'phone': 155464615}, 'key': u'alix'}) => { \"msg\": \"{'key': u'alix', 'value': {u'gender': u'female', u'name': u'feom', u'phone': 155464615}} alix phone \\\\n is 155464615\" } ok: [dbserver] => (item={'value': {u'gender': u'male', u'name': u'mair', u'phone': 179444684}, 'key': u'boo'}) => { \"msg\": \"{'key': u'boo', 'value': {u'gender': u'male', u'name': u'mair', u'phone': 179444684}} alix phone \\\\n is 179444684\" } 遍历每一项子元素users 变量列表中有两个块序列，这两个块序列分别代表两个用户，bob 和alice，变量 users 经过 with_subelements 处理时还指定一个hobby属性，hobby 属性正是 users 变量中每个用户的子属性 --- - hosts: dbserver remote_user: root vars: users: - name: bob gender: male hobby: - skateboard - videogame - name: alice gender: female hobby: - music - name: qwe hobby: - da tasks: - debug: msg: \"{{ item }}\" with_subelements: - \"{{ users }}\" - hobby 上面的 Playbook 执行后得到如下结果，我们在使用 with_subelements 处理变量 users 时指定了 hobby 属性，hobby 属性中的每一个子元素都被当做一个整体，而其他的子元素作为另一个整体，组成了键值对 ok: [dbserver] => (item=[{u'gender': u'male', u'name': u'bob'}, u'skateboard']) => { \"msg\": [ { \"gender\": \"male\", \"name\": \"bob\" }, \"skateboard\" ] } ok: [dbserver] => (item=[{u'gender': u'male', u'name': u'bob'}, u'videogame']) => { \"msg\": [ { \"gender\": \"male\", \"name\": \"bob\" }, \"videogame\" ] } ok: [dbserver] => (item=[{u'gender': u'female', u'name': u'alice'}, u'music']) => { \"msg\": [ { \"gender\": \"female\", \"name\": \"alice\" }, \"music\" ] } ok: [dbserver] => (item=[{u'name': u'qwe'}, u'da']) => { \"msg\": [ { \"name\": \"qwe\" }, \"da\" ] } 获取控制节点的文件内容我想要获取控制节点上的几个文件的内容，那么可以使用 with_file 关键字，循环获取到文件的内容，这里 hosts 指定的是 dbserver 这个管理节点，但是无论管理节点写的是什么都不影响，因为我们读取的是管理节点的文件 --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_file: - /etc/passwd - /etc/hosts ok: [dbserver] => (item=root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin sync:x:5:0:sync:/sbin:/bin/sync shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown halt:x:7:0:halt:/sbin:/sbin/halt mail:x:8:12:mail:/var/spool/mail:/sbin/nologin operator:x:11:0:operator:/root:/sbin/nologin games:x:12:100:games:/usr/games:/sbin/nologin ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin nobody:x:99:99:Nobody:/:/sbin/nologin systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin dbus:x:81:81:System message bus:/:/sbin/nologin polkitd:x:999:998:User for polkitd:/:/sbin/nologin sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin postfix:x:89:89::/var/spool/postfix:/sbin/nologin ntp:x:38:38::/etc/ntp:/sbin/nologin) => { \"msg\": \"root:x:0:0:root:/root:/bin/bash\\nbin:x:1:1:bin:/bin:/sbin/nologin\\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\\nadm:x:3:4:adm:/var/adm:/sbin/nologin\\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\\nsync:x:5:0:sync:/sbin:/bin/sync\\nshutdown:x:6:0:shutdown:/sbin:/sbin/shutdown\\nhalt:x:7:0:halt:/sbin:/sbin/halt\\nmail:x:8:12:mail:/var/spool/mail:/sbin/nologin\\noperator:x:11:0:operator:/root:/sbin/nologin\\ngames:x:12:100:games:/usr/games:/sbin/nologin\\nftp:x:14:50:FTP User:/var/ftp:/sbin/nologin\\nnobody:x:99:99:Nobody:/:/sbin/nologin\\nsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologin\\ndbus:x:81:81:System message bus:/:/sbin/nologin\\npolkitd:x:999:998:User for polkitd:/:/sbin/nologin\\nsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin\\npostfix:x:89:89::/var/spool/postfix:/sbin/nologin\\nntp:x:38:38::/etc/ntp:/sbin/nologin\" } ok: [dbserver] => (item=127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6) => { \"msg\": \"127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4\\n::1 localhost localhost.localdomain localhost6 localhost6.localdomain6\" } 匹配控制节点的文件我们可以通过通配符去匹配控制节点上的文件，这里需要使用到 with_fileglob 这个关键字。注意 with_fileglob 只能是匹配到文件 --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_fileglob: - /etc/* - /tmp/* # 这里写成/dir/的话是匹配不到文件的，需要使用*通配符 ok: [dbserver] => (item=/etc/fstab) => { \"msg\": \"/etc/fstab\" } ok: [dbserver] => (item=/etc/crypttab) => { \"msg\": \"/etc/crypttab\" } ok: [dbserver] => (item=/etc/mtab) => { \"msg\": \"/etc/mtab\" } ok: [dbserver] => (item=/etc/resolv.conf) => { \"msg\": \"/etc/resolv.conf\" } ok: [dbserver] => (item=/etc/magic) => { \"msg\": \"/etc/magic\" }...... Ansible 的 loop 循环在2.5版本之前的 Ansible 中，大多数人习惯使用 “with_X” 风格的关键字操作循环，从2.6版本开始，官方开始推荐使用 “loop” 关键字代替 “with_X” 风格的关键字。现在就来聊聊这种新的方式，以便能够更好的从老版本的使用习惯过渡过来 loop标准循环 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" loop: - abc - cde loop 循环安装软件 --- - hosts: dbserver remote_user: root tasks: - name: install packages yum: name: \"{{ item }}\" state: latest loop: - rsync - sl - psmisc loop 批量创建用户 --- - hosts: dbserver remote_user: tasks: - name: \"add user\" user: name: \"{{ item.name }}\" state: present groups: \"{{ item.groups }}\" loop: - {name: \"abc\",groups: \"root\"} - {name: \"cde\",groups: \"root\"}","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible 变量","slug":"Ansible 变量","date":"2020-05-28T02:13:41.000Z","updated":"2020-09-26T07:19:42.081Z","comments":true,"path":"post/e2d2af3c.html","link":"","permalink":"https://www.missf.top/post/e2d2af3c.html","excerpt":"","text":"Ansible的变量在 Ansible 中使用变量，能让我们的工作变得更加灵活 变量定义规则 变量名应该由字母、数字、下划线组成 变量名需要以字母开头 Ansible 内置的关键字不能作为变量名 在 Playbook 中使用变量使用 vars 关键字定义名为 Package1 值为 Nginx 的变量，在 task 中使用 进行调用 --- - hosts: all vars: package1: nginx remote_user: root tasks: - name: task1 yum: name: \"{{ package1 }}\" state: installed 使用块序列化语法定义变量 vars: - testvar1: a1 - testvar2: b2 使用属性的方式定义变量 --- - hosts: all remote_user: root vars: nginx: # 定义两个变量 conf80: /etc/nginx/conf.d/80.conf conf8080: /etc/nginx/conf.d/8080.conf tasks: - name: task1 file: path: \"{{ nginx.conf80 }}\" # 第一种调用方法 state: touch - name: task2 file: path: \"{{ nginx['conf8080']}}\" # 第二种调用方法 注意：如果引用变量时，变量处于开头的位置，那么变量必须要用双引号引起来，否则语法会报错 - name: task2 file: path: \"{{ nginx['conf8080']}}\" # 引用这种变量处于开头位置的必须使用引号引起来 - name: task2 file: path: /root/{{ nginx['conf8080']}} # 这样的不用 引入文件内的变量，创建 nginx_vars.yaml 文件，直接在文件中以自己喜欢的方式定义变量 testvar1: zxc testvar2: qwe - testvar3: rty - testvar4: poi nginx: conf1: /usr/local/nginx/conf/nginx1.conf conf2: /usr/local/nginx/conf/nginx2.conf 在 Playbook 中以 vars_files 关键字引入文件中的变量 --- - hosts: all remote_user: root vars: # vars关键字和vars_files关键字可以同时使用 - /root/vars.yaml vars_files: - /playbook/nginx_vars.yaml tasks: - name: task1 file: path: \"{{ nginx.conf80 }}\" state: touch - name: task2 file: path: \"{{ nginx['conf8080']}}\" 变量与 setup 模块前面我们说过在执行 Playbook 的时候，默认都会运行一个名为 Gathering Facts 的任务，这个任务会收集管理节点的相关信息(例如管理节点的 IP 地址，主机名，系统版本，硬件配置等信息)，这些被收集到的信息都会保存在对应的变量中，我们想要使用这些信息时，可以获取对应的变量，从而使用这些信息。关于 setup 模块具体查看前面 Ansible 模块学习 查看从管理节点收集到的所有相关信息 ansible all -m setup # 由于返回信息的比较多，这里不作示例 查看管理节点的内存使用情况 ansible all -m setup -a 'filter=ansible_memory_mb' 在管理节点创建自定义变量 除了 Ansible 默认收集的信息以外，我们还能够在管理节点写入一些自定义变量，这些自定义变量也是可以被 setup 模块收集到 首先在管理节点创建自定义变量的文件 hello.fact，此类文件必须以 *.fact 命名 # 管理节点 mkdir -p /etc/ansible/facts.d vim /etc/ansible/facts.d/hello.fact [info] name: mwj age: 24 # 控制节点 ansible dbserver -m setup -a \"filter=ansible_local\" # 使用ansible_local关键字过滤信息得到管理节点的自定义变量 10.10.110.122 | SUCCESS => { \"ansible_facts\": { \"ansible_local\": { \"hello\": { \"info\": { \"age\": \"24\", \"name\": \"mwj\" } } }, \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false } 注意：管理节点上的 hello.fact 文件必须不是可执行文件，不然这个文件不会被成功读取，具体可查看 Ansible 官方文档有详细说明。在管理节点的 /etc/ansible/facts.d/ 这个目录是使用 ansible_local 关键字过滤时的默认路径，如果想要自定义路径可以使用 fact_path 关键字定义 ansible dbserver -m setup -a \"fact_path=/tmp/facts.d/\" 变量与 debug 模块debug 模块是帮我们进行调试的，可以把对我们有用的信息输出到控制台上，以便能够定位问题 Playbook 中使用 debug 模块 --- - hosts: all remote_user: root tasks: - name: touch file file: path: /tmp/debug.txt state: touch - name: debug demo debug: msg: this is debug info,File created successfully 执行 Playbook 模块查看信息 如下图所示，在 touch 文件之后会输出我们定义好的 debug 信息 PLAY [all] *********************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] ok: [webserver] TASK [touch file] **************************************************************************************************************** changed: [webserver] changed: [dbserver] TASK [debug demo] **************************************************************************************************************** ok: [webserver] => { \"msg\": \"this is debug info,File created successfully\" } ok: [dbserver] => { \"msg\": \"this is debug info,File created successfully\" } PLAY RECAP *********************************************************************************************************************** dbserver : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 webserver : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 使用 debug 模块输出变量信息 debug 模块除了能够使用 msg 参数输出自定义的信息，还能够使用 var 参数直接输出变量中的信息 --- - hosts: all remote_user: root vars: testvar: this is a debug variable tasks: - name: debug demo debug: var: testvar 使用 debug 模块的 msg 参数一样可以打印变量信息 --- - hosts: all remote_user: root tasks: - name: debug demo debug: msg: \"Remote host memory information: {{ ansible_memory_mb }}\" 执行结果如下 PLAY [all] *********************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] ok: [webserver] TASK [debug demo] **************************************************************************************************************** ok: [webserver] => { \"msg\": \"Remote host memory information: {u'real': {u'total': 216, u'used': 213, u'free': 3}, u'swap': {u'cached': 0, u'total': 1023, u'free': 1022, u'used': 1}, u'nocache': {u'used': 163, u'free': 53}}\" } ok: [dbserver] => { \"msg\": \"Remote host memory information: {u'real': {u'total': 216, u'used': 212, u'free': 4}, u'swap': {u'cached': 0, u'total': 1023, u'free': 1013, u'used': 10}, u'nocache': {u'used': 170, u'free': 46}}\" } PLAY RECAP *********************************************************************************************************************** dbserver : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 webserver : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 ansible_memory_mb 其中其实包含了 “nocache”、”real”、 “swap” 三个部分的信息，我们只想获得 “real” 部分的信息，在 Playbook 中引用变量时可以使用如下示例： msg: \"Remote host memory information: {{ ansible_memory_mb.real }}\" msg: \"Remote host memory information: {{ ansible_memory_mb['real'] }}\" 注册变量Ansible 的模块运行之后都会返回一些返回值，只是默认情况下，这些返回值并不会显示而已，我们可以把这些返回值写入到某个变量中，这样我们就能够通过引用对应的变量从而获取到这些返回值了，这种将模块的返回值写入到变量中的方法被称为注册变量 下面这个 Playbook 有两个任务，第一个任务使用 shell 模块执行了一条命令，然后在这个任务下使用 register 注册了一个 testvar 的变量，第二个任务是使用 debug 模块的 var 参数打印这个变量，最后输出 shell 模块的返回值 --- - hosts: dbserver remote_user: root tasks: - name: test shell shell: \"echo test > /tmp/test\" register: testvar - name: shell module return values debug: var: testvar Playbook 执行的结果如下图，返回的是一个 json 格式的数据 PLAY [dbserver] ****************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] TASK [test shell] **************************************************************************************************************** changed: [dbserver] TASK [shell module return values] ************************************************************************************************ ok: [dbserver] => { \"testvar\": { \"changed\": true, \"cmd\": \"echo test > /tmp/test\", \"delta\": \"0:00:00.025987\", \"end\": \"2020-06-02 22:34:36.185101\", \"failed\": false, \"rc\": 0, \"start\": \"2020-06-02 22:34:36.159114\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": [] } } PLAY RECAP *********************************************************************************************************************** dbserver : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 如果你想要查看模块对应的返回值，可以先查找官方手册，但并不是所有模块的官方手册中都对模块的返回值进行了描述，你可以自己去官网查看模块的返回值，这些返回值不仅仅能够用于输出，通常我们会利用到这些返回值，比如通过模块的返回值决定之后的一些动作，所以注册变量在 Playbook 中还是会被经常用到的，在之后的文章中我们会给出示例 变量与用户交互信息在运行 shell 脚本时，有些时候需要用户输入信息，脚本再根据用户输入的信息决定下一步的动作，这种交互是必须的。我们也可以在Playbook 中实现这种交互，首先提示用户输入信息，然后将用户输入的信息存放到指定的变量中，当我们需要使用这些信息时，只要引用对应的变量即可 下面我们使用 vars_prompt 关键字定义了两个变量，变量名为别为 your_name 和 your_age，变量下面是提示用户输入时的信息 --- - hosts: dbserver remote_user: root vars_prompt: - name: \"your_name\" prompt: \"what is your name\" - name : \"your_age\" prompt: \"how old are you\" tasks: - name: output vars debug: msg: your name is {{your_name}},you are {{your_age}} years old. Playbook 执行如下图，提示用户输入信息时默认是不显示信息的，这和输入密码的场景类似 what is your name: how old are you: PLAY [dbserver] ****************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] TASK [output vars] ************************************************************************************************************** ok: [dbserver] => { \"msg\": \"your name is mwj,you are 24 years old.\" } PLAY RECAP *********************************************************************************************************************** dbserver : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 如果想要用户输入信息时显示信息内容，可以将 private 参数设置为 no --- - hosts: dbserver remote_user: root vars_prompt: - name: \"your_name\" prompt: \"what is your name\" - name : \"your_age\" prompt: \"how old are you\" private: no # 显示用户输入的内容 tasks: - name: output vars debug: msg: your name is {{your_name}},you are {{your_age}} years old. 我们还可以为提示信息设置默认值，如果用户不输入任何信息就将默认值赋予变量，如果用户输入信息，就把输入的信息赋值给变量 --- - hosts: dbserver remote_user: root vars_prompt: - name: \"your_name\" prompt: \"what is your name\\n\" private: no default: mike tasks: - name: output vars debug: msg: your name is {{your_name}} 上面 Playbook 的执行过程如下，中括号内的内容是我们设置的默认值，如果用户直接回车那就将中括号内的内容直接赋值给变量 what is your name [mike]: mwj PLAY [dbserver] ****************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] TASK [output vars] ************************************************************************************************************** ok: [dbserver] => { \"msg\": \"your name is mwj\" } PLAY RECAP *********************************************************************************************************************** dbserver : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 通过命令行传入变量我们可以在执行 Playbook 时直接传入需要使用到的变量。编写一个 Playbook，打印一个 passwd 的变量 --- - hosts: dbserver remote_user: root tasks: - name: \"passing in variables from the command line\" debug: msg: \"{{ passwd }}\" 执行 Playbook 时传入变量 ansible-playbook --extra-vars \"passwd=mdf123456\" passwd.yaml # --extra-vars参数可以简写成-e，还可以一次性传入多个变量，用空格隔开 ansible-playbook -e \"passwd=mdf123456 username=ewe\" passwd.yaml 注意：如果 Playbook 中并没有定义 passwd 变量，在执行 Playbook 时也没有传入 passwd 变量，则会报错。如果在 Playbook 中事先定义好了 passwd 变量，在执行时再次传入名字相同的变量，最终还是以传入的变量值为准，命令行传入的变量的优先级要高于 Playbook 中的变量 不仅 ansible-playbook 可以使用 “-e” 传递变量，Ansible 命令行一样可以，在执行 ad-hoc 命令时可以使用下面的方法传入变量 ansible dbserver -e \"name=mwj\" -m shell -a \"echo my name in {{ name }}\" json 格式传入变量，除了以键值对的方式传入变量，我们还可以传入 json 格式的变量 ansible-playbook passwd.yaml -e '{\"username\":\"mwj\",\"passwd\":\"123456\"}' ansible-playbook passwd.yaml -e '{\"countlist\":[\"one\",\"two\",\"three\",\"four\"]}' # {{countlist[0]}}或{{countlist.0}}引用变量 执行 Playbook 时传入变量文件，编写变量文件，可以是 json 格式或者 yaml 格式的文件 namevar: mwj countlist: - one - two - three - four Playbook 内容调用变量 --- - hosts: dbderver remote_user: root tasks: - name: \"name\" debug: msg: \"{{ namevar }} {{ countlist[0] }}\" 命令行传入对应的文件，使用 @ 符号加上变量文件的路径，变量文件中的所有变量都可以在 Playbook 中引用 ansible-playbook test.yaml -e '@/ansible/var1' 在主机清单中配置变量在主机清单中，可以配置我们的管理节点，也可以将部分管理节点分为一组，其实在配置清单时还可以为主机或主机组设置变量 主机变量：在主机清单中配置变量时，可以同时为管理节点配置对应的变量，当操作这个主机时，即可直接使用对应的变量，而其他主机不能引用到这个变量 # ini风格 dbserver ansible_host=10.1.1.70 name: mwj age: 24 # yaml风格 all: children: server: hosts: dbserver: ansible_host: 10.10.110.122 ansible_port: 22 name: mwj age: 24 webserver: ansible_host: 10.10.110.123 ansible_port: 22 可以在命令行引用主机变量，也可以在 Playbook 中引用主机变量 ansible dbserver -m shell -a 'echo {{name}}' 使用层级关系定义更复杂的主机变量 all: children: server: hosts: dbserver: ansible_host: 10.10.110.122 ansible_port: 22 name: n1: mike n2: masha n3: laki # 引用时使用{{ name.n1 }}或{{ name['n1'] }} 主机组变量：在主机清单中，我们可以将多个主机分为一组，这样方便我们同时去操作同一组的管理节点，我们可以为这个主机组定义变量，组内的所有主机都可以使用 # ini风格 [webserver] web01 ansible_host: 10.10.110.121 web02 ansible_host: 10.10.110.122 web03 ansible_host: 10.10.110.123 [webserver:vars] path=\"/usr/local/nginx/html/\" user=\"root\" # yaml格式 all: children: server: hosts: dbserver: ansible_host: 10.10.110.122 ansible_port: 22 webserver: ansible_host: 10.10.110.123 ansible_port: 22 vars: user: \"root\" path: \"/usr/local/nginx/html/\" set_fact 定义变量set_fact 是一个模块，我们可以通过 set_fact 模块在 tasks 中定义变量 testvar1，然后打印这个变量 --- - hosts: dbserver remote_user: root tasks: - set_fact: testvar1: mid - debug: msg: \"{{ testvar1 }}\" set_fact 定义变量的特殊性 通过 set_fact 模块创建的变量还有一个特殊性，通过 set_fact 创建的变量就像主机上的 facts 信息一样，可以在之后的 play 中被引用。而我们使用 vars 关键字创建的变量则不能被其他 Playbook 所引用到 下面这个 Playbook 有两个 play，第一个 play 中有两个变量分别是 ts1 和 ts2，它们分别用 vars 和 set_fact 定义，只有使用 set_fact 定义的 ts2 变量，才能被下面这个 play 所引用，而使用 vars 定义的 ts1 变量则不能被下面的 play 所引用 --- - hosts: dbserver remote_user: root vars: ts1: team1 tasks: - set_fact: ts2: team2 - debug: msg: \"{{ ts1 }}---{{ ts2 }}\" - hosts: webserver remote_user: root tasks: - name: get ts1 # 这里引用会报错 debug: msg: \"{{ ts1 }}\" - name: get ts2 debug: msg: \"{{ ts2 }}\" 注意：set_fact 变量类似于管理节点的全局变量，可以跨 play 获取变量，注册变量也能被之后的 play 所引用 内置变量除了我们各种各样的定义变量之外，Ansible 还有一些内置的变量供我们使用，这些内置变量的变量名是被 Ansible 所保留的，我们定义变量时不能使用这些变量名 内置变量 ansible_version，查看 Ansible 的版本 ansible all -m debug -a 'msg={{ansible_version}}' 内置变量 hostvars，hostvars 可以帮助我们在操作当前管理节点时获取到其他管理节点中的信息。下面 Playbook 有两个 play，第一个没有任何 task，只是将 webserver 主机的信息收集起来，供后面的 play 调用。第二个 play 则是使用了 debug 模块打印了 webserver 的内置变量 hostvars，输出了 webserver 的 IP 地址，这就是在操作 dbserver 管理节点时获取了 webserver 管理节点的信息 --- - name: \"gather facts of webserver\" hosts: webserver remote_user: root - name: \"get facts webserver\" hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ hostvars['webserver'].ansible_ens32.ipv4 }}\" # 如果没有第一个play，在执行时调用[Gathering Facts]任务，将webserver的信息收集起来，后面dbserver调用这个变量就会报错 内置变量 inventory_hostname，通过 inventory_hostname 变量可以获取到管理节点的当前主机名称，注意这个不是指 Linux 系统的主机名，而是对应管理节点在控制节点的主机清单中的配置名称 # 主机清单 [abc] 10.10.110.122 dbserver ansible_host: 10.10.110.123 使用内置变量 inventory_hostname 获取各个主机的对应的主机名 ansible abc -m debug -a 'msg={{inventory_hostname}}' 10.10.110.122 | SUCCESS => { \"msg\": \"10.10.110.122\" } dbserver | SUCCESS => { \"msg\": \"dbserver\" } # 定义是IP则返回IP，定义是别名则返回别名 内置变量 inventory_hostname_short，与内置变量 inventory_hostname 类似，通过 inventory_hostname_short 也可以获取当前 play 操作的管理节点在清单中对应的名称，但是这个名称更加简短 [abc] 10.10.110.122 dbserver.com ansible_host=10.10.110.123 按上面主机清单的配置，我们可以使用 inventory_hostname_short 获取到管理节点的简短名称 ansible all -m debug -a 'msg={{inventory_hostname_short}}' 10.10.110.122 | SUCCESS => { \"msg\": \"10\" } dbserver.com | SUCCESS => { \"msg\": \"dbserver\" } # 可以看到无论是IP还是主机名，inventory_hostname_short都会取得主机名中第一个\".\"之前的字符作为主机的简短名称 内置变量 play_hosts，通过内置变量 play_hosts 可以获取到当前 play 所操作的所有管理节点的主机名列表 --- - hosts: 10.10.110.122,dbserver.com remote_user: root tasks: - name: debug debug: msg: \"{{ play_hosts }}\" # 返回的是所操作的所有管理节点的主机名列表 ok: [10.10.110.122] => { \"msg\": [ \"10.10.110.122\", \"dbserver.com\" ] } ok: [dbserver.com] => { \"msg\": [ \"10.10.110.122\", \"dbserver.com\" ] } 内置变量 inventory_dir，我们可以通过 inventory_dir 变量获取到 ansible 主机中清单文件的存放路径 ansible all -m debug -a 'msg={{inventory_dir}}' 10.10.110.122 | SUCCESS => { \"msg\": \"/etc/ansible\" } dbserver.com | SUCCESS => { \"msg\": \"/etc/ansible\" } 重新加载变量文件先来看一个小示例，假如 Playbook 中有三个任务，第一个任务调用了控制节点的一个变量文件，第二个任务在变量文件中新增了一个变量，第三个任务在变量文件中引用新增的那个变量，看看结果会如何 cat /root/playbook/var_file.yaml # 变量文件已有v1变量 v1: 111 --- - hosts: master remote_user: root tasks: vars_files: - /root/playbook/var_file.yaml tasks: - debug: msg: \"{{ v1 }}\" - lineinfile: path: \"/root/playbook/var_file.yaml\" line: \"v2: 222\" # 往变量文件新增v2变量 - debug: msg: \"{{ v1 }},{{ v2 }}\" # 输出v1和v2变量,这里输出v2变量会出错 fatal: [master]: FAILED! => {\"msg\": \"The task includes an option with an undefined variable. The error was: 'v2' is undefined\\n\\nThe error appears to be in '/root/playbook/include.yaml': line 13, column 5, but may\\nbe elsewhere in the file depending on the exact syntax problem.\\n\\nThe offending line appears to be:\\n\\n line: \\\"v2: 222\\\"\\n - debug:\\n ^ here\\n\"} 上面的示例中，其实 v2 变量已经成功添加到变量文件中了，但是由于我们是先读取了变量文件，再写入 v2 变量到文件，这时候我们没有重新读取变量文件，那么就会报错 v2 变量未定义了，我们可以使用 include_vars 关键字从新加载变量文件 --- - hosts: master remote_user: root tasks: vars_files: - /root/playbook/var_file.yaml tasks: - debug: msg: \"{{ v1 }}\" - lineinfile: path: \"/root/playbook/var_file.yaml\" line: \"v2: 222\" - include_vars: \"/root/playbook/var_file.yaml\" # 重新加载变量文件 - debug: msg: \"{{ v1 }},{{ v2 }}\" # 这时候输出v2变量就不会出错","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible tags","slug":"Ansible tags","date":"2020-05-27T02:38:40.000Z","updated":"2020-09-26T06:31:18.272Z","comments":true,"path":"post/8ecedcd4.html","link":"","permalink":"https://www.missf.top/post/8ecedcd4.html","excerpt":"","text":"Ansible 的 tags 用法我们学习 Ansible，以后都是要编写各种各样的 Playbook 的。假如我们有一天，写了一个很长很长的 Playbook，其中包含了非常多的任务，这其实没有什么问题，但是我有时候可能只是需要执行这个 Playbook 的一部分任务而已，而非每一次都执行 Playbook 的全部任务，这个时候我们可以借助 tags 实现这个需求 --- - hosts: all remote_user: root tasks: - name: task1 file: path: /tmp/task1 state: touch tags: t1 - name: task2 file: path: /tmp/task2 state: touch tags: t2 上面定义了两个 task 任务，每个任务有自己的 tags，我们可以在执行 Playbook 时借助标签指定只执行那些任务，而忽略其他任务 ansible-playbook --tags=t2 testtags.yaml # 只执行t2标签的task任务 ansible-playbook --skip-tags=t1 testtags.yaml # 跳过t1标签任务，其他的任务都会执行 tags 的三种语法语法一: tags: - t1 - t2 语法二: tags: t1,t2 语法三: tags: ['t1','t2'] 我们可以为一个任务添加多个标签,下面两个 task 任务都有一个共同的 tag1 标签，当执行时指定 tag1 标签，下面两个任务都会执行 --- - hosts: all remote_user: root tasks: - name: task1 file: path: /tmp/task1 state: touch tags: t1,tag1 - name: task2 file: path: /tmp/task2 state: touch tags: ['t2','tag1'] 具有共同标签的任务，可以将共同标签从 task 中提取出来写在 play 中，下面的两个 task 任务分别有自己的 t1 和 t2 标签，同时又具有共同的 t3 标签，tags 写在 tasks 上面时，tasks 会继承当前 play 中的 tags --- - hosts: all remote_user: root tags: t3 tasks: - name: task1 file: path: /tmp/task1 state: touch tags: t1 - name: task2 file: path: /tmp/task2 state: touch tags: t2 调用标签时，可以一次性指定多个标签，调用多个标签需要用逗号隔开 ansible-playbook --tags=t1,t2 testtags.yaml 我们还可以在调用标签时先概览一下 Playbook 中的标签 ansible-playbook --list-tags testtags.yaml tags 的五个内置标签 always：当把任务的 tags 的值指定为 always 时，那么这个任务就总是会被执行，除非你使用 “–skip-tags” 选项明确指定跳过这个任务 never：当把任务的 tags 的值指定为 never 时，那么这个任务就总是不会被执行，2.5版本中新加入的特殊 tag tagged：调用标签时使用的，只执行有标签的任务，没有任何标签的任务不会被执行 untagged：只执行没有标签的任务，但是如果某些任务包含always标签，那么这些任务也会被执行 all：执行所有标签 只执行有标签的任务，没有任何标签的任务不会被执行 ansible-playbook --tags tagged testtag.yml 跳过包含标签的任务，即使对应的任务包含 always 标签，也会被跳过 ansible-playbook --skip-tags tagged testtag.yml 只执行没有标签的任务，但是如果某些任务包含 always 标签，那么这些任务也会被执行 ansible-playbook --tags untagged testtag.yml","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible Handlers","slug":"Ansible Handlers","date":"2020-05-26T07:13:48.000Z","updated":"2020-09-26T06:29:09.829Z","comments":true,"path":"post/b39bea85.html","link":"","permalink":"https://www.missf.top/post/b39bea85.html","excerpt":"","text":"Ansible 的 Handlers 用法许多的 Linux 服务在修改配置文件后都是需要重启服务的，以便能够重新读取配置文件，使新的配置能够生效。那怎么用 Playbook 实现这个简单的功能呢？下面我们来编写一个修改 Nginx 端口的 Playbook，并且在修改完之后重启 Nginx --- - hosts: all remote_user: root tasks: - name: modify config replace: path: /etc/nginx/nginx.conf regexp: \"listen(.*)80;\" # 替换nginx端口为8080 replace: \"listen 8080;\" backup: yes - name: restart nginx # 重启nginx服务 service: name: nginx state: restarted 注意思考：这个 Playbook 虽然可以帮助我们成功修改 Nginx 端口并重启 Nginx 服务，但是大家请注意如果我再次执行这个 Playbook 的话，Nginx 端口已经是8080了，由于 Ansible 幂等性的缘故，所以 modify config 这个 task 没有发生状态的改变，所以这一步返回了绿色的信息，但是 Nginx 的服务还是被重启了，其实我们并没有真正去改变 Nginx 的配置文件，但是却还是重启了 Nginx 服务，这是因为重启服务这个任务是写死了的。这种多余的重启是不需要的。那么在 Playbook 中就是使用 Handlers 来解决这种问题的，下面我们就继续以 Nginx 服务这个小例子来学习 Playbook 的 Handlers 用法 --- - hosts: all remote_user: root tasks: - name: modify config replace: path: /etc/nginx/nginx.conf regexp: \"listen(.*)80;\" replace: \"listen 8080;\" backup: yes notify: # 在modify config这个任务调用handlers任务列表的restart nginx任务(认真理解这句话) restart nginx handlers: # 定义一个handlers任务列表 - name: restart nginx service: name: nginx state: restarted 上面示例我们使用 Handlers 用法，如果 modify config 这个 task 的状态被真正修改过了，notify 就会调用 Handlers 任务列表的 restart Nginx 任务，就会执行重启 Nginx 服务，这样就能达到只有 Nginx 配置文件被真正修改了，才会去重启 Nginx 服务 Handlers 是一种任务列表在 Playbook 中 Handlers 和 tasks 是同级别的，这是因为 Handlers 也是任务列表的一种。只不过Handlers 中的任务是被用于 tasks 任务列表的 notify 调用而已 --- - hosts: all remote_user: root tasks: - name: make testfile1 file: path: /testdir/testfile1 state: directory notify: ht2 - name: make testfile2 file: path: /testdir/testfile2 state: directory notify: ht1 handlers: - name: ht1 file: path: /testdir/ht1 state: touch - name: ht2 file: path: /testdir/testfile2 state: touch 上面 Playbook 的执行过程如下： PLAY [all] *********************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [webserver] ok: [dbserver] TASK [make testfile1] ************************************************************************************************************ changed: [webserver] changed: [dbserver] TASK [make testfile2] ************************************************************************************************************ changed: [webserver] changed: [dbserver] RUNNING HANDLER [ht1] ************************************************************************************************************ changed: [webserver] changed: [dbserver] RUNNING HANDLER [ht2] ************************************************************************************************************ changed: [dbserver] changed: [webserver] PLAY RECAP *********************************************************************************************************************** dbserver : ok=5 changed=4 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 webserver : ok=5 changed=4 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 默认情况下，所有 task 执行完毕后，才会执行各个 Handler，而且 Handler 的执行顺序与 Handler 在 Playbook 中的定义顺序是相同的，与 Handler 被 notify 调用的顺序无关，这一点大家要注意。如果你想要在执行完某些 task 以后立即执行对应的 Handler，则需要使用 meta 模块 --- - hosts: all remote_user: root tasks: - name: make testfile1 file: path: /testdir/testfile1 state: directory notify: ht2 - meta: flush_handlers # 定义一个meta任务，表示立即执行之前task任务对应的handlers - name: make testfile3 file: path: /testdir/testfile3 state: directory notify: ht1 handlers: - name: ht1 file: path: /testdir/testfile4 state: touch - name: ht2 file: path: /testdir/testfile2 state: touch Handlers 分组我们可以将 Handlers 任务列表分组，将多个 Handlers 任务组成一个组，然后在 task 任务列表 notify 一个 Handlers 组，这时候 task 任务执行完之后就会一次性执行多个 Handlers 任务 --- - hosts: all remote_user: root tasks: - name: make testfile1 file: path: /testdir/testfile1 state: directory notify: handlers group1 - meta: flush_handlers handlers: - name: ht1 listen: handlers group1 file: path: /testdir/testfile4 state: touch - name: ht2 listen: handlers group1 file: path: /testdir/testfile2 state: touch 将 ht1 和 ht2 这两个 Handlers 任务都监听 Handlers group1 这一个组，这时候在 task 任务列表 notify “handlers group1” 这个组名时，就执行这个组的所有 Handlers 任务","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible Playbook","slug":"Ansible Playbook","date":"2020-05-24T06:24:36.000Z","updated":"2020-09-26T06:26:19.937Z","comments":true,"path":"post/11b6c727.html","link":"","permalink":"https://www.missf.top/post/11b6c727.html","excerpt":"","text":"Ansible Playbook 初识前一章我们学习了 Ansible 的模块，在控制节点上使用了很多 Ansible 的命令对管理节点进行配置和管理，但是在我们真正的工作场景中，如果需要配置一个 Nginx 服务，其实并不是在控制节点执行 Ansible 命令去实现的，你可以想象一下，如果我们需要对管理节点做大量的操作，是不是就是要在控制节点执行非常多的命令呢，而且直接执行命令的方式对管理不同的管理节点时，命令又是需要修改的，这并不是我们想要的。其实 Ansible 是可以写成”脚本”的，注意这里所说的脚本，并不是说将大量的 Ansible 命令放到 shell 脚本里面去，Ansible 在部署较为复杂的任务时，有自己的一套执行流程，称为 “剧本”，剧本翻译过来就是我们所说的 Playbook。编写 Playbook 需要遵循 YAML 语法，那什么又是 YAML 语法呢，它是为了方便人类读写而设计出来的一种通用的数据串行化格式 编写第一个 PlaybookPlaybook 文件都以 “yaml” 或 “yml” 作为文件后缀，这里我们创建一个名为 first.yaml 的 Playbook 文件 # 将下面的ansible命令转化为playbook ansible all -m ping ansible all -m file -a 'path=/etc/nodes state=directory' # playbook的写法: --- - hosts: all remote_user: root tasks: - name: ping nodes ping: - name: mkdir directory file: path: /etc/nodes state: directory 第一行：使用三个横杠作为开始，在 YAML 语法中，”-“ 表示文档开始 第二行：使用 “-“ 作为开头表示一个块序列的节点，后面使用 hosts 关键字指定了要操作的主机 第三行：使用 remote_user 关键字可以指定在管理节点进行操作时使用哪个用户进行操作 第四行：使用 tasks 关键字指明要进行操作的任务列表，之后的行都属于 tasks 键值对中的值 tasks 之后的行都属于任务列表的任务，可以看出任务列表一共有两个任务，每个任务以 “-“ 开头，每个任务都有自己的名字，任务名字使用 name 关键字进行指定，第一个任务使用 ping 模块，ping 模块在使用时不需要指定任何参数。第二个任务使用 file 模块，使用 file 模块时，指定了 path 参数和 state 参数的值 执行 Playbook[root@localhost ~/playbook]# ansible-playbook first.yaml PLAY [all] ********************************************************************************************************************************************************* TASK [Gathering Facts] ********************************************************************************************************************************************* ok: [10.10.110.123] ok: [10.10.110.122] TASK [ping nodes] ************************************************************************************************************************************************** ok: [10.10.110.123] ok: [10.10.110.122] TASK [mkdir directory] ********************************************************************************************************************************************* ok: [10.10.110.122] ok: [10.10.110.123] PLAY RECAP ********************************************************************************************************************************************************* 10.10.110.122 : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 10.10.110.123 : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 如上所示，Playbook 执行后返回了一些信息，这些信息是这次剧本运行的概况。PLAY [all] 表示这次运行的 Playbook 有一个 “play” 是针对所有主机运行的，一个 Playbook 可以是由一个或者多个 play 组成的。这个 play 包含了三个任务，这三个任务分别是 TASK [Gathering Facts]，TASK [ping nodes]，TASK [mkdir directory]。我们只创建了两个任务，为什么却执行了三个任务呢？其实每个 paly 在执行前都会执行一个默认任务，这个默认任务就是 TASK [Gathering Facts]，它会收集当前 play 对应的目标主机的相关信息，收集完这些基础信息后，才会执行我们指定的任务，这里它是收集我们这个 play 的所有主机的信息，然后返回主机的 IP 地址。第二个任务是用 ping 模块去测试管理节点的状态，给我们返回的是绿色的信息，表示管理节点的状态没有发生改变。第三个任务是创建目录，这里如果管理节点没有 /etc/nodes 目录，则会返回黄色的信息，表示在管理节点上创建了目录，管理节点的状态发生了改变。这是再次执行 Playbook，发现创建目录任务的返回信息变成了绿色的，是因为已经创建过目录了，由于幂等性的原因，管理节点的状态没有发生改变。返回信息的最后一个PLAY RECAP 中可以对所有主机的执行情况进行回顾 检查 Playbook 语法ansible-playbook --syntax-check first.yaml 如果执行语法检查命令之后，只返回了 Playbook 的名称，就表示没有语法错误 模拟执行 Playbookansible-playbook --check first.yaml 除了对 Playbook 进行语法测试，我们还能够模拟执行 Playbook，模拟执行并不是真正的执行，只是假装执行一下， Playbook 中的任务并不会真正在目标主机中运行，所以你可以放心大胆的进行模拟，模拟运行功能可以帮助我们 预估 Playbook 是否能够正常执行 注意：使用上述命令进行模拟时，一些任务可能会报错，这可能是因为报错的任务在执行时需要依赖之前的其他任务的完成结果，但是因为是模拟执行，所以之前的任务并不会真正的执行，既然之前的任务没有真正的执行，自然不会产生对应的结果，所以后面的任务就报错了。也就是说，我们并不能完全以模拟的反馈结果作为 Playbook 是否能够正常运行的判断依据，只能通过模拟大概的预估一下而已 使用 Playbook 安装 Nginx目录文件规划 tree /root/playbook/ /root/playbook/ ├── index.html.j2 ├── nginx.conf └── nginx.yaml 编写 Playbook --- - hosts: all remote_user: root vars: # 定义变量，可以在nginx.conf文件中调用 http_port: 80 max_clients: 65535 tasks: - name: ensure nginx is at the latest version yum: name: nginx state: installed - name: write the nginx config file template: # 模板模块，将当前目录下的nginx.conf文件(文件里面定义的变量会自动赋值再拷贝)拷贝到管理节点 src: nginx.conf dest: /etc/nginx/nginx.conf - name: write the site file template: src: index.html.j2 dest: /usr/share/nginx/html/index.html notify: - restart nginx - name: ensure nginx is running service: name: nginx state: started handlers: - name: restart nginx service: name=nginx state=restarted 编写 Nginx 配置文件 #user nobody; worker_processes auto; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections {{ max_clients }}; # 调用nginx.yaml中定义的变量 } http { include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server { listen {{ http_port }}; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root /usr/share/nginx/html/; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht { # deny all; #} } } 编写 index.html.j2 文件 Hello Ansible! This is {{ansible_all_ipv4_addresses}} 在 Ansible 控制节点上查看 curl 10.10.110.122 Hello Ansible! This is [u'10.10.110.122'] # 这个是可变变量 curl 10.10.110.123 Hello Ansible! This is [u'10.10.110.123']","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible YAML 基本语法","slug":"Ansible YAML 基本语法","date":"2020-05-23T03:54:36.000Z","updated":"2020-09-26T06:20:59.178Z","comments":true,"path":"post/cbb0a0c0.html","link":"","permalink":"https://www.missf.top/post/cbb0a0c0.html","excerpt":"","text":"Ansible 的 YAML 基本语法大小写敏感 使用缩进表示层级关系 缩进时不允许使用 Tab 键，只允许使用空格 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可 YAML 文件以 “-“ 作为文档的开始，”…” 作为文档的结束 # 表示注释，从这个字符一直到行尾，都会被解析器忽略 相同缩进级别的行以 “-“ (破折号和空格)开头的组成一个列表 YAML 支持的三种数据结构 数组：一组按次序排列的值，又称为序列 (sequence) / 列表 (list) 对象：键值对的集合，又称为映射 (mapping)/ 哈希 (hashes) / 字典 (dictionary) 纯量：单个的、不可再分的值 数组相同缩进级别的行以 “-“ (破折号和空格) 开头组成一个列表就是数组 --- fruits: - Apple - Banana - orange - melon # 行内表示法 fruits: ['Apple', 'Banana', 'orange', 'melon'] 对象对象的一组键值对，使用冒号结构表示(冒号后面要有个空格) sb: name: Alex job: python skill: brag # 行内表示法 sb: {name: Alex, job: python, skill: brag} 纯量数值 number: 12 float: 15.20 布尔值 表示true的值 true, True, TRUE, yes, Yes, YES, on, On, ON, y, Y 表示false的值 false, False, FALSE, no, No, NO, off, Off, OFF, n, N 强制类型转换 a: !!str 123 d: !!str true # 这个true的数据类型不再是布尔值，而是str类型 字符串 str: 这是字符串 s1: '内容\\n字符串' # 如果字符之中包含空格和特殊字符，需要放在引号之中，单引号和双引号都可以使用，双引号不会对特殊字符转义 空值 # null: 用~表示 parent: ~ 引用&amp; 用来建立锚点(defaults)，&lt;&lt; 表示合并到当前数据，* 用来引用锚点 defaults: &amp;defaults adapter: postgres host: localhost development: database: myapp_development &lt;&lt;: *defaults test: database: myapp_test &lt;&lt;: *defaults # 上面的写法等同于下面的代码: defaults: adapter: postgres host: localhost development: database: myapp_development adapter: postgres host: localhost test: database: myapp_test adapter: postgres host: localhost 参考Palybooks 更多的 YAML 语法请参考：http://docs.ansible.com/YAMLSyntax.html","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible 模块学习","slug":"Ansible 模块学习","date":"2020-05-12T03:12:59.000Z","updated":"2020-09-26T06:12:31.506Z","comments":true,"path":"post/8704a1a2.html","link":"","permalink":"https://www.missf.top/post/8704a1a2.html","excerpt":"","text":"setup模块setup 模块主要用于获取主机信息，每个管理节点在接收控制节点命令之前，会将主机的信息告知控制节点 filter：用于进行条件过滤，如果设置，仅返回匹配过滤条件的信息 关键字 说明 返回值例子 ansible_nodename 节点名 “6-dns-1.hunk.tech” ansible_fqdn FQDN名 “6-dns-1.hunk.tech” ansible_hostname 主机短名称 “6-dns-1” ansible_domain 主机域名后缀 “hunk.teh” ansible_memtotal_mb 总物理内存 “ansible_memtotal_mb”: 222 ansible_swaptotal_mb SWAP总大小 “1023” ansible_processor CPU信息 Intel(R) Core(TM) i5-5200U CPU @ 2.20GHz ansible_processor_cores CPU核心数量 4 ansible_processor_vcpus CPU逻辑核心数量 2 ansible_all_ipv4_addresses 有所IPV4地址 192.168.0.200 ansible_all_ipv6_addresses 所有IPV6地址 ansible_default_ipv4 默认网关的网卡配置信息 ansible_eth2 具体某张网卡信息 不同系统名称需要变化 ansible_dns DNS设置信 ansible_architecture 系统架构 x86_64 ansible_machine 主机类型 x86_64 ansible_kernel 内核版本 “2.6.32-696.el6.x86_64” ansible_distribution 发行版本 “CentOS” ansible_distribution_major_version 操作系统主版本号 “6” ansible_distribution_release 发行版名称 “Final” ansible_distribution_version 完整版本号 “7.4.1708” ansible_pkg_mgr 软件包管理方式 “yum” ansible_service_mgr 进行服务方式 “systemd” ansible_os_family 家族系列 “RedHat” ansible_cmdline 内核启动参数 ansible_selinux SElinux状态 “disabled” ansible_env 当前环境变量参数 ansible_date_time 时间相关 ansible_python_version python版本 “2.6.6” ansible_lvm LVM卷相关信息 ansible_mounts 所有挂载点 ansible_device_links 所有挂载的设备的UUID和卷标名 ansible_devices 所有/dev/下的正在使用的设备的信息 ansible_user_dir 执行用户的家目录 “/root” ansible_user_gecos 执行用户的描述信息 “The root “ ansible_user_gid 执行用户的的GID 0 ansible_user_id 执行用户的的用户名 “root” ansible_user_shell 执行用户的shell类型 “/bin/bash” ansible_user_uid 执行用户的UID 0 查看管理节点的 Python 版本信息 ansible all -m setup -a 'filter=ansible_python_version' 查看管理节点的发行版本 ansible all -m setup -a 'filter=ansible_distribution' command 模块Ansible 的默认模块，可以不用 “-m” 指定，”-a” 是 command 的参数 free_form：其实没有名为 “free form” 的实际参数，command 模块接受自由格式的命令运行 chdir：在执行对应的命令之前，会先进入到 chdir 参数指定的目录中 creates：如果指定的文件存在时，就不执行对应命令 removes：当指定的文件不存在时，就不执行对应命令 查看管理节点 /etc/ 目录下的 hosts 文件内容 ansible all -a \"chdir=/etc cat hosts\" 查看管理节点 /etc/ 目录下的 hosts 文件内容，如果存在 /etc/passwd 文件则不执行 ansible all -a \"chdir=/etc creates=/etc/passwd cat hosts\" command 模块不支持调用 “$HOME” 这样的变量，还有像( &lt; &gt; | ; &amp; )这些正则和通配符都将不可用，但是 command 模块更安全，因为他不受用户环境的影响。 也很大的避免了潜在的 shell 注入风险 shell 模块shell 模块可以帮助我们在远程主机上执行命令。与 command 模块不同的是，shell 模块在远程主机中执行命令时，会经过远程主机上的 /bin/sh 程序处理，能够使用( &lt; &gt; | ; &amp; )这些符号和环境变量 free_form：其实没有名为 “free form” 的实际参数，command 模块接受自由格式的命令运行 chdir：在执行对应的命令之前，会先进入到 chdir 参数指定的目录中 creates：如果指定的文件存在时，就不执行对应命令 removes：当指定的文件不存在时，就不执行对应命令 executable：默认 shell 模块会调用远程主机中的 /bin/sh 去执行对应的命令，也可以指定 shell，需要使用绝对路径 shell 模块在管理节点上执行命令时，支持管道和重定向等符号 ansible all -m shell -a 'chdir=/etc executable=/bin/bash cat hosts >/tmp/hosts.bak' script 模块script 模块可以帮助我们在管理节点上执行控制节点上的脚本，也就是说在管理节点上执行脚本不需要把脚本拷贝过去 free_form：指定需要执行的脚本，其实没有名为 “free form” 的实际参数 chdir：在执行对应的脚本之前，会先进入到 chdir 参数指定的目录中 creates：如果指定的文件存在时，就不执行脚本 removes：当指定的文件不存在时，就不执行脚本 在管理节点上执行控制节点的 /root/test.sh 脚本，执行之前切换到 /opt 目录 ansible all -m script -a 'chdir=/opt /root/test.sh' copy 模块copy 模块的作用就是将 Control node 的文件拷贝到 Managed nodes scr：用于指定控制节点上被 copy 的文件或目录 dest：用于指定文件将被拷贝到管理节点的路径，dest 为必须参数 content：当不使用 src 指定拷贝的文件时，可以使用 content 直接指定文件内容，src 与 content 两个参数必有其一 force：当管理节点的目标路径存在同名文件，并且两个文件内容不同，是否强制覆盖，可选值有 yes 和 no，默认值为 yes backup：当管理节点的目标路径存在同名文件，并且两个文件内容不同，是否对管理节点的文件进行备份，可选值有 yes 和 no owner：指定文件拷贝到管理节点后的属主，但是管理节点上必须有对应的用户 group：指定文件拷贝到管理节点后的属组，但是管理节点上必须有对应的组 mode：指定文件拷贝到管理节点后的权限，可以使用 mode=0644 表示，也使用 mode=u+x 表示 将控制节点的 /etc/hosts 文件复制到管理节点的 /root 目录下，如果管理节点的 /root 目录已经存在文件，则会默认覆盖 ansible all -m copy -a \"src=/etc/hosts dest=/root/\" # 如无意外这里你看到的字体颜色是黄色的，这是成功执行并且状态发生了改变的 复制文件，指定文件的属主和属组，需要注意的是管理节点必须存在对应的用户和组 ansible all -m copy -a \"src=/etc/hosts dest=/tmp/ owner=mwj group=mwj\" 复制文件，如果管理节点的目标路径已存在同名文件且内容不相同，则对管理节点的文件先进行备份，再把控制节点的文件复制到管理节点 ansible all -m copy -a \"src=/etc/hosts dest=/tmp/ backup=yes\" # 在返回的结果列表能看到: \"backup_file\": \"/tmp/hosts.15575.2020-05-12@22:28:50~\" # ansibel是用哈希值去校验两个文件的内容是否一致的 file 模块file 模块可以完成对文件增删查改的基本操作 path：用于指定要操作的文件或目录，必须参数 state：ansible无法从 path=/test/a/b 得知我们想要创建目录还是文件，所以需要使用 state 参数配和 path 来声明操作的类型 state=directory 创建的是目录 state=touch 创建的是文件 state=link 创建的是软连接文件 state=hard 创建的是硬链接文件 state=absent 删除文件或者目录，absent 意为 “缺席” src：当 state 设置为 link 或者 hard 时，我们必须指明软硬链链接到哪个文件，通过 src 参数即可指定链接源 force：当 state=link 的时候，可配合 force=yes 参数强制创建链接文件，但是强制创建会有两种情况 情况一：当要创建的链接文件所指向的源文件并不存在时，使用此参数可以先强制创建出链接文件 情况二：当要创建链接文件的路径中已经存在与链接文件同名的文件时，将 force 设置为 yes，会将同名文件覆盖为链接文件 owner：用于指定被操作文件或目录的属主 group：用于指定被操作文件或目录的属组 mdoe：用于指定被操作文件或目录的权限，使用 mode=755，设置特殊权限则可以使用 mode=4700 recurse：当要操作的对象为目录，将 recurse 设置为 yes，可以递归的修改目录中文件的属性 在管理节点上创建一个名为 testdir 的目录，如果目录已存在则不进行任何操作 ansible all -m file -a \"path=/testdir/ state=directory\" 在管理节点上创建一个名为 testfile 的文件，如果文件已存在则会更新文件的时间戳 ansible all -m file -a \"path=/testdir/testfile state=touch\" 在管理节点创建一个名为 /testdir/linkfile 的链接文件，链接的源文件 /testdir/testfile 已存在 ansible all -m file -a \"path=/testdir/linkfile state=link src=/testdir/testfile\" 在管理节点上删除指定的文件或目录 ansible all -m file -a \"path=/testdir/testfile state=absent\" fetch 模块从管理节点拉取文件到控制节点 dest：用来存放从管理节点拉取到的文件 src：管理节点被拉取的文件，必须是文件不能是目录 flat：默认为 no，会将拉取到控制节点的文件以 hostname/file 的命名存放在 dest 目录，如果为 yes，则直接按文件名存放 Validate_checksum：拉取文件之后进行 MD5 检查 拉取管理节点的 /etc/hosts 文件到控制节点的 /data/ 目录 ansible all -m fetch -a \"src=/etc/hosts dest=/data/\" # 这里flat默认为no，所以拉取之后存放的方式是这样的 tree /data/ /data/ ├── 10.10.110.122 │ └── etc │ └── hosts └── 10.10.110.123 └── etc └── hosts ansible all -m fetch -a \"src=/etc/hosts dest=/data/ flat=yes\" # flat=yes是直接按文件名存放 tree /data/ /data/ └── hosts # 只有一个hosts文件是因为第一个hosts被覆盖掉了 blockinfile 模块blockinfile 模块可以帮助我们在指定的文件中插入 “一段文本”，这段文本是被标记过的，我们在这段文本上做了记号，以便在以后的操作中可以通过 “标记” 找到这段文本，然后修改或者删除它 path：指定要操作的文件 block：此参数用于指定我们想要插入的那 “一段文本”，此参数有一个别名叫 “content”，使用 content 或 block 的作用是相同的 marker：自定义开始和结束的标记，marker=#{mark}test:开始为# BEGIN test，结束为# END test insertafter：在插入一段文本时，默认会在文件的末尾插入文本，如果你想要将文本插入在某一行的后面，可以使用此参数指定对应的行 insertbefore：在插入一段文本时，默认会在文件的末尾插入文本，如果你想要将文本插入在某一行的前面，可以使用此参数指定对应的行 backup：是否在修改文件之前对文件进行备份 create：当要操作的文件并不存在时，是否创建对应的文件 在管理节点的 /testdir/rc.local 文件末尾插入一行 systemctl start mariadb ansible all -m blockinfile -a 'path=/testdir/rc.local block=\"systemctl start mariadb\"' 自定义插入的开始和结束的标记 ansible all -m blockinfile -a 'path=/testdir/rc.local block=\"systemctl restart mysqld\\nnginx -s reload\" marker=\"#{mark} serivce to start\"' # 查看被插入的文本 #BEGIN serivce to start systemctl restart mysqld nginx -s reload #END serivce to start 使用 create 参数，如果指定的文件不存在则创建它 ansible all -m blockinfile -a 'path=/testdir/date block=\"今天是5月12号\\n汶川地震12周年\" marker=\"#{mark} 日期记录\" create=yes' 使用 backup 参数，可以在操作修改文件之前对文件进行备份 ansible all -m blockinfile -a 'path=/testdir/date block=\"今天是5月12号\\n汶川地震12周年\" marker=\"#{mark} 日期记录\" backup=yes' lineinfile 模块我们可以借助 lineinfile 模块，确保 “某一行文本” 存在于指定的文件中，还可以根据正则表达式替换 “某一行文本” path：指定要操作的文件 line：使用此参数指定文本内容 regexp：使用正则表达式匹配对应的行 state：当想要删除对应的文本时，需要将 state 参数的值设置为 absent backrefs：开启后向引用，line 参数中就能对 regexp 参数中的分组进行后向引用了 insertafter：借助 insertafter 参数可以将文本插入到 “指定的行” 之后 insertbefore：借助 insertbefore 参数可以将文本插入到 “指定的行” 之前 backup：是否在修改文件之前对文件进行备份 create：当要操作的文件并不存在时，是否创建对应的文件 确保 “test lineinfile” 这行文本存在于 /testdir/date 文件中，如果存在则不做任何操作，如果不存在则在末尾插入 ansible all -m lineinfile -a 'path=/testdir/date line=\"test lineinfile\"' 根据正则表达式替换 “某一行”，如果多行能够匹配正则，只有最后匹配的行才会被替换，如果没有匹配到则会在末尾插入 line 的内容 ansible all -m lineinfile -a 'path=/testdir/date regexp=\"^test\" line=\"被替换后的内容\"' 根据正则匹配删除对应的行，如果文件多行都与正则匹配，则删除多行 ansible all -m lineinfile -a 'path=/testdir/date regexp=\"^#.*-$\" state=absent' # 删除#开头-结尾中间有任意个字符的行 在管理节点的 /testdir/date 文件的 “#Hello saltstack,Hiiii” 这一行之后插入 123 ansible all -m lineinfile -a 'path=/testdir/date line=\"123\" insertafter=\"#Hello saltstack,Hiiii\"' find 模块find 模块可以帮助我们在管理节点中查找符合条件的文件，就像 find 命令一样 paths：必须参数，指定在哪个目录中查找文件，可以指定多个路径，路径间用逗号隔开 recurse：默认只会在指定的目录中查找文件，当 recurse 参数设置为 yes 时，表示会递归的查找文件 hidden：默认不会去查找隐藏文件，只有当 hidden 参数的值设置为 yes 时才会查找隐藏文件 file_type：默认只会根据条件查找 “文件”，可以通过 file_type 指定文件类型，any | directory | file | link patterns：使用此参数指定需要查找的文件名称，支持使用 shell (比如通配符)或者正则表达式去匹配文件名称 use_regex：当 use_regex 设置为 yes 时，表示使用 python 正则解析 patterns 参数中的表达式 contains：使用此参数可以根据文章内容查找文件，此参数的值为一个正则表达式 age：用此参数可以根据时间范围查找文件，默认以文件的 mtime 为标准与指定的时间进行对比 age_stamp：文件的时间属性中有三个时间种类：atime、ctime、mtime，当我们根据时间范围查找文件时，可以指定以哪个时间种类为准 size：使用此参数可以根据文件大小查找文件 get_checksum：当有符合查找条件的文件被找到时，会同时返回对应文件的 sha1 校验码 在管理节点的 /etc 目录中查找包含 www 字符串的文件，不进行递归并忽略隐藏文件 ansible all -m find -a 'paths=/etc contains=\".*www.*\"' 在管理节点的 /etc 目录查找以 .sh 结尾的文件，包括隐藏文件并进行递归查找 ansible all -m find -a 'paths=/etc patterns=\"*.sh\" hidden=yes recurse=yes' 在管理节点的 /etc 目录查找链接文件，包括隐藏文件并进行递归查找 ansible all -m find -a 'paths=/etc file_type=link hidden=yes recurse=yes' 在管理节点的 /etc 目录查找以 .sh 结尾的文件，只不过patterns 对应的表达式为正则表达式，包括所有文件类型 ansible all -m find -a 'paths=/etc patterns=\"\\*.sh\" file_type=any use_regex=yes' 在管理节点的 /etc 目录递归查找 mtime 在 4 天以内的文件 ansible all -m find -a 'paths=/etc age=-4d recurse=yes' 在管理节点的 /etc 目录递归查找大于 2G 的文件 ansible all -m find -a 'paths=/etc size=2g recurse=yes' 在管理节点的 /etc 目录递归查找 .conf 结尾的文件，并且返回符合条件的文件的 sha1 校验码 ansible all -m find -a 'paths=/etc patterns=\"*.conf\" recurse=yes get_checksum=yes' replace 模块replace 模块可以根据我们指定的正则表达式替换文件中的字符串，文件中所有被正则匹配到的字符串都会被替换 path：必须参数，指定要操作的文件，别名：dest | destfile | name regexp：必须参数，指定一个 python 正则表达式，文件中与正则匹配的字符串将会被替换 replace：指定最终要替换成的字符串 backup：是否在修改文件之前对文件进行备份，最好设置为 yes 将管理主机的 /testdir/date 文件中所有的 ansible 替换为 saltstack，操作前进行文件备份 ansible all -m replace -a 'path=/testdir/date regexp=\"ansible\" replace=saltstack backup=yes' cron 模块cron 模块可以帮助我们配置管理节点的计划任务，功能相当于 crontab 命令 minute：用于设置分钟值，格式为 minute=5，如不指定此参数，则分钟值默认为 * hour：用于设置小时值，格式为 hour=5，如不指定此参数，则小时值默认为 * day：用于设置日值，如不指定此参数，则日值默认为 * month：用于设置月值，如不指定此参数，则月值默认为 * weekday：用于设置周值，如不指定此参数，则月值默认为 * special_time：时间设定格式为 @reboot 或者 @hourly，这种 @ 开头的时间设定格式则需要使用 special_time 参数进行设置 注意：如果以上参数都不设置，则默认使用 * * * * * ，表示每分钟都执行一次，我们应该谨慎设置时间参数 user：设置当前计划任务属于哪个用户，不指定则默认为管理员用户 job：执行计划任务中需要实际执行的命令或脚本 name：设置计划任务的名称，方便我们以后根据名称修改或者删除计划任务 state：可以根据已有名称的计划任务进行修改和删除，当删除时需要将 state 的值设置为 absent disabled：可以将已有名称的计划任务注释，但使用此参数除了指定任务名称还需要指定 job 以及时间的设定，否则注释任务时，任务的时间会被修改 backup：当此参数设置为 yes，那么修改和删除计划任务时，会在管理节点的 tmp 目录下创建备份文件 在管理节点创建名为 test cron 计划任务，每天的12点5分，任务内容为将 test 重定向到 /tmp/test ansible all -m cron -a 'name=\"test cron\" minute=5 hour=12 job=\"echo test > /tmp/test\"' # 管理节点的计划任务构建如下: #Ansible: test cron 5 12 * * * echo test > /tmp/test 在管理节点创建名为 day cron 计划任务，每三天执行一次。与执行当天的14点5分开始执行，任务内容为输出 test ansible all -m cron -a 'name=\"day cron\" minute=5 hour=14 day=*/3 job=\"echo test\"' # 管理节点的计划任务构建如下: #Ansible: day cron 5 14 */3 * * echo test 在管理节点创建名为 day cron 计划任务，任务在重启时执行，任务内容为输出 test ansible all -m cron -a 'name=\"day cron\" special_time=reboot job=\"echo test\"' # 由于已存在day cron任务，ansible就会认为我们是需要修改这个任务，计划任务被修改为: #Ansible: day cron @reboot echo test 在管理节点注释掉我们之前创建的 test cron 任务，注释时进行备份 ansible all -m cron -a 'name=\"test cron\" minute=5 hour=12 job=\"echo test > /tmp/test\" disabled=yes backup=yes' # 符合注释条件的计划任务就会被注释掉: #Ansible: test cron #5 12 * * * echo test > /tmp/test 如果你注释计划任务时，设置了错误的时间和 job，那么注释对应任务时(以name去对应)，时间和 job 的设定也会发生改变 ansible all -m cron -a 'name=\"test cron\" hour=23 job=\"echo test > /tmp/test\" disabled=yes backup=yes' #Ansible: test cron #* 23 * * * echo test > /tmp/test # 注释的同时，时间设定也会改变 service 模块service 模块可以对管理节点上的服务进行管理，例如启动或停止管理节点的 Nginx 服务。但前提是这个服务必须被 BSD init | OpenRC | SysV | Solaris SMF | systemd | upstart 中的任意一种所管理，意思就是这个服务在 CentOS6 管理节点能以 service nginx start 启动，在CentOS7 管理节点能以 systemctl start nginx 启动。如果管理节点上的服务无法通过这样的方式启动，那么 service 模块也无法对它进行管理 name：用于指定操作的服务名称，例如 name=nginx state：用户指定服务的状态，可用值有 started | stopped | restarted | reloaded enabled：用于指定是否将服务设置为开机启动项，设置为 yes 则表示开机启动，设置为 no 表示不会开机启动 在管理节点上启动 Nginx 服务 ansible all -m service -a 'name=nginx state=started' 在管理节点上启动 mysql 服务并设置为开机启动 ansible all -m service -a 'name=mysql state=started enabled=yes' user 模块user：模块可用帮助我们在管理节点上创建用户、修改用户、删除用户、为用户创建密钥对等操作 name：必须参数，用于指定要操作的用户名称 group：用于指定用户所在的基本组 shell：用于指定用户的默认 shell uid：用于指定用户的 uid 号 expires：用于指定用户的过期时间 comment：用于指定用户的注释信息 state：用于指定用户是否存在于远程主机中，默认值为 present，表示用户需要存在，当设置为 absent 时表示删除用户 remove：默认值为 no，表示删除用户时不会删除家目录，设置为 yes 则表示删除用户时删除用户家目录 password：用于指定用户的密码，但是这个密码不能是明文的密码 generate_ssh_key：默认值为 no，如果设置为 yes 则表示为用户在家目录的 .ssh 下创建密钥对，如果对应的路径已有同名密钥对则不进行任何操作 ssh_key_file：默认值为 yes，使用此参数自定义生成 ssh 私钥的路径和名称 ssh_key_passph rase：当 generate_ssh_key 参数的值为 yes 时，在创建证书时使用此参数设置私钥的密码 ssh_key_type：当 generate_ssh_key 参数的值为 yes 时，在创建证书时使用此参数设置密钥对的类型 在管理节点上创建 mis 用户，并把用户添加到 root 组，如果用户已存在则不做任何操作 ansible all -m user -a 'name=mis group=root' 在管理节点上删除 mis 用户，同时把用户家目录也删除 ansible all -m user -a 'name=mis state=absent remove=yes' 在管理节点上创建 mis 用户，指定用户的注释信息，设置用户过期时间是 2020-06-15 ansible all -m user -a 'name=mis comment=\"missf.top\" expires=1592150400' # 先使用\"date -d 2020-06-15 +%s\"命令得到Unix时间戳 在管理节点上为 mis 用户设置密码，加密字符串可以使用 python 得到 ansible all -m user -a 'name=mis password=\"$6$d62UFoKtSRA9Yaq4$qtvyr5atLdoXgvXOhktU.baVqbtlcaWc9dizmM41Bc9XOaTZW/Pqaxb8pofS5Wo4n5Nu/CEk8GEsKnC2zTfEl1\"' 可以使用 import crypt; crypt.crypt(\"123456\") 得到123456加密之后的字符串 在管理节店上为 mis 用户生成密钥对，同时指定私钥密码为 123456，密钥对的类型为 dsa，如不指定密钥对类型默认为 rsa ansible all -m user -a 'name=mis generate_ssh_key=yes ssh_key_passphrase=\"123456\" ssh_key_type=dsa' group 模块group 模块可以帮助我们在管理节点上管理用户组 name：用于指定操作的服务名称，例如 name=nginx state：用户指定服务的状态，可用值有 started | stopped | restarted | reloaded enabled：用于指定是否将服务设置为开机启动项，设置为 yes 则表示开机启动，设置为 no 表示不会开机启动 确保管理节点上存在 mkd 组，如果没有则创建，如果已存在则不做任何操作 ansible all -m group -a 'name=mkd' 在管理节点上删除 mkd 组，前提是不能有用户把被删除的组当成主组，不然不能成功删除 ansible all -m group -a 'name=mkd state=absent' yum_repository 模块yum_repository：模块可以帮助我们在管理节点上管理yum仓库 name：必须参数，指定要操作的唯一仓库 ID，repo 配置文件中括号的仓库 ID baseurl：用于设置 yum 仓库的 baseurl description：用于设置仓库的注释信息，repo 配置文件中 name 字段对应的内容 file：用户设置仓库的配置文件名称，就是 repo 配置文件的前缀，如不指定则默认以仓库 ID 命名 enabled：用于设置是否激活对应的 yum 源 gpgcheck：用于设置是否开启 rpm 包验证功能，默认值为 no 表示不开启包验证，设置为 yes 表示开启 gpgcakey：当开启包验证功能时，使用此参数指定验证包所需的公钥 state：默认值为 present，设置为 absent 表示删除对应的 yum 源 在管理节点上创建前缀为 aliepel 的 repo 文件，设置注释信息和不验证包功能 ansible all -m yum_repository -a 'name=aliepel description=\"alibaba_epel\" baseurl=https://mirrors.aliyun.com/epel/$releasever\\Server/$basearch/ gpgcheck=no' 在管理节点创建指定名称为 ali 的 repo 文件，但是不启用它 ansible all -m yum_repository -a 'name=aliepel description=\"alibaba_epel\" file=ali baseurl=https://mirrors.aliyun.com/epel/$releasever\\Server/$basearch/ gpgcheck=no enabled=no' yum 模块yum 模块可以帮助我们在管理节点上管理软件包 name：必须参数，用于指定需要管理的软件包名字 state：用户指定软件包的状态，默认是 present，表示确认已安装软件包，installed 与 present 等效，absent 和 removed 等效，表示删除对应的软件包 disable_gpg_check：用于禁用对 rpm 包的公钥 gpg 验证，默认值为no表示不禁用验证，设置为 yes 表示禁用验证，如果 yum 源没有开启验证需要将此参数设置为 yes enablerepo：用于安装软件包时临时启用 yum 源，想要从A源安装软件，但是A源没有启用时，这个参数设置为 yes 表示临时启用 disablerepo：用于安装软件包时临时禁用 yum 源，当多个源中同时存在软件包时，可以临时禁用某个源 确保管理节点上安装了 Nginx，禁用 rpm 包验证 ansible all -m yum -a 'name=nginx state=installed disable_gpg_check=yes' 确保管理节点上安装了 Telnet，并禁用 rpm 包验证和临时禁用 local 源 ansible all -m yum -a 'name=telnet disable_gpg_check=yes disablerepo=local' template 模块 src：控制节点上的模板文件 dest：管理节点上将被控制节点上的模板文件所替换的文件 owner：指定控制节点拷贝到管理节点的文件属主 group：指定控制节点拷贝到管理节点的文件属组 mode：指定控制节点拷贝到管理节点的文件权限 force：如果管理节点已存在同名文件并且内容不同时，是否强制覆盖，默认值为 yes 表示覆盖 backup：如果管理节点已存在同名文件并且内容不同时，是否对管理节点源文件进行备份 将控制节点配置好的模板文件分发到管理节点的 /etc/redis.conf，设置不强制覆盖 ansible all -m template -a 'src=/root/redis.conf dest=/etc/redis.conf force=no'","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible 主机清单","slug":"Ansible 主机清单","date":"2020-05-10T02:12:59.000Z","updated":"2020-09-25T09:30:51.649Z","comments":true,"path":"post/794bbd49.html","link":"","permalink":"https://www.missf.top/post/794bbd49.html","excerpt":"","text":"主机清单介绍Ansible 可同时操作属于一个组的多台主机， 组和主机之间的关系通过 inventory 文件配置. 默认的文件路径为 /etc/ansible/hosts，执行命令的时候使用 “-i” 参数即可指定主机清单 主机清单示例主机清单文件主要有 ini 和 yaml 格式两种语法格式 mail.example.com # 定义主机fqdn地址, 需要已经与控制节点ssh互信 localhost ansible_connection=local # ansible_connection可以定义连接类型, local是在本地执行,默认是smart host4 ansible_host=10.10.110.123 ansible_port=50312 ansible_user=root ansible_password=12345 # 指定别名，定义主机ssh连接信息 www[1:50].example.com # 定义 1-50范围内的主机 www-[a:d].example.com # 定义 a-d 范围内的主机 [dbservers] three.example.com ansible_python_interpreter=/usr/local/bin/python3 # 定义python执行ansible，这个是指定被控节点的python 192.168.77.123 ansible_ruby_interpreter=/usr/bin/ruby.1.9.3 # 定义ruby执行文件 webservers:vars] # 定义webservers组的变量 ntp_server=ntp.example.com proxy=proxy.example.com [server:children] # 定义server组的子成员，执行server组时，webservers和dbservers组内的管理节点也会执行 webservers dbservers ini 和 yaml 格式对比# 先写出ini风格 [dbserver] db1 ansible_host=10.10.110.122 ansible_port=22 ansible_user=root ansible_password=0 [webserver] web1 ansible_host=10.10.110.123 ansible_port=22 ansible_user=root ansible_password=0 [server:children] dbserver webserver # 定义子组成员时，需要children关键字 # 和上面一样的配置，这是yaml风格的写法 all: children: server: children: dbserver: hosts: 10.10.110.122 webserver: hosts: 10.10.110.123 yaml 格式配置的还是挺复杂的，可读性也差，建议使用 ini 方式来设置主机清单 默认组在主机清单中，Ansible 会自动的生成两个组 all：所有主机 ungrouped：包含没有组的主机 尽管这两个组是永远存在的，但也有可能是隐藏的，不会出现 group_names 之类的组列表中 主机变量和组变量如果你不想在主机清单中定义主机的变量或者组的变量，Ansible 还支持在特定的目录中定义变量，变量文件必须以 YAML 语法定义 默认在 /etc/ansible/host_vars/ 目录中定义主机变量，文件名称以主机名称命名，结束可以用 “.yml”、”.yaml”、”.json” 三种格式 cat /etc/ansible/host_vars/db1 ntp_server: acme.example.org database_server: storage.example.org 变量优先级问题，如果在各个环节都设置了变量，到底哪个变量生效呢？优先顺序：all 最低，host 最高： all group parent group child group host 使用多个主机清单在命令参数中，使用多个 “-i” 就可以指定多个主机清单 ansible all -i staging -i production -m ping ansible all -i /tmp/staging -i /tmp/production -m ping 使用 SSH 秘钥连接主机# 生成秘钥 ssh-keygen -t rsa # 发送公钥文件到管理节点 ssh-copy-id -i /root/.ssh/id_rsa.pub -p 22 root@10.10.110.122 # 现在主机清单里不用再填写账号密码了","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible 快速开始","slug":"Ansible 快速开始","date":"2020-05-09T01:12:59.000Z","updated":"2020-09-25T09:27:01.405Z","comments":true,"path":"post/f57ff704.html","link":"","permalink":"https://www.missf.top/post/f57ff704.html","excerpt":"","text":"Ansible 快速开始Control OS：CentOS 7.7 x64 Ansible version：2.9.7 Python version：2.7.5` 任务Control node 连接 Managed node 定义主机清单定义一个简单的通过 SSH 认证的主机清单 cat /etc/ansible/hosts 10.10.110.122 ansible_user=root ansible_pass=0 ansible_port=22 主机清单的配置含义: ansible_host 定义管理节点 ip 地址 ansible_user 连接管理节点的用户 ansible_pass 连接管理节点的用户密码 ansible_port 连接端口号默认是 22 执行 Ansible 命令测试 Control node 和 Managed nodes 的连接状态 ansible 10.10.110.122 -m ping # 命令中的含义 -192.168.77.135 用于匹配主机清单中的主机名称 -m ping 指定 ping 模块，用于测试与管理节点的连接状态 如果提示如下错误： 10.10.110.122 | FAILED! => { \"msg\": \"Using a SSH password instead of a key is not possible because Host Key checking is enabled and sshpass does not support this. Please add this host's fingerprint to your known_hosts file to manage this host.\" } 这是因为 Control node 和 Managed nodes 第一次连接需要先添加指纹信息，可以先使用 SSH 连接一次，如果机器太多的话，可以在 Ansible 配置文件开启 host_key_checking = False cat /etc/ansible/ansible.cfg host_key_checking = False 再次测试连接状态 ansible 10.10.110.122 -m ping 10.10.110.122 | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" } # 看到\"ping\": \"pong\"表示连接成功","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible 安装","slug":"Ansible 安装","date":"2020-05-08T03:12:59.000Z","updated":"2020-09-25T09:22:49.544Z","comments":true,"path":"post/4e2cec72.html","link":"","permalink":"https://www.missf.top/post/4e2cec72.html","excerpt":"","text":"安装 Ansible对控制节点的要求： 目前，只要机器上安装了 Python 2 (2.6或更高版本) 或 Python 3 (3.5或更高版本)，都可以运行 Ansible ，windows系统不可以做控制节点，控制节点的系统可以是 Red Hat、Debian、CentOS、macOS、BSD的各种版本 对管理节点的要求： 通常我们使用 ssh 与节点通信，默认使用 sftp. 如果 sftp 不可用，可在 ansible.cfg 配置文件中配置成 scp 的方式. 在节点上也需要安装 Python 2 (2.6或更高版本) 或 Python 3 (3.5或更高版本) 控制节点上安装 Ansible# Centos/RHEL wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo yum install -y ansible # Ubuntu sudo apt update sudo apt install software-properties-common sudo apt-add-repository --yes --update ppa:ansible/ansible sudo apt install ansible Bash命令行自动补全 在Ansible 2.9之后，就支持了命令行参数补齐功能 # Centos/RHEL yum install -y epel-release yum install -y python-argcomplete 将补全加入环境变量activate-global-python-argcomplete source /etc/profile","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Ansible 介绍","slug":"Ansible 介绍","date":"2020-05-07T08:12:59.000Z","updated":"2020-09-25T09:17:25.324Z","comments":true,"path":"post/b5ccc3ed.html","link":"","permalink":"https://www.missf.top/post/b5ccc3ed.html","excerpt":"","text":"Ansible 介绍Ansible 是 2012 年推出的一种通用自动化工具，Ansible 也是我接触的第一个自动化运维工具，Ansible 可以帮助我们完成一些批量任务，或者完成一些经常性的重复工作，在服务器集群场景下，Ansible 是我们运维的利器，Ansible 在2015年时被 Redhat 公司收购。Ansible 是使用 Python 语言编写的，它使用 SSH 协议在不同的机器上执行命令。Ansible 是无代理的，这使得更容易入手。你只需要在相关机器上安装 SSH 和 Python环境。Ansible 使用声明式 YAML 语言，编写 “playbook” 将一组主机 “hosts” 映射到定义明确的角色 也许你会说，我写个 shell 脚本不也一样能实现批量服务器的管理吗？这里我想说的是，Ansible 还支持一些很优秀的特性： 支持幂等性 No Agent 支持 Palybook 实现复杂的任务 使用 YAML 语言 先来说说什么是幂等性。假如我要在目标主机安装 Nginx 服务，但是我不确定这个主机是否已经安装了 Nginx 服务，当使用 Ansible 完成这个任务时，问题就会变得简单，如果目标主机已经安装 Nginx 服务，则 Ansible 不会进行任何操作，如果目标主机未安装 Nginx 服务， Ansible 才会开始工作，Ansible 是以导向为结果的，我们指定一个状态，Ansible 就会自动判断，把服务器的状态调整为我们指定的状态，我多次执行结果都是一样的，这就是幂等性 使用 Zabbix 监控一百台服务器，这一百台服务器都需要安装 Zabbix Agent，但是 Ansible 是不需要在管理节点上安装客户端代理程序的，因为它基于 SSH 工作，只要 Control node 能通过 SSH 连接到 Managed nodes 就能通过 Ansible 管理对应的管理节点，还有就是 Ansible 的控制节点不用单独启动服务，能直接运行命令 Ansible 的目标实现一切自动化 Ansible 的应用场景自动化部署应用 自动化管理配置 自动化的持续交付 自动化的云服务管理 自动化网络设备管理 Ansible 的工作原理 安装 Ansible 到控制节点，定义主机清单，编写好 Palybook，就能运行 Ansible 批量管理管理节点。步骤如下： 1.在控制节点上安装 Ansible 2.配置主机清单: 将管理节点的连接信息配置到控制节点的主机清单中 3.定义 Playbook：指定运行主机和执行任务 对节点主机的要求通常我们使用 SSH 与节点通信，默认使用 sftp 协议，如果 sftp 协议不可用，可在 ansible.cfg 配置文件中配置成 scp 的方式，在管理节点上也需要安装 Python 2 (2.6或更高版本) 或 Python 3 (3.5或更高版本) Ansible 的概念控制节点 (Control node)： 任何装有 Ansible 的机器可称为控制节点 ，你可以从任何控制节点运行命令和剧本，并调用 /usr/bin/ansible 或 /usr/bin/ansible-playbook 命令，你可以将任何安装了 Python 的计算机用作控制节点，笔记本电脑，共享桌面和服务器都可以运行 Ansible， 但是不能将 Windows 计算机用作控制节点 管理节点 (Managed nodes)： 使用 Ansible 管理的网络设备或服务器可称为管理节点，受管节点有时也称为主机 ，受管节点上不需要安装 Ansible 主机清单 (Inventory)： 托管节点的列表，库存文件有时也称为主机文件。你的目录可以为每个托管节点指定诸如 IP 地址之类的信息，库存还可以组织托管节点，创建和嵌套组，以便于扩展 模块 (Modules)： Ansible 执行的具体代码，每个模块都有特定的用途，从管理特定类型数据库的用户到管理特定类型网络设备上的 VLAN 接口。您可以使用任务调用单个模块，也可以调用剧本中的几个不同模块 任务 (Tasks)： Ansible 的行动单位，tasks 包含一组由 module 组成的任务列表，你可以使用特别的命令一次性执行单个任务 剧本 (Playbooks)： 保存了已排序的任务列表，因此可以按此顺序重复运行这些任务。剧本可以包括变量和任务。剧本是用 YAML 编写的，易于阅读、编写、共享和理解","categories":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Hello World","slug":"Hello World","date":"2019-03-28T04:14:29.000Z","updated":"2020-06-02T07:51:22.003Z","comments":true,"path":"post/4a17b156.html","link":"","permalink":"https://www.missf.top/post/4a17b156.html","excerpt":"","text":"所有无法深入问题本质的那些人，最终都将离开这个行业。","categories":[{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/categories/Hello-World/"}],"tags":[{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/tags/Hello-World/"}]},{"title":"我在人间凑数的日子","slug":"我在人间凑数的日子","date":"2019-03-28T04:14:29.000Z","updated":"2020-09-28T03:52:51.871Z","comments":true,"path":"post/world.html","link":"","permalink":"https://www.missf.top/post/world.html","excerpt":"","text":"语言这东西，在表达爱意的时候如此无力，在表达伤害的时候，却如此锋利。 你住的城市下雨了，想问你有没有带伞，可我不敢。因为我怕你说没带，而我又无能为力，就像是我爱你，却给不了你想要的。 十年太长，什么都会变。一辈子太短，一件事也有可能做不完。回忆永远站在背后，你无法抛弃，只能拥抱。 没有回音的山谷不值得纵身一跃。 世界上只有一种英雄、看透了生活的真相，却依然热爱生活。 你联系我，我就听你说，你不联系我，我就顺其自然；实不相瞒，我很想你，但我能控制，因为这样很酷。 我不知道凌晨五点该说晚安还是早安，也不知道这个年龄是该说爱还是喜欢。 曾经我发誓要把生命献给爱情，后来我没死，只是青春替我偿了命。 我与春风皆过客，你携秋水揽星河。 我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 从此无心爱良夜，任他明月下西楼。 仅一夜之间，我的心判若两人。 真正的离别没有长亭古道，也没有劝君更尽一杯酒，只是在一个和往常一样的清晨，有的人留在昨天了。 我吹过你吹过的晚风，那我们算不算相拥。 明智的放弃胜过盲目的执着，去吹吹风吧，能清醒的话，感冒也没关系。 以后不见面的日子要按年算了。 没有特别挚爱的东西，没有一定要得到的人，也没有非做不可的事。 艺术，值得为之痛苦。 我于杀戮之中盛放，亦如黎明中的花朵。 生如蝼蚁，当立鸿鹄之志，命薄如纸，应有不屈之心。 好像什么都还来得及，又好像什么都无能为力。 旧时王谢堂前燕，飞入寻常百姓家。 越过山丘，才发现无人等候。 没有好好告别的人一定会重逢。 如果不是刻意相见，原来真的不会遇见。 有时候生活没那么好，有时候生活也没那么坏。 可能给不了你世间所有温柔，但有个词叫尽我所能。 真正爱你的人会督促你变的优秀，而不是蹉跎你的青春。 人间忽晚，山河已秋。 人间度日，何缘其身。我喜欢这种孤身只影的感觉，它让我孤独得像一个死去多年的人。 我原本可以接受所有的黑暗，如果我不曾见过光明。 我最遗憾的是，从未拥有过一个女孩的青春。 逢人不必言深，孤独本是常态。 种下一棵树最好的时间是十年前，其次是现在。 巅峰产生虚伪的拥护，黄昏见证真正的使徒。 所有命运馈赠的礼物，都早已在暗中标好了价格。 如不抽出时间来创造自己想要的生活，你最终将不得不花费大量的时间来应付自己不想要的生活。 往往最简单的东西里面，藏着最深刻的道理。 俄罗斯方块让我明白，成功会消失，错误会积累；贪吃蛇让我明白，越到后面越危险，最大的敌人是自己。 从来没有什么岁月静好，只不过是有人在替你负重前行！ 书上说，如果有一天你梦见了一个很久没见的人，代表她正在遗忘你。 虽然分手是我提的，但我很清楚是谁要走。 真实发生在身边的事情，让我瞬间明白了许多道理。 Make me feel the warmth,Make me feel the cold. 总有人会洗去生来的泥土，站在云端与诸神共舞。 等人是会上瘾的，因为等着等着，你会发现，如果你不等了，不是放弃了对方，而是背叛了自己。 人难免天生有自怜情绪，唯有时刻保持清醒，才能看清真正的价值在哪里。 可能是未来的架构师，也可能送外卖。 永恒燃烧的羽翼，带我脱离凡间的沉沦。 这世人的喧嚣之上，我追寻着荣光飞翔。 我拿起了母亲的剑，还有她的决心。 无意者烈火焚身，悲索者该当死罪，欺诈者判你无能，忤逆者烈焰加身，堕落者不可饶恕。 我们登上并非我们所选择的舞台，演出并非我们所选择的剧本。 读书是对平庸生活的一次越狱。","categories":[{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/categories/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"}],"tags":[{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/tags/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"},{"name":"记忆","slug":"记忆","permalink":"https://www.missf.top/tags/%E8%AE%B0%E5%BF%86/"},{"name":"语录","slug":"语录","permalink":"https://www.missf.top/tags/%E8%AF%AD%E5%BD%95/"}]}],"categories":[{"name":"MariaDB","slug":"MariaDB","permalink":"https://www.missf.top/categories/MariaDB/"},{"name":"Maxscale","slug":"MariaDB/Maxscale","permalink":"https://www.missf.top/categories/MariaDB/Maxscale/"},{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"},{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"},{"name":"CODING","slug":"CODING","permalink":"https://www.missf.top/categories/CODING/"},{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/categories/Ansible/"},{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/categories/Hello-World/"},{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/categories/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"}],"tags":[{"name":"MariaDB","slug":"MariaDB","permalink":"https://www.missf.top/tags/MariaDB/"},{"name":"数据库","slug":"数据库","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"读写分离","slug":"读写分离","permalink":"https://www.missf.top/tags/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/"},{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"},{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"CODING","slug":"CODING","permalink":"https://www.missf.top/tags/CODING/"},{"name":"持续集成","slug":"持续集成","permalink":"https://www.missf.top/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"name":"Ansible","slug":"Ansible","permalink":"https://www.missf.top/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"},{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/tags/Hello-World/"},{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/tags/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"},{"name":"记忆","slug":"记忆","permalink":"https://www.missf.top/tags/%E8%AE%B0%E5%BF%86/"},{"name":"语录","slug":"语录","permalink":"https://www.missf.top/tags/%E8%AF%AD%E5%BD%95/"}]}