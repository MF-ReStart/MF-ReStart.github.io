{"meta":{"title":"荒原饮露","subtitle":"可能是未来的架构师，也可能送外卖。","description":"","author":"荒原饮露","url":"https://www.missf.top","root":"/"},"pages":[{"title":"","date":"2020-06-02T02:12:04.531Z","updated":"2020-04-13T10:37:51.000Z","comments":false,"path":"categories/index.html","permalink":"https://www.missf.top/categories/index.html","excerpt":"","text":""},{"title":"","date":"2020-06-02T02:12:04.533Z","updated":"2020-04-13T10:37:41.000Z","comments":false,"path":"tags/index.html","permalink":"https://www.missf.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Elastic 收集Java日志(9)","slug":"Elastic 收集Java日志(9)","date":"2020-09-08T10:20:14.000Z","updated":"2020-09-09T07:18:39.266Z","comments":true,"path":"post/5a1ae96.html","link":"","permalink":"https://www.missf.top/post/5a1ae96.html","excerpt":"","text":"安装Tomcattomcat属于java应用，这里收集tomcat日志作为示例 # 下载软件包 wget -P /server/tools/https://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.53/bin/apache-tomcat-8.5.53.tar.gz # 解压 tar xf apache-tomcat-8.5.53.tar.gz -C /usr/local/ &amp;&amp; mv /usr/local/apache-tomcat-8.5.53/ /usr/local/tomcat # 启动tomcat /usr/local/tomcat/bin/startup.sh 编写Filebeat pipelinefilebeat获取所有不以”[“开头的行，并将它们合并到上一行以”[“开头的行之后 filebeat.inputs: - type: log enabled: true paths: - /usr/local/tomcat/logs/catalina.out tags: [\"catalina\"] fields: server: tomcat type: tomcat-catalina fields_under_root: true multiline: pattern: '^\\[' negate: true match: after #output.console: output.redis: hosts: [\"10.10.110.194:56379\"] password: \"123456\" key: \"tomcat\" db: 0 datatype: list 模拟Tomcat报错日志往tomcat的日志写入错误信息，模拟报错信息 cat > /usr/local/tomcat/logs/catalina.out &lt;&lt; EOF Sep 09, 2020 5:50:33 PM org.apache.catalina.startup.Catalina stopServer SEVERE: Catalina.stop: org.xml.sax.SAXParseException; systemId: file:/usr/local/tomcat/conf/server.xml; lineNumber: 22; columnNumber: 45; Attribute name \"dda\" associated with an element type \"Server\" must be followed by the ' = ' character. at java.xml/com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.parse(AbstractSAXParser.java:1243) at java.xml/com.sun.org.apache.xerces.internal.jaxp.SAXParserImpl$JAXPSAXParser.parse(SAXParserImpl.java:635) at org.apache.tomcat.util.digester.Digester.parse(Digester.java:1495) at org.apache.catalina.startup.Catalina.stopServer(Catalina.java:485) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.apache.catalina.startup.Bootstrap.stopServer(Bootstrap.java:389) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:479) EOF 编写Logstash pipelineinput { redis { host => \"10.10.110.194\" port => 56379 password => \"123456\" db => \"0\" data_type => \"list\" key => \"tomcat\" } } output { if [type] == \"tomcat-catalina\" { if [tags][0] == \"catalina\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-tomcat-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Kibana展示数据这里展示数据是不显示完全的，我们可以指定字段查看更详细的信息 指定message字段，查看被合并成一行的tomcat报错日志","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic 收集Nginx日志(8)","slug":"Elastic 收集Nginx日志(8)","date":"2020-08-25T06:27:22.000Z","updated":"2020-09-09T04:03:07.084Z","comments":true,"path":"post/baa98a96.html","link":"","permalink":"https://www.missf.top/post/baa98a96.html","excerpt":"","text":"Nginx配置Json格式日志修改Nginx配置文件，定义输出json格式的日志，便于filebeat和logstash收集 http { log_format main '{\"@timestamp\": \"$time_iso8601\", ' '\"clientRealIp\": \"$remote_addr\", ' '\"scheme\": \"$scheme\", ' '\"method\": \"$request_method\", ' '\"host\": \"$host\", ' '\"url\": \"$request_uri\", ' '\"size\": $body_bytes_sent, ' '\"referrer\": \"$http_referer\", ' '\"agent\": \"$http_user_agent\", ' '\"upstream_addr\": \"$upstream_addr\", ' '\"request_time\": $request_time, ' '\"request_length\": $request_length, ' '\"upstream_connect_time\": \"$upstream_connect_time\", ' '\"upstream_response_time\": \"$upstream_response_time\", ' '\"upstream_status\": \"$upstream_status\", ' '\"status\": \"$status\"}'; } Filebeat配置文件编写filebeat配置文件，收集Nginx的access.log和error.log，并且添加自定义字段和标签存储到redis cat /etc/filebeat/filebeat-nginx.yml filebeat.inputs: - type: log enabled: true json.keys_under_root: true paths: - /usr/local/nginx/logs/access.log tags: [\"access\"] fields: server: nginx type: nginx-access fields_under_root: true - type: log enabled: true json.keys_under_root: true paths: - /usr/local/nginx/logs/error.log tags: [\"error\"] fields: server: nginx type: nginx-error fields_under_root: true processors: - drop_fields: fields: [\"input_type\", \"ecs.version\", \"host.name\", \"agent\", \"log.offset\"] #output.console: output.redis: hosts: [\"10.10.110.194:56379\"] password: \"123456\" key: \"nginx\" db: 0 datatype: list 控制台调试Filebeat输出的日志数据通过drop_fields去控制我们想要输出的字段，得到精简的日志数据 { \"@timestamp\": \"2020-09-07T18:08:49.000Z\", \"@metadata\": { \"beat\": \"filebeat\", \"type\": \"_doc\", \"version\": \"7.9.0\" }, \"server\": \"nginx\", \"ecs\": {}, \"host\": {}, \"log\": { \"file\": { \"path\": \"/usr/local/nginx/logs/access.log\" } }, \"json\": {}, \"input\": { \"type\": \"log\" }, \"type\": \"nginx-access\", \"message\": \"10.10.110.194 - - [08/Sep/2020:02:08:41 +0800] \\\"GET /848dd HTTP/1.1\\\" 404 153 \\\"-\\\" \\\"curl/7.29.0\\\"\", \"tags\": [\"access\"] } Logstash读取Redis中的日志数据logstash读取redis中的日志数据，并且在Kibana展示Nginx日志 # logstash配置文件通过我们定义的fields字段和标签匹配数据,将不同的数据存储到不同的index input { redis { host => \"10.10.110.194\" port => 56379 password => \"123456\" db => \"0\" data_type => \"list\" key => \"nginx\" } } output { # 通过字段和标签判断日志数据,存储到不同的index if [type] == \"nginx-access\" { if [tags][0] == \"access\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-nginx-access%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } if [type] == \"nginx-error\" { if [tags][0] == \"error\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-nginx-error%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Kibana展示Nginx日志我们可以在kibana上创建索引，查看Nginx日志，通过字段去统计和展示日志数据","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic 引入Filebeat(7)","slug":"Elastic 引入Filebeat(7)","date":"2020-08-20T03:58:57.000Z","updated":"2020-09-08T10:33:23.246Z","comments":true,"path":"post/9482a90c.html","link":"","permalink":"https://www.missf.top/post/9482a90c.html","excerpt":"","text":"引入Filebeat架构简介filebeat代替logstash去收集日志数据，然后将收集到的日志数据存储到redis或者kafka，再由logstash去消费数据。filebeat是非常轻量级单用途的日志采集器，属于Beats家族。早期的elk架构使用logstash收集、解析日志，但是logstash对内存、CPU、IO等资源消耗比较高(因为logstash是使用java语言编写的)，后来出现了使用golang编写的filebeat日志收集器，可以不依赖任何环境安装即可使用，同时对资源的占用可以忽略不计，使用filebeat替代logstash去收集日志是非常好的方案 安装Filebeat# 下载filebeat wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.9.0-x86_64.rpm # 安装 yum install -y filebeat-7.9.0-x86_64.rpm 编写Filebeat配置文件filebeat配置文件负责收集日志，然后将数据存到redis cat /etc/filebeat/filebeat.yml filebeat.inputs: - type: log enabled: true paths: - /var/log/messages tags: [\"messages\",\"syslog\"] #include_lines: ['sometext'] Filebeat仅导出与列表中的正则表达式匹配的行 #exclude_lines: ['^DBG'] Filebeat会删除列表中与正则表达式匹配的所有行 fields: # 可以指定字段向输出添加附加信息 type: system # fields_under_root: true # 如果为true,则自定义字段将作为顶级字段而不是作为fields字段的子字典 - type: log enabled: true paths: - /var/log/audit/audit.log tags: [\"audit\",\"syslog\"] fields: type: system # fields_under_root: true output.console: # 将收集到的日志数据输出到控制台,可以查看fields定义的字段 output.redis: # filebeat将收集到的日志存储到redis hosts: [\"10.10.110.194:56379\"] password: \"123456\" key: \"filebeat\" db: 0 timeout: 5 查看Filebeat输出的Json数据我们在调试日志格式时使用命令去启动filebeat，使用systemctl的方式去调试会出现很多转义符，不便于查看 /usr/bin/filebeat -c /etc/filebeat/filebeat.yml # 这里需要将控制台输出的数据json格式化 { \"@timestamp\": \"2020-09-07T16:17:42.615Z\", \"@metadata\": { \"beat\": \"filebeat\", \"type\": \"_doc\", \"version\": \"7.9.0\" }, \"ecs\": { \"version\": \"1.5.0\" }, \"host\": { \"name\": \"localhost.localdomain\" }, \"agent\": { \"ephemeral_id\": \"660a2bfb-9a56-43a8-ae93-788060f5d243\", \"id\": \"6a8ff370-52b5-4f89-ad9c-b6feecf938a9\", \"name\": \"localhost.localdomain\", \"type\": \"filebeat\", \"version\": \"7.9.0\", \"hostname\": \"localhost.localdomain\" }, \"log\": { \"offset\": 997322, \"file\": { \"path\": \"/var/log/messages\" } }, \"message\": \"Sep 8 00:01:01 localhost systemd: Started Session 7 of user root.\", \"tags\": [\"messages\", \"syslog\"], \"fields\": { # 这里由于filebeat配置文件中没有开启fields_under_root: true这个选项,所以我们定义的字段会在fields里面 \"type\": \"system\" }, \"input\": { \"type\": \"log\" } } 定义Filebeat输出的Json数据我们除了可以自己自定义字段，还可以删除一些filebeat默认输出的字段，让日志数据更加易于查看 # 定义filebeat配置文件,过滤不需要的json数据 filebeat.inputs: - type: log enabled: true # json.keys_under_root: true 开始json解析,不是json格式的日志不要开启此选项 paths: - /var/log/messages tags: [\"messages\",\"syslog\"] fields: type: system fields_under_root: true - type: log enabled: true paths: - /var/log/audit/audit.log tags: [\"audit\",\"syslog\"] fields: type: system fields_under_root: true processors: - drop_fields: fields: [\"input_type\", \"ecs.version\", \"host.name\", \"agent\", \"log.offset\"] # 将这些字段丢弃 output.console: 查看自定义之后的json数据 { \"@timestamp\": \"2020-09-07T17:37:59.500Z\", \"@metadata\": { \"beat\": \"filebeat\", \"type\": \"_doc\", \"version\": \"7.9.0\" }, \"tags\": [\"messages\", \"syslog\"], \"input\": { \"type\": \"log\" }, \"type\": \"system\", # fields_under_root: true 将作为顶级字段 \"ecs\": {}, \"host\": {}, \"log\": { \"file\": { \"path\": \"/var/log/messages\" } }, \"message\": \"Sep 8 01:35:28 localhost systemd-logind: Removed session 4.\" } Logstash消费Redis中的数据filebeat将日志数据存储到redis之后，logstash从redis读取日志数据就是非常简单的事情了 cat /etc/logstash/conf.d/sys-from-redis.conf input { redis { host => \"10.10.110.194\" port => 56379 password => \"123456\" db => \"0\" data_type => \"list\" batch_count => \"1\" key => \"filebeat\" } } filter { } output { if [type] == \"system\" { # 这里的匹配由filebeat输出的json数据格式来定义 if [tags][0] == \"messages\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-fromredis-messages-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } else if [tags][0] == \"audit\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-fromredis-audit-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Elasticsearch查看数据索引的命名根据我们在logstash处理数据时的定义格式","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic 引入Redis(6)","slug":"Elastic 引入Redis(6)","date":"2020-08-17T10:48:56.000Z","updated":"2020-09-07T10:45:28.472Z","comments":true,"path":"post/23bc2fbc.html","link":"","permalink":"https://www.missf.top/post/23bc2fbc.html","excerpt":"","text":"引入Redis架构简介logstash分为shipper(负责收集日志数据)和indexer(负责对日志做过滤存储到ES)两个角色。当日志量达到一个量级之后，我们就不能继续使用logstash去收集和处理数据，由于ES的HTTP API处理能力有限，在日志写入频繁的情况下可能会超时、丢失，所以用队列来做缓冲在两个logstash角色之间可以引入redis或者kafka。使用消息队列的方式可减少ES压力，队列起到缓冲作用，也可以一定程度保护数据不丢失。同时我们还能将所有收集到的日志统一在logstash indexer进行处理 环境准备logstash 10.10.110.195 # logstash shipper生产数据,将获取到的数据存到redis logstash + redis 10.10.110.194 # logstash indexer消费redis中的日志数据 生产日志数据编写logstash pipeline配置文件，将收集到的日志数据存储到redis input { file { path => [\"/var/log/messages\"] type => \"syslog\" tags => [\"messages\",\"log\"] start_position => \"beginning\" } file { path => [\"/var/log/audit/audit.log\"] type => \"syslog\" tags => [\"audit\",\"log\"] start_position => \"beginning\" } } filter { } output { redis { host => [\"10.10.110.194:56379\"] password => \"123456\" db => \"0\" data_type => \"list\" key => \"logstash\" } } 启动logstash进行收集日志存储到redis /usr/share/logstash/bin/logstash -rf /etc/logstash/conf.d/syslog-toredis.conf Redis查看日志数据logstash在收集到日志数据并且添加上标签和类型然后存储到redis，我们可以返回列表的长度来得知日志数据是否被存储到redis {% image https://pic.imgdb.cn/item/5f55cd21160a154a674bc848.jpg '' '' %} 消费日志数据编写logstash pipeline配置文件，将redis中的日志数据存储到ES input { redis { host => \"10.10.110.194\" port => 56379 password => \"123456\" db => \"0\" data_type => \"list\" key => \"logstash\" } } filter { } output { if [type] == \"syslog\" { if [tags][0] == \"messages\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"syslog-fromredis-messages-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } else if [tags][0] == \"audit\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"syslog-fromredis-audit-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Redis查看消费的数据日志数据被消费完之后就代表已经写入到ES # redis中的key会全部存到ES中(日志数据被消费完) 127.0.0.1:56379> llen logstash (integer) 7041 127.0.0.1:56379> llen logstash (integer) 5791 127.0.0.1:56379> llen logstash (integer) 4541 127.0.0.1:56379> llen logstash (integer) 3041 127.0.0.1:56379> llen logstash (integer) 1666 127.0.0.1:56379> llen logstash (integer) 0 127.0.0.1:56379>","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Kibana展示系统日志(5)","slug":"Elastic Kibana展示系统日志(5)","date":"2020-08-16T10:39:44.000Z","updated":"2020-09-07T10:41:59.888Z","comments":true,"path":"post/c802a07c.html","link":"","permalink":"https://www.missf.top/post/c802a07c.html","excerpt":"","text":"编写logstash pipeline配置文件定义日志收集、过滤、存储的方式 input { file { path => [\"/var/log/messages\"] type => \"syslog\" tags => [\"messages\",\"log\"] start_position => \"beginning\" # 从文件开头读取 } file { path => [\"/var/log/audit/audit.log\"] type => \"syslog\" tags => [\"audit\",\"log\"] start_position => \"beginning\" } } filter { } output { if [type] == \"syslog\" { if [tags][0] == \"messages\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] # 存储带ES index => \"syslog-messages-%{+YYYY.MM.dd}\" # index的命名格式 } stdout { codec=> rubydebug } } else if [tags][0] == \"audit\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"syslog-audit-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Logstash收集日志存储到ES# 启动logstash,systemctl启动方式可以指定配置文件 /usr/share/logstash/bin/logstash -rf /etc/logstash/conf.d/syslog.conf # logstash常用参数 -n 指定logstash实例的名称,默认为当前主机名 -f 指定启动配置文件 -e 指定直接执行的配置文件内容,可以不指定-f参数了 -r 检测配置文件变化,自动重新加载 -t 检查配置的语法是否正确并退出 Elasticsearch查看数据索引的命名格式按日期去分割 将ES的日志索引到KibanaKibana的配置文件指定ES的地址，使用正则匹配去创建索引 配置时间过滤器字段 Kibana展示日志数据可以根据日志数据的字段去查看指定的信息","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Kibana(4)","slug":"Elastic Kibana(4)","date":"2020-08-14T07:56:54.000Z","updated":"2020-09-09T02:59:49.058Z","comments":true,"path":"post/e26112db.html","link":"","permalink":"https://www.missf.top/post/e26112db.html","excerpt":"","text":"Kibana简述Kibana是一个针对Elasticsearch的开源分析及可视化平台，用来搜索、查看交互存储在Elasticsearch索引中的数据。使用Kibana，可以通过各种图表进行高级数据分析及展示。Kibana让海量数据更容易理解，它操作简单，基于浏览器的用户界面可以快速创建仪表板(dashboard)实时显示Elasticsearch查询动态。设置Kibana非常简单，无需编码或者额外的基础架构，就可以完成Kibana安装并启动Elasticsearch索引监测 Kibana安装配置# 下载Kibana wget https://artifacts.elastic.co/downloads/kibana/kibana-7.8.1-x86_64.rpm # 安装 shasum -a 512 kibana-7.8.1-x86_64.rpm rpm --install kibana-7.8.1-x86_64.rpm # 修改Kibana配置文件 grep -v \"^#\" /etc/kibana/kibana.yml server.port: 5601 server.host: \"127.0.0.1\" elasticsearch.hosts: [\"http://10.10.110.191:9200\"] i18n.locale: \"zh-CN\" # 启动Kibana systemctl start kibana.service 配置Nginx代理Kibana配置Nginx反向代理实现鉴权 vim /usr/local/nginx/conf/nginx.conf server { listen 9090; server_name localhost; location / { auth_basic \"Restricted Access\"; auth_basic_user_file /usr/local/nginx/conf/passwd.db; # 账号密码文件 proxy_pass http://127.0.0.1:5601; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 配置验证登录账号密码 # 需要安装httpd-tools工具,文件里的密码是密文的 htpasswd -c /usr/local/nginx/conf/passwd.db admin # 连续输入两次密码 # 测试本机kibana能否连接,如果本机都不能连接,那么Nginx代理就没有意义 curl -L -u admin:12345678 http://127.0.0.1:5601 登录Kibana登录kibana的地址 http://10.10.110.194:9090/ Nginx账号密码 kibana web页面","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Logstash(3)","slug":"Elastic Logstash(3)","date":"2020-08-11T07:04:57.000Z","updated":"2020-09-01T07:00:22.418Z","comments":true,"path":"post/fe947601.html","link":"","permalink":"https://www.missf.top/post/fe947601.html","excerpt":"","text":"Logstash概述logstash是elasticsearch的数据管道，负责对数据源进行处理。工作原理分别是输入、过滤、输出。其中input(负责从数据源采集数据)和output(将数据传输到目的地)是必要的，filter(将数据修改为你指定的格式或内容)是非必要的。logstash是插件式管理模式，在输入、过滤、输出以及编码过程中都可以使用插件进行定制，Logstash社区有超过200种可用插件 Logstash安装这里使用yum是因为二进制安装的jdk，在Logstash启动时会报could not find java # 安装jdk yum install -y java-11-openjdk java-11-openjdk-devel java-11-openjdk-headless # 下载logstash wget https://artifacts.elastic.co/downloads/logstash/logstash-7.8.1.rpm # 安装logstash yum install -y logstash-7.8.1.rpm # 修改启动分配内存 vim /etc/logstash/jvm.options -Xms512m -Xmx512m # 第一个logstash示例 cd logstash Installation directory bin/logstash -e 'input { stdin { } } output { stdout {} }' 执行结果如下 Logstash配置详解Logstash的配置有两个必须元素(input和output)和一个可选元素(filter) input { # 输入 stdin { ... # 标准输入 } } filter { # 过滤 ... # 对数据进行分割、截取等处理 } output { # 输出 stdout { ... # 标准输出 } } 输入 采集各种样式、大小和来源的数据，数据往往以各种各样的形式，或分散或集中地存在于不同的系统中 Logstash支持各种输入选择 ，可以在同一时间从众多常用来源捕捉事件 能够以连续的流式传输方式，轻松地从您的日志、指标、Web 应用、数据存储以及各种AWS服务采集数据 过滤 实时解析和转换数据，Logstash过滤器能够解析各个事件 识别已命名的字段以构建结构，并将它们转换成通用格式，以便更轻松更快速地分析和实现商业价值 输出 Logstash提供众多输出选择，你可以将数据发送到指定的地方，并且能够灵活地解锁众多下游用例 输入插件Stdin示例从标准输入读取数据输出到标准输出 input { stdin { } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 mwj { \"host\" => \"localhost.localdomain\", \"@timestamp\" => 2020-08-12T18:36:32.683Z, \"message\" => \"mwj\", \"@version\" => \"1\" } test data { \"host\" => \"localhost.localdomain\", \"@timestamp\" => 2020-08-12T18:36:47.691Z, \"message\" => \"test data\", \"@version\" => \"1\" } 输入插件File示例从文件中读取数据，输出到标准输出 input { file { # 调用file这个插件,logstash社区有非常多的插件可以供我们使用 path =>\"/var/log/messages\" # 数据源来自这个文件的内容 tags =>\"messages\" # 打标签 type =>\"syslog\" } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 { \"type\" => \"syslog\", \"@timestamp\" => 2020-08-13T11:41:45.031Z, \"@version\" => \"1\", \"path\" => \"/var/log/messages\", \"host\" => \"localhost.localdomain\", \"tags\" => [ [0] \"messages\" ], \"message\" => \"Aug 13 19:41:44 localhost yum[86466]: Installed: 1:nginx-mod-http-image-filter-1.16.1-1.el7.x86_64\" } { \"type\" => \"syslog\", \"@timestamp\" => 2020-08-13T11:41:45.032Z, \"@version\" => \"1\", \"path\" => \"/var/log/messages\", \"host\" => \"localhost.localdomain\", \"tags\" => [ [0] \"messages\" ], \"message\" => \"Aug 13 19:41:44 localhost yum[86466]: Installed: 1:nginx-all-modules-1.16.1-1.el7.noarch\" } 输入插件TCP示例logstash从本机端口读取数据，其他机器通过nc工具发送数据到logstash指定的端口 input { tcp { port =>12345 # 监听12345端口 type =>\"nc\" # 通过nc工具使用tcp/udp连接去发送网络数据给logstash } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 { \"@version\" => \"1\", \"type\" => \"nc\", \"@timestamp\" => 2020-08-13T06:28:13.448Z, \"host\" => \"10.10.110.191\", \"port\" => 35228, \"message\" => \"we\" # logstash接收到其他机器nc工具发送过来的信息(nc 10.10.110.194 12345) } { \"@version\" => \"1\", \"type\" => \"nc\", \"@timestamp\" => 2020-08-13T06:28:40.148Z, \"host\" => \"10.10.110.191\", \"port\" => 35228, \"message\" => \"test\" } 编解码插件Json示例只有输入json格式的数据才会被成功编解码，不是json格式的数据logstash不处理 input { stdin { codec => json { charset => [\"UTF-8\"] } } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 {\"name\":\"孙七\",\"age\": 24,\"mail\": \"555@qq.com\",\"hobby\":\"听音乐、看电影\"} { \"hobby\" => \"听音乐、看电影\", \"name\" => \"孙七\", \"mail\" => \"555@qq.com\", \"age\" => 24, \"@version\" => \"1\", \"host\" => \"localhost.localdomain\", \"@timestamp\" => 2020-09-01T14:27:24.066Z } 编解码插件Multline示例multline会将不是以字母开头的行合并到上一行(next是合并到下一行)，下面模拟java日志报错 input { stdin { codec => multiline { pattern => \"^\\s\" what => \"previous\" } } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 [INFO] 2020-08-13 15:56:53,195 --AsyncResolver-bootstrap-executor-0-- # 模拟java报错信息 at com.curre at org.sprin at org.sprin { \"@timestamp\" => 2020-09-01T14:36:50.642Z, \"tags\" => [ [0] \"multiline\" ], \"@version\" => \"1\", \"message\" => \"[INFO] 2020-08-13 15:56:53,195 --AsyncResolver-bootstrap-executor-0--\\n at com.curre\\n at org.sprin\\n at org.sprin\", \"host\" => \"localhost.localdomain\" } 过滤插件Json示例将json数据做过滤放在content字段里面 input { stdin { } } filter { json { source => \"message\" target => \"content\" } } output { stdout { codec => rubydebug } } 执行结果如下 {\"request\":\"get\", \"status\":\"404\", \"bytes\":\"563\"} # 数据源 { \"host\" => \"localhost.localdomain\", \"@timestamp\" => 2020-08-13T09:28:26.702Z, \"content\" => { \"request\" => \"get\", \"bytes\" => \"563\", \"status\" => \"404\" }, \"message\" => \"{\\\"request\\\":\\\"get\\\", \\\"status\\\":\\\"404\\\", \\\"bytes\\\":\\\"563\\\"}\", \"@version\" => \"1\" } 过滤插件Kv示例以&amp;和?作为分隔符，得到key=value形式的数据 input { stdin { } } filter { kv { field_split => \"&amp;?\" # 以&amp;和?作为分隔符,得到key=value的形式 field_split_pattern => \":+\" # 以一个或者多个:作为分隔符 } } output { stdout { codec => rubydebug } } 执行结果如下 pin=12345~0&amp;d=123&amp;e=foo@bar.com&amp;oq=bo?oi=bo&amp;ss=12345: # 数据源 { \"d\" => \"123\", \"pin\" => \"12345~0\", \"ss\" => \"12345:\", \"oq\" => \"bo\", \"oi\" => \"bo\", \"e\" => \"foo@bar.com\", \"@timestamp\" => 2020-08-13T09:31:41.881Z, \"host\" => \"localhost.localdomain\", \"message\" => \"pin=12345~0&amp;d=123&amp;e=foo@bar.com&amp;oq=bo?oi=bo&amp;ss=12345:\", \"@version\" => \"1\" } 输出插件ES示例logstash将日志输出到ES节点，存储到missf这个index并且以时间去命名 output { elasticsearch { hosts => \"localhost:9200\" index => \"missf-%{+YYYY.MM.dd}\" } }","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Elasticsearch(2)","slug":"Elastic Elasticsearch(2)","date":"2020-08-05T10:26:09.000Z","updated":"2020-09-09T02:58:45.361Z","comments":true,"path":"post/1abc58c4.html","link":"","permalink":"https://www.missf.top/post/1abc58c4.html","excerpt":"","text":"Elasticsearch简介Elasticsearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java语言开发，并作为Apache许可条款下的开放源代码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索、稳定、可靠、快速、使用方便 我们建立一个网站或应用程序，并要添加搜索功能，但是想要完成搜索工作的创建是非常困难的。我们希望搜索解决方案要运行速度快，我们希望能有一个零配置和一个完全免费的搜索模式，我们希望能够简单地使用JSON通过HTTP来索引数据，我们希望搜索服务器始终可用，我们希望能够从一台开始并扩展到数百台，我们要实时搜索，我们要简单的多用户，我们希望建立一个云的解决方案。因此我们利用Elasticsearch来解决所有这些问题及可能出现的更多其它问题 Elasticsearch集群部署Elasticsearch的发展是非常快速的，所以在ES5.0之前，ELK的各个版本都不统一，出现了版本号混乱的状态，所以从5.0开始，所有Elastic Stack中的项目全部统一版本号。目前最新版本是7.8.1 # 环境准备 ES1 10.10.110.191 ES2 10.10.110.192 ES3 10.10.110.193 # 下载elasticsearch和校验文件 wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.1-x86_64.rpm wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.1-x86_64.rpm.sha512 # 安装elasticsearch shasum -a 512 -c elasticsearch-7.8.1-x86_64.rpm.sha512 yum install -y elasticsearch-7.8.1-x86_64.rpm # 修改jvm启动参数,根据自己机器决定 vim /etc/elasticsearch/jvm.options -Xms512m # 确保Xmx和Xms的大小是相同的，其目的是为了能够在java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源 -Xmx512m # 修改进程在VMAs(虚拟内存区域)创建内存映射最大数量 echo \"vm.max_map_count=655360\" >> /etc/sysctl.conf &amp;&amp; sysctl -p # 修改elasticsearch配置文件 grep -v '^#' /etc/elasticsearch/elasticsearch.yml cluster.name: elk-cluster # 集群名称,所有节点一样 node.name: node-1 # 不同节点,分别用node-1/node-2/node-3... path.data: /var/lib/elasticsearch # 数据目录,如果加入集群失败可以清空数据目录再重启服务 path.logs: /var/log/elasticsearch # 日志目录 network.host: 10.10.110.191 # 不同节点,分别用10.10.110...... http.port: 9200 # 监听端口 discovery.seed_hosts: [\"10.10.110.191\", \"10.10.110.192\", \"10.10.110.193\"] # 集群发现,可以写成10.10.110.191:9200 cluster.initial_master_nodes: [\"node-1\", \"node-2\", \"node-3\"] # 指定可以成为master的节点,此参数只有在初始化集群时生效 # 启动elasticsearch服务 systemctl start elasticsearch.service Elasticsearch集群常用查询查看集群状态 curl -X GET http://10.10.110.191:9200/_cluster/health?pretty # 响应 { \"cluster_name\" : \"elk-cluster\", \"status\" : \"green\", # 集群状态红绿灯,绿:健康,黄:亚健康,红:病态 \"timed_out\" : false, \"number_of_nodes\" : 3, \"number_of_data_nodes\" : 3, \"active_primary_shards\" : 0, \"active_shards\" : 0, \"relocating_shards\" : 0, \"initializing_shards\" : 0, \"unassigned_shards\" : 0, \"delayed_unassigned_shards\" : 0, \"number_of_pending_tasks\" : 0, \"number_of_in_flight_fetch\" : 0, \"task_max_waiting_in_queue_millis\" : 0, \"active_shards_percent_as_number\" : 100.0 } 查看节点状态 curl -X GET 'http://10.10.110.191:9200/_cat/nodes?v' ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name 10.10.110.191 62 93 0 0.00 0.01 0.05 dilmrt - node-1 10.10.110.193 62 74 0 0.00 0.01 0.05 dilmrt * node-3 # *代表当前节点是master 10.10.110.192 70 75 0 0.00 0.01 0.05 dilmrt - node-2 查询节点所有索引 curl -X GET 'http://10.10.110.191:9200/_cat/indices?v' health status index uuid pri rep docs.count docs.deleted store.size pri.store.size green open data njHuT0XvSOa2NHPJM3Aj-g 1 1 3 0 19.5kb 9.7kb 查询一个索引所有数据 curl -X GET 'http://10.10.110.191:9200/data/_search/?pretty' Elasticsearch-head安装由于ES官方并没有为ES提供界面管理工具，仅仅是提供了后台的服务。elasticsearch-head是一个为ES开发的一个页面客户端工具，其源码托管于GitHub，地址为：https://github.com/mobz/elasticsearch-head elasticsearch-head提供了四种安装方式： 源码安装通过npm run start启动(不推荐) 通过docker安装(推荐) 通过chrome插件安装(推荐) 通过ES的plugin方式安装(不推荐) 通过docker安装 # 拉取镜像 docker pull mobz/elasticsearch-head:5 # 启动容器 docker run -itd --name \"elasticsearch-head\" -p 9100:9100 -v elasticsearch_head:/usr/src/app --restart always mobz/elasticsearch-head:5 # 由于前后端分离开发,所以会存在跨域问题,需要在服务端做CORS的配置 vim /etc/elasticsearch/elasticsearch.yml http.cors.enabled: true http.cors.allow-origin: \"*\" # Web访问 http://10.10.110.191:9100/ Elasticsearch Head数据浏览不显示数据，使用浏览器按F12查看发现406 Not Acceptable错误，出现这个错误是因为后台返回的数据是json格式前台无法解析，解决方法如下： # 找到docker数据卷在宿主机上的目录 docker volume inspect elasticsearch_head # 修改数据卷目录下_site/vendor.js文件 contentType: \"application/x-www-form-urlencoded\" 修改为 contentType: \"application/json;charset=UTF-8\" var inspectData = s.contentType === \"application/x-www-form-urlencoded\" &amp;&amp; 修改为 var inspectData = s.contentType === \"application/json;charset=UTF-8\" &amp;&amp; Elasticsearch基本概念索引(index)是Elasticsearch存放数据的地方，可以理解为关系型数据库的数据库。我们的数据被存储和索引在分片(shards)中，索引只是一个把一个或多个分片分组在一起的逻辑空间。索引的结构是为快速有效的全文索引准备的，索引名称必须是小写，并且不能用下划线开头 类型(type)用于区分同一个索引下不同的数据类型，相当于关系型数据库中的表。在Elasticsearch中，我们使用相同类型的文档表示相同的”事物”，因为他们的数据结构也是相同的。每个类型都有自己的映射(mapping)或者结构定义，就像传统数据库表中的列一样。所有类型下的文档被存储在同一个索引下，但是类型的映射会告诉Elasticsearch不同的文档如何被索引(ES6.0之后一个索引只能存在一种类型) 文档(document)是ElasticSearch中存储的实体数据，一个文档相当于数据库表中的一行记录。在Elasticsearch中，文档这个术语有着特殊含义。它特指最顶层结构或者根对象(root object)序列化成的JSON数据(以唯一ID标识并存储于Elasticsearch中) 关系型数据库与Elasticsearch的概念类比如下 Relational DB Databases Tables Rows Columns Elasticsearch Indices Types Documents Fields RESTful API在Elasticsearch中，提供了功能丰富的RESTful API的操作，包括基本的CRUD、创建索引、删除索引等操作。RESTful是统一规范的http接口，任何语言都可以使用。我们可以直接使用web客户端(postman)来测试，甚至还可以使用Linux上的curl工具测试，不需要自己写程序来调用Elasticsearch服务 # Elasticsearch RESTful操作数据的风格 curl -X &lt;verb> '&lt;protocol>://&lt;host>:&lt;port>/&lt;path>?&lt;query_string> -d &lt;body>' verb: HTTP方法，如GET、POST、PUT、HEAD、DELETE host: ES集群中的任意节点主机名 port: ES HTTP服务端口默认9200 path: 索引路径 query_string: 可选的查询请求参数，例如?pretty参数将格式化输出JSON数据 -d: 一个GET的JSON格式请求主体 body: 自己写的JSON格式的请求主体 创建索引在Lucene中创建索引是需要定义字段名称以及字段的类型，在Elasticsearch中提供了非结构化的索引，就是不需要创建索引结构，即可写入数据到索引中，实际上在Elasticsearch底层会进行结构化操作，此操作对用户是透明的 # 创建一个data的空索引 curl -X PUT '10.10.110.191:9200/data' # 删除索引 curl -X DELETE '10.10.110.191:9200/data' 插入数据URL规则：POST /索引/类型/id # 往data这个索引下的user类型中插入一条ID为1的数据,?pretty是以json格式返回数据 curl -X POST '10.10.110.191:9200/data/user/1?pretty' -H \"Content-Type:application/json\" -d ' { \"name\": \"mowenjie\", \"job\": \"DevOps\", \"base\": \"sz\" }' # 响应 { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"1\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : { \"total\" : 2, \"successful\" : 1, \"failed\" : 0 }, \"_seq_no\" : 0, \"_primary_term\" : 1 } # 不指定ID插入数据会自动生成ID curl -X POST '10.10.110.191:9200/data/user/?pretty' -H \"Content-Type:application/json\" -d ' { \"name\": \"missf\", \"job\": \"linux\", \"base\": \"sz\" }' # 响应 { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"-J1PMXQBkHjO2vDovLJx\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : { \"total\" : 2, \"successful\" : 2, \"failed\" : 0 }, \"_seq_no\" : 1, \"_primary_term\" : 1 } 更新数据在Elasticsearch中可以通过覆盖的方式对数据进行更新 # 对ID为1的这条数据进行更新 curl -X PUT '10.10.110.191:9200/data/user/1?pretty' -H \"Content-Type:application/json\" -d ' { \"name\": \"fan\", \"job\": \"java\", \"base\": \"bj\" }' # 查询更新结果 curl -X GET '10.10.110.191:9200/data/user/1?pretty' { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"1\", \"_version\" : 2, # 更新之后的数据版本进行了+1 \"_seq_no\" : 2, \"_primary_term\" : 1, \"found\" : true, \"_source\" : { \"name\" : \"fan\", \"job\" : \"java\", \"base\" : \"bj\" } } # 上面是更新整条数据,下面是局部更新一条数据的某些字段,需要使用_update标识 curl -X POST '10.10.110.191:9200/data/user/1/_update?pretty' -H \"Content-Type:application/json\" -d ' { \"doc\":{ \"name\": \"aaa\" } }' 删除数据在Elasticsearch中，删除文档数据只需要发起DELETE请求即可 # 删除ID为1的这条数据 curl -X DELETE 'http://10.10.110.191:9200/data/user/1?pretty' # 响应,看到返回\"result\" : \"deleted\"就表示删除成功,如果删除一条不存在的数据会返回404 { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"1\", \"_version\" : 2, \"result\" : \"deleted\", \"_shards\" : { \"total\" : 2, \"successful\" : 2, \"failed\" : 0 }, \"_seq_no\" : 1, \"_primary_term\" : 1 } 删除一个文档也不会立即从磁盘上移除，它只是被标记成已删除。Elasticsearch将会在你之后添加更多索引的时候才在后台进行删除内容的清理 搜索数据根据id搜索数据 curl -X GET '10.10.110.191:9200/data/user/003?pretty' 搜索全部数据 curl -X GET '10.10.110.191:9200/data/user/_search?pretty' # 响应默认只返回10条数据 关键字搜素数据 # 查询base等于sz的用户数据 curl -X GET '10.10.110.191:9200/data/user/_search?q=base:sz' DSL搜索Elasticsearch提供基于JSON的完整查询语言DSL(Query DSL)来定义查询，它允许你构建更加复杂、强大的查询 # 查询base等于sz的用户 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { # 请求体 \"query\" : { \"match\" : { \"base\" : \"sz\" } } } ' # 查询age大于16且job等于Linux的用户 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"bool\": { \"filter\": { \"range\": { \"age\": { \"gt\": 16 } } }, \"must\": { \"match\": { \"job\": \"Linux\" } } } } } ' # 全文搜索 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"match\": { \"name\": \"miss lisi\" } } } ' 高亮显示查询得到需要高亮的数据，再使用highlight将需要高亮的字段写在fields里面 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"match\": { \"name\": \"miss lisi\" } }, \"highlight\": { \"fields\": { \"name\": {} } } } ' 聚合在Elasticsearch中支持聚合操作，类似SQL中的group by操作 # 根据字段值分组聚合 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"aggs\": { \"age_terms\": { \"terms\": { \"field\": \"age\" } } } } ' # 响应,age字段值为16的有1条数据,age字段值为25的有2条数据 \"aggregations\" : { \"age_terms\" : { \"doc_count_error_upper_bound\" : 0, \"sum_other_doc_count\" : 0, \"buckets\" : [ { \"key\" : 16, \"doc_count\" : 1 }, { \"key\" : 25, \"doc_count\" : 2 }, { \"key\" : 36, \"doc_count\" : 1 } ] } } 文档一个文档不只有数据，它还包含了元数据(metadata)——关于文档的信息。三个必须的元数据节点是 节点 说明 _index 文档存储的地方 _type 文档代表的对象的类 _id 文档的唯一标识 索引(index)类似于关系型数据库里的”数据库”——它是我们存储和索引关联数据的地方 _type(类型)，在关系型数据库中，我们经常将相同类的对象存储在一个表里，因为它们有着相同的结构。同理，在Elasticsearch中我们使用相同类型(type)的文档表示相同的”事物”，因为他们的数据结构也是相同的 id仅仅是一个字符串，它与_index和_type组合时，就可以在Elasticsearch中唯一标识一个文档。当创建一个文档时你可以自定义_id ，也可以让Elasticsearch帮你自动生成 响应查询指定响应字段 # 只响应_source下的name,job字段 curl -X GET '10.10.110.191:9200/data/user/001/?_source=name,job' 不返回元数据，仅仅返回原始数据 curl -X GET '10.10.110.191:9200/data/user/001/_source' 判断文档存在如果我们只需要判断文档是否存在，而不查询文档内容 # 如果文档存在,Elasticsearch将返回HTTP/1.1 200 OK,如果不存在就返回HTTP/1.1 404 Not Found curl -i -X HEAD 'http://10.10.110.191:9200/data/user/001' 当然，这只表示你在查询的那一刻文档不存在，但并不表示几毫秒后依旧不存在，另一个进程在这期间可能创建新文档 批量操作有些情况下可以通过批量操作以减少网络请求，如：批量查询、批量插入数据 # 批量查询 curl -X POST '10.10.110.191:9200/data/user/_mget?pretty' -H \"Content-Type:application/json\" -d ' { \"ids\": [\"001\", \"002\"] }' # 响应 { \"docs\" : [ { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"001\", \"_version\" : 1, \"_seq_no\" : 0, \"_primary_term\" : 1, \"found\" : true, \"_source\" : { \"name\" : \"lisi\", \"job\" : \"Python\", \"base\" : \"sh\", \"age\" : 16 } }, { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"002\", \"_version\" : 1, \"_seq_no\" : 1, \"_primary_term\" : 1, \"found\" : true, \"_source\" : { \"name\" : \"mowenjie\", \"job\" : \"Linux\", \"base\" : \"sz\", \"age\" : 36 } } ] } 分页和SQL使用LIMIT关键字返回只有一页的结果一样，Elasticsearch接受from和size参数 size: 结果数,默认10 from: 从第n条数据之后开始,默认0 查询一个区间的数据 # 导入官方测试数据 curl -H \"Content-Type: application/x-ndjson\" -XPOST \"10.10.110.191:9200/bank/account/_bulk?pretty\" --data-binary @accounts.json # 将数据的account_number字段进行排序之后再取数据 curl -X GET \"http://10.10.110.191:9200/bank/account/_search?pretty\" -H \"Content-Type:application/json\" -d ' { \"query\": {\"match_all\": {} }, \"sort\": [{\"account_number\": \"asc\"}], \"from\": 10, # 从第10条数据之后开始 \"size\": 30 # 一共返回30条数据,就是account_number为10-39的数据 }' # 取1000到2000这个区间的随机数据 curl -X GET \"http://10.10.110.191:9200/bank/account/_search?pretty\" -H \"Content-Type:application/json\" -d' { \"query\": { \"bool\": { \"must\": { \"match_all\": {} }, \"filter\": { \"range\": { \"balance\": { \"gte\": 1000, \"lte\": 2000 } } } } } }' 映射前面我们创建的索引以及插入数据，都是由Elasticsearch进行自动判断类型，有些时候我们是需要进行明确字段类型的，否则自动判断的类型和实际需求是不相符的。每个字段都有一个数据类型，可以是一个简单的类型：text、keyword、date、long、double、boolean、ip，或者一个支持JSON层次结构的类型：例如object、nested，或者是一种特殊的类型：geo_point、geo_shape、completion 创建明确类型的索引 curl -X PUT '10.10.110.191:9200/itcast' -H \"Content-Type:application/json\" -d ' { \"settings\": { \"index\": { \"number_of_shards\": \"2\", \"number_of_replicas\": \"0\" } }, \"mappings\": { \"properties\": { \"name\": { \"type\": \"text\" }, \"age\": { \"type\": \"integer\" }, \"mail\": { \"type\": \"keyword\" }, \"hobby\": { \"type\": \"text\" } } } }' 查看索引映射 curl -X GET '10.10.110.191:9200/itcast/_mapping' # 响应 { \"itcast\" : { \"mappings\" : { \"properties\" : { \"age\" : { \"type\" : \"integer\" }, \"hobby\" : { \"type\" : \"text\" }, \"mail\" : { \"type\" : \"keyword\" }, \"name\" : { \"type\" : \"text\" } } } } } 批量插入数据 # 如果插入的数据类型与我们字段定义的类型不同,那么就无法插入 curl -X POST '10.10.110.191:9200/itcast/_bulk' -H \"Content-Type:application/json\" --data-binary @itcast.json {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"1\"}} {\"name\":\"张三\",\"age\": 20,\"mail\": \"111@qq.com\",\"hobby\":\"羽毛球、乒乓球、足球\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"2\"}} {\"name\":\"李四\",\"age\": 21,\"mail\": \"222@qq.com\",\"hobby\":\"羽毛球、乒乓球、足球、篮球\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"3\"}} {\"name\":\"王五\",\"age\": 22,\"mail\": \"333@qq.com\",\"hobby\":\"羽毛球、篮球、游泳、听音乐\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"4\"}} {\"name\":\"赵六\",\"age\": 23,\"mail\": \"444@qq.com\",\"hobby\":\"跑步、游泳\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"5\"}} {\"name\":\"孙七\",\"age\": 24,\"mail\": \"555@qq.com\",\"hobby\":\"听音乐、看电影\"} 查询插入的数据 curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' 结构化查询term主要用于精确匹配某些值，比如数字、日期、布尔值或not_analyzed的字符串(未经分析的文本数据类型) curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\" : { \"term\" : { \"age\" : 20 } } }' range过滤允许我们按照指定范围查询一批数据 # 查询age大于等于20小于等于22范围的数据(gt:大于,gte:大于等于,lt:小于,lte:小于等于) curl -X POST '10.10.110.191:9200/bank/account/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\" : { \"range\": { \"age\": { \"gte\": 20, \"lte\": 22 } } } }' exists查询可以用于查找文档中是否包含指定字段或没有某个字段，类似于SQL语句中的IS_NULL条件 # 查询原始数据中含有address字段的文档 curl -X POST '10.10.110.191:9200/bank/account/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\" : { \"exists\": { \"field\": \"address\" } } }' match是一个模糊查询，需要指定字段名，但是会进行分词(中英文分词不一样) # 查询hobby字段是乒乓球的记录,在查询之前会进行分词(只要记录包含[乒/乓/球]都会被匹配成功) curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"match\": { \"hobby\": \"乒乓球\" } } }' bool查询可以用来合并多个条件查询结果的布尔逻辑，它包含以下操作符： must: 多个查询条件的完全匹配，相当于and must_not: 多个查询条件的相反匹配，相当于not should: 至少有一个查询条件匹配，相当于or filter: 必须匹配，但它不会对匹配的数据进行评分 # 只要包含\"乒乓 游泳\"的数据都会被匹配 curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"bool\": { \"must\": [ { \"match\": { \"hobby\": \"乒乓 游泳\" } } ] } } }' # hobby包含乒乓但是age不等于21的数据 curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"bool\": { \"must\": [ { \"match\": { \"hobby\": \"乒乓\" } } ], \"must_not\": [ { \"match\": { \"age\": \"21\" } } ] } } }' 中文分词中文分词的难点在于在汉语中没有明显的词汇分界点，如在英语中空格可以作为分隔符，如果分隔不正确就会造成歧义。常用中文分词器有IK、jieba、THULAC等，推荐使用IK分词器 IK Analyzer是一个开源的，基于java语言开发的轻量级的中文分词工具包。从2006年12月推出1.0版开始，IKAnalyzer已经推出了3个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。新版本的IK Analyzer 3.0则发展为面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。采用了特有的”正向迭代最细粒度切分算法”，具有80万字/秒的高速处理能力 采用了多子处理器分析模式，支持：英文字母（IP地址、Email、URL）、数字（日期，常用中文数量词，罗马数字，科学计数法），中文词汇（姓名、地名处理）等分词处理。 优化的词典存储，更小的内存占用 安装ik中文分词器 # 下载对应es版本的ik分词器 https://github.com/medcl/elasticsearch-analysis-ik # 创建目录 cd your-es-root/plugins/ &amp;&amp; mkdir ik # 解压 unzip plugin to folder your-es-root/plugins/ik # 重启es(集群环境每一台都要配置) 分词测试 curl -X POST '10.10.110.191:9200/_analyze?pretty' -H \"Content-Type:application/json\" -d ' { \"analyzer\": \"ik_max_word\", \"text\": \"我是中国人\" }' 结果 { \"tokens\" : [ { \"token\" : \"我\", \"start_offset\" : 0, \"end_offset\" : 1, \"type\" : \"CN_CHAR\", \"position\" : 0 }, { \"token\" : \"是\", \"start_offset\" : 1, \"end_offset\" : 2, \"type\" : \"CN_CHAR\", \"position\" : 1 }, { \"token\" : \"中国人\", \"start_offset\" : 2, \"end_offset\" : 5, \"type\" : \"CN_WORD\", \"position\" : 2 }, { \"token\" : \"中国\", \"start_offset\" : 2, \"end_offset\" : 4, \"type\" : \"CN_WORD\", \"position\" : 3 }, { \"token\" : \"国人\", \"start_offset\" : 3, \"end_offset\" : 5, \"type\" : \"CN_WORD\", \"position\" : 4 } ] }","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Stack(1)","slug":"Elastic Stack(1)","date":"2020-08-05T06:19:27.000Z","updated":"2020-09-03T09:26:42.011Z","comments":true,"path":"post/cb83e724.html","link":"","permalink":"https://www.missf.top/post/cb83e724.html","excerpt":"","text":"Elastic Stack简介ELK日志收集分析平台相信所有的运维工程师都听说过，实际上ELK不是一门技术，而是三个软件的简称。它们分别是由Elasticsearch、Logstash、Kibana组成，在ELK发展的过程中，又有新成员Beats的加入，所以就形成了Elastic Stack Elastic Stack的组成 ElasticsearchElasticsearch基于java语言开发，是个开源分布式搜索引擎，它的特点有:分布式、零配置、自动发现、索引自动分片、索引副本机制、RESTful风格接口、多数据源、自动搜索负载等 LogstashLogstash基于java语言开发，是一个开源的用于收集，分析和存储日志的工具 KibanaKibana基于nodejs，也是一个开源和免费的工具，Kibana可以为 Logstash和ElasticSearch提供的日志分析的友好Web界面，可以汇总、分析和搜索重要数据日志 BeatsBeats是elastic公司开源的一款采集系统监控数据的代理agent，是在被监控服务器上以客户端形式运行的数据收集器的统称，可以直接把数据发送给Elasticsearch或者通过Logstash发送给Elasticsearch，然后进行后续的数据分析活动 Beats由如下组成： Packetbeat：一个网络数据包分析器，用于监控、收集网络流量信息，Packetbeat嗅探服务器之间的流量，解析应用层协议，并关联到消息的处理，其支持ICMP(v4 and v6)、DNS、HTTP、Mysql、PostgreSQL、Redis、MongoDB、Memcache等协议 Filebeat：用于监控、收集服务器日志文件，其已取代logstash forwarder Metricbeat：可定期获取外部系统的监控指标信息，其可以监控、收集 Apache、HAProxy、MongoDB、MySQL、Nginx、PostgreSQL、Redis、System、Zookeeper等服务 Winlogbeat：用于监控、收集Windows系统的日志信息","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Prometheus的pushgateway工具(8)","slug":"Prometheus的pushgateway工具(8)","date":"2020-08-04T10:05:33.000Z","updated":"2020-08-28T03:02:24.983Z","comments":true,"path":"post/5cf39589.html","link":"","permalink":"https://www.missf.top/post/5cf39589.html","excerpt":"","text":"PushGateway部署prometheus基于http的pull方式去采集时间序列数据，但是由于业务需求，prometheus和exporter可能不在一个子网或者防火墙原因，导致Prometheus无法直接拉取各个target数据，或者需要将不同的数据进行汇总，这时候就可以使用prometheus的自带组件pushgateway进行数据的汇总，将默认的pull方式改为push方式进行数据的采集 # 下载pushgateway wget https://github.com/prometheus/pushgateway/releases/download/v1.2.0/pushgateway-1.2.0.linux-amd64.tar.gz # 解压 tar xf pushgateway-1.2.0.linux-amd64.tar.gz &amp;&amp; mv pushgateway-1.2.0.linux-amd64 /usr/local/pushgateway # 创建pushgateway启动文件 vim /usr/lib/systemd/system/pushgateway.service [Unit] Documentation=pushgateway exporter After=local-fs.target network-online.target network.target Wants=local-fs.target network-online.target network.target [Service] Restart=on-failure ExecStart=/usr/local/pushgateway/pushgateway # 需要修改监听端口可以自行添加参数 [Install] WantedBy=multi-user.target # 启动pushgateway systemctl start pushgateway.service Prometheus添加PushGateway在我们的prometheus配置文件添加pushgateway的地址 vim /usr/local/prometheus/prometheus.yml scrape_configs: - job_name: 'pushgateway' static_configs: - targets: ['49.233.200.185:9091'] # 这个是安装了pushgateway的服务器地址 labels: instance: pushgateway 重启prometheus服务 systemctl restart prometheus.service pushgateway其实是一个中转站，我们可以使用任何高级语言发送post请求到pushgateway，然后对数据进行增加删除等操作，pushgateway再把数据实时推送到prometheus 推送数据到PushGatewayecho \"missf 123456\" | curl --data-binary @- http://49.233.200.185:9091/metrics/job/prometheus # 数据:missf,值:123456 # --data-binary 表示发送二进制数据(post方式) # http://49.233.200.185:9091 pushgateway的地址 查看pushgateway推送到prometheus上的数据，这可以看到有exported_job=”prometheus”和job=”pushgateway”两个指标，我们推送数据时指定的job是prometheus，为什么这里的job会显示pushgateway呢？这里需要修改一个honor_labels的参数 修改prometheus的配置文件，开启honor_labels参数(默认为false) scrape_configs: - job_name: 'pushgateway' honor_labels: true static_configs: - targets: ['49.233.200.185:9091'] labels: instance: pushgateway 重启prometheus 再次推送数据到pushgateway，然后查看prometheus上的数据 echo \"mwj 123456\" | curl --data-binary @- http://49.233.200.185:9091/metrics/job/prometheus/instance/missf 这里说明一下honor_labels的作用:因为prometheus配置pushgateway的时候，也会指定job和instance，但是它只表示pushgateway实例本身，不能真正表达收集数据的含义。所以配置pushgateway需要添加honor_labels:true参数，避免收集到的数据本身的job和instance被覆盖。具体参考官网 在PushGateway删除数据curl -X DELETE http://49.233.200.185:9091/metrics/job/prometheus/instance/missf","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus业务监控(7)","slug":"Prometheus业务监控(7)","date":"2020-08-03T02:26:26.000Z","updated":"2020-08-28T03:01:55.386Z","comments":true,"path":"post/f261c617.html","link":"","permalink":"https://www.missf.top/post/f261c617.html","excerpt":"","text":"Blackbox_exporter部署Blackbox_exporter是prometheus官方提供的exporter之一，可以提供http、dns、tcp、icmp 的监控数据采集 # 下载 wget https://github.com/prometheus/blackbox_exporter/releases/download/v0.17.0/blackbox_exporter-0.17.0.linux-amd64.tar.gz # 解压 tar xf blackbox_exporter-0.17.0.linux-amd64.tar.gz &amp;&amp; mv blackbox_exporter-0.17.0.linux-amd64 /usr/local/blackbox # 创建blackbox启动文件 vim /usr/lib/systemd/system/blackbox.service [Unit] Documentation=Blackbox exporter After=local-fs.target network-online.target network.target Wants=local-fs.target network-online.target network.target [Service] Restart=on-failure ExecStart=/usr/local/blackbox/blackbox_exporter --config.file=/usr/local/blackbox/blackbox.yml [Install] WantedBy=multi-user.target # 启动blackbox systemctl daemon-reload systemctl restart blackbox.service 配置TCP端口检测及告警传统的端口检测方式，调用命令的方式去实现 ncat -vz 47.100.107.121 80 # 返回seconds而不是timeout那么端口就是通的 telnet ...... zabbix监控端口可以通过模板或者自定义key写脚本实现 修改prometheus配置文件，配置TCP端口检测 vim /usr/local/prometheus/prometheus.yml scrape_configs: - job_name: 'nginx_port_check' metrics_path: /probe params: module: [tcp_connect] file_sd_configs: - files: - check/port/nginx.json relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 47.100.107.121:9115 # 这个是blackbox所在主机以及端口 编写监控TCP端口的告警规则 vim /usr/local/prometheus/rules/nginx_port_check.yml groups: - name: nginx port check rules: - alert: nginx_port_check failed for: 5s expr: probe_success{job=\"nginx_port_check\"} == 0 labels: serverity: critical annotations: description: \"{{ $labels.group }} port connection fail,{{ $labels.group }} value is:{{ $value }}\" summary: \"{{ $labels.group }} port connection failed\" 修改prometheus配置文件需要重启prometheus服务 systemctl restart prometheus.service 关闭Nginx测试当80端口无法访问之后的告警结果 业务接口检测及告警基于现在Java + Vue前后端分离的开发模式下，我们很多时候需要去检测Java的接口是否正常。传统的手动检测可以使用postman，或者写shell脚本也可以实现，但是prometheus可以通过blackbox去更好的检测业务接口 修改prometheus配置文件，添加监控业务接口的job scrape_configs: - job_name: 'get_mysite' scrape_interval: 5s metrics_path: /probe params: module: [http_2xx] file_sd_configs: - files: - check/url/*.json relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 47.100.107.121:9115 编写监控url链接的告警规则文件 vim /usr/local/prometheus/rules/get_mysite.yml groups: - name: get mysite check rules: - alert: get_mysite_check failed for: 5s expr: probe_success{group=\"get_mysite\",instance=\"https://www.missf.top\",job=\"get_mysite\"} == 0 labels: serverity: critical annotations: description: \"{{ $labels.group }} failed, {{ $labels.group }} value is:{{ $value }}\" summary: \"{{ $labels.group }} website not accessible\" 修改prometheus配置文件之后记得重启prometheus服务 systemctl restart prometheus.service 如果https://www.missf.top这个链接的http请求不是返回2xx的状态码就会告警 {% image https://pic.imgdb.cn/item/5f28fbe914195aa5944ce74b.jpg '' '' %} 我们在监控业务接口时，只监控到接口的返回状态(2xx状态码)，假如我们想要监控业务接口的返回内容该如何实现呢？那就需要修改blackbox的配置文件 modules: http_2xx: prober: http # 下面这段是需要添加的内容 http: method: GET headers: Host: www.missf.top Accept-Language: en-US Origin: missf.top fail_if_body_matches_regexp: # 如果我get的url地址返回的正文中有\"apache\",那么就会失败,则probe_success值为0 - \"apache\" fail_if_body_not_matches_regexp: - \"nginx\" # 如果我get的url地址返回的正文中没有\"nginx\",那么就会失败,则probe_success值为0 http_post_2xx: prober: http http: method: POST tcp_connect: prober: tcp pop3s_banner: prober: tcp tcp: query_response: - expect: \"^+OK\" tls: true tls_config: insecure_skip_verify: false ssh_banner: prober: tcp tcp: query_response: - expect: \"^SSH-2.0-\" irc_banner: prober: tcp tcp: query_response: - send: \"NICK prober\" - send: \"USER prober prober prober :prober\" - expect: \"PING :([^ ]+)\" send: \"PONG ${1}\" - expect: \"^:[^ ]+ 001\" icmp: prober: icmp 修改了blackbox配置文件需要重启blackbox服务 systemctl restart blackbox.service 上面所配置的匹配返回内容是在http_2xx这个模块下添加的，我们需要修改prometheus配置文件对应的http_2xx模块的规则文件，配置我们监控业务接口的返回内容的url地址 vim /usr/local/prometheus/check/url/get_mysite.json [ { \"targets\": [ \"47.100.107.121\" # 这个url返回的是默认的Nginx页面,对应我上面的匹配规则(nginx/apache) ], \"labels\": { \"group\": \"get_mysite\" } } ] 查看blackbox的采集数据 probe_success的值是根据我们在blackbox配置文件的正则去决定的 这时候我们get_mysite.json这个规则文件的job的probe_success值就是通过get获取一个url的返回值去确定的，我们这样就可以去监控接口的返回内容了 配置网络监控我们可以让服务器使用icmp协议去请求www.baidu.com或者是一个公网IP，测试服务器的网络是否正常 修改prometheus配置文件，添加网络监控的job scrape_configs: - job_name: 'icmp_check_network' scrape_interval: 5s metrics_path: /probe params: module: [icmp] file_sd_configs: - files: - check/icmp/*.json relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 47.100.107.121:9115 编写网络监控的规则文件 vim /usr/local/prometheus/rules/check_network.yml groups: - name: icmp check network rules: - alert: icmp check network failed for: 10s expr: probe_success{group=\"icmp_check_network\",instance=\"www.baidu.com\",job=\"icmp_check_network\"} == 0 labels: serverity: critical annotations: description: \"{{ $labels.group }} icmp connection failed, {{ $labels.group }} value is: {{ $value }}\" summary: \"{{ $labels.group }} connection failed, instance: {{ $labels.instance }}\" 修改prometheus配置文件之后记得重启prometheus服务 systemctl restart prometheus.service","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus告警(6)","slug":"Prometheus告警(6)","date":"2020-07-23T03:53:03.000Z","updated":"2020-08-28T03:01:19.617Z","comments":true,"path":"post/615f0093.html","link":"","permalink":"https://www.missf.top/post/615f0093.html","excerpt":"","text":"Alertmanager概述prometheus发出告警时分为两部分，首先prometheus按告警规则(rule_files配置)向alertmanager发送告警，即告警规则是在prometheus上定义的，然后由alertmanager去管理这些告警，包括去重(deduplicating)、分组(grouping)、静音(silencing)、抑制(inhibition)、聚合(aggregation)，最终通过丰富的告警通知渠道(电话、微信、短信、邮件)将告警通知路由给对应的联系人。prometheus的大部分组件都是go语言开发的，zabbix到4.4之后的客户端才是go编写 Alertmanager二进制安装# 下载 wget https://github.com/prometheus/alertmanager/releases/download/v0.21.0/alertmanager-0.21.0.linux-amd64.tar.gz # 解压 tar xf alertmanager-0.21.0.linux-amd64.tar.gz &amp;&amp; mv alertmanager-0.21.0.linux-amd64 /usr/local/alertmanager # 创建alertmanager启动文件 vim /usr/lib/systemd/system/alertmanager.service [Unit] Documentation=alertmanager [Service] Restart=on-failure ExecStart=/usr/local/alertmanager/alertmanager --config.file=/usr/local/alertmanager/alertmanager.yml --storage.path=/usr/local/alertmanager/data [Install] WantedBy=multi-user.target # 启动 systemctl daemon-reload systemctl start alertmanager.service Alertmanager配置文件详解vim /usr/local/alertmanager/alertmanager.yml global: resolve_timeout: 5m # 恢复的超时时间,这个跟告警恢复通知有关,此参数并不是说在这个时间没有收到告警就会恢复 route: group_by: ['alertname'] # 默认以告警名进行分组,就是rule文件的alert值进行分组 group_wait: 10s # 发送警报前，至少等待多少秒才会发送(为了收集同组更多的警报信息一起发送) group_interval: 10s # 如果警报1已经发送,这时又出现同组的警报2,由于组状态发生变化,警报会在group_interval这个时间内发送,不会被repeat_interval这个时间收敛 repeat_interval: 20m # 报警信息已发送，但事件并没有恢复,则等待多久时间再重新发送(生产环境一般设成20min或者30min) receiver: 'web.hook' # 发送警报的接收者名称,如果一个报警没有被一个route匹配,则发送给默认的接收器 receivers: # 发送告警信息给那个接收者 - name: 'web.hook' # 这个需要和上面定义的接收者名称一致 webhook_configs: - url: 'http://127.0.0.1:5001/' inhibit_rules: # 抑制规则,防止告警风暴 - source_match: severity: 'critical' target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] 检查Alertmanager配置文件# 提示SUCCESS,则配置文件没有问题 ./amtool check-config alertmanager.yml # 修改配置文件之后重启alertmanager systemctl restart alertmanager.service 配置邮件告警修改alertmanager配置文件，填写邮箱的验证信息，定义路由的收件人，配置发送告警邮件到那个邮箱 cat /usr/local/alertmanager/alertmanager.yml global: resolve_timeout: 3m smtp_smarthost: 'smtp.qq.com:465' smtp_from: '1173354099@qq.com' smtp_auth_username: '1173354099@qq.com' smtp_auth_password: '' # 授权码 smtp_require_tls: false route: group_by: ['alertname'] group_wait: 10s group_interval: 10s repeat_interval: 20m receiver: 'devops.mail' receivers: - name: 'devops.mail' email_configs: - to: 'mf_2013@163.com' headers: { Subject: \"[WARN] Prometheus 报警邮件\" } send_resolved: true # 发送告警恢复通知 #inhibit_rules: # - source_match: # severity: 'critical' # target_match: # severity: 'warning' # equal: ['alertname', 'dev', 'instance'] 配置prometheus与alertmanager通信，设置规则文件的路径和正则匹配 # 修改prometheus配置文件 vim /usr/local/prometheus/prometheus.yml alerting: alertmanagers: - static_configs: - targets: - 127.0.0.1:9093 # 这里由于alertmanager是和prometheus部署在同一台机器上,所以写本机地址 rule_files: - \"rules/*.yml\" # rules这个目录是在prometheus上的,指当前配置文件的同级目录,这个目录需要自己创建 # 检查prometheus配置文件 ./promtool check config prometheus.yml systemctl restart prometheus.service 编写rules文件，根据rules文件中的表达式去告警，这个规则文件的路径是prometheus配置文件中定义的 # 监控节点的状态 cat /usr/local/prometheus/rules/node.yml groups: - name: node_alert rules: - alert: Node_InstanceDown expr: up == 0 # 表达式 for: 5s labels: serverity: error annotations: summary: \"Instance {{ $labels.instance }} down\" description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes\" 在prometheus的web控制台查看配置的规则 关闭node_exporter.service节点，查看告警邮件 配置微信告警修改alertmanager配置文件，定义路由规则 cat /usr/local/alertmanager/alertmanager.yml global: resolve_timeout: 3m smtp_smarthost: 'smtp.qq.com:465' smtp_from: '1173354099@qq.com' smtp_auth_username: '1173354099@qq.com' smtp_auth_password: '' # 授权码 smtp_require_tls: false templates: - /usr/local/alertmanager/template/wechat.temp route: group_by: ['alertname'] group_wait: 10s group_interval: 10s repeat_interval: 20m #receiver: 'devops.mail' receiver: 'devops.mailwechat' routes: # 为node_exporter、docker、mysqld_exporter定义匹配路由,每个路由有自己的分组在微信告警时信息就会单独发送 - receiver: 'devops.mailwechat' # 每个服务可以定义自己的接收者,这样在发送时就可以发送给不同的人,不同的服务对应不同的处理人员 group_wait: 10s group_by: ['node_exporter'] match_re: job: node_exporter - receiver: 'devops.mailwechat' group_wait: 10s group_by: ['docker'] match_re: job: docker - receiver: 'devops.mailwechat' group_wait: 10s group_by: ['mysqld_exporter'] match_re: job: mysqld_exporter receivers: - name: 'devops.mailwechat' # 将这个告警同时发送到邮件和微信 email_configs: - to: 'mf_2013@163.com' headers: { Subject: \"[WARN] Prometheus 报警邮件\" } send_resolved: true wechat_configs: - api_secret: '' agent_id: '' corp_id: '' to_party: '' send_resolved: true #inhibit_rules: # - source_match: # severity: 'critical' # target_match: # severity: 'warning' # equal: ['alertname', 'dev', 'instance'] 编写rules文件，为了每个服务单独报警，这里将node_exporter、docker、mysqld_exporter分开去写匹配规则 cat /usr/local/prometheus/rules/node.yml groups: - name: node_exporter rules: - alert: node_exporter_Down expr: up{job=\"node_exporter\"} == 0 for: 5s labels: serverity: error annotations: summary: \"Instance {{ $labels.instance }} down\" description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes\" - name: mysqld_exporter rules: - alert: mysqld_exporter_Down expr: up{job=\"mysqld_exporter\"} == 0 for: 5s labels: serverity: error annotations: summary: \"Instance {{ $labels.instance }} down\" description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes\" - name: docker rules: - alert: docker_Down expr: up{job=\"docker\"} == 0 for: 5s labels: serverity: error annotations: summary: \"Instance {{ $labels.instance }} down\" description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes\" 配置完成之后重启alertmanager systemctl restart alertmanager.service 关闭node_exporter和docker_cadvisor服务，这时候会每个服务单独发送告警信息，由于将全部服务group_by在一个组里面，在发送恢复信息时会出现服务混乱的情况，所以我将每个服务做了路由，每一个服务都有自己的group_by，这样在发送信息时才会单独去发送 配置钉钉告警先去创建一个钉钉机器人，具体过程这里就不详细说明了 prometheus配置钉钉告警需要使用到prometheus-webhook-dingtalk插件，我们先使用二进制安装钉钉插件，dingtalk服务默认启动的端口是8060 prometheus-webhook-dingtalk插件下载地址 # 下载prometheus-webhook-dingtalk wget https://github.com/timonwong/prometheus-webhook-dingtalk/releases/download/v1.4.0/prometheus-webhook-dingtalk-1.4.0.linux-amd64.tar.gz # 解压prometheus-webhook-dingtalk tar xf prometheus-webhook-dingtalk-1.4.0.linux-amd64.tar.gz &amp;&amp; mv prometheus-webhook-dingtalk-1.4.0.linux-amd64 /usr/local/dingtalk # 编写dingtalk启动文件 vim /usr/lib/systemd/system/dingtalk.service [Unit] Description=prometheus-webhook-dingtalk After=network-online.target [Service] Restart=on-failure ExecStart=/usr/local/dingtalk/prometheus-webhook-dingtalk \\ --ding.profile=Prometheus告警=https://oapi.dingtalk.com/robot/send?access_token=xxxxxx [Install] WantedBy=multi-user.target # 启动dingtalk.service systemctl daemon-reload systemctl restart dingtalk.service # 查看dingtalk的webhook地址 journalctl -fu dingtalk.service Jul 29 18:38:01 iZuf6fpaicz5jt7kep555qZ prometheus-webhook-dingtalk[5504]: ts=2020-07-29T10:38:01.655Z caller=main.go:133 component=configuration msg=\"Webhook urls for prometheus alertmanager\" urls=http://localhost:8060/dingtalk/Prometheus告警/send 修改prometheus的alertmanager配置，更改告警的路由和接收者 route: receiver: 'devops_dingtalk' # 接收者必须和下面的一致 receivers: - name: 'devops_dingtalk' webhook_configs: - url: 'http://localhost:8060/dingtalk/Prometheus告警/send' # 这个URL是dingtalk的webhook地址 send_resolved: true 关闭docker收集器查看告警效果 告警状态prometheus的告警状态有三种，我们可以在prometheus的控制台页面上查看告警的状态 inactive没有触发任何阈值，这个是根据scrape_interval参数(采集数据周期)和evaluation_interval参数(对比规则周期)去决定的 pending已触发阈值但未满足告警持续时间，告警进入pending状态之后，需要等待规则配置的for时间，如果在这个时间内触发阈值的表达式一直成立，才会进入firing状态 firing已触发阈值且满足告警持续时间，将告警从prometheus发送给alertmanager，在alertmanager收到告警之后并不会立刻发送，还需要等待一个group_wait时间，直到某个计算周期表达式为假，告警状态变更为inactive，发送一个resolve给altermanger，说明此告警已解决 告警收敛alertmanager在收到prometheus发送的告警之后，并不是把收到的信息简单的直接发送出去，而是通过一系列的收敛机制(分组、抑制、静默)去筛选出需要发送的信息，如果alertmanager收到信息就直接发送出去，会导致告警信息过多，运维人员会被告警信息淹没，错过重要的告警信息 分组将类似性质的告警分类为单个通知，减少告警消息数量 将类似性质的告警进行聚合发送，帮助运维更好的排查问题 抑制当告警发出后，停止重复发送由此告警而引起的其他告警，帮助运维第一时间掌握最核心的告警信息 inhibit_rules: - source_match: severity: 'critical' # 当发生critical级别的告警时,就会抑制下面warning级别的告警 target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] # 已发送的告警与新产生的告警中equal定义的标签完全相同,则启动抑制机制 静默是一种简单的特定时间静音的提醒机制，在发布新版本时我们需要停掉某些进程，这时候告警肯定会触发的，由于这是我们已经预知的现象，我们可以打开prometheus主机的9093端口暂时将告警设置成静音 Prometheus一条告警是怎么触发的1.采集数据 scrape_interval: 15s 2.比对采集到的数据是否触发阈值 evaluation_interval: 15s 3.判断是否超出持续时间(在这个时间内一直处于触发阈值状态)for: 5s 4.告警到达alertmanager然后进行分组、抑制、静默 5.通过分组、抑制、静默一系列机制的信息将会被发送，但是会延迟发送group_wait: 10s 编写告警规则案例groups: - name: general.rules rules: - alert: node_FileSystemUsage # 监控磁盘使用率 expr: 100 - node_filesystem_free_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"} / node_filesystem_size_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"} * 100 > 80 for: 5s labels: serverity: warning annotations: summary: \"Instance {{ $labels.instance }} : {{ $labels.mountpoint }} Partition utilization is too high\" description: \"{{ $labels.instance }} : {{ $labels.mountpoint }} Partition utilization is greater than 80% (Currently: {{ $value }})\" - alert: node_MemoryUsage # 监控内存使用率 expr: 100 - (node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) / node_memory_MemTotal_bytes * 100 > 80 for: 5s labels: serverity: warning annotations: summary: \"Instance {{ $labels.instance }} High memory usage\" description: \"{{ $labels.instance }} Memory usage greater than 80% (Currently: {{ $value }})\" - alert: node_cpuUsage # 监控CPU使用率 expr: 100 - irate(node_cpu_seconds_total{mode=\"idle\",job=\"node_exporter\",instance=\"47.100.107.121:9100\"}[5m]) * 100 > 80 for: 5s labels: serverity: warning annotations: summary: \"Instance {{ $labels.instance }} High cpu usage\" description: \"{{ $labels.instance }} Memory usage greater than 60% (Currently: {{ $value }})\"","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus监控案例(5)","slug":"Prometheus监控案例(5)","date":"2020-07-16T07:43:16.000Z","updated":"2020-08-28T03:00:43.029Z","comments":true,"path":"post/ba827699.html","link":"","permalink":"https://www.missf.top/post/ba827699.html","excerpt":"","text":"监控Linux服务器部署node_exporterprometheus官方提供Node_exporter来让我们收集机器的系统数据，除node_exporter外，官方还提供consul、memcached、haproxy、mysqld等exporter。exporter类似于zabbix写好的监控模板，但是这些exporter都是需要在被监控节点安装 # 下载node_exporter wget https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz # 解压 tar xf node_exporter-1.0.1.linux-amd64.tar.gz &amp;&amp; mv node_exporter-1.0.1.linux-amd64 /usr/local/node_exporter # 编写启动文件 vim /usr/lib/systemd/system/node_exporter.service [Unit] Description=prometheus [Service] Restart=on-failure ExecStart=/usr/local/node_exporter/node_exporter [Install] WantedBy=multi-user.target # 启动node_exporter systemctl daemon-reload systemctl start node_exporter.service # 访问node_exporter的数据接口 http://10.10.110.23:9100/metrics # 默认端口是9100,默认接口是metrics 配置监控# 修改prometheus配置文件 vim /usr/local/prometheus/prometheus.yml - job_name: 'node_exporter' file_sd_configs: - files: ['/usr/local/prometheus/sd_config/node/*.yaml'] refresh_interval: 5s # 创建服务发现的文件 vim /usr/local/prometheus/sd_config/node/*.yaml - targets: - '10.10.110.23:9100' # 这个地址是被监控节点的IP地址 promSQL监控CPU、内存、硬盘CPU监控# 计算CPU五分钟内平均的使用率表达式 100 - irate(node_cpu_seconds_total{mode=\"idle\",instance=\"10.10.110.23:9100\",job=\"node_exporter\"}[5m]) * 100 # node_cpu_seconds_total{mode=\"idle\",instance=\"10.10.110.23:9100\",job=\"node_exporter\"}[5m]:取CPU五分钟之内的空闲值 # irate函数:将会用于计算某个指标在一定时间间隔内的变化速率 # 将得到的空闲值乘以100再得到CPU百分比的空闲值,再以100减去CPU百分比的空闲值,就得到CPU五分钟内平均的使用率 内存监控# 计算内存使用率表达式 100 - (node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) / node_memory_MemTotal_bytes * 100 # (node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes)是内存剩余的总量 在系统层面来考虑:buff和cache是已经被使用的内存 在程序层面来考虑:buff和cache是剩余的内存 # 内存剩余的总量除以内存总量得到内存剩余率,再以100减去内存剩余率得到内存使用率 硬盘监控# 计算硬盘使用率表达式 100 - node_filesystem_free_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"} / node_filesystem_size_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"} * 100 # node_filesystem_free_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"}是根分区硬盘剩余容量,只计算ext4|xfs类型的文件系统 # node_filesystem_size_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"}是根分区的硬盘总量 # 根分区硬盘剩余容量除以根分区的硬盘总量得到根分区硬盘的剩余率,再以100减去硬盘的剩余率得到硬盘使用率 监控系统服务状态修改node_exporter的启动参数vim /usr/lib/systemd/system/node_exporter.service [Unit] Description=prometheus [Service] Restart=on-failure ExecStart=/usr/local/node_exporter/node_exporter --collector.systemd --collector.systemd.unit-whitelist=(docker|sshd).service # 利用正则匹配监控systemd的docker|sshd这三个服务 [Install] WantedBy=multi-user.target 重启node_exportersystemctl daemon-reload systemctl restart node_exporter.service 查看监控服务的数据指标node_systemd_unit_state{name=\"docker.service\"} 在activating、active、deactivating、failed、inactive五个状态中value为1的状态，就是服务当前的状态 {% image https://pic.imgdb.cn/item/5f1fa26414195aa5947438c7.jpg '' '' %} 使用Grafana图表展示监控数据安装Grafana# 下载软件包 wget https://dl.grafana.com/oss/release/grafana-7.1.0-1.x86_64.rpm # 安装 yum install grafana-7.1.0-1.x86_64.rpm -y # 启动 systemctl enable grafana-server.service systemctl start grafana-server.service # Grafana默认端口为3000,账号密码都为admin,初次登录会提示需要修改密码 Grafana配置数据源填写prometheus主机的地址，在配置数据源时我们还可以配置验证、定义HTTP头部、以及其他的一些信息 Grafana导入仪表盘我们可以自己编写仪表盘，也可以使用官方网站上别人已经写好的仪表盘模板直接导入使用，这里我们没有必要自己去编写(重复造轮子而且还没有人家专业…)。我们先去Grafana Labs上找到监控Linux主机的仪表盘，然后将仪表盘的ID号导入到Grafana 查看仪表盘Grafana监控Linux主机的仪表盘数据是从prometheus的数据源获取的，就是被监控主机上的node_exporter获取到的数据 监控Docker服务器部署cadvisor想要监控Docker容器，需要在被监控主机安装cadvisor插件，暴露一个HTTP端口，为prometheus提供容器的监控数据 # 由于国内无法连接到gcr.io,这里使用张馆长仓库的镜像地址 docker run \\ --volume=/:/rootfs:ro \\ --volume=/var/run:/var/run:ro \\ --volume=/sys:/sys:ro \\ --volume=/var/lib/docker/:/var/lib/docker:ro \\ --volume=/dev/disk/:/dev/disk:ro \\ --publish=8080:8080 \\ --detach=true \\ --name=cadvisor \\ --privileged \\ --device=/dev/kmsg \\ registry.aliyuncs.com/k8sxio/cadvisor:latest 配置Prometheus监控cadvisorcadvisor可以搜集一台机器上所有运行的容器信息，还提供基础查询界面和http接口，供其他组件如prometheus拉取数据 vim /usr/local/prometheus/prometheus.yml # 在prometheus配置文件加入监控主机的cadvisor端口(拉取容器数据) - job_name: 'docker' static_configs: - targets: ['10.10.110.23:8080'] systemctl daemon-reload systemctl restart prometheus.service Grafana导入仪表盘我们去Grafana Labs网站寻找一个监控Docker主机的仪表盘，在Grafana进行导入 查看Docker主机仪表盘 监控MySQL服务器监控MySQL主机和监控Linux主机一样，都是需要导出器去获取数据，这里我们去prometheus官网下载mysqld_exporter，然后在mysql主机上安装(监控那台mysql主机就在那台主机安装mysqld_exporter) MySQL主机安装mysqld_exporter# 下载 wget https://github.com/prometheus/mysqld_exporter/releases/download/v0.12.1/mysqld_exporter-0.12.1.linux-amd64.tar.gz # 解压 tar xf mysqld_exporter-0.12.1.linux-amd64.tar.gz &amp;&amp; mv mysqld_exporter-0.12.1.linux-amd64 /usr/local/mysqld_exporter # 创建启动文件 vim /usr/lib/systemd/system/mysqld_exporter.service [Unit] Documentation=https://prometheus.io/ [Service] Restart=on-failure Environment=DATA_SOURCE_NAME=exporter:Missf.top123@(localhost:3306)/ # 连接数据库的账号密码,也可以指定.my.cnf文件 ExecStart=/usr/local/mysqld_exporter/mysqld_exporter [Install] WantedBy=multi-user.target # 被监控数据库添加mysql用户及监控权限 CREATE USER 'exporter'@'localhost' IDENTIFIED BY 'Missf.top123' WITH MAX_USER_CONNECTIONS 3; GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'exporter'@'localhost'; FLUSH PRIVILEGES; # 启动mysqld_exporter systemctl start mysqld_exporter # 获取监控数据 curl [IP]:9104/metrics 配置Prometheus监控mysqld_exporter# 修改配置文件 vim /usr/local/prometheus/prometheus.yml - job_name: 'mysqld_exporter' # 添加监控mysqld_exporter static_configs: - targets: ['47.100.107.121:9104'] # 重启 systemctl restart prometheus.service 导入MySQL仪表盘导入ID为7362的MySQL仪表盘，查看MySQL的监控数据","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus配置文件与核心功能(4)","slug":"Prometheus配置文件与核心功能(4)","date":"2020-07-15T11:06:15.000Z","updated":"2020-08-28T03:00:04.834Z","comments":true,"path":"post/521f1005.html","link":"","permalink":"https://www.missf.top/post/521f1005.html","excerpt":"","text":"全局配置文件介绍global: # 全局默认的数据拉取间隔,默认每隔1m拉取一次监控数据 [ scrape_interval: &lt;duration> | default = 1m ] # 全局默认的单次数据拉取超时 [ scrape_timeout: &lt;duration> | default = 10s ] # 对告警规则做定期计算的间隔时间,每隔1m对比一次我采集到的数据跟我设置的告警规则,符合告警规则的事件就会被发送到alertmanager,由alertmanager做路由匹配然后进行告警处理 [ evaluation_interval: &lt;duration> | default = 1m ] # 监控告警的规则设置 rule_files: [ - &lt;filepath_glob> ... ] # 配置被监控指标 scrape_configs: [ - &lt;scrape_config> ... ] # 指定告警和告警管理器相关的设置 alerting: alert_relabel_configs: [ - &lt;relabel_config> ... ] alertmanagers: [ - &lt;alertmanager_config> ... ] scrape_configs配置数据源，拉取数据的对象称为Targets，每个Targets用job_name命名，添加数据源又分为静态配置和服务发现 # 定义job名称,是一个拉取单元,每个job_name都会自动引入默认配置如: # scrape_interval 依赖全局配置 # scrape_timeout 依赖全局配置 # metrics_path 默认为'/metrics' # scheme 默认为'http' job_name: &lt;job_name> # 数据拉取间隔 [ scrape_interval: &lt;duration> | default = &lt;global_config.scrape_interval> ] # 数据拉取超时时间 [ scrape_timeout: &lt;duration> | default = &lt;global_config.scrape_timeout> ] # 拉取数据指标的地址 [ metrics_path: &lt;path> | default = /metrics ] 基于文件的服务发现基于文件的服务发现不需要依赖其他平台与第三方服务，用户只需将要更新的target信息以yaml或json文件格式添加到target文件中，prometheus会定期的从指定文件中读取target信息并更新。给我们带来的好处就是不需要一个个target去添加，只需要一个yaml或者json文件，便于管理 编写配置文件vim prometheus.yml # my global config 全局配置文件 global: scrape_interval: 5s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration 告警管理 alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093 # Load rules once and periodically evaluate them according to the global 'evaluation_interval'. rule_files: # - \"first_rules.yml\" # - \"second_rules.yml\" # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs: # The job name is added as a label `job=&lt;job_name>` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. # scrape_interval: 5s # static_configs: # - targets: ['localhost:9090'] file_sd_configs: # 文件服务发现 - files: ['/usr/local/prometheus/sd_config/*.yaml'] # 指定服务发现的文件路径 refresh_interval: 5s # 每过5秒动态发现服务配置 创建目录及文件vim /usr/local/prometheus/sd_config/test.yaml # 需要监控那一台主机就在那一台主机上创建 - targets: - '10.10.110.150:9090' # 这个是填写prometheus主机的地址,如果prometheus启动时监听的是8080端口,那么这里就需要和prometheus端口一致,不然获取不到数据 labels: group: prometheus 重载配置文件ps -ef | grep prometheus root 1774 1 0 Jul15 ? 00:02:21 /usr/local/prometheus/prometheus --config.file=/usr/local/prometheus/prometheus.yml root 2741 1702 0 14:13 pts/1 00:00:00 grep --color=auto prometheus kill -hup 1774","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus部署(3)","slug":"Prometheus部署(3)","date":"2020-07-15T09:11:11.000Z","updated":"2020-08-28T02:59:52.799Z","comments":true,"path":"post/d26dfcbe.html","link":"","permalink":"https://www.missf.top/post/d26dfcbe.html","excerpt":"","text":"二进制部署# 下载二进制安装包 wget https://github.com/prometheus/prometheus/releases/download/v2.19.2/prometheus-2.19.2.linux-amd64.tar.gz # 解压 tar xf prometheus-2.19.2.linux-amd64.tar.gz &amp;&amp; mv prometheus-2.19.2.linux-amd64 /usr/local/prometheus # 创建启动文件 cp /usr/lib/systemd/system/sshd.service /usr/lib/systemd/system/prometheus.service # 编写启动文件 tee /usr/lib/systemd/system/prometheus.service &lt;&lt; EOF [Unit] Description=http://prometheus.io [Service] Restart=on-failure ExecStart=/usr/local/prometheus/prometheus --config.file=/usr/local/prometheus/prometheus.yml [Install] WantedBy=multi-user.target EOF # 启动prometheus systemctl daemon-reload systemctl restart prometheus.service 修改配置文件vim /usr/local/prometheus/prometheus # my global config global: scrape_interval: 5s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093 # Load rules once and periodically evaluate them according to the global 'evaluation_interval'. rule_files: # - \"first_rules.yml\" # - \"second_rules.yml\" # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs: # The job name is added as a label `job=&lt;job_name>` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['127.0.0.1:9090'] Docker部署docker run -d --name \"prometheus\" -p 9090:9090 \\ --mount src=prometheus,dst=/etc/prometheus \\ --mount type=bind,src=/prometheus/prometheus.yml,dst=/etc/prometheus/prometheus.yml prom/prometheus 启动常用命令行参数./prometheus -h --config.file=\"prometheus.yml\" # 指定配置文件 --web.listen-address=\"0.0.0.0:9090\" # 指定端口 --log.level=info # 指定日志级别","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus概述(2)","slug":"Prometheus概述(2)","date":"2020-07-14T06:48:33.000Z","updated":"2020-08-28T02:59:28.304Z","comments":true,"path":"post/ef0b21f0.html","link":"","permalink":"https://www.missf.top/post/ef0b21f0.html","excerpt":"","text":"Prometheus简介Prometheus(普罗米修斯)是一个最初在SoundCloud上构建的监控系统。自2012年成为社区开源项目，拥有非常活跃的开发人员和用户社区。为强调开源及独立维护，Prometheus于2016年加入云原生云计算基金会(CNCF)，成为继Kubernetes之后的第二个托管项目 可能有些运维小伙伴不知道Prometheus，但是你们一定用过zabbix。现在由于Docker和Kubernetes的兴起，zabbix渐渐的失去了监控的优势，现在Prometheus是用来监控容器的最好实现，只有用到Docker和Kubernetes就离不开Prometheus提供监控支持。以前刚接触zabbix时，配置的微信告警让我开心了一整天，那时候觉得zabbix是世界上最好的监控软件，但是现在却觉得Prometheus才是。可能人总是需要不断向前看、不断向前奔跑的吧！ prometheus官网 Prometheus特点 多维数据模型(由时序列数据metric和一组key/value组成) 使用多维度数据完成复杂的语言查询，为prometheus的后期发展奠定基础(PromSQL) 不依赖分布式存储，单个服务器节点可直接工作 通过pushgateway进行时序列数据推送(pushing) 可以通过服务发现或者静态配置去获取要采集的目标服务器 多种可视化图表及仪表盘支持 基于HTTP的pull方式采集时间序列数据 Prometheus 组成及架构Prometheus根据配置定时去拉取各个节点的数据，默认使用的拉取方式是pull，也可以使用pushgateway提供的push方式获取各个监控节点的数据。将获取到的数据存入TSDB(时序型数据库)，此时prometheus已经获取到监控数据，可以使用内置的promSQL进行查询。它的报警功能使用alertmanager提供，alertmanager是prometheus的告警管理和发送报警的一个组件。prometheus原生的图表结构过于简单，prometheus的图表展示功能一般由grafana进行统一管理 Prometheus数据模型Prometheus将所有数据存储为时间序列，具有相同度量名称以及标签属于同一个指标。每个时间序列都由度量标准名称和一组键值对(也成为标签)唯一标识 # 时间序列格式示例 &lt;metric name>{&lt;label name>=&lt;label value>, ...} api_http_requests_total{method=\"POST\", handler=\"/messages\"} Prometheus指标类型Counter: 递增的计数器 Gauge: 可以任意变化的数值 Histogram: 对一段时间范围内数据进行采样，并对所有数值求和与统计数量 Summary: 与Histogram类似 不同的指标类型用于渲染不同的图表 Prometheus作业和实例实例: 可以抓取的目标称为实例(Instances) 作业: 具有相同目标的实例集合称为作业(Job) scrape_configs: - job_name: 'prometheus' # prometheus这个job作用于localhost:9090这个目标 static_configs: - targets: ['localhost:9090'] - job_name: 'node' # node这个job作用于192.168.1.10:9090这个目标 static_configs: - targets: ['192.168.1.10:9090']","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus监控的意义(1)","slug":"Prometheus监控的意义(1)","date":"2020-07-13T17:28:39.000Z","updated":"2020-08-28T02:59:02.610Z","comments":true,"path":"post/ded057ed.html","link":"","permalink":"https://www.missf.top/post/ded057ed.html","excerpt":"","text":"监控目的监控分为白盒监控和黑盒监控。白盒监控: 通过监控内部的运行状态及指标判断接下来可能会发生的问题，从而做出预判或应对的方法。黑盒监控: 监控系统或服务，在发生异常时做出相应的措施。prometheus属于黑盒监控，是在服务发生异常时，我们通过告警信息得知，才去处理异常问题 监控的目的主要分为以下方面: 根据历史监控数据，对未来做出预测 发生异常时即使告警，或做出相应措施 根据监控报警及时定位问题根源，记录问题出现的证据(记录网络波动) 通过可视化图表展示，便于直观获取信息 领导查看数据图表(PV、UV、订单趋势图) 运维人员能够提前预知风险，避免故障的产生或者在故障发生时能够迅速处理 怎么监控使用传统监控工具，直接调用Linux系统命令去获取服务状态和信息 # free # vmstat # df # top # ss # iftop ... 使用监控系统去监控系统和服务，能够整体监控每一项数据 # zabbix # nagios # prometheus # open-falcon 监控流程监控的大概流程分为:数据采集、数据存储、数据分析、以及展示和告警 监控什么 监控类型 具体参数 硬件监控 硬件参数、温度、故障等 系统监控 CPU，内存，硬盘，网卡流量，TCP状态，进程数 应用监控 Nginx、Tomcat、PHP、MySQL、Redis等 日志监控 系统日志、服务日志、访问日志、错误日志 安全监控 WAF，敏感文件监控 API监控 可用性，接口请求，响应时间 业务监控 例如电商网站，每分钟产生多少订单、注册多少用户、多少活跃用户、推广活动效果 流量分析 根据流量获取用户相关信息，例如用户地理位置、某页面访问状况、页面停留时间等","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Docker Compose单机编排利器(9)","slug":"Docker Compose单机编排利器(9)","date":"2020-07-10T06:27:09.000Z","updated":"2020-09-01T02:08:32.638Z","comments":true,"path":"post/34699079.html","link":"","permalink":"https://www.missf.top/post/34699079.html","excerpt":"","text":"Docker Compose 概述Compose是用于定义和运行多容器的工具，通过Compose可以使用YAML文件来配置容器。然后使用一个命令就可以从配置中创建并启动所有服务。其实在刚学习Docker时我就想过，如果我是LNMP架构容器化项目，因为每次都要一个个容器的启动，是否有必要将启停多个容器的命令写成一个shell脚本呢。现在学到Docker Compose，才知道根本没有这个必要，我们现在所有能想到的东西，其实早就有人帮我们实现了。这里不得不敬佩那些为开源项目做出贡献的伟大开发者们 使用Compose大概分为三个步骤: 定义Dockerfile，以便可以在任意环境运行 定义应用程序启动配置文件 docker-compose.yml docker-compose启动并管理整个应用程序生命周期 Linux 安装 Compose其实前面我们在学习Harbor时已经安装过docker-compose，这是一个使用python开发的编排工具，国内下载可能会比较慢(你应该知道怎么做了吧…) curl -L \"https://github.com/docker/compose/releases/download/1.26.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/bin/docker-compose chmod ,+x ，/usr/bin/docker-compose ， , docker-compose.yaml配置文件参数build使用docker-compose启动容器服务除了可以基于指定的镜像，还可以基于一份Dockerfile，在使用up启动时执行构建镜像的任务，这个构建标签就是build。Compose将会利用它自动构建这个镜像，然后使用这个镜像启动服务容器 version:\"3.7\" services: web: context:./web dockerfile:Dockerfile contextcontext选项可以是Dockerfile的文件路径，也可以是到链接到git仓库的url。当提供的值是相对路径时，它被解析为相对于撰写文件的路径，此目录也是发送到Docker守护进程的context build: context:./dir dockerfile使用此dockerfile文件来构建，必须使用context指定构建路径 build: context:. # 知道dockerfile必须要有构建路径,.表示当前路径 dockerfile:Dockerfile-alternate image指定docker-compose启动容器服务的镜像，可以是存储仓库、标签以及镜像ID，如果镜像不存在，Compose会自动拉去镜像 image: redis image: ubuntu:14.04 image: tutum/influxdb image: example-registry.com:4000/postgresql image: a4bc65fd command覆盖容器启动后默认执行的命令 command:bundle exec thin -p 3000 command:[\"bundle\",\"exec\",\"thin\",\"-p\",\"3000\"] container_name指定容器名称，由于容器名称是唯一的，如果指定自定义名称，则无法使用scale container_name:my-web-container environment添加环境变量，可以使用数组或字典。这个标签的作用是设置镜像变量，它可以保存变量到镜像里面，类似ENV指令一样会把变量一直保存在镜像、容器中 environment: RACK_ENV:development SHOW:'true' SESSION_SECRET: environment: -RACK_ENV=development -SHOW=true -SESSION_SECRET networks加入指定网络 networks: - lnmp ports映射端口 ports: -\"3000\" -\"3000-3005\" -\"8000:8000\" -\"9090-9091:8080-8081\" -\"49100:22\" -\"127.0.0.1:8001:8001\" -\"127.0.0.1:5000-5010:5000-5010\" # 指定IP+端口的话只会监听ipv4的地址 -\"6060:6060/udp\" expose暴露端口，但不映射到宿主机，只被连接的服务访问。这个标签与Dockerfile中的EXPOSE指令一样，用于指定暴露的端口，实际上docker-compose.yml的端口映射还得ports这样的标签 extra_hosts添加主机名的标签，就是往/etc/hosts文件中添加一些记录，与Docker客户端中的–add-host类似 extra_hosts: -\"www.missf.top:124.156.205.241\" -\"mf_missf.gitee.io:212.64.62.174\" volumes挂载一个目录或者一个已存在的数据卷容器 volumes: - /opt/data:/var/lib/mysql # 挂载宿主机的/opt/data目录到容器的/var/lib/mysql - datavolume:/var/lib/mysq # 将容器的/var/lib/mysq挂载到datavolume数据卷 restart默认值为 no ，即在任何情况下都不会重新启动容器。当值为 always 时，容器总是重新启动。当值为on-failure时，当出现on-failure报错容器退出时，容器重新启动。 restart: \"no\" restart: always restart: on-failure restart: unless-stopped hostname定义容器主机名 hostname: foo Compose 常用选项与命令up该命令十分强大，它将尝试自动完成包括构建镜像，创建服务，启动服务，并关联服务相关容器的一系列操作 up选项如下: -d: 在后台运行服务容器 –force-recreate: 强制重新创建容器，不能与–no-recreate同时使用 –no-recreate: 如果容器已经存在了，则不重新创建，不能与–force-recreate同时使用 -no-build: 不自动构建缺失的服务镜像 –no-deps: 不启动服务所链接的容器 build可以随时在项目目录下运行docker-compose build来重新构建服务 build选项如下: –force-rm: 删除构建过程中的临时容器 –no-cache: 构建镜像过程中不使用cache(这将加长构建过程) –pull: 始终尝试通过pull来获取更新版本的镜像 ps列出项目中目前的所有容器 ps选项如下: -q: 只打印容器的ID信息 logs查看服务容器的输出，默认情况下，docker-compose将对不同的服务输出使用不同的颜色来区分 docker-compose logs [选项] rm删除所有(停止状态的)服务容器，推荐先执行docker-compose stop命令来停止容器 rm选项如下: -f/–force: 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项 -v: 删除容器所挂载的数据卷 scale设置指定服务运行的容器个数 docker-compose scale web=3 db=2 down删除容器、网络 start/stop/restart启动/停止/重启服务 docker-compose编排lnmp容器docker-compose目录设计tree /docker-compose_lnmp/ /docker-compose_lnmp/ ├── docker-compose.yaml ├── mysql │ └── start ├── nginx │ ├── Dockerfile │ ├── nginx-1.16.1.tar.gz │ ├── nginx.conf │ ├── php.conf │ └── start └── php ├── Dockerfile ├── php-7.4.0.tar.gz ├── php-fpm.conf ├── php.ini ├── start └── www.conf docker-compose.yamlversion: '3' services: php: hostname: php build: context: ./php dockerfile: Dockerfile networks: - \"lnmp\" volumes: - \"nginx:/usr/local/nginx/html\" nginx: hostname: nginx build: context: ./nginx dockerfile: Dockerfile ports: - \"80:80\" - \"443:443\" networks: - \"lnmp\" volumes: - \"nginx:/usr/local/nginx/html/\" mysql: hostname: mysql image: mysql:5.7 ports: - \"53306:3306\" networks: - \"lnmp\" volumes: - \"mysql:/var/lib/mysql/\" command: --character-set-server=utf8mb4 environment: MYSQL_ROOT_PASSWORD: mwj123456 MYSQL_DATABASE: wordpress networks: lnmp: {} volumes: nginx: {} # 把php代码放到这个数据卷的目录下 mysql: {} docker-compose编排nginx反向代理tomcat集群docker-compose目录设计tree /docker-compose_lnmt/ /docker-compose_lnmt/ ├── docker-compose.yaml ├── nginx │ ├── Dockerfile │ ├── nginx-1.16.1.tar.gz │ ├── nginx.conf │ ├── start │ └── tomcat.conf └── tomcat ├── apache-tomcat-8.5.57.tar.gz ├── Dockerfile ├── jdk-8u211-linux-x64.tar.gz └── start docker-compose.yamlcat docker-compose.yaml version: '3' services: nginx: hostname: nginx build: context: ./nginx dockerfile: Dockerfile ports: - \"80:80\" - \"443:443\" networks: - \"lnmt\" volumes: - \"webapps:/usr/local/tomcat/webapps/\" tomcat1: hostname: tomcat1 build: context: ./tomcat dockerfile: Dockerfile networks: - \"lnmt\" volumes: - \"webapps:/usr/local/tomcat/webapps/\" tomcat2: hostname: tomcat2 build: context: ./tomcat dockerfile: Dockerfile networks: - \"lnmt\" volumes: - \"webapps:/usr/local/tomcat/webapps/\" tomcat3: hostname: tomcat3 build: context: ./tomcat dockerfile: Dockerfile networks: - \"lnmt\" volumes: - \"webapps:/usr/local/tomcat/webapps/\" mysql: hostname: mysql image: mysql:5.7 ports: - \"53306:3306\" networks: - \"lnmt\" volumes: - \"mysql:/var/lib/mysql/\" command: --character-set-server=utf8mb4 environment: MYSQL_ROOT_PASSWORD: mwj123456 MYSQL_DATABASE: test volumes: webapps: {} # 把war包放到这个数据卷的目录下,就会自动解压 mysql: {} networks: lnmt: {} 监听Nginx容器访问日志tail -f /usr/local/nginx/logs/access.log # 点击浏览器刷新页面,可以看到upstream_addr的IP变化,这样就实现了反向代理Tomcat集群 {\"@timestamp\": \"2020-07-14T08:03:19+08:00\", \"clientRealIp\": \"10.10.110.1\", \"scheme\": \"http\", \"method\": \"GET\", \"host\": \"10.10.110.150\", \"url\": \"/\", \"size\": 1056, \"referrer\": \"-\", \"agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36\", \"upstream_addr\": \"192.168.16.3:8080\", \"request_time\": 0.323, \"request_length\": 450, \"upstream_connect_time\": \"0.003\", \"upstream_response_time\": \"0.324\", \"upstream_status\": \"200\", \"status\": \"200\"} {\"@timestamp\": \"2020-07-14T08:03:28+08:00\", \"clientRealIp\": \"10.10.110.1\", \"scheme\": \"http\", \"method\": \"GET\", \"host\": \"10.10.110.150\", \"url\": \"/\", \"size\": 1056, \"referrer\": \"-\", \"agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36\", \"upstream_addr\": \"192.168.16.6:8080\", \"request_time\": 0.345, \"request_length\": 450, \"upstream_connect_time\": \"0.000\", \"upstream_response_time\": \"0.345\", \"upstream_status\": \"200\", \"status\": \"200\"} {\"@timestamp\": \"2020-07-14T08:03:29+08:00\", \"clientRealIp\": \"10.10.110.1\", \"scheme\": \"http\", \"method\": \"GET\", \"host\": \"10.10.110.150\", \"url\": \"/\", \"size\": 1056, \"referrer\": \"-\", \"agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36\", \"upstream_addr\": \"192.168.16.4:8080\", \"request_time\": 0.355, \"request_length\": 450, \"upstream_connect_time\": \"0.000\", \"upstream_response_time\": \"0.354\", \"upstream_status\": \"200\", \"status\": \"200\"}","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker图形化页面管理(8)","slug":"Docker图形化页面管理(8)","date":"2020-07-10T02:03:55.000Z","updated":"2020-08-28T03:17:36.719Z","comments":true,"path":"post/92368be2.html","link":"","permalink":"https://www.missf.top/post/92368be2.html","excerpt":"","text":"Docker图形化页面管理Portainer概述Portainer是Docker的图形化管理工具，portainer通过连接/var/run/docker.sock文件去管理容器，可让你轻松管理不同的Docker环境(Docker主机或Swarm群集)。Portainer提供状态显示面板、应用模板快速部署、容器镜像网络数据卷、事件日志显示、容器控制台操作、登录用户管理和控制等功能。Docker图形化管理界面有很多实现的工具，但生态一直不温不火，这是由于Docker的很多操作都是直接在命令行进行，再加上Docker的操作也比较简单。一般这样的图形化管理平台都是交给开发和测试人员去使用的 Portainer安装docker run -d -p 8000:8000 -p 9000:9000 --name \"portainer\" --restart=always \\ -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer # 这里portainer通过连接/var/run/docker.sock文件去管理容器,所以需要把宿主机的docker.sock文件挂载到portainer 登录Portainer页面 Portainer连接容器的方式Local:管理Portainer所在主机上的Docker主机，需要将宿主机的docker.sock文件挂载到Portainer容器内 Remote:管理远程主机上的Docker主机，但是要开启远程的Docker主机的Docker API，允许Portainer通过TCP连接 Agent:直接连接到在Swarm集群中运行的Portainer代理 Azure:连接到Microsoft Azure 这里我们先使用Local的方式连接到Portainer所在的主机 Portainer管理界面通过下图可以看到Portainer提供了对容器、镜像、网络、数据卷、变量、主机的操作，App templates是一些供我们下载的公共镜像，我们还可以看到正在运行的容器状态、日志、基于镜像、创建时间、映射端口等 Portainer连接远程Docker主机首先需要在远程Docker主机上开启Docker API vim /usr/lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 # 表示所有地址都能连接到Docker API,也可以指定IP连接,默认端口是2375 systemctl daemon-reload systemctl restart docker.service 然后在Portainer再创建一个连接远程Docker主机API的节点 这时候我们可以使用Portainer去管理本地和远程主机上的Docker资源了","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker企业级镜像仓库Harbor(7)","slug":"Docker企业级镜像仓库Harbor(7)","date":"2020-07-08T05:33:50.000Z","updated":"2020-08-28T03:17:23.392Z","comments":true,"path":"post/d46af348.html","link":"","permalink":"https://www.missf.top/post/d46af348.html","excerpt":"","text":"Harbor 概述Harbor是由VMWare公司开源的容器镜像仓库。事实上，Harbor是在Docker Registry上进行了相应的企业级扩展，从而获得了更加广泛的应用，这些新的企业级特性包括：管理用户界面，基于角色的访问控制 ，AD/LDAP集成以及审计日志等，足以满足基本企业需求 Harbor 官网 Harbor GitHub 地址 Harbor 部署条件服务器硬件配置最低要求:CPU2核/内存4G/硬盘40GB 推荐:CPU4核/内存8G/硬盘160GB 软件Docker 17.06版本+ Docker Compose 1.18版本+ 安装方式在线安装:从Docker Hub下载Harbor相关镜像，因此安装软件包非常小 离线安装:安装包包含部署的相关镜像，因此安装包比较大 docker-compose安装下载二进制文件https://github.com/docker/compose/releases # docker-compose下载地址 # 下载docker-compose-Linux-x86_64这个二进制文件 配置二进制文件mv docker-compose-Linux-x86_64 /usr/bin/docker-compose chmod +x /usr/bin/docker-compose docker-compose --help # 安装完成 Harbor HTTP部署下载Harbor安装包wget https://github.com/goharbor/harbor/releases/download/v2.0.1/harbor-offline-installer-v2.0.1.tgz 解压安装包tar xf harbor-offline-installer-v2.0.1.tgz 修改配置文件cp harbor.yml.tmpl harbor.yml vim harbor.yml hostname: reg.missf.com # 修改Harbor默认域名 https: # 先注释https相关配置 harbor_admin_password: MF-yihan # 修改Harbor的密码 部署Harbor./prepare # 做一系列的准备工作 ./install.sh # 利用docker-compose拉取一系列的镜像,安装好之后就会直接启动 访问Harbor# 通过本地电脑配置hosts,然后在浏览器访问我们的域名reg.missf.com {% image https://pic.imgdb.cn/item/5f05980114195aa5940c513f.jpg '' '' %} 登录Harborvim /etc/hosts # 添加解析,登录时可以直接访问域名 10.10.110.151 reg.missf.com vim /etc/docker/daemon.json # 配置域名可信任,因为现在没有配置https,而docker默认是使用https协议去连接的,不配置不能登录成功 { \"registry-mirrors\": [\"https://265wemgl.mirror.aliyuncs.com\"], \"insecure registries\": [\"reg.missf.com\"] } systemctl restart docker.service # 修改了daemon.json需要重启docker docker-compose down &amp;&amp; docker-compose up -d # 重启docker之后容器有些会退出,重启harbor重启把容器拉起来 docker login reg.missf.com # 登录成功 Username: admin Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded 推送镜像到Harbor仓库docker tag nginx:1.0 reg.missf.com/library/nginx:1.0 # 推送之前修改镜像的标签(镜像中心/项目/镜像:标签) docker push reg.missf.com/library/nginx:1.0 # 推送镜像，pull拉取镜像也是使用这个标签去拉取 The push refers to repository [reg.missf.com/library/nginx] b1b653ec37ba: Pushed fe503a975c26: Pushed 60165efe909a: Pushed e098d2f9f0dd: Pushed ae9b67129281: Pushed d2039520c249: Pushed 034f282942cd: Pushed 1.0: digest: sha256:a4c155ecb6b7eee5d332764057c29a74d8965de19f9d739f1792cf479c2bf030 size: 1786 查看Harbor上推送成功的镜像 Harbor HTTPS部署由于Harbor不附带任何证书，它默认使用HTTP来提供注册表请求。但是强烈建议为生产环境配置ssl证书。这里我们由于是实验测试，使用自签名证书，到时候生产环境配置可以去阿里云购买ssl证书。 生成自签名ssl证书由于kubernetes使用cfssl自签证书,这里我们也使用cfssl生成自签证书 # 执行这个脚本,安装cfssl并将命令放到/usr/bin/下供我们直接使用 cat cfssl.sh wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 chmod +x cfssl* mv cfssl_linux-amd64 /usr/bin/cfssl mv cfssljson_linux-amd64 /usr/bin/cfssljson mv cfssl-certinfo_linux-amd64 /usr/bin/cfssl-certinfo # 执行这个脚本,生成两个json的ca配置文件并自动生成证书,cfssl是根据json的配置文件去生成ca证书的 cat certs.sh cat > ca-config.json &lt;&lt;EOF { \"signing\": { \"default\": { \"expiry\": \"87600h\" }, \"profiles\": { \"kubernetes\": { \"expiry\": \"87600h\", \"usages\": [ \"signing\", \"key encipherment\", \"server auth\", \"client auth\" ] } } } } EOF cat > ca-csr.json &lt;&lt;EOF { \"CN\": \"kubernetes\", \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"Beijing\", \"ST\": \"Beijing\" } ] } EOF cfssl gencert -initca ca-csr.json | cfssljson -bare ca - # 初始化ca配置文件 cat > reg.missf.com-csr.json &lt;&lt;EOF { \"CN\": \"reg.missf.com\", \"hosts\": [], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"BeiJing\", \"ST\": \"BeiJing\" } ] } EOF cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes reg.missf.com-csr.json | cfssljson -bare reg.missf.com # 生成ca证书 # 执行完上面两个脚本之后我们会得到下面这两个文件 reg.missf.com-key.pem reg.missf.com.pem Harbor启用HTTPShttps: # https port for harbor, default is 443 port: 443 # The path of cert and key files for nginx certificate: /root/ssh/reg.missf.com.pem private_key: /root/ssh/reg.missf.com-key.pem 重新配置并部署Harborsystemctl restart docker.service ./prepare docker-compose down docker-compose up –d # 重新打开Harbor页面会自动跳转到https,但是由于是自签证书,所以仍会显示不安全 其他Docker主机连接Harbor仓库一般Harbor仓库都是自己公司内部使用,但是有时候也会开放给别的Docker主机去pull镜像，如果其他的Docker主机需要连接Harbor，必须要有证书才能连接 # 复制Harbor主机的证书到需要连接Harbor仓库的Docker主机上 mkdir -p /etc/docker/certs.d/reg.missf.com/ # 在Docker主机上创建目录 cp reg.missf.com.pem /etc/docker/certs.d/reg.missf.com/reg.missf.com.crt # 将Harbor主机的证书复制到Docker主机 echo \"10.10.110.151 reg.missf.com\" >> /etc/hosts # 这里由于是实验环境,需要配置域名解析 docker login reg.missf.com # 在其他的docker主机登录到Harbor,就可以pull拉取Harbor仓库的镜像了 Username: admin Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded Harbor主从复制Harbor主从复制的三种方式学习过MySQL主从的同学可以看出，其实Harbor的主从复制和MySQL的主从复制方式非常相似 主节点的仓库管理新建目标新建一个目标，就代表本地Harbor可以连接到这个远程Harbor，当我们配置复制管理的目的Registry时，可以从新建目标里面填写复制镜像到那个Harbor节点 主节点的复制管理新建规则配置复制模式和目的Registry，将本地Harbor主节点上的镜像(可以使用过滤器进行选择性推送)推送到备用Harbor节点上 推送验证这时候只有有镜像被推送到Harbor的主节点，那么Harbor主节点就会把镜像push到Harbor的备用节点，可以查看复制记录 Harbor运行维护Harbor容器功能介绍 容器 功能 harbor-core 配置管理中心 harbor-jobservice 负责镜像复制 harbor-log 记录操作日志 harbor-portal Web管理页面和API harbor-db PG数据库 registryctl 镜像存储 nginx 前端代理，负责前端页面和镜像上传/下载转发 redis 会话 Harbor容器数据持久化目录:/data(这个目录需要定时备份) 日志文件目录:/var/log/harbor","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Dockerfile定制容器镜像(6)","slug":"Dockerfile定制容器镜像(6)","date":"2020-06-30T05:33:50.000Z","updated":"2020-08-28T03:16:37.711Z","comments":true,"path":"post/44241b5a.html","link":"","permalink":"https://www.missf.top/post/44241b5a.html","excerpt":"","text":"Dockerfile 介绍Dockerfile是由一行一行的命令语句组成，并且从上到下执行，支持以#注释行。一般Dockerfile的内容分为四个部分，基础镜像信息、维护者信息、镜像操作指令、容器启动时执行指令 Dockerfile 常用指令 指令 描述 FROM 指定构建新镜像时是基于那个镜像，Dockerfile的第一条指令必须为FROM指令，如果在同一个Dockerfile中创建多个镜像可以使用多个FROM指令 LABEL 为镜像添加标签 RUN 每条RUN指令将在当前镜像的基础上执行指定shell命令，并提交为新的镜像 COPY 拷贝宿主机(Dockerfile所在目录的相对路径)的文件或目录到镜像中 ADD 复制指定的&lt;src&gt;到容器中的&lt;dest&gt;，&lt;src&gt;可以是Dockerfile所在目录的文件或目录，可以是一个URL，还可以是一个tar文件(自动解压缩) ENV 指定一个环境变量，会被后续RUN指令使用，并在容器运行时保持 USER 指定运行容器时的用户名或UID，后续的RUN也会使用指定用户 EXPOSE 声明容器运行的服务端口，启动容器时可以将这些端口转发到宿主机或者指定宿主机那个端口映射过来 WORKDIR 为后续的RUN、CMD、ENTRYPOINT指令配置工作目录 VOLUME 在镜像中创建挂载点，这样只要通过该镜像创建的容器都有了挂载点，查看容器详细信息可以看到容器挂载点映射到宿主机的目录 CMD 容器启动时执行指令，每个Dockerfile只能有一条CMD指令，如果有多个CMD指令只有最后一个生效 ENTRYPOINT ENTRYPOINT如果与CMD一起使用，CMD将作为ENTRYPOINT的默认参数，如果有多个ENTRYPOINT指令只有最后一个生效 构建镜像Dockerfile demo# This dockerfile demo for project build to docker images FROM centos:7 LABEL maintainer www.missf.top USER root RUN yum install -y nginx EXPOSE 80 443 VOLUME [\"/usr/local/nginx/\"] CMD [\"/usr/local/nginx/bin\"] Docker build构建镜像# 在Dockerfile所在的目录下构建镜像,后面的\".\"表示当前目录 docker build -t demo:1.0 . # 构建过程如下 Sending build context to Docker daemon 2.048kB Step 1/8 : FROM centos:7 7: Pulling from library/centos 524b0c1e57f8: Pull complete Digest: sha256:e9ce0b76f29f942502facd849f3e468232492b259b9d9f076f71b392293f1582 Status: Downloaded newer image for centos:7 ---> b5b4d78bc90c Step 2/8 : LABEL maintainer mownejie ---> Running in 7dbcab7ef3ce Removing intermediate container 7dbcab7ef3ce ---> 4db1e9da6977 Step 3/8 : ENV JAVA_HOME /usr/local/java ---> Running in b896cedee458 Removing intermediate container b896cedee458 ---> f8991838d97e Step 4/8 : USER root ---> Running in 8252457198f0 Removing intermediate container 8252457198f0 ---> 96ef213928ad Step 5/8 : RUN yum install -y nginx ---> Running in 8807973810c5...... # -t 指定这个镜像的tag # -f 指定这个Dockerfile文件的位置 CMD 与 ENTRYPOINT 区别CMD用法# exec形式,首选形式,传参不支持引用变量 CMD [\"executable\", \"param1\", \"param2\"] # CMD作为ENTRYPOINT的默认参数 CMD [\"param1\", \"param2\"] # Shell形式 CMD command param1 param2 ENTRYPOINT用法ENTRYPOINT [\"executable\", \"param1\", \"param2\"] # 假如配合CMD一起使用,那么[\"param1\", \"param2\"]可以写在CMD作为ENTRYPOINT的默认参数 ENTRYPOINT command param1 param2 总结1. CMD和ENTRYPOINT指令都可以用来定义运行容器时所使用的命令 2. Dockerfile至少指定一个CMD或ENTRYPOINT 3. CMD可以用作ENTRYPOINT默认参数，或者用作容器的默认命令 4. docker run启动容器时指定&lt;command>，将会覆盖dockerfile定义的CMD 构建Nginx容器镜像dockerfile内容FROM centos:7.7.1908 LABEL maintainer www.missf.top RUN yum install -y gcc gcc-c++ make \\ openssl-devel pcre-devel gd-devel \\ iproute net-tools telnet wget curl && \\ yum clean all && rm -rf /var/cache/yum/* ADD nginx-1.16.1.tar.gz / RUN cd nginx-1.16.1 && \\ ./configure --user=nginx --group=nginx \\ --prefix=/usr/local/nginx \\ --with-http_stub_status_module \\ --with-http_ssl_module \\ --with-http_gzip_static_module \\ --with-http_sub_module && \\ make -j4 && make install && \\ mkdir /usr/local/nginx/conf/vhost && \\ cd / && rm -rf nginx* && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime RUN useradd -s /sbin/nologin nginx ENV PATH $PATH:/usr/local/nginx/sbin ENV LANG=\"en_US.utf8\" COPY nginx.conf /usr/local/nginx/conf/nginx.conf COPY php.conf /usr/local/nginx/conf/vhost/php.conf WORKDIR /usr/local/nginx EXPOSE 80 443 CMD [\"nginx\", \"-g\", \"daemon off;\"] 目录结构[root@localhost /Dockerfile/nginx]# ll total 1028 -rw-r--r-- 1 root root 890 Jul 6 18:58 Dockerfile -rw-r--r-- 1 root root 1032630 Jan 14 09:53 nginx-1.16.1.tar.gz -rw-r--r-- 1 root root 3297 Jul 6 18:46 nginx.conf -rw-r--r-- 1 root root 362 Jul 6 20:13 php.conf -rw-r--r-- 1 root root 128 Jul 6 18:51 start 构建PHP容器镜像dockerfile内容FROM centos:7.7.1908 LABEL maintainer www.missf.top RUN yum install -y epel-release && \\ yum install -y sqlite-devel libmcrypt-devel mhash-devel libxslt-devel \\ libjpeg-devel libpng libpng-devel freetype freetype-devel \\ libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel libjpeg \\ glib2 glib2-develbzip2 bzip2-devel ncurses ncurses-devel \\ curl-devel e2fsprogs e2fsprogs-devel krb5 gcc krb5-devel libidn \\ openssl-devel libsqlite3x-devel oniguruma-devel openssl libidn-devel \\ iproute net-tools telnet wget curl && \\ yum clean all && rm -rf /var/cache/yum/* ADD php-7.4.0.tar.gz / RUN cd /php-7.4.0 && \\ ./configure --prefix=/usr/local/php \\ --with-config-file-path=/usr/local/php/etc \\ --enable-opcache --with-curl --enable-fpm \\ --enable-gd --with-iconv --enable-mbstring \\ --with-mysqli --with-openssl --enable-static \\ --enable-sockets --enable-inline-optimization \\ --with-zlib --disable-ipv6 --disable-fileinfo \\ --with-mcrypt --enable-hash --with-jpeg-dir --with-png-dir \\ --with-freetype-dir --with-pdo-mysql --disable-debug && \\ make -j 4 && make install && \\ cp /php-7.4.0/php.ini-production /usr/local/php/etc/php.ini && \\ cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf && \\ cp /usr/local/php/etc/php-fpm.d/www.conf.default /usr/local/php/etc/php-fpm.d/www.conf && \\ sed -i \"90a \\daemonize = no\" /usr/local/php/etc/php-fpm.conf && \\ mkdir /usr/local/php/log && \\ cd / && rm -rf php* && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime ENV PATH $PATH:/usr/local/php/sbin ENV LANG=\"en_US.utf8\" COPY php.ini /usr/local/php/etc/ COPY php-fpm.conf /usr/local/php/etc/ COPY www.conf /usr/local/php/etc/php-fpm.d/ WORKDIR /usr/local/php EXPOSE 9000 CMD [\"php-fpm\"] 目录结构[root@localhost /Dockerfile/php]# ll total 16144 -rw-r--r-- 1 root root 1758 Jul 6 18:53 Dockerfile -rw-r--r-- 1 root root 16418792 Jul 1 10:39 php-7.4.0.tar.gz -rw-r--r-- 1 root root 5394 Jul 1 21:51 php-fpm.conf -rw-r--r-- 1 root root 72953 Jul 1 22:09 php.ini -rw-r--r-- 1 root root 93 Jul 6 18:56 start -rw-r--r-- 1 root root 19616 Jul 6 18:53 www.conf 容器化搭建个人博客自定义网络docker network create lnmp # 将多个容器加入到一个自定义网络 创建MySQL容器docker volume create mysql docker run -e MYSQL_ROOT_PASSWORD=mwj123456 -e MYSQL_DATABASE=wordpress -p 53306:3306 --name \"mysql\" --network lnmp --mount src=mysql,dst=/var/lib/mysql/ -d mysql:5.7 # 将MySQL数据库的数据持久化到mysql这个数据卷 创建PHP容器docker volume create nginx docker run --name php --network lnmp --mount src=nginx,dst=/usr/local/nginx/html/ -d php:1.0 # 这里先启动PHP容器再启动Nginx容器,因为Nginx要去连接PHP容器,如果PHP容器没有启动,那Nginx就因为无法连接到PHP所有退出了 # 这里需要把Nginx代码也挂载到PHP容器内,而且容器内的路径要与Nginx配置文件路径一致 # 因为Nginx配置文件将所有*.php的请求都通过fastcgi_pass代理到PHP容器去处理,所有需要把代码也挂载到PHP容器内,不然访问php文件会提示未找到文件 创建Nginx容器docker container run --name \"nginx\" --mount src=nginx,dst=/usr/local/nginx/html --network lnmp -p 80:80 -p 443:443 -d nginx:1.0 部署WordPress代码docker volume inspect nginx # 先查看数据卷在宿主机上的目录,然后把代码解压到对应的目录下 tar xf wordpress-5.4.2-zh_CN.tar.gz -C /var/lib/docker/volumes/nginx/_data/ # 这时候通过访问宿主机的IP就能看到WordPress的安装页面了,如果无法对wp-config.php文件写入,就手动创建并写入 构建Tomcat容器镜像dockerfile内容FROM centos:7.7.1908 LABEL maintainer www.missf.top ADD jdk-8u211-linux-x64.tar.gz /usr/local/ ADD apache-tomcat-8.5.57.tar.gz /usr/local/ RUN mv /usr/local/jdk1.8.0_211 /usr/local/jdk && \\ mv /usr/local/apache-tomcat-8.5.57 /usr/local/tomcat && \\ rm -rf /usr/local/tomcat/webapps/* ENV JAVA_HOME /usr/local/jdk ENV CLASSPATH ${JAVA_HOME}/lib/dt.jar:${JAVA_HOME}/lib/tools.jar ENV CATALINA_HOME /usr/local/tomcat ENV PATH $PATH:${JAVA_HOME}/bin:${CATALINA_HOME}/lib:${CATALINA_HOME}/bin RUN sed -i '1a JAVA_OPTS=\"-Djava.security.egd=file:/dev/./urandom\"' ${CATALINA_HOME}/bin/catalina.sh && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime WORKDIR ${CATALINA_HOME} EXPOSE 8080 CMD [\"catalina.sh\", \"run\"] 目录结构[root@localhost /Dockerfile/tomcat]# ll total 200568 -rw-r--r-- 1 root root 10379806 Jul 7 11:19 apache-tomcat-8.5.57.tar.gz -rw-r--r-- 1 root root 728 Jul 7 19:41 Dockerfile -rw-r--r-- 1 root root 194990602 Jul 2 2019 jdk-8u211-linux-x64.tar.gz 部署测试代码docker volume inspect tomcat # 查看Tomcat容器代码目录持久化到宿主机的目录 ll /var/lib/docker/volumes/tomcat/_data # 放到这个目录的war包会被自动解压 total 17840 drwxr-x--- 4 root root 37 Jul 7 21:34 ROOT -rw-r--r-- 1 root root 18265402 Jun 20 13:08 ROOT.war 构建java微服务项目镜像dockerfile内容# 一个容器内只跑一个jar包 FROM java:8-jdk-alpine LABEL maintainer www.missf.top ENV JAVA_OPTS=\"$JAVA_OPTS -Dfile.encoding=UTF8 -Duser.timezone=GMT+08 -Xms128m -Xmx128m\" RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories && \\ apk add -U tzdata && \\ mkdir /projects && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime COPY hello.jar /projects/ EXPOSE 8888 CMD [\"/bin/sh\", \"-c\", \"java -jar $JAVA_OPTS /projects/hello.jar\"] Dockerfile 最佳实践减少镜像层一次RUN指令形成新的一层镜像，shell命令尽量写在一行，减少镜像层 优化镜像大小在形成新的一层镜像之后，如果没有在同一层删除缓存或者没用的文件，那么这些文件都会被带到下一层，所有要在每一层清理对应的残留数据，减少镜像大小 减少网络传输例如镜像所需要下载的软件包，mvn仓库 多阶段构建代码编译、部署在一个Dockerfile完成，只会保留部署阶段产生的数据 选择最小的基础镜像例如alpine","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker容器网络(5)","slug":"Docker容器网络(5)","date":"2020-06-23T01:49:44.000Z","updated":"2020-08-28T03:15:54.026Z","comments":true,"path":"post/bc1d2f66.html","link":"","permalink":"https://www.missf.top/post/bc1d2f66.html","excerpt":"","text":"容器的四种网络模式bridge 模式当启动docker进程之后，docker会默认创建一个名为docker0的虚拟网桥，创建容器时如果不指定网络，默认就是添加到这个网桥中。这样docker主机上的所有容器都可以通过交换机的方式连接在一个二层网络中。创建容器时，docker会先创建容器的虚拟网卡，容器的虚拟网卡去连接docker主机的docker0虚拟网桥，相当于用一根网线将容器和docker主机连接起来。虚拟网卡连接到docker0子网后，由docker0虚拟网桥分配IP给容器的虚拟网卡使用，并设置docker0虚拟网桥的IP地址为容器的默认网关。除了docker启动时默认创建的bridge默认网络，我们还可以自定义bridge网络。相比默认的具备内部DNS发现，bridge网络模式还可以通过容器名去实现容器之间的网络通信 查看docker宿主机上的docker0虚拟网桥，默认网段是172.17.0.1，安装docker之后默认创建的 ip a s docker0 3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default link/ether 02:42:9f:dc:ee:74 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:9fff:fedc:ee74/64 scope link valid_lft forever preferred_lft forever 查看默认定义好的网络模式,这里没有container模式是因为container是启动容器时直接指定的 docker network ls NETWORK ID NAME DRIVER SCOPE a42d2b0e12ec bridge bridge local 168bbf4b0447 host host local ec481d03e2a1 none null local 21be62f7b97e webserver bridge local 查看bridge网络模式的详细信息 docker network inspect bridge [ { \"Name\": \"bridge\", \"Id\": \"a42d2b0e12ec0e039e7c4686099468585b88c8df8b639eaa780700980adb9e1b\", \"Created\": \"2020-06-23T17:16:25.717600267+08:00\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [ { \"Subnet\": \"172.17.0.0/16\", \"Gateway\": \"172.17.0.1\" } ] }, \"Internal\": false, \"Attachable\": false, \"Ingress\": false, \"ConfigFrom\": { \"Network\": \"\" }, \"ConfigOnly\": false, \"Containers\": { \"253d0d8f196182eccaa52238068513cebfbf2abe69d2a7980e40d8c136b53960\": { \"Name\": \"nginx\", \"EndpointID\": \"7fd4576f90bc1d0fd966ed5794710dd43461d077ea32f99e54a8b3c56ba1de08\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" }, \"8652448b6f9a99d9b9a6c70277ea23924b21df57289d4deb29a146974ad4c4dd\": { \"Name\": \"centos7\", \"EndpointID\": \"e112927463f07a606a3a019f3af7400c711b9a903fec19c130b27c7d5f53d359\", \"MacAddress\": \"02:42:ac:11:00:03\", \"IPv4Address\": \"172.17.0.3/16\", \"IPv6Address\": \"\" } }, \"Options\": { \"com.docker.network.bridge.default_bridge\": \"true\", \"com.docker.network.bridge.enable_icc\": \"true\", \"com.docker.network.bridge.enable_ip_masquerade\": \"true\", \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\", \"com.docker.network.bridge.name\": \"docker0\", \"com.docker.network.driver.mtu\": \"1500\" }, \"Labels\": {} } ] 安装网桥管理工具包 yum install -y bridge-utils.x86_64 查看虚拟网桥上的接口信息 brctl show docker0 bridge name bridge id STP enabled interfaces docker0 8000.02429fdcee74 no veth81bdc19 vetha8f66a7 创建类型为bridge的自定义网桥 docker network create webserver 21be62f7b97ebfc9ce6f6a1aaaffd59a4a220c6b778f36a98c72162023b5c5e5 启动容器时指定使用自定义创建的webserver网桥(具备DNS发现) docker container run -itd --name \"app1\" --network webserver centos:7.7.1908 98efd7fb3c63c0bd487039b7ef00925d786e0499f10d76003afa2277cc93b404 docker container run -itd --name \"app2\" --network webserver centos:7.7.1908 c81e58db50ca74111d46f460ff322378b45414a36804738597559ec3c06cf542 docker container run -itd --name \"app3\" --network webserver centos:7.7.1908 41fb1a7dd161c03a158a104da54dcfa3b226035feceecabd003f7a18e91bff61 查看容器的IP地址 docker inspect --format='{{.NetworkSettings.Networks.webserver.IPAddress}}' app1 172.18.0.2 docker inspect --format='{{.NetworkSettings.Networks.webserver.IPAddress}}' app2 172.18.0.3 docker inspect --format='{{.NetworkSettings.Networks.webserver.IPAddress}}' app3 172.18.0.4 容器之间的通信测试，自定义的bridge网桥相比默认的bridge网桥具备内部DNS发现， IP和主机名都是可以PING通 ping 172.18.0.2 PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data. 64 bytes from 172.18.0.2: icmp_seq=1 ttl=64 time=0.203 ms 64 bytes from 172.18.0.2: icmp_seq=2 ttl=64 time=0.085 ms ping 98efd7fb3c63 # 如果启动容器时不指定自定义的网桥,那就会使用默认的bridge模式,这样是不能PING通主机名的 PING 98efd7fb3c63 (172.18.0.2) 56(84) bytes of data. 64 bytes from app1.webserver (172.18.0.2): icmp_seq=1 ttl=64 time=0.402 ms 64 bytes from app1.webserver (172.18.0.2): icmp_seq=2 ttl=64 time=0.100 ms host模式如果启动容器时指定host模式，那么这个容器将不会获得一个独立的Network namespace，而是和宿主机共用一个Network namespace。容器不会虚拟出自己的网卡，而是使用宿主机的IP和端口。这种无需NAT转换的网络模式无需再映射容器与宿主机之间的端口，在提高网络传输性能的同时，造成了网络环境隔离性弱化。容器之间不再拥有隔离独立的网络，docker host上已使用的端口就不能再用了 启动一个nginx容器，再查看宿主机上的80端口是否被使用 docker container run -itd --name \"host_nginx\" --network=host nginx:1.1 查看宿主机上的80端口是否被nginx容器所使用 netstat -lntup | grep 80 tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 7358/nginx: master 查看宿主机上nginx进程的父进程是否为docker ps -afx | grep containerd -A 1 1100 ? Ssl 1:18 /usr/bin/containerd 7341 ? Sl 0:00 \\_ containerd-shim -namespace moby -workdir /var/lib/containerd/io.containerd.runtime.v1.linux/moby/adf66250b1fcd95c2531f04f8504bea614dd90903f4f074e150ce6202895a023 -address /run/containerd/containerd.sock -containerd-binary /usr/bin/containerd -runtime-root /var/run/docker/runtime-runc 7358 pts/0 Ss+ 0:00 \\_ nginx: master process nginx -g daemon off; # 这个nginx进程是容器中启动的nginx进程,这也正如我们前面所说,使用host模式启动容器,容器会和宿主机共用一个Network namespace 进入容器中查看网卡信息，可以看到宿主机上的网卡也会显示，这就是共用了一个Network namespace的结果 ifconfig br-21be62f7b97e: flags=4099&lt;UP,BROADCAST,MULTICAST> mtu 1500 inet 172.18.0.1 netmask 255.255.0.0 broadcast 172.18.255.255 inet6 fe80::42:6fff:fe77:c9f0 prefixlen 64 scopeid 0x20&lt;link> ether 02:42:6f:77:c9:f0 txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 docker0: flags=4099&lt;UP,BROADCAST,MULTICAST> mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:9fff:fedc:ee74 prefixlen 64 scopeid 0x20&lt;link> ether 02:42:9f:dc:ee:74 txqueuelen 0 (Ethernet) RX packets 3 bytes 114 (114.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 8 bytes 677 (677.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ens32: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 10.10.110.150 netmask 255.255.255.0 broadcast 10.10.110.255 inet6 fe80::20c:29ff:fec4:cbac prefixlen 64 scopeid 0x20&lt;link> ether 00:0c:29:c4:cb:ac txqueuelen 1000 (Ethernet) RX packets 91694 bytes 118390130 (112.9 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 41857 bytes 2875558 (2.7 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73&lt;UP,LOOPBACK,RUNNING> mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host> loop txqueuelen 1000 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 none模式容器启动时指定none模式是获取独立的Network namespace，但不为容器进行任何网络配置。容器内部只有loopback网络设备不会再有其他的网络资源，将网络创建的责任完全交给用户。作为 Docker 开发者，才能在这基础做其他无限多可能的网络定制开发，这种方式可以实现更加灵活复杂的网络，同时也体现了Docker设计理念的开放 启动一个none模式的容器 docker container run -itd --name \"none_centos\" --network=none centos:7.7.1908 进入容器查看网卡设备信息 docker container exec -it none_centos /bin/bash ifconfig # 这里只有一个回环口地址,因为none模式不会对容器进行任何网络配置 lo: flags=73&lt;UP,LOOPBACK,RUNNING> mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host> loop txqueuelen 1000 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 container模式创建新的容器时指定和已存在的容器共享一个Network namespace，这些容器之间共享IP、端口范围等网络配置，容器之间传输效率高。两个容器除了网络资源共享之外，其他资源还是隔离的。虽然多个容器共享网络环境，但是多个容器形成的整体依然与宿主机以及其他容器形成网络隔离 启动一个名为server1的容器 docker container run -itd --name \"server1\" centos:7.7.1908 再启动两个容器，把它们加入到server1这个容器的Network namespace docker container run -itd --name \"server2\" --network=container:server1 centos:7.7.1908 docker container run -itd --name \"server3\" --network=container:server1 centos:7.7.1908 查看各个容器的IP地址 docker inspect --format='{{.NetworkSettings.Networks.bridge.IPAddress}}' server1 172.17.0.3 docker inspect --format='{{.NetworkSettings.Networks.bridge.IPAddress}}' server2 &lt;no value> docker inspect --format='{{.NetworkSettings.Networks.bridge.IPAddress}}' server3 &lt;no value> 这里我们在查看server2和server3容器IP时，显示为&lt;no value&gt;，其实它们是和server1共用一个Network namespace的 docker container exec -it server2 /bin/bash [root@41436b0be6f7 /]# ifconfig eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 172.17.0.3 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:03 txqueuelen 0 (Ethernet) RX packets 10969 bytes 20985758 (20.0 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 6234 bytes 344851 (336.7 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 docker container exec -it server3 /bin/bash [root@41436b0be6f7 /]# ifconfig eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 172.17.0.3 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:03 txqueuelen 0 (Ethernet) RX packets 10969 bytes 20985758 (20.0 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 6234 bytes 344851 (336.7 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 # 两个容器的IP、主机名都相同 容器虚拟网卡和docker0网桥的veth pair配对veth是成对出现的虚拟网络设备， 发送到veth一端虚拟设备的请求会从另一端的虚拟设备中发出。创建一个容器的同时会为这个容器创建一对虚拟网卡veth pair，这个成对出现的虚拟网卡veth pair，分别放到宿主机和容器中，宿主机一端桥接到默认的docker0或者自定义的网桥上，容器一端放到新创建容器的Network namespace中，并把名字修改为eth0。虚拟网卡veth pair就像是一根网线，将宿主机的docker0和容器连接起来 docker container run -itd --name \"server1\" centos:7.7.1908 # 创建容器 brctl show docker0 # 查看宿主机上的docker0网桥 bridge name bridge id STP enabled interfaces docker0 8000.02429fdcee74 no veth7459cf7 ip a s veth7459cf7 # 这是虚拟网卡veth pair在宿主机上的一端 34: veth7459cf7@if33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 86:54:3c:c6:70:6b brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::8454:3cff:fec6:706b/64 scope link valid_lft forever preferred_lft forever [root@ec94bfbd724f /]# ifconfig # 容器内部的eth0网卡是虚拟网卡veth pair在容器中的一端 eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 172.17.0.2 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:02 txqueuelen 0 (Ethernet) RX packets 5495 bytes 10346440 (9.8 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 3386 bytes 186731 (182.3 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 容器网络访问原理图 容器网络实现的核心技术: iptablesdocker容器的跨网络隔离与通信，是使用iptables去实现的 源IP地址变换规则docker在安装完成后，将默认在宿主机上增加一些iptables规则，以用于docker容器和容器之间的隔离与通信，可以使用使用iptables-save命令查看 iptables-save | grep docker -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE 参数说明: -s:源地址172.17.0.0/16 -o:指定数据报文流出接口为docker0 -j:动作为MASQUERADE(地址伪装) 上面这条规则关系着docker容器和外界的通信，含义是源地址为172.17.0.0/16的数据包(即docker容器发出的数据)，当不是从docker0网卡发出时做SNAT(源地址转换)。这样使得docker容器访问外网的流量，在外界看来就是从宿主机上发出的，外界感觉不到docker容器的存在 目标IP地址变换规则从docker容器访问外网的流量，在外部看来就是从宿主机上发出的，外部感觉不到docker容器的存在。其实这也是由相应的iptables规则去实现的 docker container run -itd --name \"nginx\" -p 80:80 nginx:1.17 查看创建容器之后生成的iptables规则 iptables-save | grep docker -A DOCKER ! -i docker0 -p tcp -m tcp --dport 80 -j DNAT --to-destination 172.17.0.2:80 -A DOCKER -d 172.17.0.2/32 ! -i docker0 -o docker0 -p tcp -m tcp --dport 80 -j ACCEPT 这两条规则将访问宿主机的80端口的流量转发到了172.17.0.2的80端口上(即真正提供服务的docker容器的IP+端口)，所以外界访问docker容器是通过iptables做DNAT(目的地址转换)实现的 etcd 和 flannel 实现 docker 跨主机通信flannel是一种基于overlay网络的跨主机容器网络解决方案，也就是将TCP数据包封装在另一种网络包里面进行路由转发和通信，flannel是CoreOS团队针对Kubernetes设计的一个网络规划服务，让集群中的不同节点主机创建的容器都具有全集群唯一的虚拟ip地址，flannel使用go语言编写 实现原理flannel为每个host分配一个subnet，容器从这个subnet中分配ip，这些ip可以在host间路由，容器间无需使用nat和端口映射即可实现跨主机通信。每个subnet都是从一个更大的ip池中划分的，flannel会在每个主机上运行一个叫flanneld的agent，其职责就是从池子中分配subnet。etcd相当于一个数据库，flannel使用etcd存放网络配置、已分配的subnet、host的IP等信息 实验环境 节点 安装软件 系统 内核版本 docker版本 10.10.110.150(master) etcd、flannel、docker CentOS7.7.1908 3.10.0-1062.el7.x86_64 19.03.12 10.10.110.151(slave) flannel、docker CentOS7.7.1908 3.10.0-1062.el7.x86_64 19.03.12 master节点配置安装配置etcd yum install -y etcd # 安装etcd,由于不配置etcd集群,所以只在10.10.110.150节点安装etcd就行了 sed -i \"s/localhost/10.10.110.150/g\" /etc/etcd/etcd.conf # 修改etcd配置文件 systemctl start etcd.service # 启动etcd 安装配置flannel yum install -y flannel sed -i \"s/127.0.0.1/10.10.110.150/g\" /etc/sysconfig/flanneld # flannel连接到etcd,slave连接也是填写master的IP etcdctl --endpoints=\"http://10.10.110.150:2379\" set /atomic.io/network/config '{ \"Network\":\"172.17.0.0/16\", \"Backend\": {\"Type\": \"vxlan\"}} ' # 配置etcd的子网,如果这一步不配置,那么etcd无法启动 systemctl start flanneld.service # 启动flannel slave节点配置安装配置flannel yum install -y flannel sed -i \"s/127.0.0.1/10.10.110.150/g\" /etc/sysconfig/flanneld # 这里是填写master节点的IP,让slave连接到master的etcd,多slave也一样 systemctl start flanneld.service # 确保slave节点能连接到master节点的etcd,如果不关闭防火墙,那必须打开2379端口 配置docker使用flannel的网络master节点 vim /usr/lib/systemd/system/docker.service EnvironmentFile=/run/flannel/docker # 加载这个文件里面的变量,这个文件记录了flannel分配给master节点的子网信息(slave也会有自己的子网) ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock $DOCKER_NETWORK_OPTIONS # 这个变量是上面文件中定义的,意思是在启动容器时指定使用flannel分配的子网去配置容器的网络 iptables -P FORWARD ACCEPT # 开启iptables转发,如不开启即使配置成功也不能通信 systemctl daemon-reload systemctl restart flanneld.service # 这里必须先重启flannel再重启docker,这时候启动容器就会使用flannel去配置容器的网络 systemctl restart docker.service slave节点配置 vim /usr/lib/systemd/system/docker.service EnvironmentFile=/run/flannel/docker # 查看slave节点上这个文件,网段是和master节点不一样的 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock $DOCKER_NETWORK_OPTIONS iptables -P FORWARD ACCEPT systemctl daemon-reload systemctl restart flanneld.service systemctl restart docker.service 查看宿主机的IP变化master节点 ip a 3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:e3:89:96:4e brd ff:ff:ff:ff:ff:ff inet 172.17.98.1/24 brd 172.17.98.255 scope global docker0 valid_lft forever preferred_lft forever 4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default link/ether 02:6f:fa:71:67:f7 brd ff:ff:ff:ff:ff:ff inet 172.17.98.0/32 scope global flannel.1 valid_lft forever preferred_lft forever inet6 fe80::6f:faff:fe71:67f7/64 scope link valid_lft forever preferred_lft forever # docker0虚拟网卡和flannel虚拟网卡已经在同一网段，这时候说明配置成功 slave节点 ip a 3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:f2:30:ba:34 brd ff:ff:ff:ff:ff:ff inet 172.17.75.1/24 brd 172.17.75.255 scope global docker0 valid_lft forever preferred_lft forever 4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default link/ether f6:ae:d1:c0:e1:a7 brd ff:ff:ff:ff:ff:ff inet 172.17.75.0/32 scope global flannel.1 valid_lft forever preferred_lft forever inet6 fe80::f4ae:d1ff:fec0:e1a7/64 scope link valid_lft forever preferred_lft forever 在两个节点创建容器相互ping验证master节点 docker run -it busybox sh / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:62:02 inet addr:172.17.98.2 Bcast:172.17.98.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1450 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:656 (656.0 B) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # ping 172.17.75.2 PING 172.17.75.2 (172.17.75.2): 56 data bytes 64 bytes from 172.17.75.2: seq=0 ttl=62 time=0.492 ms 64 bytes from 172.17.75.2: seq=1 ttl=62 time=0.353 ms 64 bytes from 172.17.75.2: seq=2 ttl=62 time=0.342 ms slave节点 docker run -it busybox sh / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:4B:02 inet addr:172.17.75.2 Bcast:172.17.75.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1450 Metric:1 RX packets:6 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:516 (516.0 B) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # ping 172.17.98.2 PING 172.17.98.2 (172.17.98.2): 56 data bytes 64 bytes from 172.17.98.2: seq=0 ttl=62 time=1.945 ms 64 bytes from 172.17.98.2: seq=1 ttl=62 time=0.344 ms 64 bytes from 172.17.98.2: seq=2 ttl=62 time=0.384 ms 注意:如果不能ping通，先重启flannel再重启docker试试","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker容器数据持久化(4)","slug":"Docker容器数据持久化(4)","date":"2020-06-19T02:14:10.000Z","updated":"2020-08-28T03:14:23.142Z","comments":true,"path":"post/a7b8d397.html","link":"","permalink":"https://www.missf.top/post/a7b8d397.html","excerpt":"","text":"容器数据持久化的三种方式由于容器的镜像分层机制，我们在容器里面创建文件或者修改文件，结果都会保存在容器的可读写层中，一旦容器被销毁，那么这个读写层也会随着容器销毁而消失。而且当一个容器需要和其他容器的读写层进行数据交互时，也会显得非常困难。于是在将容器数据持久化到宿主机方面，docker为我们提供了三种持久化的方式 volumesvolumes由docker负责创建、管理。用户可以显式的调用命令docker volume create创建volume，也可以通过container、service的启动隐式创建 docker创建的volumes本质上还是宿主机文件系统中的一个目录，一个volumes可以供多个容器使用，即使没有容器使用此volumes，它也不会自动删除，除非用户明确删除它 如果用户显式创建volumes则需要给它一个名称，如果是隐式创建volumes则docker会为它分配一个在宿主机范围内唯一的名字 通过使用第三方提供的volume driver，用户可以将数据持久到远程主机或者云存储中，也就是说存储空间可以不由宿主机提供 # 创建volumes docker volume create nginx_volumes # 查看volumes docker volume ls # 查看卷详细信息 docker volume inspect nginx_volumes [ { \"CreatedAt\": \"2020-06-19T18:47:49+08:00\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/nginx_volumes/_data\", # 这是volumes在宿主机上的真实路径 \"Name\": \"nginx_volumes\", \"Options\": {}, \"Scope\": \"local\" } ] # 清理volumes docker volume rm nginx_volumes 将nginx容器的html目录映射到宿主机的nginx_volumes目录 # 创建数据持久化的容器,如果卷不存在则自动创建 docker container run -itd --name \"nginx1\" -p 80:80 -v nginx_volumes:/usr/share/nginx/html nginx:1.17 # -v方式 docker container run -itd --name \"nginx1\" -p 80:80 --mount src=nginx_volumes,dst=/usr/share/nginx/html nginx:1.17 # --mount方式 # 查看nginx_volumes在宿主机的真实目录 ll /var/lib/docker/volumes/nginx_volumes/_data total 8 -rw-r--r-- 1 root root 494 Apr 14 22:19 50x.html # 这时候nginx容器内部的文件已经被映射到宿主机上了 -rw-r--r-- 1 root root 612 Apr 14 22:19 index.html # 修改宿主机上的index.html文件 echo \"nginx_volumes test\" > /var/lib/docker/volumes/nginx_volumes/_data/index.html # 访问宿主机的80端口(前面启动容器时将容器的80端口绑定到宿主机的80端了) curl 10.10.110.150 nginx_volumes test # nginx容器内的文件确实被修改成功 bind mountsbind mounts本质上是容器共享宿主机文件系统，比如docker将宿主机的/etc/resov.conf文件bind mount到容器里，两者会使用相同的dns服务器 # 创建容器,将宿主机的/nginx/app绑定到容器的/usr/share/nginx/html目录 docker container run -itd --name \"nginx1\" --mount type=bind,src=/nginx/app,dst=/usr/share/nginx/html nginx:1.17 docker container run -itd --name \"nginx1\" -v /nginx/app:/usr/share/nginx/html nginx:1.17 # 查看宿主机和容器的目录 ls /nginx/app docker exec -it nginx1 ls /usr/share/nginx/html # 两个目录都为空,这是因为bind mounts是将宿主机的目录绑定到容器的目录,容器目录已有的内容会被隐藏(bind mounts以宿主机目录为主) 注意: 如果源文件或源目录不存在，则不会自动创建。如果容器目录为非空目录，则容器目录现有内容会被宿主机目录内容所隐藏。 tmpfs出于安全原因，或者容器性能优化的原因有时候不需要容器的数据长久保存时可以使用这种方式。将容器数据挂载存储在宿主机的内存中，避免写入容器可写层，提高容器性能 volumes 和 bind mounts 的使用场景和区别volumes适合多个容器需要共享数据、将数据保存到远程主机或云上等场景。bind mounts适合将宿主机的系统配置文件共享给容器。volumes是将容器内部的数据映射到宿主机对应的volumes目录，如果容器内部是一个非空目录，volumes目录也是一个非空目录，那么两个目录的文件会合并。而bind mounts是将宿主机上任意位置的目录或文件挂载到容器中，如果宿主机的目录非空，那么容器目录的数据将会被宿主机目录的数据隐藏，容器内的数据要卸除挂载后才会恢复 Bind mounts和volumes都可以通过使用标志-v或–volume来挂载到容器中，只是格式有些许不同。然而，在Docker17.06及其以上版本中，我们推荐使用–mount来对容器或服务进行这三种方式的挂载，因为这种格式更加清晰","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker容器管理(3)","slug":"Docker容器管理(3)","date":"2020-06-17T08:23:38.000Z","updated":"2020-08-28T03:14:07.956Z","comments":true,"path":"post/39a5b294.html","link":"","permalink":"https://www.missf.top/post/39a5b294.html","excerpt":"","text":"创建容器常用选项 选项 描述 -i, –interactive 交互式 -t, –tty 分配一个伪终端 -d, –detach 运行容器到后台 -e, –env 设置环境变量 -p, –publish list 发布容器端口到主机 -P, –publish-all 发布容器所有EXPOSE的端口到宿主机随机端口 –name string 指定容器名称 -h, –hostname 设置容器主机名 –ip string 指定容器IP,只能用于自定义网络 –network 连接容器到一个网络 –mount mount 将文件系统附加到容器 -v, –volume list 绑定挂载一个卷 –restart string 容器退出时重启策略,默认no,可选值:[always|on-failure] 创建容器示例# 启动一个nginx容器,指定名字、映射端口、设置重启 # 如果不加-it分配一个交互式的伪终端,容器就会直接退出了,容器内的第一个程序必须一直处于前台运行(必须hang住) docker container run -itd --name \"nginx\" -p 80:80 --restart always nginx:1.17 容器资源限制 选项 描述 -m，–memory 容器可以使用的最大内存量 –memory-swap 允许交换到磁盘的内存量 –memory-swappiness=&lt;0-100&gt; 容器使用SWAP分区交换的百分比(0-100，默认为-1) –oom-kill-disable 禁用OOM Killer –cpus 可以使用的CPU数量 –cpuset-cpus 限制容器使用特定的CPU核心，如(0-3, 0,1) –cpu-shares CPU共享(相对权重) 内存限额示例# 允许容器最多使用500M内存和600M的swap,并禁用OOM Killer docker container run -d --name \"nginx1\" --memory=\"500M\" --memory-swap=\"600M\" --oom-kill-disable nginx:1.17 CPU限额示例# 允许容器最多使用两个的CPU docker container run -d --name \"nginx2\" --cpus=\"2\" nginx:1.17 # 允许容器最多使用50%的CPU docker container run -d --name \"nginx3\" --cpus=\".5\" nginx:1.17 容器资源配额扩容# 容器资源可更新选项 docker update --help Usage: docker update [OPTIONS] CONTAINER [CONTAINER...] Update configuration of one or more containers Options: --blkio-weight uint16 Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0) --cpu-period int Limit CPU CFS (Completely Fair Scheduler) period --cpu-quota int Limit CPU CFS (Completely Fair Scheduler) quota --cpu-rt-period int Limit the CPU real-time period in microseconds --cpu-rt-runtime int Limit the CPU real-time runtime in microseconds -c, --cpu-shares int CPU shares (relative weight) --cpus decimal Number of CPUs --cpuset-cpus string CPUs in which to allow execution (0-3, 0,1) --cpuset-mems string MEMs in which to allow execution (0-3, 0,1) --kernel-memory bytes Kernel memory limit -m, --memory bytes Memory limit --memory-reservation bytes Memory soft limit --memory-swap bytes Swap limit equal to memory plus swap: '-1' to enable unlimited swap --pids-limit int Tune container pids limit (set -1 for unlimited) --restart string Restart policy to apply when a container exits # 更新正在运行中的容器内存限额 docker update --memory=\"400M\" --memory-swap=\"500M\" --restart=\"on-failure\" 4e860294d239 管理容器常用命令 选项 描述 ls 列出容器 inspect 查看一个或多个容器详细信息 exec 在运行容器中执行命令 commit 创建一个新镜像来自一个容器 cp 拷贝文件/文件夹到一个容器 logs 获取一个容器日志 port 列出或指定容器端口映射 top 显示一个容器运行的进程 stats 显示容器资源使用统计 stop/start/restart 停止/启动一个或多个容器 rm 删除一个或多个容器 prune 移除已停止的容器 管理容器示例# 列出真正运行的所有容器 docker container ls -a # 获取一个容器日志 docker container logs --tail=\"5\" nginx # 仅列出最新N条容器log信息 docker container logs -f nginx # 跟踪log信息输出 docker logs --since=\"2020-06-18\" --tail=\"10\" nginx # 显示某个时间之后的最新十条log信息 # 进入正在运行的容器中执行命令 docker container exec -it nginx /bin/bash # 显示一个容器运行的进程 docker container top nginx # 删除一个或删除全部容器 docker container rm -f nginx docker container rm -f $(docker container ls -q) 容器实现核心技术: Namespace在容器化中，一台物理计算机可以运行多个不同操作系统(一个容器就类似于一个系统)，那就需要解决”隔离性”，让彼此感知不到对方的存在，出现问题也互不影响 Linux内核从2.4.19版本开始引入了namespace概念，其目的是将特定的全局系统资源通过抽象方法使得namespace中的进程看起来拥有自己隔离的资源。Docker就是借助这个机制实现了容器资源隔离 Linux的namespace机制提供了6种不同的命名空间: IPC: 隔离进程间通信 MOUNT: 隔离文件系统挂载点 NET: 隔离网络协议栈 PID: 隔离进程号，容器命名空间对父进程空间可见 USER: 隔离用户 UTS: 隔离主机名和域名 容器实现核心技术: CGroupsDocker利用namespace实现了容器之间资源隔离，但是namespace不能对容器资源限制，比如CPU、内存。如果某一个容器属于CPU密集型任务，那么会影响其他容器使用CPU，导致多个容器相互影响并且抢占资源。如何对多个容器的资源使用进行限制就成了容器化的主要问题。所以容器引入了Control Groups(简称CGroups)，限制容器资源 CGroups 以某种标准讲一组进程为目标进行资源分配和控制，例如CPU、内存、带宽等，并且可以动态配置: 限制进程组使用的资源数量(Resource limitation ):可以为进程组设定资源使用上限，例如内存 进程组优先级控制( Prioritization):可以为进程组分配特定CPU、磁盘IO吞吐量 记录进程组使用的资源数量(Accounting ):例如使用记录某个进程组使用的CPU时间 进程组控制(Control ):可以将进程组挂起和恢复 查看cgroups可控制的资源 资源 描述 blkio 对块设备的IO进行限制 cpu 限制CPU时间片的分配，与cpuacct挂载同一目录 cpuacct 生成cgroup中的任务占用CPU资源的报告，与cpu挂载同一目录 cpuset 给cgroup中的任务分配独立的CPU(多核处理器)和内存节点 devices 允许或者拒绝 cgroup 中的任务访问设备 freezer 暂停/恢复 cgroup 中的任务 hugetlb 限制使用的内存页数量 memory 对cgroup中任务的可用内存进行限制，并自动生成资源占用报告 net_cls 使用等级识别符(classid)标记网络数据包，这让 Linux 流量控制程序(tc)可以识别来自特定从cgroup任务的数据包，并进行网络限制 net_prio 允许基于cgroup设置网络流量的优先级 perf_event 允许使用perf工具来监控cgroup pids 限制任务的数量 资源控制在容器中的实际位置ll /sys/fs/cgroup/\"资源名\"/docker/\"容器ID\"/ Docker核心组件之间关系我们使用docker client运行一个容器，其实容器运行时底层是需要依赖一系列组件的，我们完全可以通过调用这些组件去启动一个容器，而不使用docker引擎的方式去启动。主要的组件有docker client、docker daemon、containerd、container-shim、runC docker clientdocker客户端程序，负责发送用户的请求给docker daemon docker daemondocker daemon守护进程，也称docker engine，负责处理docker client的请求，并返回处理结果 containerdcontainerd是一个工业级标准的容器运行时，它强调简单性、健壮性和可移植性。Containerd可以在宿主机中管理完整的容器生命周期:容器镜像的传输和存储、容器的执行和管理、存储和网络等。为docker daemon提供接口去管理容器，docker对容器的管理和操作基本都是通过containerd完成的。但是要注意的是:containerd被设计成嵌入到一个更大的系统中，而不是直接由开发人员或终端用户使用 container-shimcontainer-shim是containerd的组件，是容器的运行时载体，我们在docker宿主机上看到的shim也正是代表着一个个通过调用containerd启动的docker容器 ps axf | grep docker -A 1 10191 ? Sl 0:01 \\_ containerd-shim -namespace moby -workdir /var/lib/containerd/io.containerd.runtime.v1.linux/moby/4dffa5d5861899400770d6470618e4e051c5f1bf0c53034999b13821fc3fe93f -address /run/containerd/containerd.sock -containerd-binary /usr/bin/containerd -runtime-root /var/run/docker/runtime-runc 10208 ? Ss 0:00 \\_ nginx: master process nginx -g daemon off; -- 4215 ? Ssl 2:06 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock runCRunC 是一个轻量级的工具，它是用来运行容器的。我们可以认为它就是个命令行小工具，可以不用通过 docker 引擎，直接运行容器。事实上runC 是标准化的产物，它根据 OCI 标准来创建和运行容器。而 OCI(Open Container Initiative)组织，旨在围绕容器格式和运行时制定一个开放的工业化标准","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker镜像管理(2)","slug":"Docker镜像管理(2)","date":"2020-06-16T07:00:10.000Z","updated":"2020-08-28T03:13:39.992Z","comments":true,"path":"post/ce2c2968.html","link":"","permalink":"https://www.missf.top/post/ce2c2968.html","excerpt":"","text":"镜像概述镜像是一个分层存储的文件 镜像就是一个软件的运行环境 一个镜像可以重复使用，创建无数个容器 一个不包含Linux内核而又精简的Linux操作系统 镜像是一种标准化的交付，镜像内包含代码以及软件的运行环境 配置镜像加速阿里云为每一个开通容器镜像服务的用户免费提供一个镜像加速地址 # 配置镜像加速 tee /etc/docker/daemon.json &lt;&lt; EOF { \"registry-mirrors\": [\"https://265wemgl.mirror.aliyuncs.com\"] } EOF systemctl daemon-reload systemctl restart docker.service 拉取镜像我们拉取镜像一般是默认从Docker Hub拉取的，但是国内访问Docker Hub速度很慢，所以我们在前面配置了阿里云的镜像加速。在拉取镜像时，直接从阿里云的docker镜像仓库拉取。我们假如要拉取一个镜像，但是不知道仓库中是否有这个镜像时，我们可以先搜索这个镜像名字，看是否有对应的镜像 # 搜索镜像 docker search nginx # 拉取镜像,如果不指定版本号,默认拉取最新(latest) docker pull nginx:1.17 镜像拉取到宿主机本地之后，会以分层的文件形式存储，下面是镜像的存放目录 [root@localhost ~]# ll /var/lib/docker/overlay2/ total 0 drwx------ 4 root root 55 Jun 17 19:04 5f4badc01c88554e78d4aaec269a84fb5e2028d42278d5f131dda81c4209622c drwx------ 3 root root 47 Jun 17 19:04 658e3b564ce9017b0bd507f1853702f6cdda4642fdc6fbf4b4d06e34cf9a8c25 drwx------ 3 root root 30 Jun 17 19:09 6d57028d1a60a66afc6959b02e0005ea424182908fadf6aa5ac90f3868c014f7 brw------- 1 root root 253, 0 Jun 17 18:31 backingFsBlockDev drwx------ 4 root root 72 Jun 17 19:04 d56648ebd71c9bdb68226b4021ec008db3ed537072b3c4f9e77afc51f8108c07 drwx------ 2 root root 142 Jun 17 19:09 l 镜像与容器的联系当启动一个新容器时，docker只加载只读镜像，并在这个只读镜像上面添加一个读写层，即容器层。但我们需要修改容器里面的文件时，会先从镜像层把这个文件拷贝到读写层，然后再执行修改操作 镜像存储核心技术:联合文件系统(UnionFS)联合文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(uniteseveral directories into a single virtual filesystem)。联合文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。另外，不同 Docker 容器就可以共享一些基础的文件系统层，同时再加上自己独有的改动层，大大提高了存储的效率 Docker 中使用的 AUFS（AnotherUnionFS）就是一种联合文件系统。 AUFS 支持为每一个成员目录（类似 Git 的分支）设定只读（readonly）、读写（readwrite）和写出（whiteout-able）权限, 同时 AUFS 里有一个类似分层的概念, 对只读权限的分支可以逻辑上进行增量地修改(不影响只读部分的) Docker 目前支持的联合文件系统包括 OverlayFS , AUFS , Btrfs , VFS , ZFS 和 DeviceMapper 镜像存储核心技术:写时复制(COW)docker镜像由多个只读层叠加而成，启动容器时，docker会加载只读镜像层并在镜像层顶部添加一个读写层。如果运行中的容器修改了一个已存在的文件，那么该文件将会从只读层复制到读写层，该文件的只读版本任然存在，只是已经被读写层中该文件的副本所隐藏，这就是写时复制机制 镜像常用管理命令# 列出镜像,-a显示所有镜像 docker image ls # 在当前目录通过Dockerfile构建镜像 docker build -t \"nginx_tomcat\" . # 查看镜像历史 docker image history nginx:1.17 # 显示镜像的详细信息 docker inspect nginx:1.17 # 从镜像仓库拉取镜像 docker pull nginx:1.17 # 推送镜像到镜像仓库 docker pull centos:7.6.1810 # 移除一个或多个镜像 docker image rm centos docker image rm $(docker image ls -q) # 删除全部镜像 # 删除没有被标记或没有被任何容器引用的镜像 docker image prune -af # 创建一个引用源镜像标记目标镜像 docker tag centos:latest coentos:v1 # 为centos:latest这个镜像打一个标签为coentos:v1 # 导出容器文件系统为tar归档文件 docker export -o centos-export.tar [CONTAINER ID] # 导入容器文件系统tar归档文件来创建镜像 docker import centos-export.tar # 保存一个或多个镜像到一个tar归档文件 docker save -o database.tar redis mysql # 加载镜像来自tar归档或标准输入 docker load -i database.tar 相信许多的初学者看到这里肯定有疑问，这里说明一下export &amp; import和save &amp; load的区别在哪里 export &amp; importexport的应用场景主要用来制作基础镜像，比如你从一个centos镜像启动一个容器，然后安装一些软件和进行一些设置后，使用docker export保存为一个基础镜像。然后把这个镜像分发给其他人使用，比如作为基础的开发环境 export:将容器导出为tar归档文件,生成的是该容器的快照，复刻了容器当前的Linux系统环境 import:将tar归档文件导入为镜像 整个过程即:容器-->tar归档文件-->镜像 save &amp; load如果你的应用是使用docker-compose.yml编排的多个镜像组合，但你要部署的客户服务器并不能连外网。这时，你可以使用docker save将用到的镜像打个包，然后拷贝到客户服务器上使用docker load载入 save:将镜像导出为tar归档文件,该命令也可以作用于容器,但导出的是容器背后的images load:将tar归档文件导入为镜像 注意: save命令生成的tar包比export命令生成的tar包大很多，两组命令不可交叉互用","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker核心概念与安装(1)","slug":"Docker核心概念与安装(1)","date":"2020-06-15T02:56:03.000Z","updated":"2020-08-28T03:13:17.233Z","comments":true,"path":"post/f7aff4ce.html","link":"","permalink":"https://www.missf.top/post/f7aff4ce.html","excerpt":"","text":"为什么使用容器提供简单轻量的建模方式，非常容易上手，运行速度非常快 使开发和运维的职责分离，开发只需要关心容器中的程序，运维只需要管理容器 快速高效的开发生命周期，开发环境和生产环境一致，避免了额外的调试有效缩短上线时间 鼓励使用面向服务的架构，docker推荐单个容器只运行一个应用程序，使分布式扩展和调试变得简单 Docker 是什么容器技术想要了解docker，首先要知道什么是容器。最早的容器技术来自于BSD的jail技术(jail一词是监狱的意思，这个技术的隔离思想来源于监狱的启发)，目的就是为了实现进程隔离，使得一个进程被攻陷后不会影响到其他进程，这是出于安全的目的。 使用最为广泛的开源容器引擎在近几年来，docker是一个非常火的名词。事实上docker只是众多容器引擎其中一款优秀的容器引擎，但是它却几乎成为了容器的代名词。许多业外人士觉得docker就是容器，这里大家要明白，docker只是属于容器技术的一种。 容器是一种操作系统级别的虚拟化技术使用docker创建的容器，以特殊进程的方式在宿主机上运行，运行一个容器就像运行一个进程一样，宿主机上可以运行多个容器，容器间的资源是互相隔离的。 依赖于Linux内核特性 Namespace &amp; Cgroups容器之间运行的是一个隔离的环境，也可以理解类似于一个沙盒，使用Namespace进行资源的隔离，使用Cgroups进行资源的控制。 Docker 基本组成Docker Client 客户端docker采用C/S架构 docker客户端和docker服务器之间的通信访问可以是本地方式也可以是远程方式 docker客户端向守护进程发送请求，守护进程的执行结果会传回给客户端 Docker Daemon 守护进程docker采用C/S架构 docker客户端和docker服务器之间的通信访问可以是本地方式也可以是远程方式 docker客户端向守护进程发送请求，守护进程的执行结果会传回给客户端 Docker Image 镜像 镜像是容器的基石，镜像包含了容器启动的一切条件，容器基于镜像去启动。镜像是层叠的只读文件系统，底层是bootfs引导文件系统，rootfs文件系统永远是只读状态，使用同一个镜像无论启动多少个容器，或者容器被如何修改，镜像都不会被改变。一个镜像可以放到一个镜像的顶部，最下面的镜像称为基础镜像，就是图中的centos/Ubuntu层。这里使用了写时复制技术(copy on write)，即通过一个镜像启动一个容器实例，这个镜像是以只读形式挂载的，即不允许任何修改操作，当在容器实例中修改一个文件时，会首先从镜像里把这个文件拷贝到可写层，然后执行更新操作。 Docker Container 容器容器通过镜像启动 docker守护进程执行命令就是在容器实例中执行 应用部署在容器中 在启动容器时会在镜像的最上层创建一个读写层，读写层加上下面的多个只读层从而构成一个容器 Docker Registry 仓库随着我们项目的增加，我们构建的镜像也会越来越多。而镜像也是像代码一样的，需要一个镜像仓库来进行管理的，镜像仓库里面保存着我们构建的镜像。镜像仓库还分为公有仓库和私有仓库。公有仓库一般指Docker Hub，Docker Hub 是一个由 Docker 公司运行和管理的基于云的存储库，它是一个在线存储库，Docker 镜像可以由其他用户发布和使用。而私有仓库一般是我们公司的组织内部拥有的一个私有仓库，仅允许公司内部用户使用。 容器的关系图 容器 VS 虚拟机虚拟机是系统级别的虚拟化，而容器是进程级别的虚拟化，这是虚拟机和容器最核心的区别。虚拟机提供了物理机硬件级别的操作系统隔离，使用虚拟机部署应用，除了应用和应用依赖的库文件，还需要虚拟完整的操作系统，每个虚拟机拥有自己独立的内核，这会大量占用系统的硬件资源。而容器是进程级别的虚拟化，当我们运行docker容器时，此时容器本身只是操作系统中的一个进程，利用了Linux系统的内核特性(Namespace &amp; Cgroups)实现了进程之间网络、空间、权限等隔离，使多个容器进程互相不知道彼此的存在。在这个追求速度的互联网时代，容器在许多方面要比虚拟机优秀。但是不意味着传统的虚拟机技术就过时了，虚拟机的操作系统级别隔离是容器无法替代的，容器的意义在于运行单个应用，如果在容器里面添加越来越多的功能，那不如一开始就直接使用虚拟机。 虚拟技术的核心区别 容器 VS 虚拟机详细对比 Container VM 启动速度 秒级 分钟级 运行性能 接近原生 5%左右损失 磁盘占用 MB GB 数量 成百上千 一般几十台 隔离性 进程级 系统级(更彻底) 操作系统 主要支持Linux 几乎所有 封装程度 只打包项目代码和依赖关系，共享宿主机内核 完整的操作系统 Docker应用场景应用程序打包和发布 应用程序环境隔离 持续集成 部署微服务 快速搭建测试环境 提供Pass产品(平台即服务) Linux 安装 Docker# 安装依赖包 yum install -y yum-utils device-mapper-persistent-data lvm2 # 添加Docker软件源 yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo # 安装Docker CE yum install -y docker-ce # 启动Docker服务并设置开机启动 systemctl start docker systemctl enable docker # 查看docker版本 docker --version Docker version 19.03.11, build 42e35e61f3 # 查看更详细的信息 docker info","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"ansible的jinja2模板(16)","slug":"ansible的jinja2模板(16)","date":"2020-06-10T12:56:59.000Z","updated":"2020-08-28T03:12:48.639Z","comments":true,"path":"post/62ac8f71.html","link":"","permalink":"https://www.missf.top/post/62ac8f71.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的jinja2模板我们在多个管理节点部署服务时，很多服务的配置文件都是需要监听服务所在主机的IP地址，这时候就需要使用到ansible的jinja2模板去分发动态的配置文件。我们先创建一份模板文件，将IP配置部分使用ansible变量进行替换，然后使用template模块对模版文件进行渲染，将根据我们定义的变量而生成不同的配置文件发送到对应的管理节点 下面我们以安装redis为示例，为不同的管理节点分发动态配置文件 cat /etc/redis/conf/redis.conf bind {{ ansible_host }} # 将默认的127.0.0.1改为管理节点本机的IP，这样就能生成各自的管理节点的配置文件 准备模板配置文件之后，下面就来编写一个playbook，完成模板配置文件的渲染和分发 --- - hosts: all remote_user: root tasks: - template: src: /root/playbook/redis.conf # 控制节点上的模板文件,定义好变量,通过template模块进行渲染 dest: /etc/redis.conf # 管理节点上这个文件将被控制节点上的模板文件所替换 jinja2语法Ansible使用Jinja2模板来启用动态表达式和对变量的访问，就是说ansible使用Jinja模板对含有动态表达式和变量的文件进行解析个渲染 变量&amp;表达式可以使用点.来访问变量的属性，也可以使用下标语法[]，下面2种方式效果是一样的 {{ foo.bar }} {{ foo['bar'] }} # 如果变量或属性不存在，会返回一个未定义值。 除了变量， {{}} 中还可以包含一些表达式 {{ 1 == 1 }} {{ 2 != 3 }} {{ 2 > 3 }} {{ 4 &lt;= 3 }} # 根据对应的表达式返回true或false {{ 3 + 2 }} {{ 3 - 4 }} {{ 3 * 5 }} {{ 2 ** 3 }} # 2的3次方 # 根据算术运算返回结果 # 字符串、数值、列表、元组、字典、布尔值等数据类型均可在\"{{ }}\"使用 控制用来装载控制语句，比如 if 控制结构，for循环控制结构 {% for item in seq %} ``` ## 注释 要把模板中一行的部分注释掉 ```yaml {# 这是被注释的内容 #} ``` ## 转义 简单的使用单引号('')进行转义，对于较大的段落，使用raw进行转义 ```yaml {% raw %} &lt;ul> {% for item in seq %} &lt;li>{{ item }}&lt;/li> {% endfor %} &lt;/ul> {% endraw %} 执行命令时传入变量cat /root/test.j2 my blog is {{ site }} ansible dbserver -m template -e \"site=missf.top\" -a \"src=/root/test.j2 dest=/opt/test\" cat /opt/test my blog is missf.top if{% if num > 3 %} gtfr derew pllu {% endif %} 使用template模板进行渲染 ansible dbserver -m template -e \"num=4\" -a \"src=/root/test.j2 dest=/opt/test\" # 渲染后的输出结果 cat /opt/test gtfr derew pllu forjinja2模板的for语法示例 {% if num > 3 %} {% for i in [5,65,7,23] %} {{ i }} {% endfor %} 使用template模板进行渲染 ansible dbserver -m template -a \"src=/root/test.j2 dest=/opt/test\" # 渲染后的输出结果 cat /opt/test 5 65 7 23 控制空白从for循环的结果看出，使用template模板进行渲染时不会去处理空格或者换行符，在开始或结束放置一个减号(-)，可以移除块前或块后的空白 {% for i in [5,65,7,23] -%} {{ i }} # 这里可以使用{{ i }}{{' '}}定义分割符 {%- endfor %} ansible dbserver -m template -a \"src=/root/test.j2 dest=/opt/test\" cat /opt/test 565723 # 将换行符和空白都移除了 5 65 7 23 # 定义分割符的效果 ​ 我要去重新学习梳理Docker了，Ansible就先到这里吧！等到有空了，再重启吧","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的include(15)","slug":"ansible的include(15)","date":"2020-06-10T11:56:59.000Z","updated":"2020-07-14T06:29:06.501Z","comments":true,"path":"post/fa9ef74f.html","link":"","permalink":"https://www.missf.top/post/fa9ef74f.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的include在所有的编程语言中，在处理重复代码的时候，都会将重复的代码提取出来作为一个逻辑单元，这个逻辑单元通常被称为函数或者方法，这样可以让我们更加方便的、重复的调用这段代码。而且如果需要修改这段代码，只需要修改这段代码本身，那么在调用这段代码的地方的逻辑就会随之改变。同时，使用函数的方式编写代码，能让我们的逻辑更清晰，通过函数的名称，大概能推算出程序的主体作用和逻辑 在ansible中，其实也有类似的功能，这种功能被称之为include。通过include，我们可以在playbook中包含另一个文件，以便实现我们刚才所说的函数效果 在配置环境的时候，我们经常会有一些需要重复使用的playbook，就像下面的LAMP环境和LNMP环境 cat lamp.yaml --- - hosts: dbserver remote_user: root tasks: - name: install lamp yum: name: - mysql - php-fpm - httpd state: present cat lnmp.yaml --- - hosts: dbserver remote_user: root tasks: - name: install lnmp yum: name: - mysql - php-fpm - nginx state: present 我们可以把上面的两个playbook改写层下面这样，便于我们直接调用 cat lamp.yaml - yum: name: - mysql - php-fpm - httpd state: present cat lnmp.yaml - yum: name: - mysql - php-fpm - nginx state: present 当我们需要执行这两个playbook时，直接使用include调用，playbook中的任务就会在被调用处执行 cat lamp_lnmp.yaml - hosts: webserver remote_user: root tasks: - name: install lamp include_tasks: lamp.yaml # 这里执行的是lamp.yaml的内容 - hosts: dbserver remote_user: root tasks: - name: install lnmp include_tasks: lnmp.yaml 给include文件传参cat baidu.yaml - shell: ping -c 3 \"{{ baidu }}\" # 在include文件使用变量 cat include_baidu.yaml --- - hosts: dbserver remote_user: root vars: baidu: \"www.baidu.com\" # 定义include文件所需要的变量 tasks: - name: ping baidu include_tasks: baidu.yaml # 调用执行include文件 import_playbook我们使用include关键字可以调用任务列表，但如果想要调用整个playbook，则需要import_playbook模块代替include模块 cat import_test.yaml --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"test task cat import_test.yaml\" - import_playbook: intest7.yaml # 调用intest7.yaml整个yaml cat intest7.yaml --- - hosts: webserver remote_user: root tasks: - debug: msg: \"test task cat intest7.yaml\"","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的lookups插件(14)","slug":"ansible的lookups插件(14)","date":"2020-06-10T11:46:58.000Z","updated":"2020-07-14T06:28:18.689Z","comments":true,"path":"post/de181bd8.html","link":"","permalink":"https://www.missf.top/post/de181bd8.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的lookups插件过滤器其实是ansible中的一种插件，除了过滤器之外，ansible中还有很多其他种类的插件。而且我们一直都在使用这些插件，比如我们在配置ansible的主机清单时，就用到了Inventory种类的插件。lookups其实也是插件的一种，lookups的所有操作都是在控制节点上进行的，与管理节点无关。ansible官网为我们总结了各个插件的作用，并且按照这些插件功能进行了分类。官网插件地址 lookups filefile插件可以读取文件，插件的源码是使用Python读取文件然后把结果返回给变量 --- - hosts: dbserver remote_user: root vars: contents: \"{{ lookup('file','/etc/hostname') }}\" tasks: - name: debug lookup file debug: msg: \"the contents is {{ contents }}\" 如果不想将所有文件的内容变成一整个字符串，而是获取一个字符串列表，可以使用wantlist参数 --- - hosts: dbserver remote_user: root vars: contents: \"{{ lookup('file','/etc/hostname',wantlist=true) }}\" tasks: - name: debug lookup file debug: msg: \"the contents is {{ contents }}\" lookups passwordpasswd插件会对传入的内容进行加密处理 --- - hosts: dbserver vars: contents: \"{{ lookup('password','ansible') }}\" # 将ansible这个字符串进行加密处理 tasks: - name: debug lookups debug: msg: \"the contents is {{ contents }}\" lookups pipepipe插件运行命令并返回结果，pipe这个插件底层是使用Python的subprocess库实现的 --- - hosts: dbserver remote_user: root vars: contents: \"{{ lookup('pipe','hostname') }}\" tasks: - name: debug lookup pipe debug: msg: \"the contents is {{ contents }}\" lookups redis_kvredis_kv插件是用来从本地redis中读取数据的 --- - hosts: dbserver remote_user: root vars: contents: \"{{ lookup('redis_kv', 'redis://127.0.0.1:6379,ansible') }}\" # 获取本地redis数据库ansible这个键的值 tasks: - name: debug lookup redis_kv debug: msg: \"the contents is {{ contents }}\" lookups dictdict插件是用来获取变量的键值对 --- - hosts: dbserver vars: users: alice: female bob: male tasks: - debug: msg: \"{{ item.key }} = {{ item.value }}\" loop: \"{{ lookup('dict',users) }}\" lookups envenv插件可以获取ansible主机中指定变量的值 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ lookup('env','PATH') }}\" lookups first_foundfirst_found插件可以获取列表中第一个找到的文件，如果列表中的所有文件都没有找到，可以添加errors=ignore忽略报错 - hosts: master remote_user: root tasks: - name: debug lookup first found debug: msg: \"{{ lookup('first_found',looklist,errors='ignore') }}\" vars: looklist: - \"/abc.txt\" - \"/tmp/str.txt\" lookups digdig插件可以获取指定域名的IP地址，需要Python安装dnspython库 --- - hosts: master remote_user: root tasks: - debug: msg: \"{{ lookup('dig','www.baidu.com',wantlist=true) }}\"","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的过滤器(13)","slug":"ansible的过滤器(13)","date":"2020-06-09T11:46:58.000Z","updated":"2020-08-28T03:11:33.341Z","comments":true,"path":"post/40656090.html","link":"","permalink":"https://www.missf.top/post/40656090.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的过滤器过滤器可以帮助我们对数据进行处理，例如将获取到的变量值中的所有字母都变成大写，过滤器能帮我们实现这样的需求 --- - hosts: dbserver remote_user: root vars: testvar: fesf1dEcd tasks: - debug: msg: \"{{ testvar | upper }}\" # 执行playbook ok: [dbserver] => { \"msg\": \"FESF1DECD\" } 过滤器是一种能够帮助我们处理数据的工具，ansible中的过滤器功能来自于jinja2模板引擎，我们可以借助jinja2的过滤器功能在ansible中对数据进行各种处理，而上例中的upper就是一种过滤器，这个过滤器的作用就是将小写字母变成大写。当然还有很多其他的过滤器，这些过滤器有些是jinja2内置的，有些是ansible特有的，如果这些过滤器都不能满足你的需求，jinja2也支持自定义过滤器 字符串操作相关的过滤器--- - hosts: dbserver remote_user: root vars: testvar: fesf1dEcd tasks: - debug: msg: \"{{ testvar | upper }}\" # 将全部字母转换成大写 - debug: msg: \"{{ testvar | lower }}\" # 将全部字母转换成小写 - debug: msg: \"{{ testvar | capitalize }}\" # 首字母大写,其他小写 - debug: msg: \"{{ testvar | reverse }}\" # 将字符串反转 - debug: msg: \"{{ testvar | first }}\" # 返回字符串的第一个字符 - debug: msg: \"{{ testvar | last }}\" # 返回字符串的最后一个字符 - debug: msg: \"{{ testvar | trim }}\" # 将字符串开头和结尾的空格去除 - debug: msg: \"{{ testvar | center(width=30) }}\" # 将字符串居中并设置字符串的长度为30,字符串两边用空格填充 - debug: msg: \"{{ testvar | length }}\" # 返回字符串长度,length与count等效,可以写为count - debug: msg: \"{{ testvar | list }}\" # 将字符串转换成列表,每个字符作为一个元素 - debug: msg: \"{{ testvar | shuffle }}\" # 将字符串转换成列表,每个字符作为一个元素,并且随机打乱顺序(洗牌) 数字操作相关的过滤器--- - hosts: dbserver remote_user: root vars: tes: -8 tasks: - debug: msg: \"{{ 5 + ('8' | int) }}\" # 把字符串类型的'8'转换为整形后再作计算 - debug: msg: \"{{ '9' | int(default=6) }}\" # 把字符串类型的'a'转换为整形,如果无法转换则返回6 - debug: msg: \"{{ '8' | float }}\" # 将对应的值转换为浮点型,如果无法转换则默认返回'0.0' - debug: msg: \"{{ 'a' | float(8.88) }}\" # 当对应的值无法返回时则返回指定的'8.88' - debug: msg: \"{{ tes | abs }}\" # 获取这个变量的绝对值 - debug: msg: \"{{ 15.2 | round }}\" # 四舍五入 - debug: msg: \"{{ 3.14159 | round(2) }}\" # 保留小数点后两位 - debug: msg: \"{{ 100 | random }}\" # 从0到100中返回一个随机数 - debug: msg: \"{{ 10 | random(start=5) }}\" # 从5到10中返回一个随机数 - debug: msg: \"{{ 15 | random(start=5,step=2) }}\" # 从5到15中返回一个随机数,步长为2 - debug: msg: \"{{ 15 | random(step=5) }}\" # 从0到10中返回一个随机数,这个数是5的倍数 列表操作相关的过滤器--- - hosts: dbserver remote_user: root tasks: vars: var1: [32,45,63,76,58] var2: [23,[34,65],34,80] var3: [23,'r',87] var4: ['fr',['po','qE'],'tT','IO'] var5: ['bc',1,5,'b','c'] var6: ['bc',5,'b','g'] tasks: - debug: msg: \"{{ var1 | length }}\" # 返回列表长度,length与count等效 - debug: msg: \"{{ var1 | first }}\" # 返回列表中的第一个值 - debug: msg: \"{{ var1 | last }}\" # 返回列表中的最后一个值 - debug: msg: \"{{ var1 | min }}\" # 返回列表中最小的值 - debug: msg: \"{{ var1 | max }}\" # 返回列表中最大的值 - debug: msg: \"{{ var1 | sort }}\" # 将列表升序排序输出 - debug: msg: \"{{ var1 | sort(reverse=true) }}\" # 将列表降序排序输出 - debug: msg: {{ var1 | sum }}\" # 返回纯数字非嵌套列表中所有数字的和 - debug: msg: \"{{ var2| flatten }}\" # 如果列表中包含列表,就把列表拉平为一个列表 - debug: msg: \"{{ var2 | flatten(levels=1) }}\" # 如果列表中嵌套了多层列表,就把第一层列表拉平 - debug: msg: \"{{ var2 | flatten | max }}\" # 将嵌套列表拉平之后取列表中的最大值 - debug: msg: \"{{ var3 | join }}\" # 将列表中的元素连接成一个字符串 - debug: msg: \"{{ var3 | join(',') }}\" # 将列表中的元素以','分割连接成一个字符串 - debug: msg: \"{{ var3 | random }}\" # 从列表中返回一个随机值 - debug: msg: \"{{ var3 | shuffle }}\" # 随机打乱列表元素的顺序 - debug: msg: \"{{ var4 | upper }}\" # 将列表中的每个元素变成纯大写 - debug: msg: \"{{ var4 | lower }}\" # 将列表中的每个元素变成纯小写 - debug: msg: \"{{ var5 | unique }}\" # 去掉列表中重复的元素,重复的元素只留一个 - debug: msg: \"{{ var5 | union(var6) }}\" # 合并列表,重复元素只留一个(并集) - debug: msg: \"{{ var5 | intersect(var6) }}\" # 取出两个列表的交集元素,重复的元素只留一个 变量未定义相关的过滤器--- - hosts: dbserver remote_user: root vars: var1: '' tasks: - debug: msg: \"{{ var0 | default('missf.top') }}\" # 如果变量没有定义则返回一个默认值,如果定义了变量即使变量值为空还是会输出变量值 - debug: msg: \"{{ var1 | default('coding',boolean=true) }}\" # 如果变量未定义或者变量值为空,则返回默认值 - debug: \"{{ var0 | mandatory }}\" # 如果变量未定义,则报出\"Mandatory variable 'var0' not defined\"错误而不是默认错误 常用过滤器--- - hosts: dbserver remote_user: root vars: users: - name: mj age: 15 hobby: - egm - book - name: mk age: 17 hobby: - pq - jk tasks: - debug: msg: \"{{ users | map(attribute='name') | list }}\" # 从users列表中获取到每个元素所共有的某个属性的值,并将这些值组成一个列表 - debug: msg: \"{{ (name == 'missf') | ternary('Mr','Ms') }}\" # 如果name变量的值是missf,那么对应的值则为Mr,否则则为Ms vars: name: 'missf' - debug: msg: \"{{ tg | basename }}\" # 可以获取到一个路径字符串中的文件名 vars: tg: \"/etc/hosts\" - debug: msg: \"{{ win | win_basename }}\" # 可以获取到windows路径字符串中的文件名 vars: win: \"C:\\studio\\missf\" - debug: msg: \"{{ path | realpath }}\" # 可以获取软链接文件所指向的真正文件 vars: path: \"/tmp/linkfile\" - debug: msg: \"{{ path | splitext }}\" # 可以将文件名后缀带有'.'的部分分开 vars: path: \"/etc/yum.conf\" - debug: msg: \"{{ path | splitext | last }}\" # 将字符串以'.'分开后取最后一个 vars: path: \"/etc/yum.conf\" - debug: msg: \"{{ vt | to_uuid }}\" # 为字符串生成uuid vars: vt: \"this is test\" - debug: msg: \"{{ sk | bool }}\" # 字符串内容为'yes','1','True','true'则返回true,内容为其他则返回false vars: sk: \"yes\" - debug: msg: \"{{ ('2016-08-16 12:00:49' | to_datetime) - ('2012-03-25 19:03:15' | to_datetime) }}\" # 使用to_datetime关键字计算时间差,默认转换的字符串的格式必须是'%Y-%m-%d %H:%M:%S' - debug: msg: \"{{ ('20160814'| to_datetime('%Y%m%d')) - ('2012-12-25 19:00:00' | to_datetime) }}\" # 如果对应的字符串不是这种格式,则需要在to_datetime中指定与字符串相同的时间格式,才能正确的转换为时间类型 - debug: msg: \"{{ '123456' | hash('sha1') }}\" # 使用sha1算法对字符串进行哈希 - debug: msg: \"{{ '123456' | password_hash('md5','ffsfsfsfsfscs') }}\" # 使用md5算法加密，指定字符串作为盐值 密码验证示例--- - hosts: dbserver remote_user: root vars_prompt: - name: username prompt: \"input username\" # 用户输入用户名 - name: password prompt: \"input password\" # 用户输入密码 tasks: - debug: msg: \"{{ username | hash('md5') }}\" # 将用户名hash register: username_md5 - debug: msg: \"{{ password | hash('md5') }}\" # 将密码hash register: password_md5 - debug: msg: \"username yes\" when: username_md5.msg == 'fac2db1a64bc2a16887e9bdf17e15f8e' # 通过比对(用户输入的用户名)和(剧本写死的MD5值)确认密码 - debug: msg: \"password yes\" when: password_md5.msg == 'e10adc3949ba59abbe56e057f20f883e'","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的条件判断(12)","slug":"ansible的条件判断(12)","date":"2020-06-08T10:27:28.000Z","updated":"2020-07-14T04:39:19.329Z","comments":true,"path":"post/3d533130.html","link":"","permalink":"https://www.missf.top/post/3d533130.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的条件判断绝大数语言中，都使用if作为条件判断的方法，而在ansible中，条件判断使用关键字when 简单示例使用when关键字指明条件是: ansible_distribution == “CentOS”，这里的ansible_distribution是facts信息中的一个key，我们在调用ansible_distribution变量时并没有为它添加{{}}，这是在when关键字中引用变量时，不需要加{{}}。如果ansible_distribution == &quot;CentOS&quot;这个条件成立，那么就调用debug模块，打印msg的内容，如果不成立则不执行debug模块 # 简单示例 --- - hosts: dbserver remote_user: root tasks: - debug: msg: 'system release is centos' when: ansible_distribution == \"CentOS\" 配合循环进行判断定义条件为item &gt; 1，只有条件成立时item才会被打印，而with_items会循环列表中的值，item变量的值不断变化 --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_items: - 1 - 2 - 3 when: item > 1 条件判断通配符 运算符 条件 结果 == 两个值是否相等 相等则为真 != 两个值是否不相等 不等则为真 &gt; 左边的值大于右边的值 则为真 &lt; 左边的值小于右边的值 则为真 &gt;= 左边的值大于或等于右边的值 则为真 &lt;= 左边的值小于或等于右边的值 则为真 逻辑运算符 运算符 条件 结果 and 当左边与右边同时为真 则返回真 or 当左边与右边有任意一个为真 则返回真 not 对一个操作取反 () 将一组操作包装在一起 逻辑运算和分组示例--- - hosts: dbserver remote_user: root tasks: - debug: msg: 'System release is centos6 or centos7' when: ansible_distribution == \"CentOS\" and (ansible_distribution_major_version == \"6\" or ansible_distribution_major_version == \"7\") 判断模块执行返回的信息我们在执行shell命令时，通常需要获取命令的返回信息，这样才能够根据返回的信息，判断之后的操作如何进行下去 --- - hosts: dbserver remote_user: root tasks: - name: touch file1 shell: \"touch /file1\" register: returnmsg - name: debug file1 debug: msg: \"Command execution successful\" when: returnmsg.rc == 0 # 命令执行成功的返回值中rc的值为0 - name: debug file2 debug: msg: \"Command execution failed\" when: returnmsg.rc != 0 跳过执行遇到的错误有些时候我们的tasks执行到一半时，遇到错误之后就不再继续往下执行了，我们可以使用ignore_errors关键字去跳过这个错误，让剧本继续往下执行 --- - hosts: dbserver remote_user: root tasks: - name: touch file1 shell: \"ls /file123\" register: returnmsg ignore_errors: true - name: debug file1 debug: msg: \"Command execution successful\" when: returnmsg.rc == 0 - name: debug file2 debug: msg: \"Command execution failed\" when: returnmsg.rc != 0 条件判断与testsLinux系统中可以使用一些常用的判断操作，例如使用test命令判断文件或者目录是否存在 test /etc/ echo $? 0 ansible中也有类似用于判断文件和目录的方法，注意这个是判断控制节点上的文件和目录，”is exists“ | “is not exists“ --- - hosts: dbserver remote_user: root vars: testpath: /etc tasks: - debug: msg: \"file exist\" when: testpath is exists # 判断testpath变量这个路径是否存在，存在则为真，打印msg内容 ok: [dbserver] => { \"msg\": \"file exist\" } 判断变量的tests defined:判断变量是否已经定义，已经定义则返回真 undefind: 判断变量是否已经定义，未定义则返回真 none: 判断变量值是否为空，如果变量已经定义，但是变量值为空，则返回真 定义变量f1赋值为test，定义h2但不赋值，debug模块根据对应的条件是否为真打印具体msg内容 --- - hosts: dbserver remote_user: root tasks: vars: f1: 'test' h2: tasks: - debug: msg: 'varf1 is undefined' when: f1 is undefined - debug: msg: 'The variable is defined, but there is no value' when: h2 is none 判断执行结果的tests *success 或 succeeded: *通过任务的返回信息判断任务的执行状态，任务执行成功则返回真 failure 或 failed: 通过任务的返回信息判断任务的执行状态，任务执行失败则返回真 change 或 changed: 通过任务的返回信息判断任务的执行状态，任务执行状态为changed则返回真 skip 或 skipped: 通过任务的返回信息判断任务的执行状态，当任务没有满足条件而被跳过执行时，则返回真 使用shell模块执行一条命令，并且使用register将返回值存进returnmsg变量，如果命令执行报错就跳过继续往下执行，下面再判断这个变量的执行结果 --- - hosts: dbserver remote_user: root tasks: - shell: \"ls /etc/hosts\" register: returnmsg ignore_errors: true - debug: msg: \"success\" when: returnmsg is success - debug: msg: \"failed\" when: returnmsg is failure - debug: msg: \"changed\" when: returnmsg is changed - debug: msg: \"skip\" when: \"returnmsg is skip\" 判断路径的testsfile: 判断路径是否是一个文件，如果是则返回真 directory: 判断路径是否是一个目录，如果是则返回真 link: 判断路径是否是一个软链接，如果是则返回真 mount: 判断路径是否是一个挂载点，如果是则返回真 exists: 判断路径是否存在，如果存在则返回真 判断字符串的testslower: 判断包含字母的字符串中的字母是否是纯小写，如果是则返回真 upper: 判断包含字母的字符串中的字母是否是纯大写，如果是则返回真 判断整除的testseven: 判断数值是否是偶数，如果是则返回真 odd: 判断数值是否是奇数，如果是则返回真 divisibleby(num): 判断是否可以整除指定的数值，如果可以整除则返回真 条件判断与block想要在条件成立时，执行多个任务，我们不需要在每个任务中都加入判断条件，我们可以使用block关键字将多个任务整合成一个块 --- - hosts: dbserver remote_user: root tasks: - shell: \"ls /loo\" ignore_errors: true - block: # 这个block块有两个任务 - debug: msg: \"run command failed\" - file: path: \"/oo\" state: touch when: 2 > 1 # 条件成立就执行block块的任务 block与rescue的错误处理我们在处理某些复杂的任务时，需要使用到错误处理的判断，使我们的playbook更加灵活。例如我需要执行多个任务，这多个任务中只要有一个执行失败，就会触发错误处理，执行我们提前定义好的救援任务进行补救 --- - hosts: dbserver remote_user: root tasks: - block: - shell: \"ls /123\" - debug: msg: \"tcodmf\" - file: path: \"/loo\" state: touch rescue: - debug: msg: \"error\" # 只要block块里面的三个任务有一个执行失败就会执行rescue定义好的任务 block和always的错误处理如果block中的任务执行出错，那么就会执行rescue中的任务，如果block中的任务执行没有出错，那么rescue中的任务就不会执行，但是always中的任务是无论如何都会执行的，不管block中的内容是否出错 --- - hosts: dbserver remote_user: root tasks: - block: - debug: msg: \"echo 123\" - command: cat /etc/hosts | wc -l # command模块不能执行带特殊字符的命令，第一次出错 - debug: msg: \"echo 456\" rescue: - debug: msg: \"echo error1\" - command: cat /etc/hosts | wc -l # command模块不能执行带特殊字符的命令，第二次出错 always: - debug: msg: \"echo error2\" # 最后执行always 条件判断与错误处理我们有时候需要在判断条件成立时，执行退出的指令，使playbook中断执行，这里我们需要使用到fail模块。我们知道，在执行playbook时，如果playbook中的任意一个任务执行失败，playbook都会终止执行，而fail模块就是天生用来执行失败的模块。只要playbook中执行fail模块，playbook就会认为有任务执行失败了。 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"123\" - debug: msg: \"456\" - fail: # 执行fail模块中断playbook执行,后面的任务不再执行 - debug: msg: \"789\" 使用fail模块终止playbook，默认打印”Failed as requested from task”的错误提示，这个我们可以自定义fail模块的错误提示 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"123\" - debug: msg: \"456\" - fail: msg: \"stop operation playbook\" - debug: msg: \"789\" 利用条件判断去控制fail模块的执行--- - hosts: dbserver remote_user: root tasks: - shell: \"echo 'This is a string for testing--error'\" register: return_value # 取到shell模块执行的返回值 - fail: msg: \"stop operation playbook\" when: \"'error' in return_value.stdout\" # 判断字符串是否存在于return_value.stdout这个输出信息 - debug: msg: \"playbook has stopped\" # 由于fail模块执行而中断playbook,这个将不会执行 failed_when关键字--- - hosts: dbserver remote_user: root tasks: - debug: msg: \"123456\" - shell: \"echo 'This is a string for testing--error'\" register: return_value failed_when: '\"error\" in return_value.stdout' # 如果条件成立,那么failed_when就会提示所对应的shell模块执行失败 - debug: msg: \"654321\" # 不会被打印 failed_changed关键字正常情况下，debug模块正常执行的情况下只能是”ok”状态，我们可以使用failed_changed关键字改变执行后的状态定义为changed --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"test message\" changed_when: 2 > 1 changed: [dbserver] => { \"msg\": \"test message\" }","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的循环(11)","slug":"ansible的循环(11)","date":"2020-06-01T02:47:20.000Z","updated":"2020-08-28T03:10:45.990Z","comments":true,"path":"post/167e62f3.html","link":"","permalink":"https://www.missf.top/post/167e62f3.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的循环我们在编写playbook的时候，不可避免的要执行一些重复性操作，比如指定安装软件包，批量创建用户，操作某个目录下的所有文件等。ansible一门简单的自动化语言，所以流程控制、循环语句这些编程语言的基本元素它同样都具备。 Ansible提供了两个用于创建循环的关键字: loop和with_&lt;lookup&gt;，ansible 2.5中添加了loop，但它还不是with_&lt;lookup&gt;的完全替代品。在官方推荐使用loop，但我们现在还可以在大多数用例中使用with_&lt;lookup&gt;，但是随着loop语法的不断改进，with_&lt;lookup&gt;以后可能会失效。 标准循环使用with_items关键字创建一个循环的列表，with_items会把列表的每一条信息，单独放到item变量里面，然后循环打印每次item变量的值 # 方式1 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" with_items: - 1 - 2 - 3 # 方式2 --- - hosts: dbserver remote_user: root tasks: - debug: msg={{ item }} with_items: [1,2,3] # 方式3 --- - hosts: dbserver remote_user: root vars: list: - a - b - c tasks: - debug: msg={{ item }} with_items: '{{ list }}' # 方式4 --- - hosts: dbserver remote_user: root vars: list: [1,2,3] tasks: - debug: msg={{ item }} with_items: '{{ list }}' # 添加多个用户 --- - hosts: dbserver remote_user: root tasks: - name: add server users user: name: \"{{ item }}\" state: present groups: server with_items: - server1 - server2 定义稍微复杂的列表自定义列表中的每一个键值对都是一个对象，我们可以通过对象的属性对应的”键”，获取到对应的”值”，执行下面的playbook之后，mm和nn都会被输出 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item.name }}\" with_items: - { name: mm, age: 23} - { name: nn, age: 24} ansible-playbook item.yaml # 执行playbook ok: [dbserver] => (item={u'age': 23, u'name': u'mm'}) => { \"msg\": \"mm\" } ok: [dbserver] => (item={u'age': 24, u'name': u'nn'}) => { \"msg\": \"nn\" } 利用循环创建多个文件# 没学习循环之前可能这样创建多个文件 --- - hosts: dbserver remote_user: root gather_facts: no tasks: - file: path: '/opt/a' state: touch - file: path: '/opt/b' state: touch - file: path: '/opt/c' state: touch - file: path: '/opt/d' state: touch # 使用循环的方式 --- - hosts: dbserver remote_user: root gather_facts: no vars: dirs: - '/opt/a' - '/opt/b' - '/opt/c' - '/opt/d' tasks: - file: path: '{{ item }}' state: touch with_items: '{{ dirs }}' 利用循环多次调用模块不使用循环的情况下调用模块，返回的信息是这样的 --- - hosts: dbserver remote_user: root tasks: - shell: 'ls /etc' register: returnvalue - debug: var: returnvalue ansible-playbook item.yaml ok: [dbserver] => { \"returnvalue\": { \"changed\": true, \"cmd\": \"ls /etc\", \"delta\": \"0:00:00.025062\", \"end\": \"2020-06-02 01:06:34.741709\", \"failed\": false, \"rc\": 0, \"start\": \"2020-06-02 01:06:34.716647\", \"stderr\": \"\", \"stderr_lines\": [],这里省略...... } 我们使用循环重复调用了shell模块两次，分别执行了两条命令，然后将shell模块的返回值存放到了returnvalue变量中，最后使用debug模块输出了returnvalue变量的值。当使用了循环之后，每次shell模块执行后的返回值都会放入一个名为results的序列中，其实，results也是一个返回值，当模块中使用了循环时，模块每次执行的返回值都会追加存放到results这个返回值中，所以，我们可以通过results关键字获取到每次模块执行后的返回值 --- - hosts: dbserver remote_user: root tasks: - shell: '{{ item }}' with_items: - 'ls /etc' - 'ls /var' register: returnvalue - debug: var: returnvalue ansible-playbook item.yaml ok: [dbserver] => { \"returnvalue\": { \"changed\": true, \"msg\": \"All items completed\", \"results\": [ { \"ansible_loop_var\": \"item\", \"changed\": true, \"cmd\": \"ls /etc\", \"delta\": \"0:00:00.026532\", \"end\": \"2020-06-02 01:08:22.264277\", \"failed\": false, \"invocation\": { 这里省略...... } 先使用循环重复的调用了shell模块，然后将shell模块每次执行后的返回值注册到了变量returnvalue中，之后，在使用debug模块时，通过返回值results获取到了之前每次执行shell模块的返回值(shell每次执行后的返回值已经被放入到item变量中)，最后又通过返回值stdout获取到了每次shell模块执行后的标准输出 --- - hosts: dbserver remote_user: root tasks: - shell: '{{ item }}' with_items: - 'ls /etc' - 'ls /var' register: returnvalue - debug: msg: '{{ item.stdout }}' with_items: '{{ returnvalue.results}}' 打印序列中的序列with_items块序列下面有一个自定义列表[1,2,3]，执行playbook会循环打印[1,2,3]列表里的每一个值 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" with_items: [1,2,3] ok: [dbserver] => (item=1) => { \"msg\": 1 } ok: [dbserver] => (item=2) => { \"msg\": 2 } ok: [dbserver] => (item=3) => { \"msg\": 3 } with_items块序列下面有两个自定义列表，执行playbook还是会循环打印两个列表里的每一个值 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" with_items: - [1,2,3] - [4,5,6] ok: [dbserver] => (item=1) => { \"msg\": 1 } ok: [dbserver] => (item=2) => { \"msg\": 2 } ok: [dbserver] => (item=3) => { \"msg\": 3 } ok: [dbserver] => (item=4) => { \"msg\": 4 } ok: [dbserver] => (item=5) => { \"msg\": 5 } ok: [dbserver] => (item=6) => { \"msg\": 6 } 当with_items块序列下面有两个自定义的列表时，我们如何让debug模块将每个小列表作为一个小整体输出，而不应该输出小列表中的每个元素呢？我们可以使用with_list关键字，替换上例playbook中的with_items关键字。 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" with_list: - [1,2,3] - [4,5,6] ok: [dbserver] => (item=[1, 2, 3]) => { # with_list块序列只会循环最外层的每一项,而with_items则是循环处理每一个元素 \"msg\": [ 1, 2, 3 ] } ok: [dbserver] => (item=[4, 5, 6]) => { \"msg\": [ 4, 5, 6 ] } 元素对齐合并with_together可以将两个列表中的元素对齐合并，如果两个列表元素不一致，缺少的元素值为null --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_together: - [1,2,3] - [a,b,c] ok: [dbserver] => (item=[1, u'a']) => { \"msg\": [ 1, \"a\" ] } ok: [dbserver] => (item=[2, u'b']) => { \"msg\": [ 2, \"b\" ] } ok: [dbserver] => (item=[3, u'c']) => { \"msg\": [ 3, \"c\" ] } 元素两两组合需求: 我们需要创建三个目录，这三个目录下面都有相同的子目录，我们使用ansible-playbook的方式去循环创建，需要用到with_cartesian这个关键字 # 需要创建的目录结构如下: dir1/sofm dir1/bin dir2/sofm dir2/bin dir3/sofm dir3/bin --- - hosts: dbserver remote_user: root tasks: - file: state: directory path: '/{{ item[0] }}/{{ item[1] }}' with_cartesian: - [dir1,dir2,dir3] - [sofm,bin] 执行playbook会将两个列表的元素两两组合，使用item[0]和item[1]来获取每一次循环的值 PLAY [dbserver] ****************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] TASK [file] ********************************************************************************************************************** changed: [dbserver] => (item=[u'dir1', u'sofm']) changed: [dbserver] => (item=[u'dir1', u'bin']) changed: [dbserver] => (item=[u'dir2', u'sofm']) changed: [dbserver] => (item=[u'dir2', u'bin']) changed: [dbserver] => (item=[u'dir3', u'sofm']) changed: [dbserver] => (item=[u'dir3', u'bin']) PLAY RECAP *********************************************************************************************************************** dbserver : ok=2 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 列表元素添加索引编号使用with_indexed_items关键字可以为列表的每一个元素添加索引编号，索引编号从0开始，我们可以在出来列表每一项元素的时候获取到索引编号 --- - hosts: dbserver remote_user: root tasks: - debug: msg: 'index is {{ item[0] }},value is {{ item[1] }}' with_indexed_items: - index1 - index2 - index3 ok: [dbserver] => (item=[0, u'index1']) => { \"msg\": \"index is 0,value is index1\" } ok: [dbserver] => (item=[1, u'index2']) => { \"msg\": \"index is 1,value is index2\" } ok: [dbserver] => (item=[2, u'index3']) => { \"msg\": \"index is 2,value is index3\" } 生成数字序列假如需要在管理节点创建dir2,dir4,dir6这样的目录，我们该如何使用循环去创建呢，这里就需要使用到with_sequence这个关键字去生成数字序列。debug模块被调用了4次，从2开始，到8结束，每一次增加2(步长)，看到这是不是有了Python的感觉呢？ --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_sequence: start=2 end=8 stride=2 ok: [dbserver] => (item=2) => { \"msg\": \"2\" } ok: [dbserver] => (item=4) => { \"msg\": \"4\" } ok: [dbserver] => (item=6) => { \"msg\": \"6\" } ok: [dbserver] => (item=8) => { \"msg\": \"8\" } 创建dir2,dir4,dir6这样不连续的目录 --- - hosts: dbserver remote_user: root tasks: - file: path: /dir{{ item }} state: directory with_sequence: start=2 end=6 stride=2 输出更简单的连续序列--- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_sequence: count=5 注意: 当我们不指定start的值时，start的值默认为1，但是当end的值小于start时则必须指定stride，而且stride的值必须是负数 返回一个随机值使用with_random_choice这个关键字可以让我们从一个列表的多个值中随机返回一个值 --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_random_choice: - qwe - rtd - fdv - oki ok: [dbserver] => (item=oki) => { \"msg\": \"oki\" # 随机返回列表中的一个值 } 使用循环去操作字典这里我们学习一个叫with_dict的字典关键字，下面来看看字典的使用场景。 定义一个users变量，users有两个用户，我们使用with_dict关键字处理这个字典格式的变量 --- - hosts: dbserver remote_user: root vars: users: alix: feom boo: mair tasks: - debug: msg: '{{ item }}' with_dict: '{{ users }}' ok: [dbserver] => (item={'value': u'feom', 'key': u'alix'}) => { \"msg\": { \"key\": \"alix\", # users变量经过with_dict处理之后，键值对分别被放入key和value关键字中 \"value\": \"feom\" } } ok: [dbserver] => (item={'value': u'mair', 'key': u'boo'}) => { \"msg\": { \"key\": \"boo\", # 我们可以通过key关键字和value关键字分别获取到字典中键值对的键和值 \"value\": \"mair\" } } 字典定义和取值--- - hosts: dbserver remote_user: root vars: users: alix: name: feom gender: female phone: 155464615 boo: name: mair gender: male phone: 179444684 tasks: - debug: msg: '{{ item }} alix phone is {{ item.value.phone }}' # 使用item.value.phone的方法取某一项的值 with_dict: '{{ users }}' ok: [dbserver] => (item={'value': {u'gender': u'female', u'name': u'feom', u'phone': 155464615}, 'key': u'alix'}) => { \"msg\": \"{'key': u'alix', 'value': {u'gender': u'female', u'name': u'feom', u'phone': 155464615}} alix phone \\\\n is 155464615\" } ok: [dbserver] => (item={'value': {u'gender': u'male', u'name': u'mair', u'phone': 179444684}, 'key': u'boo'}) => { \"msg\": \"{'key': u'boo', 'value': {u'gender': u'male', u'name': u'mair', u'phone': 179444684}} alix phone \\\\n is 179444684\" } 遍历每一项子元素users变量列表中有两个块序列，这两个块序列分别代表两个用户，bob和alice，变量users经过with_subelements处理时还指定一个hobby属性，hobby属性正是users变量中每个用户的子属性 --- - hosts: dbserver remote_user: root vars: users: - name: bob gender: male hobby: - skateboard - videogame - name: alice gender: female hobby: - music - name: qwe hobby: - da tasks: - debug: msg: \"{{ item }}\" with_subelements: - \"{{ users }}\" - hobby 上面的playbook执行后得到如下结果，我们在使用with_subelements处理变量users时指定了hobby属性，hobby属性中的每一个子元素都被当做一个整体，而其他的子元素作为另一个整体，组成了键值对 ok: [dbserver] => (item=[{u'gender': u'male', u'name': u'bob'}, u'skateboard']) => { \"msg\": [ { \"gender\": \"male\", \"name\": \"bob\" }, \"skateboard\" ] } ok: [dbserver] => (item=[{u'gender': u'male', u'name': u'bob'}, u'videogame']) => { \"msg\": [ { \"gender\": \"male\", \"name\": \"bob\" }, \"videogame\" ] } ok: [dbserver] => (item=[{u'gender': u'female', u'name': u'alice'}, u'music']) => { \"msg\": [ { \"gender\": \"female\", \"name\": \"alice\" }, \"music\" ] } ok: [dbserver] => (item=[{u'name': u'qwe'}, u'da']) => { \"msg\": [ { \"name\": \"qwe\" }, \"da\" ] } 获取控制节点的文件内容我想要获取控制节点上的几个文件的内容，那么可以使用with_file关键字，循环获取到文件的内容，这里hosts指定的是dbserver这个管理节点，但是无论管理节点写的是什么都不影响，因为我们读取的是管理节点的文件 --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_file: - /etc/passwd - /etc/hosts ok: [dbserver] => (item=root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin sync:x:5:0:sync:/sbin:/bin/sync shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown halt:x:7:0:halt:/sbin:/sbin/halt mail:x:8:12:mail:/var/spool/mail:/sbin/nologin operator:x:11:0:operator:/root:/sbin/nologin games:x:12:100:games:/usr/games:/sbin/nologin ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin nobody:x:99:99:Nobody:/:/sbin/nologin systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin dbus:x:81:81:System message bus:/:/sbin/nologin polkitd:x:999:998:User for polkitd:/:/sbin/nologin sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin postfix:x:89:89::/var/spool/postfix:/sbin/nologin ntp:x:38:38::/etc/ntp:/sbin/nologin) => { \"msg\": \"root:x:0:0:root:/root:/bin/bash\\nbin:x:1:1:bin:/bin:/sbin/nologin\\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\\nadm:x:3:4:adm:/var/adm:/sbin/nologin\\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\\nsync:x:5:0:sync:/sbin:/bin/sync\\nshutdown:x:6:0:shutdown:/sbin:/sbin/shutdown\\nhalt:x:7:0:halt:/sbin:/sbin/halt\\nmail:x:8:12:mail:/var/spool/mail:/sbin/nologin\\noperator:x:11:0:operator:/root:/sbin/nologin\\ngames:x:12:100:games:/usr/games:/sbin/nologin\\nftp:x:14:50:FTP User:/var/ftp:/sbin/nologin\\nnobody:x:99:99:Nobody:/:/sbin/nologin\\nsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologin\\ndbus:x:81:81:System message bus:/:/sbin/nologin\\npolkitd:x:999:998:User for polkitd:/:/sbin/nologin\\nsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin\\npostfix:x:89:89::/var/spool/postfix:/sbin/nologin\\nntp:x:38:38::/etc/ntp:/sbin/nologin\" } ok: [dbserver] => (item=127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6) => { \"msg\": \"127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4\\n::1 localhost localhost.localdomain localhost6 localhost6.localdomain6\" } 匹配控制节点的文件我们可以通过通配符去匹配控制节点上的文件，这里需要使用到with_fileglob这个关键字。注意with_fileglob只能是匹配到文件 --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_fileglob: - /etc/* - /tmp/* # 这里写成/dir/的话是匹配不到文件的，需要使用*通配符 ok: [dbserver] => (item=/etc/fstab) => { \"msg\": \"/etc/fstab\" } ok: [dbserver] => (item=/etc/crypttab) => { \"msg\": \"/etc/crypttab\" } ok: [dbserver] => (item=/etc/mtab) => { \"msg\": \"/etc/mtab\" } ok: [dbserver] => (item=/etc/resolv.conf) => { \"msg\": \"/etc/resolv.conf\" } ok: [dbserver] => (item=/etc/magic) => { \"msg\": \"/etc/magic\" }...... ansible的loop循环在2.5版本之前的ansible中，大多数人习惯使用”with_X”风格的关键字操作循环，从2.6版本开始，官方开始推荐使用”loop”关键字代替”with_X”风格的关键字。现在就来聊聊这种新的方式，以便能够更好的从老版本的使用习惯过渡过来。 loop标准循环--- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" loop: - abc - cde loop循环安装软件--- - hosts: dbserver remote_user: root tasks: - name: install packages yum: name: \"{{ item }}\" state: latest loop: - rsync - sl - psmisc loop批量创建用户--- - hosts: dbserver remote_user: tasks: - name: \"add user\" user: name: \"{{ item.name }}\" state: present groups: \"{{ item.groups }}\" loop: - {name: \"abc\",groups: \"root\"} - {name: \"cde\",groups: \"root\"}","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的变量(10)","slug":"ansible的变量(10)","date":"2020-05-28T02:13:41.000Z","updated":"2020-08-28T03:10:00.069Z","comments":true,"path":"post/4736d6b2.html","link":"","permalink":"https://www.missf.top/post/4736d6b2.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的变量在ansible中使用变量，能让我们的工作变得更加灵活 变量定义规则变量名应该由字母、数字、下划线组成 变量名需要以字母开头 ansible内置的关键字不能作为变量名 在playbook中使用变量使用vars关键字定义名为package1值为nginx的变量，在task中使用进行调用 --- - hosts: all vars: package1: nginx remote_user: root tasks: - name: task1 yum: name: \"{{ package1 }}\" state: installed 使用块序列化语法定义变量vars: - testvar1: a1 - testvar2: b2 使用属性的方式定义变量--- - hosts: all remote_user: root vars: nginx: # 定义两个变量 conf80: /etc/nginx/conf.d/80.conf conf8080: /etc/nginx/conf.d/8080.conf tasks: - name: task1 file: path: \"{{ nginx.conf80 }}\" # 第一种调用方法 state: touch - name: task2 file: path: \"{{ nginx['conf8080']}}\" # 第二种调用方法 注意: 如果引用变量时，变量处于开头的位置，那么变量必须要用双引号引起来，否则语法会报错 - name: task2 file: path: \"{{ nginx['conf8080']}}\" # 引用这种变量处于开头位置的必须使用引号引起来 - name: task2 file: path: /root/{{ nginx['conf8080']}} # 这样的不用 引入文件内的变量创建nginx_vars.yaml文件，直接在文件中以自己喜欢的方式定义变量 testvar1: zxc testvar2: qwe - testvar3: rty - testvar4: poi nginx: conf1: /usr/local/nginx/conf/nginx1.conf conf2: /usr/local/nginx/conf/nginx2.conf 在playbook中以vars_files关键字引入文件中的变量 --- - hosts: all remote_user: root vars: # vars关键字和vars_files关键字可以同时使用 - /root/vars.yaml vars_files: - /playbook/nginx_vars.yaml tasks: - name: task1 file: path: \"{{ nginx.conf80 }}\" state: touch - name: task2 file: path: \"{{ nginx['conf8080']}}\" 变量与setup模块前面我们说过在执行playbook的时候，默认都会运行一个名为Gathering Facts的任务，这个任务会收集管理节点的相关信息(例如管理节点的IP地址，主机名，系统版本，硬件配置等信息)，这些被收集到的信息都会保存在对应的变量中，我们想要使用这些信息时，可以获取对应的变量，从而使用这些信息。关于setup模块具体查看前面ansible模块学习 查看从管理节点收集到的所有相关信息ansible all -m setup # 由于返回信息的比较多，这里不作示例 查看管理节点的内存使用情况ansible all -m setup -a 'filter=ansible_memory_mb' 在管理节点创建自定义变量除了ansible默认收集的信息以外，我们还能够在管理节点写入一些自定义变量，这些自定义变量也是可以被setup模块收集到 首先在管理节点创建自定义变量的文件hello.fact，此类文件必须以*.fact命名 # 管理节点 mkdir -p /etc/ansible/facts.d vim /etc/ansible/facts.d/hello.fact [info] name: mwj age: 24 # 控制节点 ansible dbserver -m setup -a \"filter=ansible_local\" # 使用ansible_local关键字过滤信息得到管理节点的自定义变量 10.10.110.122 | SUCCESS => { \"ansible_facts\": { \"ansible_local\": { \"hello\": { \"info\": { \"age\": \"24\", \"name\": \"mwj\" } } }, \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false } 注意: 管理节点上的hello.fact文件必须不是可执行文件，不然这个文件不会被成功读取，具体可查看ansible官方文档有详细说明。在管理节点的/etc/ansible/facts.d/这个目录是使用ansible_local关键字过滤时的默认路径，如果想要自定义路径可以使用fact_path关键字定义 ansible dbserver -m setup -a \"fact_path=/tmp/facts.d/\" 变量与debug模块debug模块是帮我们进行调试的，可以把对我们有用的信息输出到控制台上，以便能够定位问题 playbook中使用debug模块--- - hosts: all remote_user: root tasks: - name: touch file file: path: /tmp/debug.txt state: touch - name: debug demo debug: msg: this is debug info,File created successfully 运行playbook模块查看信息如下图所示，在touch文件之后会输出我们定义好的debug信息 PLAY [all] *********************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] ok: [webserver] TASK [touch file] **************************************************************************************************************** changed: [webserver] changed: [dbserver] TASK [debug demo] **************************************************************************************************************** ok: [webserver] => { \"msg\": \"this is debug info,File created successfully\" } ok: [dbserver] => { \"msg\": \"this is debug info,File created successfully\" } PLAY RECAP *********************************************************************************************************************** dbserver : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 webserver : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 使用debug模块输出变量信息debug模块除了能够使用msg参数输出自定义的信息，还能够使用var参数直接输出变量中的信息 --- - hosts: all remote_user: root vars: testvar: this is a debug variable tasks: - name: debug demo debug: var: testvar 使用debug模块的msg参数一样可以打印变量信息 --- - hosts: all remote_user: root tasks: - name: debug demo debug: msg: \"Remote host memory information: {{ ansible_memory_mb }}\" 执行结果如下 PLAY [all] *********************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] ok: [webserver] TASK [debug demo] **************************************************************************************************************** ok: [webserver] => { \"msg\": \"Remote host memory information: {u'real': {u'total': 216, u'used': 213, u'free': 3}, u'swap': {u'cached': 0, u'total': 1023, u'free': 1022, u'used': 1}, u'nocache': {u'used': 163, u'free': 53}}\" } ok: [dbserver] => { \"msg\": \"Remote host memory information: {u'real': {u'total': 216, u'used': 212, u'free': 4}, u'swap': {u'cached': 0, u'total': 1023, u'free': 1013, u'used': 10}, u'nocache': {u'used': 170, u'free': 46}}\" } PLAY RECAP *********************************************************************************************************************** dbserver : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 webserver : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 ansible_memory_mb其中其实包含了 “nocache”、”real”、 “swap”三个部分的信息，我们只想获得”real”部分的信息，在playbook中引用变量时可以使用如下示例: msg: \"Remote host memory information: {{ ansible_memory_mb.real }}\" msg: \"Remote host memory information: {{ ansible_memory_mb['real'] }}\" 注册变量ansible的模块运行之后都会返回一些返回值，只是默认情况下，这些返回值并不会显示而已，我们可以把这些返回值写入到某个变量中，这样我们就能够通过引用对应的变量从而获取到这些返回值了，这种将模块的返回值写入到变量中的方法被称为注册变量 下面这个playbook有两个任务，第一个任务使用shell模块执行了一条命令，然后在这个任务下使用register注册了一个testvar的变量，第二个任务是使用debug模块的var参数打印这个变量，最后输出shell模块的返回值 --- - hosts: dbserver remote_user: root tasks: - name: test shell shell: \"echo test > /tmp/test\" register: testvar - name: shell module return values debug: var: testvar playbook执行的结果如下图，返回的是一个json格式的数据，我们还可以使用&lt;!–￼11–&gt;或者&lt;!–￼12–&gt;指定key来获取某一项特定的值 PLAY [dbserver] ****************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] TASK [test shell] **************************************************************************************************************** changed: [dbserver] TASK [shell module return values] ************************************************************************************************ ok: [dbserver] => { \"testvar\": { \"changed\": true, \"cmd\": \"echo test > /tmp/test\", \"delta\": \"0:00:00.025987\", \"end\": \"2020-06-02 22:34:36.185101\", \"failed\": false, \"rc\": 0, \"start\": \"2020-06-02 22:34:36.159114\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": [] } } PLAY RECAP *********************************************************************************************************************** dbserver : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 如果你想要查看模块对应的返回值，可以先查找官方手册，但并不是所有模块的官方手册中都对模块的返回值进行了描述，你可以自己去官网查看模块的返回值，这些返回值不仅仅能够用于输出，通常我们会利用到这些返回值，比如通过模块的返回值决定之后的一些动作，所以注册变量在playbook中还是会被经常用到的，在之后的文章中我们会给出示例 变量与用户交互信息在运行shell脚本时，有些时候需要用户输入信息，脚本再根据用户输入的信息决定下一步的动作，这种交互是必须的。我们也可以在playbook中实现这种交互，首先提示用户输入信息，然后将用户输入的信息存放到指定的变量中，当我们需要使用这些信息时，只要引用对应的变量即可 下面我们使用vars_prompt关键字定义了两个变量，变量名为别为your_name和your_age，变量下面是提示用户输入时的信息 --- - hosts: dbserver remote_user: root vars_prompt: - name: \"your_name\" prompt: \"what is your name\" - name : \"your_age\" prompt: \"how old are you\" tasks: - name: output vars debug: msg: your name is {{your_name}},you are {{your_age}} years old. playbook执行如下图，提示用户输入信息时默认是不显示信息的，这和输入密码的场景类似 what is your name: how old are you: PLAY [dbserver] ****************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] TASK [output vars] ************************************************************************************************************** ok: [dbserver] => { \"msg\": \"your name is mwj,you are 24 years old.\" } PLAY RECAP *********************************************************************************************************************** dbserver : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 如果想要用户输入信息时显示信息内容，可以将private参数设置为no --- - hosts: dbserver remote_user: root vars_prompt: - name: \"your_name\" prompt: \"what is your name\" - name : \"your_age\" prompt: \"how old are you\" private: no # 显示用户输入的内容 tasks: - name: output vars debug: msg: your name is {{your_name}},you are {{your_age}} years old. 我们还可以为提示信息设置默认值，如果用户不输入任何信息就将默认值赋予变量，如果用户输入信息，就把输入的信息赋值给变量 --- - hosts: dbserver remote_user: root vars_prompt: - name: \"your_name\" prompt: \"what is your name\\n\" private: no default: mike tasks: - name: output vars debug: msg: your name is {{your_name}} 上面playbook的执行过程如下，中括号内的内容是我们设置的默认值，如果用户直接回车那就将中括号内的内容直接赋值给变量 what is your name [mike]: mwj PLAY [dbserver] ****************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] TASK [output vars] ************************************************************************************************************** ok: [dbserver] => { \"msg\": \"your name is mwj\" } PLAY RECAP *********************************************************************************************************************** dbserver : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 通过命令行传入变量我们可以在执行playbook时直接传入需要使用到的变量。编写一个playbook，打印一个passwd的变量 --- - hosts: dbserver remote_user: root tasks: - name: \"passing in variables from the command line\" debug: msg: \"{{ passwd }}\" 执行playbook时传入变量ansible-playbook --extra-vars \"passwd=mdf123456\" passwd.yaml # --extra-vars参数可以简写成-e，还可以一次性传入多个变量，用空格隔开 ansible-playbook -e \"passwd=mdf123456 username=ewe\" passwd.yaml 注意: 如果playbook中并没有定义passwd变量，在执行playbook时也没有传入passwd变量，则会报错。如果在playbook中事先定义好了passwd变量，在执行时再次传入名字相同的变量，最终还是以传入的变量值为准，命令行传入的变量的优先级要高于playbook中的变量。 不仅ansible-playbook可以使用-e传递变量，ansible命令行一样可以，在执行ad-hoc命令时可以使用下面的方法传入变量 ansible dbserver -e \"name=mwj\" -m shell -a \"echo my name in {{ name }}\" json格式传入变量除了以键值对的方式传入变量，我们还可以传入json格式的变量 ansible-playbook passwd.yaml -e '{\"username\":\"mwj\",\"passwd\":\"123456\"}' ansible-playbook passwd.yaml -e '{\"countlist\":[\"one\",\"two\",\"three\",\"four\"]}' # {{countlist[0]}}或{{countlist.0}}引用变量 执行playbook时传入变量文件编写变量文件，可以是json格式或者yaml格式的文件 namevar: mwj countlist: - one - two - three - four playbook内容调用变量 --- - hosts: dbderver remote_user: root tasks: - name: \"name\" debug: msg: \"{{ namevar }} {{ countlist[0] }}\" 命令行传入对应的文件，使用@符号加上变量文件的路径，变量文件中的所有变量都可以在playbook中引用 ansible-playbook test.yaml -e '@/ansible/var1' 在主机清单中配置变量在主机清单中，可以配置我们的管理节点，也可以将部分管理节点分为一组，其实，在配置清单时还可以为主机或主机组设置变量 主机变量在主机清单中配置变量时，可以同时为管理节点配置对应的变量，当操作这个主机时，即可直接使用对应的变量，而其他主机不能引用到这个变量 # ini风格 dbserver ansible_host=10.1.1.70 name: mwj age: 24 # yaml风格 all: children: server: hosts: dbserver: ansible_host: 10.10.110.122 ansible_port: 22 name: mwj age: 24 webserver: ansible_host: 10.10.110.123 ansible_port: 22 可以在命令行引用主机变量，也可以在playbook中引用主机变量 ansible dbserver -m shell -a 'echo {{name}}' 使用层级关系定义更复杂的主机变量 all: children: server: hosts: dbserver: ansible_host: 10.10.110.122 ansible_port: 22 name: n1: mike n2: masha n3: laki # 引用时使用{{ name.n1 }}或{{ name['n1'] }} 主机组变量 在主机清单中，我们可以将多个主机分为一组，这样方便我们同时去操作同一组的管理节点，我们可以为这个主机组定义变量，组内的所有主机都可以使用 # ini风格 [webserver] web01 ansible_host: 10.10.110.121 web02 ansible_host: 10.10.110.122 web03 ansible_host: 10.10.110.123 [webserver:vars] path=\"/usr/local/nginx/html/\" user=\"root\" # yaml格式 all: children: server: hosts: dbserver: ansible_host: 10.10.110.122 ansible_port: 22 webserver: ansible_host: 10.10.110.123 ansible_port: 22 vars: user: \"root\" path: \"/usr/local/nginx/html/\" set_fact定义变量set_fact是一个模块，我们可以通过set_fact模块在tasks中定义变量testvar1，然后打印这个变量 --- - hosts: dbserver remote_user: root tasks: - set_fact: testvar1: mid - debug: msg: \"{{ testvar1 }}\" set_fact定义变量的特殊性通过set_fact模块创建的变量还有一个特殊性，过set_fact创建的变量就像主机上的facts信息一样，可以在之后的play中被引用。而我们使用vars关键字创建的变量则不能被其他playbook所引用到。 下面这个playbook有两个play，第一个play中有两个变量分别是ts1和ts2，它们分别用vars和set_fact定义，只有使用set_fact定义的ts2变量，才能被下面这个play所引用，而使用vars定义的ts1变量则不能被下面的play所引用。 --- - hosts: dbserver remote_user: root vars: ts1: team1 tasks: - set_fact: ts2: team2 - debug: msg: \"{{ ts1 }}---{{ ts2 }}\" - hosts: webserver remote_user: root tasks: - name: get ts1 # 这里引用会报错 debug: msg: \"{{ ts1 }}\" - name: get ts2 debug: msg: \"{{ ts2 }}\" 注意: set_fact变量类似于管理节点的全局变量，可以跨play获取变量，注册变量也能被之后的play所引用。 内置变量除了我们各种各样的定义变量之外，ansible还有一些内置的变量供我们使用，这些内置变量的变量名是被ansible所保留的，我们定义变量时不能使用这些变量名。 内置变量ansible_version查看ansible的版本 ansible all -m debug -a 'msg={{ansible_version}}' 内置变量hostvarshostvars可以帮助我们在操作当前管理节点时获取到其他管理节点中的信息。下面playbook有两个play，第一个没有任何task，只是将webserver主机的信息收集起来，供后面的play调用。第二个play则是使用了debug模块打印了webserver的内置变量hostvars，输出了webserver的IP地址，这就是在操作dbserver管理节点时获取了webserver管理节点的信息。 --- - name: \"gather facts of webserver\" hosts: webserver remote_user: root - name: \"get facts webserver\" hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ hostvars['webserver'].ansible_ens32.ipv4 }}\" # 如果没有第一个play，在执行时调用[Gathering Facts]任务，将webserver的信息收集起来，后面dbserver调用这个变量就会报错 内置变量inventory_hostname通过inventory_hostname变量可以获取到管理节点的当前主机名称，注意这个不是指Linux系统的主机名，而是对应管理节点在控制节点的主机清单中的配置名称。 # 主机清单 [abc] 10.10.110.122 dbserver ansible_host: 10.10.110.123 使用内置变量inventory_hostname获取各个主机的对应的主机名 ansible abc -m debug -a 'msg={{inventory_hostname}}' 10.10.110.122 | SUCCESS => { \"msg\": \"10.10.110.122\" } dbserver | SUCCESS => { \"msg\": \"dbserver\" } # 定义是IP则返回IP，定义是别名则返回别名 内置变量inventory_hostname_short与内置变量inventory_hostname类似，通过inventory_hostname_short也可以获取当前play操作的管理节点在清单中对应的名称，但是这个名称更加简短， [abc] 10.10.110.122 dbserver.com ansible_host=10.10.110.123 按上面主机清单的配置，我们可以使用inventory_hostname_short获取到管理节点的简短名称 ansible all -m debug -a 'msg={{inventory_hostname_short}}' 10.10.110.122 | SUCCESS => { \"msg\": \"10\" } dbserver.com | SUCCESS => { \"msg\": \"dbserver\" } # 可以看到无论是IP还是主机名，inventory_hostname_short都会取得主机名中第一个\".\"之前的字符作为主机的简短名称 内置变量play_hosts通过内置变量play_hosts可以获取到当前play所操作的所有管理节点的主机名列表 --- - hosts: 10.10.110.122,dbserver.com remote_user: root tasks: - name: debug debug: msg: \"{{ play_hosts }}\" # 返回的是所操作的所有管理节点的主机名列表 ok: [10.10.110.122] => { \"msg\": [ \"10.10.110.122\", \"dbserver.com\" ] } ok: [dbserver.com] => { \"msg\": [ \"10.10.110.122\", \"dbserver.com\" ] } 内置变量inventory_dir我们可以通过inventory_dir变量获取到ansible主机中清单文件的存放路径 ansible all -m debug -a 'msg={{inventory_dir}}' 10.10.110.122 | SUCCESS => { \"msg\": \"/etc/ansible\" } dbserver.com | SUCCESS => { \"msg\": \"/etc/ansible\" } 重新加载变量文件我们先来看一个小示例。假如playbook中有三个任务，第一个任务调用了控制节点的一个变量文件，第二个任务在变量文件中新增了一个变量，第三个任务在变量文件中引用新增的那个变量，看看结果会如何。 cat /root/playbook/var_file.yaml # 变量文件已有v1变量 v1: 111 --- - hosts: master remote_user: root tasks: vars_files: - /root/playbook/var_file.yaml tasks: - debug: msg: \"{{ v1 }}\" - lineinfile: path: \"/root/playbook/var_file.yaml\" line: \"v2: 222\" # 往变量文件新增v2变量 - debug: msg: \"{{ v1 }},{{ v2 }}\" # 输出v1和v2变量,这里输出v2变量会出错 fatal: [master]: FAILED! => {\"msg\": \"The task includes an option with an undefined variable. The error was: 'v2' is undefined\\n\\nThe error appears to be in '/root/playbook/include.yaml': line 13, column 5, but may\\nbe elsewhere in the file depending on the exact syntax problem.\\n\\nThe offending line appears to be:\\n\\n line: \\\"v2: 222\\\"\\n - debug:\\n ^ here\\n\"} 上面的示例中，其实v2变量已经成功添加到变量文件中了，但是由于我们是先读取了变量文件，再写入v2变量到文件，这时候我们没有重新读取变量文件，那么就会报错v2变量未定义了，我们可以使用include_vars关键字从新加载变量文件。 --- - hosts: master remote_user: root tasks: vars_files: - /root/playbook/var_file.yaml tasks: - debug: msg: \"{{ v1 }}\" - lineinfile: path: \"/root/playbook/var_file.yaml\" line: \"v2: 222\" - include_vars: \"/root/playbook/var_file.yaml\" # 重新加载变量文件 - debug: msg: \"{{ v1 }},{{ v2 }}\" # 这时候输出v2变量就不会出错","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的tags(9)","slug":"ansible的tags(9)","date":"2020-05-27T02:38:40.000Z","updated":"2020-08-28T03:08:29.174Z","comments":true,"path":"post/dd3a7968.html","link":"","permalink":"https://www.missf.top/post/dd3a7968.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的tags用法我们学习ansible，以后都是要编写各种各样的playbook的。假如我们有一天，写了一个很长很长的playbook，其中包含了非常多的任务，这其实没有什么问题，但是我有时候可能只是需要执行这个playbook的一部分任务而已，而非每一次都执行playbook的全部任务，这个时候我们可以借助tags实现这个需求 --- - hosts: all remote_user: root tasks: - name: task1 file: path: /tmp/task1 state: touch tags: t1 - name: task2 file: path: /tmp/task2 state: touch tags: t2 上面定义了两个task任务，每个任务有自己的tags，我们可以在执行playbook时借助标签指定只执行那些任务，而忽略其他任务 ansible-playbook --tags=t2 testtags.yaml # 只执行t2标签的task任务 ansible-playbook --skip-tags=t1 testtags.yaml # 跳过t1标签任务，其他的任务都会执行 tags的三种语法语法一: tags: - t1 - t2 语法二: tags: t1,t2 语法三: tags: ['t1','t2'] 我们可以为一个任务添加多个标签,下面两个task任务都有一个共同的tag1标签，当执行时指定tag1标签，下面两个任务都会执行 --- - hosts: all remote_user: root tasks: - name: task1 file: path: /tmp/task1 state: touch tags: t1,tag1 - name: task2 file: path: /tmp/task2 state: touch tags: ['t2','tag1'] 具有共同标签的任务，可以将共同标签从task中提取出来写在play中，下面的两个task任务分别有自己的t1和t2标签，同时又具有共同的t3标签，tags写在tasks上面时，tasks会继承当前play中的tags --- - hosts: all remote_user: root tags: t3 tasks: - name: task1 file: path: /tmp/task1 state: touch tags: t1 - name: task2 file: path: /tmp/task2 state: touch tags: t2 调用标签时，可以一次性指定多个标签，调用多个标签需要用逗号隔开 ansible-playbook --tags=t1,t2 testtags.yaml 我们还可以在调用标签时先概览一下playbook中的标签 ansible-playbook --list-tags testtags.yaml tags的五个内置标签always: 当把任务的tags的值指定为always时，那么这个任务就总是会被执行，除非你使用’–skip-tags’选项明确指定跳过这个任务 never: 当把任务的tags的值指定为never时，那么这个任务就总是不会被执行，2.5版本中新加入的特殊tag tagged: 调用标签时使用的，只执行有标签的任务，没有任何标签的任务不会被执行 untagged: 只执行没有标签的任务，但是如果某些任务包含always标签，那么这些任务也会被执行 all: 执行所有标签 只执行有标签的任务，没有任何标签的任务不会被执行 ansible-playbook --tags tagged testtag.yml 跳过包含标签的任务，即使对应的任务包含always标签，也会被跳过 ansible-playbook --skip-tags tagged testtag.yml 只执行没有标签的任务，但是如果某些任务包含always标签，那么这些任务也会被执行 ansible-playbook --tags untagged testtag.yml","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的handlers(8)","slug":"ansible的handlers(8)","date":"2020-05-26T07:13:48.000Z","updated":"2020-08-28T03:06:57.401Z","comments":true,"path":"post/b93ea0db.html","link":"","permalink":"https://www.missf.top/post/b93ea0db.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的handlers用法许多的Linux服务在修改配置文件后都是需要重启服务的，以便能够重新读取配置文件，使新的配置能够生效。那怎么用playbook实现这个简单的功能呢？下面我们来编写一个修改nginx端口的playbook，并且在修改完之后重启nginx --- - hosts: all remote_user: root tasks: - name: modify config replace: path: /etc/nginx/nginx.conf regexp: \"listen(.*)80;\" # 替换nginx端口为8080 replace: \"listen 8080;\" backup: yes - name: restart nginx # 重启nginx服务 service: name: nginx state: restarted 注意思考: 这个playbook虽然可以帮助我们成功修改nginx端口并重启nginx服务，但是大家请注意如果我再次执行这个playbook的话，nginx端口已经是8080了，由于ansible幂等性的缘故，所以modify config这个task没有发生状态的改变，所以这一步返回了绿色的信息，但是nginx的服务还是被重启了，其实我们并没有真正去改变nginx的配置文件，但是却还是重启了nginx服务，这是因为重启服务这个任务是写死了的。这种多余的重启是不需要的。那么在playbook中就是使用handlers来解决这种问题的，下面我们就继续以nginx服务这个小例子来学习playbook的handlers用法 --- - hosts: all remote_user: root tasks: - name: modify config replace: path: /etc/nginx/nginx.conf regexp: \"listen(.*)80;\" replace: \"listen 8080;\" backup: yes notify: # 在modify config这个任务调用handlers任务列表的restart nginx任务(认真理解这句话) restart nginx handlers: # 定义一个handlers任务列表 - name: restart nginx service: name: nginx state: restarted 上面示例我们使用handlers用法，如果modify config这个task的状态被真正修改过了，notify就会调用handlers任务列表的restart nginx任务，就会执行重启nginx服务，这样就能达到只有nginx配置文件被真正修改了，才会去重启nginx服务 handlers是一种任务列表在playbook中handlers和tasks是同级别的，这是因为handlers也是任务列表的一种。只不过handlers中的任务是被用于tasks任务列表的notify调用罢了 --- - hosts: all remote_user: root tasks: - name: make testfile1 file: path: /testdir/testfile1 state: directory notify: ht2 - name: make testfile2 file: path: /testdir/testfile2 state: directory notify: ht1 handlers: - name: ht1 file: path: /testdir/ht1 state: touch - name: ht2 file: path: /testdir/testfile2 state: touch 上面playbook的执行过程如下: PLAY [all] *********************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [webserver] ok: [dbserver] TASK [make testfile1] ************************************************************************************************************ changed: [webserver] changed: [dbserver] TASK [make testfile2] ************************************************************************************************************ changed: [webserver] changed: [dbserver] RUNNING HANDLER [ht1] ************************************************************************************************************ changed: [webserver] changed: [dbserver] RUNNING HANDLER [ht2] ************************************************************************************************************ changed: [dbserver] changed: [webserver] PLAY RECAP *********************************************************************************************************************** dbserver : ok=5 changed=4 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 webserver : ok=5 changed=4 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 默认情况下，所有task执行完毕后，才会执行各个handler，而且handler的执行顺序与handler在playbook中的定义顺序是相同的，与handler被notify调用的顺序无关，这一点大家要注意。如果你想要在执行完某些task以后立即执行对应的handler，则需要使用meta模块 --- - hosts: all remote_user: root tasks: - name: make testfile1 file: path: /testdir/testfile1 state: directory notify: ht2 - meta: flush_handlers # 定义一个meta任务，表示立即执行之前task任务对应的handlers - name: make testfile3 file: path: /testdir/testfile3 state: directory notify: ht1 handlers: - name: ht1 file: path: /testdir/testfile4 state: touch - name: ht2 file: path: /testdir/testfile2 state: touch 大家可以看到下图的执行顺序，是执行了make testfile1这个task之后，立即执行它所对应的ht2这个handlers handlers分组我们可以将handlers任务列表分组，将多个handlers任务组成一个组，然后在task任务列表notify一个handlers组，这时候task任务执行完之后就会一次性执行多个handlers任务 --- - hosts: all remote_user: root tasks: - name: make testfile1 file: path: /testdir/testfile1 state: directory notify: handlers group1 - meta: flush_handlers handlers: - name: ht1 listen: handlers group1 file: path: /testdir/testfile4 state: touch - name: ht2 listen: handlers group1 file: path: /testdir/testfile2 state: touch 将ht1和ht2这两个handlers任务都监听handlers group1这一个组，这时候在task任务列表notify “handlers group1”这个组名时，就执行这个组的所有handlers任务","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的playbook(7)","slug":"ansible的playbook(7)","date":"2020-05-24T06:24:36.000Z","updated":"2020-08-28T03:06:23.690Z","comments":true,"path":"post/1b138d79.html","link":"","permalink":"https://www.missf.top/post/1b138d79.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 Ansible playbook初识前一章我们学习了ansible的模块，在控制节点上使用了很多ansible的命令对管理节点进行配置和管理，但是在我们真正的工作场景中，如果需要配置一个nginx服务，其实并不是在控制节点执行ansible命令去实现的，你可以想象一下，如果我们需要对管理节点做大量的操作，是不是就是要在控制节点执行非常多的命令呢，而且直接执行命令的方式对管理不同的管理节点时，命令又是需要修改的，这并不是我们想要的。其实ansible是可以写成”脚本”的，注意这里所说的脚本，并不是说将大量的ansible命令放到shell脚本里面去，ansible在部署较为复杂的任务时，有自己的一套执行流程，称为”剧本”，剧本翻译过来就是我们所说的playbook。编写playbook需要遵循yaml语法，那什么又是yaml语法呢，它是为了方便人类读写而设计出来的一种通用的数据串行化格式 编写第一个playbookplaybook文件都以”yaml”或”yml”作为文件后缀，这里我们创建一个名为first.yaml的playbook文件 # 将下面的ansible命令转化为playbook ansible all -m ping ansible all -m file -a 'path=/etc/nodes state=directory' # playbook的写法: --- - hosts: all remote_user: root tasks: - name: ping nodes ping: - name: mkdir directory file: path: /etc/nodes state: directory 第一行: 使用三个横杠作为开始，在YAML语法中，”—“表示文档开始 第二行: 使用”-“作为开头表示一个块序列的节点，后面使用hosts关键字指定了要操作的主机 第三行: 使用remote_user关键字可以指定在管理节点进行操作时使用哪个用户进行操作 第四行: 使用tasks关键字指明要进行操作的任务列表，之后的行都属于tasks键值对中的值 tasks之后的行都属于任务列表的任务，可以看出任务列表一共有两个任务，每个任务以”-“开头，每个任务都有自己的名字，任务名字使用name关键字进行指定，第一个任务使用ping模块，ping模块在使用时不需要指定任何参数。第二个任务使用file模块，使用file模块时，指定了path参数和state参数的值 运行playbook[root@localhost ~/playbook]# ansible-playbook first.yaml PLAY [all] ********************************************************************************************************************************************************* TASK [Gathering Facts] ********************************************************************************************************************************************* ok: [10.10.110.123] ok: [10.10.110.122] TASK [ping nodes] ************************************************************************************************************************************************** ok: [10.10.110.123] ok: [10.10.110.122] TASK [mkdir directory] ********************************************************************************************************************************************* ok: [10.10.110.122] ok: [10.10.110.123] PLAY RECAP ********************************************************************************************************************************************************* 10.10.110.122 : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 10.10.110.123 : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 如上所示，playbook执行后返回了一些信息，这些信息是这次剧本运行的概况。PLAY [all]表示这次运行的playbook有一个’play’是针对所有主机运行的，一个playbook可以是由一个或者多个play组成的。这个play包含了三个任务，这三个任务分别是TASK [Gathering Facts]，TASK [ping nodes]，TASK [mkdir directory]。我们只创建了两个任务，为什么却执行了三个任务呢？其实每个paly在执行前都会执行一个默认任务，这个默认任务就是TASK [Gathering Facts]，它会收集当前play对应的目标主机的相关信息，收集完这些基础信息后，才会执行我们指定的任务，这里它是收集我们这个play的所有主机的信息，然后返回主机的IP地址。第二个任务是用ping模块去测试管理节点的状态，给我们返回的是绿色的信息，表示管理节点的状态没有发生改变。第三个任务是创建目录，这里如果管理节点没有/etc/nodes目录，则会返回黄色的信息，表示在管理节点上创建了目录，管理节点的状态发生了改变。这是再次执行playbook，发现创建目录任务的返回信息变成了绿色的，是因为已经创建过目录了，由于幂等性的原因，管理节点的状态没有发生改变。返回信息的最后一个PLAY RECAP中可以对所有主机的执行情况进行回顾 检查playbook语法ansible-playbook --syntax-check first.yaml 如果执行语法检查命令之后，只返回了playbook的名称，就表示没有语法错误 模拟执行playbookansible-playbook --check first.yaml 除了对playbook进行语法测试，我们还能够模拟执行playbook，模拟执行并不是真正的执行，只是假装执行一下，playbook中的任务并不会真正在目标主机中运行，所以你可以放心大胆的进行模拟，模拟运行功能可以帮助我们’预估’playbook是否能够正常执行 注意: 使用上述命令进行模拟时，一些任务可能会报错，这可能是因为报错的任务在执行时需要依赖之前的其他任务的完成结果，但是因为是模拟执行，所以之前的任务并不会真正的执行，既然之前的任务没有真正的执行，自然不会产生对应的结果，所以后面的任务就报错了。也就是说，我们并不能完全以模拟的反馈结果作为playbook是否能够正常运行的判断依据，只能通过模拟大概的预估一下而已 使用playbook安装nginx目录文件规划tree /root/playbook/ /root/playbook/ ├── index.html.j2 ├── nginx.conf └── nginx.yaml 编写playbook--- - hosts: all remote_user: root vars: # 定义变量，可以在nginx.conf文件中调用 http_port: 80 max_clients: 65535 tasks: - name: ensure nginx is at the latest version yum: name: nginx state: installed - name: write the nginx config file template: # 模板模块，将当前目录下的nginx.conf文件(文件里面定义的变量会自动赋值再拷贝)拷贝到管理节点 src: nginx.conf dest: /etc/nginx/nginx.conf - name: write the site file template: src: index.html.j2 dest: /usr/share/nginx/html/index.html notify: - restart nginx - name: ensure nginx is running service: name: nginx state: started handlers: - name: restart nginx service: name=nginx state=restarted 编写nginx配置文件#user nobody; worker_processes auto; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections {{ max_clients }}; # 调用nginx.yaml中定义的变量 } http { include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server { listen {{ http_port }}; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root /usr/share/nginx/html/; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht { # deny all; #} } } 编写index.html.j2文件Hello Ansible! This is {{ansible_all_ipv4_addresses}} 在ansible控制节点上查看curl 10.10.110.122 Hello Ansible! This is [u'10.10.110.122'] # 这个是可变变量 curl 10.10.110.123 Hello Ansible! This is [u'10.10.110.123']","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的yaml基本语法(6)","slug":"ansible的yaml基本语法(6)","date":"2020-05-23T08:37:52.000Z","updated":"2020-07-14T04:33:20.766Z","comments":true,"path":"post/b39d16c2.html","link":"","permalink":"https://www.missf.top/post/b39d16c2.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的yaml基本语法大小写敏感 使用缩进表示层级关系 缩进时不允许使用Tab键，只允许使用空格 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可 yaml文件以”—“作为文档的开始，”…”作为文档的结束 # 表示注释，从这个字符一直到行尾，都会被解析器忽略 相同缩进级别的行以”-“(破折号和空格)开头的组成一个列表 yaml支持的三种数据结构数组: 一组按次序排列的值，又称为序列（sequence） / 列表（list） 对象: 键值对的集合，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary） 纯量: 单个的、不可再分的值 数组相同缩进级别的行以“- ”（破折号和空格）开头组成一个列表就是数组 --- fruits: - Apple - Banana - orange - melon # 行内表示法 fruits: ['Apple', 'Banana', 'orange', 'melon'] 对象对象的一组键值对，使用冒号结构表示(冒号后面要有个空格) sb: name: Alex job: python skill: brag # 行内表示法 sb: {name: Alex, job: python, skill: brag} 纯量数值number: 12 float: 15.20 布尔值表示true的值 true, True, TRUE, yes, Yes, YES, on, On, ON, y, Y 表示false的值 false, False, FALSE, no, No, NO, off, Off, OFF, n, N 强制类型转换yaml 允许使用两个感叹号，强制转换数据类型 a: !!str 123 d: !!str true # 这个true的数据类型不再是布尔值，而是str类型 字符串字符串默认不使用引号表示 str: 这是字符串 s1: '内容\\n字符串' # 如果字符之中包含空格和特殊字符，需要放在引号之中，单引号和双引号都可以使用，双引号不会对特殊字符转义 空值null: 用~表示 parent: ~ 引用&amp;用来建立锚点(defaults)，&lt;&lt;表示合并到当前数据，*****用来引用锚点 defaults: &amp;defaults adapter: postgres host: localhost development: database: myapp_development &lt;&lt;: *defaults test: database: myapp_test &lt;&lt;: *defaults # 上面的写法等同于下面的代码: defaults: adapter: postgres host: localhost development: database: myapp_development adapter: postgres host: localhost test: database: myapp_test adapter: postgres host: localhost 参考palybooks更多的yaml语法请参考: http://docs.ansible.com/YAMLSyntax.html","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"coding持续集成Java项目","slug":"coding持续集成Java项目","date":"2020-05-18T07:42:59.000Z","updated":"2020-08-28T03:19:20.167Z","comments":true,"path":"post/1b979c3e.html","link":"","permalink":"https://www.missf.top/post/1b979c3e.html","excerpt":"","text":"coding介绍在说到持续集成这方面，相信所有做运维的小伙伴都知道Jenkins，就是那个拿着托盘的老头子。但是说到coding，可能很多人都没听说过。什么是coding呢？coding涵盖了软件开发从构想到交付的一切所需，使研发团队在云端高效协同，实践敏捷开发与 DevOps，提升软件交付质量与速度。这是来自官网的介绍，下面就让我们一起学习coding吧 注册codingcoding所有的东西都是在这个云平台上实现的，所谓的使研发团队在云端高效协同说的就是这个吧 创建项目选择DevOps项目模板 填写项目基本信息 下载若依的源码若依源码gitee地址 配置若依数据库将若依自带的两个SQL文件导入到ry数据库 初始化本地仓库git init git add . git commit -m \"第一次提交\" 配置coding SSH秘钥在Windows电脑生成ssh密钥对，然后将id_rsa.pub公钥添加到coding SSH公钥 推送本地仓库到coding 注意: 如果已经在coding配置了ssh秘钥，git添加远程仓库的时候不要使用https的地址，不然还是会提示需要输入coding的账号密码 git remote add origin git@e.coding.net:missf/RuoYi.git # 配置了SSH秘钥的，一定要填写项目的git地址 git push -u origin master # 这样推送时就不需要输入账号密码啦 持续集成创建持续集成任务 新建构建计划 录入项目凭据在服务器生成SSH秘钥对，将私钥录入到coding的凭据管理，coding就能持续集成部署代码到服务器 编写静态配置的 Jenkinsfile 配置环境变量 这里附上完整Jenkinsfile pipeline { agent any stages { stage('检出') { steps { checkout([$class: 'GitSCM', branches: [[name: env.GIT_BUILD_REF]], userRemoteConfigs: [[url: env.GIT_REPO_URL, credentialsId: env.CREDENTIALS_ID]]]) } } stage('构建') { steps { echo '构建中...' sh 'java -version' sh 'mvn package' echo '构建完成.' } } stage('压缩jar包') { steps { echo '压缩中...' sh 'cd /root/workspace/ruoyi-admin/target/ &amp;&amp; tar -zcf /tmp/ruoyi-admin.tar.gz ruoyi-admin.jar' echo '压缩完成.' } } stage('部署') { steps { echo '部署中...' script { def remote = [:] remote.name = 'java-server' remote.allowAnyHosts = true remote.host = \"${env.REMOTE_HOST}\" remote.port = 50312 remote.user = \"${env.REMOTE_USER_NAME}\" // 把「CODING 凭据管理」中的「凭据 ID」填入 credentialsId，而 id_rsa 无需修改 withCredentials([sshUserPrivateKey(credentialsId: \"${env.REMOTE_CRED}\", keyFileVariable: 'id_rsa')]) { remote.identityFile = id_rsa // SSH 上传文件到服务器 sshPut remote: remote, from: '/tmp/ruoyi-admin.tar.gz', into: '/tmp/' // 解压缩 sshCommand remote: remote, sudo: false, command: \"tar -zxf /tmp/ruoyi-admin.tar.gz -C /home/ruoyi/\" // 执行Java应用启停脚本 sshCommand remote: remote, sudo: true, command: \"sh /home/ruoyi/start.sh stop &amp;&amp; sh /home/ruoyi/start.sh start\" } } echo '部署完成' } } } } 触发规则本地仓库推送代码到master分支时就会自动触发持续集成任务 开启缓存目录开启缓存目录后可以大大提升构建的速度 立即构建 查看构建过程构建失败可以查看完整日志分析失败原因 服务器的启停脚本[root@java-server ~]# cd /home/ruoyi/ [root@java-server ruoyi]# ll total 65080 drwxr-xr-x 2 root root 4096 May 18 10:18 logs -rw-r--r-- 1 root root 67 May 18 17:04 nohup.out -rw-r--r-- 1 root root 66627886 May 18 17:04 ruoyi-admin.jar -rwxr-xr-x 1 root root 760 May 18 14:29 start.sh [root@java-server ruoyi]# cat start.sh #!/bin/bash WORKSPACE=/home/ruoyi if [ -d \"${WORKSPACE}\" ]; then cd ${WORKSPACE} else echo \"${WORKSPACE} directory does not exist\" exit 1 fi APP_NAME='ruoyi-admin.jar' USE_JAVA_HOME='/usr/local/jdk1.8.0_211' JVM_OPTS='-Xms512m -Xmx512m' CONFIG_OPTS='' if [ $1 == 'start' ]; then echo 'start service '$APP_NAME nohup java -jar ${JVM_OPTS} ${APP_NAME} > ${WORKSPACE}/nohup.out 2>&amp;1 &amp; elif [ $1 == 'stop' ]; then echo 'stop service '$APP_NAME PID=$(ps -ef | grep -v grep | grep ${APP_NAME} | awk '{print $2}') if [ -z ${PID} ]; then echo ${APP_NAME} ' had stopped' else kill ${PID} sleep 2 if [ $? -ne 0 ]; then echo ${APP_NAME} ' stop failed' exit 1 fi fi fi 查看持续集成的效果","categories":[{"name":"coding","slug":"coding","permalink":"https://www.missf.top/categories/coding/"}],"tags":[{"name":"coding","slug":"coding","permalink":"https://www.missf.top/tags/coding/"},{"name":"持续集成","slug":"持续集成","permalink":"https://www.missf.top/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"}]},{"title":"ansible模块学习(5)","slug":"ansible模块学习(5)","date":"2020-05-12T03:12:59.000Z","updated":"2020-08-28T03:05:37.742Z","comments":true,"path":"post/cd036e92.html","link":"","permalink":"https://www.missf.top/post/cd036e92.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 setup模块setup模块主要用于获取主机信息，每个管理节点在接收控制节点命令之前，会将主机的信息告知控制节点 filter: 用于进行条件过滤，如果设置，仅返回匹配过滤条件的信息 关键字 说明 返回值例子 ansible_nodename 节点名 “6-dns-1.hunk.tech” ansible_fqdn FQDN名 “6-dns-1.hunk.tech” ansible_hostname 主机短名称 “6-dns-1” ansible_domain 主机域名后缀 “hunk.teh” ansible_memtotal_mb 总物理内存 “ansible_memtotal_mb”: 222 ansible_swaptotal_mb SWAP总大小 “1023” ansible_processor CPU信息 Intel(R) Core(TM) i5-5200U CPU @ 2.20GHz ansible_processor_cores CPU核心数量 4 ansible_processor_vcpus CPU逻辑核心数量 2 ansible_all_ipv4_addresses 有所IPV4地址 192.168.0.200 ansible_all_ipv6_addresses 所有IPV6地址 ansible_default_ipv4 默认网关的网卡配置信息 ansible_eth2 具体某张网卡信息 不同系统名称需要变化 ansible_dns DNS设置信 ansible_architecture 系统架构 x86_64 ansible_machine 主机类型 x86_64 ansible_kernel 内核版本 “2.6.32-696.el6.x86_64” ansible_distribution 发行版本 “CentOS” ansible_distribution_major_version 操作系统主版本号 “6” ansible_distribution_release 发行版名称 “Final” ansible_distribution_version 完整版本号 “7.4.1708” ansible_pkg_mgr 软件包管理方式 “yum” ansible_service_mgr 进行服务方式 “systemd” ansible_os_family 家族系列 “RedHat” ansible_cmdline 内核启动参数 ansible_selinux SElinux状态 “disabled” ansible_env 当前环境变量参数 ansible_date_time 时间相关 ansible_python_version python版本 “2.6.6” ansible_lvm LVM卷相关信息 ansible_mounts 所有挂载点 ansible_device_links 所有挂载的设备的UUID和卷标名 ansible_devices 所有/dev/下的正在使用的设备的信息 ansible_user_dir 执行用户的家目录 “/root” ansible_user_gecos 执行用户的描述信息 “The root “ ansible_user_gid 执行用户的的GID 0 ansible_user_id 执行用户的的用户名 “root” ansible_user_shell 执行用户的shell类型 “/bin/bash” ansible_user_uid 执行用户的UID 0 查看管理节点的python版本信息 ansible all -m setup -a 'filter=ansible_python_version' 查看管理节点的发行版本 ansible all -m setup -a 'filter=ansible_distribution' command模块ansible的默认模块，可以不用-m指定，-a是command的参数 free_form: 其实没有名为“free form”的实际参数，command模块接受自由格式的命令运行 chdir: 在执行对应的命令之前，会先进入到chdir参数指定的目录中 creates: 如果指定的文件存在时，就不执行对应命令 removes: 当指定的文件不存在时，就不执行对应命令 查看管理节点/etc/目录下的hosts文件内容 ansible all -a \"chdir=/etc cat hosts\" 查看管理节点/etc/目录下的hosts文件内容，如果存在/etc/passwd文件则不执行 ansible all -a \"chdir=/etc creates=/etc/passwd cat hosts\" command模块不支持调用$HOME这样的变量，还有像&lt;, &gt;, |, ;, &amp;这些正则和通配符都将不可用，但是command 模块更安全，因为他不受用户环境的影响。 也很大的避免了潜在的shell注入风险。 shell模块shell 模块可以帮助我们在远程主机上执行命令。与command模块不同的是，shell模块在远程主机中执行命令时，会经过远程主机上的 /bin/sh 程序处理，能够使用&lt;, &gt;, |, ;, &amp;这些符号和环境变量。 free_form: 其实没有名为“free form”的实际参数，command模块接受自由格式的命令运行 chdir: 在执行对应的命令之前，会先进入到chdir参数指定的目录中 creates: 如果指定的文件存在时，就不执行对应命令 removes: 当指定的文件不存在时，就不执行对应命令 executable: 默认shell模块会调用远程主机中的/bin/sh去执行对应的命令，也可以指定shell，需要使用绝对路径 shell模块在管理节点上执行命令时，支持管道和重定向等符号 ansible all -m shell -a 'chdir=/etc executable=/bin/bash cat hosts >/tmp/hosts.bak' script模块script模块可以帮助我们在管理节点上执行控制节点上的脚本，也就是说在管理节点上执行脚本不需要把脚本拷贝过去 free_form: 指定需要执行的脚本，其实没有名为“free form”的实际参数 chdir: 在执行对应的脚本之前，会先进入到chdir参数指定的目录中 creates: 如果指定的文件存在时，就不执行脚本 removes: 当指定的文件不存在时，就不执行脚本 在管理节点上执行控制节点的/root/test.sh脚本，执行之前切换到/opt目录 ansible all -m script -a 'chdir=/opt /root/test.sh' copy模块nnbcopy模块的作用就是将Control node的文件拷贝到Managed nodes scr: 用于指定控制节点上被copy的文件或目录 dest: 用于指定文件将被拷贝到管理节点的路径，dest为必须参数 content: 当不使用src指定拷贝的文件时，可以使用content直接指定文件内容，src与content两个参数必有其一 force: 当管理节点的目标路径存在同名文件，并且两个文件内容不同，是否强制覆盖，可选值有yes和no，默认值为yes backup: 当管理节点的目标路径存在同名文件，并且两个文件内容不同，是否对管理节点的文件进行备份，可选值有yes和no owner: 指定文件拷贝到管理节点后的属主，但是管理节点上必须有对应的用户 group: 指定文件拷贝到管理节点后的属组，但是管理节点上必须有对应的组 mode: 指定文件拷贝到管理节点后的权限，可以使用mode=0644表示，也使用mode=u+x表示 将控制节点的/etc/hosts文件复制到管理节点的/root目录下，如果管理节点的/root目录已经存在文件，则会默认覆盖 ansible all -m copy -a \"src=/etc/hosts dest=/root/\" # 如无意外这里你看到的字体颜色是黄色的，这是成功执行并且状态发生了改变的 复制文件，指定文件的属主和属组，需要注意的是管理节点必须存在对应的用户和组 ansible all -m copy -a \"src=/etc/hosts dest=/tmp/ owner=mwj group=mwj\" 复制文件，如果管理节点的目标路径已存在同名文件且内容不相同，则对管理节点的文件先进行备份，再把控制节点的文件复制到管理节点 ansible all -m copy -a \"src=/etc/hosts dest=/tmp/ backup=yes\" # 在返回的结果列表能看到: \"backup_file\": \"/tmp/hosts.15575.2020-05-12@22:28:50~\" # ansibel是用哈希值去校验两个文件的内容是否一致的 file模块file模块可以完成对文件增删查改的基本操作 path: 用于指定要操作的文件或目录，必须参数 state: ansible无法从path=/test/a/b得知我们想要创建目录还是文件，所以需要使用state参数配和path来声明操作的类型 ​ state=directory 创建的是目录 ​ state=touch 创建的是文件 ​ state=link 创建的是软连接文件 ​ state=hard 创建的是硬链接文件 ​ state=absent 删除文件或者目录，absent意为”缺席” src: 当state设置为link或者hard时，我们必须指明软硬链链接到哪个文件，通过src参数即可指定链接源 force: 当state=link的时候，可配合force=yes参数强制创建链接文件，但是强制创建会有两种情况 ​ 情况一: 当要创建的链接文件所指向的源文件并不存在时，使用此参数可以先强制创建出链接文件 ​ 情况二: 当要创建链接文件的路径中已经存在与链接文件同名的文件时，将force设置为yes，会将同名文件覆盖为链接文件 owner: 用于指定被操作文件或目录的属主 group: 用于指定被操作文件或目录的属组 mdoe: 用于指定被操作文件或目录的权限，使用mode=755，设置特殊权限则可以使用mode=4700 recurse: 当要操作的对象为目录，将recurse设置为yes，可以递归的修改目录中文件的属性 在管理节点上创建一个名为testdir的目录，如果目录已存在则不进行任何操作 ansible all -m file -a \"path=/testdir/ state=directory\" 在管理节点上创建一个名为testfile的文件，如果文件已存在则会更新文件的时间戳 ansible all -m file -a \"path=/testdir/testfile state=touch\" 在管理节点创建一个名为/testdir/linkfile的链接文件，链接的源文件/testdir/testfile已存在 ansible all -m file -a \"path=/testdir/linkfile state=link src=/testdir/testfile\" 在管理节点上删除指定的文件或目录 ansible all -m file -a \"path=/testdir/testfile state=absent\" fetch模块从管理节点拉取文件到控制节点 dest: 用来存放从管理节点拉取到的文件 src: 管理节点被拉取的文件，必须是文件不能是目录 flat: 默认为no，会将拉取到控制节点的文件以hostname/file的命名存放在dest目录，如果为yes，则直接按文件名存放 Validate_checksum: 拉取文件之后进行MD5检查 拉取管理节点的/etc/hosts文件到控制节点的/data/目录 ansible all -m fetch -a \"src=/etc/hosts dest=/data/\" # 这里flat默认为no，所以拉取之后存放的方式是这样的 tree /data/ /data/ ├── 10.10.110.122 │ └── etc │ └── hosts └── 10.10.110.123 └── etc └── hosts ansible all -m fetch -a \"src=/etc/hosts dest=/data/ flat=yes\" # flat=yes是直接按文件名存放 tree /data/ /data/ └── hosts # 只有一个hosts文件是因为第一个hosts被覆盖掉了 blockinfile模块blockinfile模块可以帮助我们在指定的文件中插入”一段文本”，这段文本是被标记过的，我们在这段文本上做了记号，以便在以后的操作中可以通过”标记”找到这段文本，然后修改或者删除它 path: 指定要操作的文件 block: 此参数用于指定我们想要插入的那”一段文本”，此参数有一个别名叫”content”，使用content或block的作用是相同的 marker: 自定义开始和结束的标记，marker=#{mark}test:开始为# BEGIN test，结束为# END test insertafter: 在插入一段文本时，默认会在文件的末尾插入文本，如果你想要将文本插入在某一行的后面，可以使用此参数指定对应的行 insertbefore: 在插入一段文本时，默认会在文件的末尾插入文本，如果你想要将文本插入在某一行的前面，可以使用此参数指定对应的行 backup: 是否在修改文件之前对文件进行备份 create: 当要操作的文件并不存在时，是否创建对应的文件 在管理节点的/testdir/rc.local文件末尾插入一行systemctl start mariadb ansible all -m blockinfile -a 'path=/testdir/rc.local block=\"systemctl start mariadb\"' 自定义插入的开始和结束的标记 ansible all -m blockinfile -a 'path=/testdir/rc.local block=\"systemctl restart mysqld\\nnginx -s reload\" marker=\"#{mark} serivce to start\"' # 查看被插入的文本 #BEGIN serivce to start systemctl restart mysqld nginx -s reload #END serivce to start 使用create参数，如果指定的文件不存在则创建它 ansible all -m blockinfile -a 'path=/testdir/date block=\"今天是5月12号\\n汶川地震12周年\" marker=\"#{mark} 日期记录\" create=yes' 使用backup参数，可以在操作修改文件之前对文件进行备份 ansible all -m blockinfile -a 'path=/testdir/date block=\"今天是5月12号\\n汶川地震12周年\" marker=\"#{mark} 日期记录\" backup=yes' lineinfile模块我们可以借助lineinfile模块，确保”某一行文本”存在于指定的文件中，还可以根据正则表达式替换”某一行文本” path: 指定要操作的文件 line: 使用此参数指定文本内容 regexp: 使用正则表达式匹配对应的行 state: 当想要删除对应的文本时，需要将state参数的值设置为absent backrefs: 开启后向引用，line参数中就能对regexp参数中的分组进行后向引用了 insertafter: 借助insertafter参数可以将文本插入到“指定的行”之后 insertbefore: 借助insertbefore参数可以将文本插入到“指定的行”之前 backup: 是否在修改文件之前对文件进行备份 create: 当要操作的文件并不存在时，是否创建对应的文件 确保”test lineinfile”这行文本存在于/testdir/date文件中，如果存在则不做任何操作，如果不存在则在末尾插入 ansible all -m lineinfile -a 'path=/testdir/date line=\"test lineinfile\"' 根据正则表达式替换”某一行”，如果多行能够匹配正则，只有最后匹配的行才会被替换，如果没有匹配到则会在末尾插入line的内容 ansible all -m lineinfile -a 'path=/testdir/date regexp=\"^test\" line=\"被替换后的内容\"' 根据正则匹配删除对应的行，如果文件多行都与正则匹配，则删除多行 ansible all -m lineinfile -a 'path=/testdir/date regexp=\"^#.*-$\" state=absent' # 删除#开头-结尾中间有任意个字符的行 在管理节点的/testdir/date文件的”#Hello saltstack,Hiiii”这一行之后插入123 ansible all -m lineinfile -a 'path=/testdir/date line=\"123\" insertafter=\"#Hello saltstack,Hiiii\"' find模块find模块可以帮助我们在管理节点中查找符合条件的文件，就像find命令一样 paths: 必须参数，指定在哪个目录中查找文件，可以指定多个路径，路径间用逗号隔开 recurse: 默认只会在指定的目录中查找文件，当recurse参数设置为yes时，表示会递归的查找文件 hidden: 默认不会去查找隐藏文件，只有当hidden参数的值设置为yes时才会查找隐藏文件 file_type: 默认只会根据条件查找”文件”，可以通过file_type指定文件类型，any | directory | file | link patterns: 使用此参数指定需要查找的文件名称，支持使用shell(比如通配符)或者正则表达式去匹配文件名称 use_regex: 当use_regex设置为yes时，表示使用python正则解析patterns参数中的表达式 contains: 使用此参数可以根据文章内容查找文件，此参数的值为一个正则表达式 age: 用此参数可以根据时间范围查找文件，默认以文件的mtime为标准与指定的时间进行对比 age_stamp: 文件的时间属性中有三个时间种类:atime、ctime、mtime，当我们根据时间范围查找文件时，可以指定以哪个时间种类为准 size: 使用此参数可以根据文件大小查找文件 get_checksum: 当有符合查找条件的文件被找到时，会同时返回对应文件的sha1校验码 在管理节点的/etc目录中查找包含www字符串的文件，不进行递归并忽略隐藏文件 ansible all -m find -a 'paths=/etc contains=\".*www.*\"' 在管理节点的/etc目录查找以.sh结尾的文件，包括隐藏文件并进行递归查找 ansible all -m find -a 'paths=/etc patterns=\"*.sh\" hidden=yes recurse=yes' 在管理节点的/etc目录查找链接文件，包括隐藏文件并进行递归查找 ansible all -m find -a 'paths=/etc file_type=link hidden=yes recurse=yes' 在管理节点的/etc目录查找以.sh结尾的文件，只不过patterns对应的表达式为正则表达式，包括所有文件类型 ansible all -m find -a 'paths=/etc patterns=\"\\*.sh\" file_type=any use_regex=yes' 在管理节点的/etc目录递归查找mtime在4天以内的文件 ansible all -m find -a 'paths=/etc age=-4d recurse=yes' 在管理节点的/etc目录递归查找大于2G的文件 ansible all -m find -a 'paths=/etc size=2g recurse=yes' 在管理节点的/etc目录递归查找.conf结尾的文件，并且返回符合条件的文件的sha1校验码 ansible all -m find -a 'paths=/etc patterns=\"*.conf\" recurse=yes get_checksum=yes' replace模块replace模块可以根据我们指定的正则表达式替换文件中的字符串，文件中所有被正则匹配到的字符串都会被替换 path: 必须参数，指定要操作的文件，别名:dest | destfile | name regexp: 必须参数，指定一个python正则表达式，文件中与正则匹配的字符串将会被替换 replace: 指定最终要替换成的字符串 backup: 是否在修改文件之前对文件进行备份，最好设置为yes 将管理主机的/testdir/date文件中所有的ansible替换为saltstack，操作前进行文件备份 ansible all -m replace -a 'path=/testdir/date regexp=\"ansible\" replace=saltstack backup=yes' cron模块cron模块可以帮助我们配置管理节点的计划任务，功能相当于crontab命令 minute: 用于设置分钟值，格式为minute=5，如不指定此参数，则分钟值默认为 * hour: 用于设置小时值，格式为hour=5，如不指定此参数，则小时值默认为 * day: 用于设置日值，如不指定此参数，则日值默认为 * month: 用于设置月值，如不指定此参数，则月值默认为 * weekday: 用于设置周值，如不指定此参数，则月值默认为 * special_time: 时间设定格式为@reboot或者@hourly，这种@开头的时间设定格式则需要使用special_time参数进行设置 注意: 如果以上参数都不设置，则默认使用 * * * * * ，表示每分钟都执行一次。我们应该谨慎设置时间参数 user: 设置当前计划任务属于哪个用户，不指定则默认为管理员用户 job: 执行计划任务中需要实际执行的命令或脚本 name: 设置计划任务的名称，方便我们以后根据名称修改或者删除计划任务 state: 可以根据已有名称的计划任务进行修改和删除，当删除时需要将state的值设置为absent disabled: 可以将已有名称的计划任务注释，但使用此参数除了指定任务名称还需要指定job以及时间的设定，否则注释任务时，任务的时间会被修改 backup: 当此参数设置为yes，那么修改和删除计划任务时，会在管理节点的tmp目录下创建备份文件 在管理节点创建名为test cron计划任务，每天的12点5分，任务内容为将test重定向到/tmp/test ansible all -m cron -a 'name=\"test cron\" minute=5 hour=12 job=\"echo test > /tmp/test\"' # 管理节点的计划任务构建如下: #Ansible: test cron 5 12 * * * echo test > /tmp/test 在管理节点创建名为day cron计划任务，每三天执行一次。与执行当天的14点5分开始执行，任务内容为输出test ansible all -m cron -a 'name=\"day cron\" minute=5 hour=14 day=*/3 job=\"echo test\"' # 管理节点的计划任务构建如下: #Ansible: day cron 5 14 */3 * * echo test 在管理节点创建名为day cron计划任务，任务在重启时执行，任务内容为输出test ansible all -m cron -a 'name=\"day cron\" special_time=reboot job=\"echo test\"' # 由于已存在day cron任务，ansible就会认为我们是需要修改这个任务，计划任务被修改为: #Ansible: day cron @reboot echo test 在管理节点注释掉我们之前创建的test cron任务，注释时进行备份 ansible all -m cron -a 'name=\"test cron\" minute=5 hour=12 job=\"echo test > /tmp/test\" disabled=yes backup=yes' # 符合注释条件的计划任务就会被注释掉: #Ansible: test cron #5 12 * * * echo test > /tmp/test 如果你注释计划任务时，设置了错误的时间和job，那么注释对应任务时(以name去对应)，时间和job的设定也会发生改变 ansible all -m cron -a 'name=\"test cron\" hour=23 job=\"echo test > /tmp/test\" disabled=yes backup=yes' #Ansible: test cron #* 23 * * * echo test > /tmp/test # 注释的同时，时间设定也会改变 service模块service模块可以对管理节点上的服务进行管理，例如启动或停止管理节点的nginx服务。但前提是这个服务必须被BSD init | OpenRC | SysV | Solaris SMF | systemd | upstart中的任意一种所管理，意思就是这个服务在centos6管理节点能以service nginx start启动，在centos7管理节点能以systemctl start nginx启动。如果管理节点上的服务无法通过这样的方式启动，那么service模块也无法对它进行管理。 name: 用于指定操作的服务名称，例如name=nginx state: 用户指定服务的状态，可用值有started | stopped | restarted | reloaded enabled: 用于指定是否将服务设置为开机启动项，设置为yes则表示开机启动，设置为no表示不会开机启动 在管理节点上启动nginx服务 ansible all -m service -a 'name=nginx state=started' 在管理节点上启动mysql服务并设置为开机启动 ansible all -m service -a 'name=mysql state=started enabled=yes' user模块user: 模块可用帮助我们在管理节点上创建用户、修改用户、删除用户、为用户创建密钥对等操作 name: 必须参数，用于指定要操作的用户名称 group: 用于指定用户所在的基本组 shell: 用于指定用户的默认shell uid: 用于指定用户的uid号 expires: 用于指定用户的过期时间 comment: 用于指定用户的注释信息 state: 用于指定用户是否存在于远程主机中，默认值为present，表示用户需要存在，当设置为absent时表示删除用户 remove: 默认值为no，表示删除用户时不会删除家目录，设置为yes则表示删除用户时删除用户家目录 password: 用于指定用户的密码，但是这个密码不能是明文的密码 generate_ssh_key: 默认值为no，如果设置为yes则表示为用户在家目录的.ssh下创建密钥对，如果对应的路径已有同名密钥对则不进行任何操作 ssh_key_file: 默认值为yes，使用此参数自定义生成ssh私钥的路径和名称 ssh_key_passph rase: 当generate_ssh_key参数的值为yes时，在创建证书时使用此参数设置私钥的密码 ssh_key_type: 当generate_ssh_key参数的值为yes时，在创建证书时使用此参数设置密钥对的类型 在管理节点上创建mis用户，并把用户添加到root组，如果用户已存在则不做任何操作 ansible all -m user -a 'name=mis group=root' 在管理节点上删除mis用户，同时把用户家目录也删除 ansible all -m user -a 'name=mis state=absent remove=yes' 在管理节点上创建mis用户，指定用户的注释信息，设置用户过期时间是2020-06-15 ansible all -m user -a 'name=mis comment=\"missf.top\" expires=1592150400' # 先使用\"date -d 2020-06-15 +%s\"命令得到Unix时间戳 在管理节点上为mis用户设置密码，加密字符串可以使用python得到 ansible all -m user -a 'name=mis password=\"$6$d62UFoKtSRA9Yaq4$qtvyr5atLdoXgvXOhktU.baVqbtlcaWc9dizmM41Bc9XOaTZW/Pqaxb8pofS5Wo4n5Nu/CEk8GEsKnC2zTfEl1\"' 可以使用 import crypt; crypt.crypt(\"123456\") 得到123456加密之后的字符串 在管理节店上为mis用户生成密钥对，同时指定私钥密码为123456，密钥对的类型为dsa，如不指定密钥对类型默认为rsa ansible all -m user -a 'name=mis generate_ssh_key=yes ssh_key_passphrase=\"123456\" ssh_key_type=dsa' group模块group模块可以帮助我们在管理节点上管理用户组 name: 用于指定操作的服务名称，例如name=nginx state: 用户指定服务的状态，可用值有started | stopped | restarted | reloaded enabled: 用于指定是否将服务设置为开机启动项，设置为yes则表示开机启动，设置为no表示不会开机启动 确保管理节点上存在mkd组，如果没有则创建，如果已存在则不做任何操作 ansible all -m group -a 'name=mkd' 在管理节点上删除mkd组，前提是不能有用户把被删除的组当成主组，不然不能成功删除 ansible all -m group -a 'name=mkd state=absent' yum_repository模块yum_repository模块可以帮助我们在管理节点上管理yum仓库 name: 必须参数，指定要操作的唯一仓库ID，repo配置文件中括号的仓库ID baseurl: 用于设置yum仓库的baseurl description: 用于设置仓库的注释信息，repo配置文件中name字段对应的内容 file: 用户设置仓库的配置文件名称，就是repo配置文件的前缀，如不指定则默认以仓库ID命名 enabled: 用于设置是否激活对应的yum源 gpgcheck: 用于设置是否开启rpm包验证功能，默认值为no表示不开启包验证，设置为yes表示开启 gpgcakey: 当开启包验证功能时，使用此参数指定验证包所需的公钥 state: 默认值为present，设置为absent表示删除对应的yum源 在管理节点上创建前缀为aliepel的repo文件，设置注释信息和不验证包功能 ansible all -m yum_repository -a 'name=aliepel description=\"alibaba_epel\" baseurl=https://mirrors.aliyun.com/epel/$releasever\\Server/$basearch/ gpgcheck=no' 在管理节点创建指定名称为ali的repo文件，但是不启用它 ansible all -m yum_repository -a 'name=aliepel description=\"alibaba_epel\" file=ali baseurl=https://mirrors.aliyun.com/epel/$releasever\\Server/$basearch/ gpgcheck=no enabled=no' yum模块yum模块可以帮助我们在管理节点上管理软件包 name: 必须参数，用于指定需要管理的软件包名字 state: 用户指定软件包的状态，默认是present，表示确认已安装软件包，installed与present等效，absent和removed等效，表示删除对应的软件包 disable_gpg_check: 用于禁用对rpm包的公钥gpg验证，默认值为no表示不禁用验证，设置为yes表示禁用验证，如果yum源没有开启验证需要将此参数设置为yes enablerepo: 用于安装软件包时临时启用yum源，想要从A源安装软件，但是A源没有启用时，这个参数设置为yes表示临时启用 disablerepo: 用于安装软件包时临时禁用yum源，当多个源中同时存在软件包时，可以临时禁用某个源 确保管理节点上安装了nginx，禁用rpm包验证 ansible all -m yum -a 'name=nginx state=installed disable_gpg_check=yes' 确保管理节点上安装了Telnet，并禁用rpm包验证和临时禁用local源 ansible all -m yum -a 'name=telnet disable_gpg_check=yes disablerepo=local' template模块src: 控制节点上的模板文件 dest: 管理节点上将被控制节点上的模板文件所替换的文件 owner: 指定控制节点拷贝到管理节点的文件属主 group: 指定控制节点拷贝到管理节点的文件属组 mode: 指定控制节点拷贝到管理节点的文件权限 force: 如果管理节点已存在同名文件并且内容不同时，是否强制覆盖，默认值为yes表示覆盖 backup: 如果管理节点已存在同名文件并且内容不同时，是否对管理节点源文件进行备份 将控制节点配置好的模板文件分发到管理节点的/etc/redis.conf，设置不强制覆盖 ansible all -m template -a 'src=/root/redis.conf dest=/etc/redis.conf force=no'","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible主机清单(4)","slug":"ansible主机清单(4)","date":"2020-05-10T02:12:59.000Z","updated":"2020-08-28T03:03:23.647Z","comments":true,"path":"post/334c7279.html","link":"","permalink":"https://www.missf.top/post/334c7279.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 认识主机清单Ansible可同时操作属于一个组的多台主机， 组和主机之间的关系通过 inventory 文件配置. 默认的文件路径为 /etc/ansible/hosts，执行命令的时候使用 -i 参数即可指定主机清单 主机清单示例主机清单文件主要有 ini 和 yaml 格式两种语法格式 mail.example.com # 定义主机fqdn地址, 需要已经与控制节点ssh互信 localhost ansible_connection=local # ansible_connection可以定义连接类型, local是在本地执行,默认是smart host4 ansible_host=10.10.110.123 ansible_port=50312 ansible_user=root ansible_password=12345 # 指定别名，定义主机ssh连接信息 www[1:50].example.com # 定义 1-50范围内的主机 www-[a:d].example.com # 定义 a-d 范围内的主机 [dbservers] three.example.com ansible_python_interpreter=/usr/local/bin/python3 # 定义python执行ansible，这个是指定被控节点的python 192.168.77.123 ansible_ruby_interpreter=/usr/bin/ruby.1.9.3 # 定义ruby执行文件 webservers:vars] # 定义webservers组的变量 ntp_server=ntp.example.com proxy=proxy.example.com [server:children] # 定义server组的子成员，执行server组时，webservers和dbservers组内的管理节点也会执行 webservers dbservers ini和yaml格式对比# 先写出ini风格 [dbserver] db1 ansible_host=10.10.110.122 ansible_port=22 ansible_user=root ansible_password=0 [webserver] web1 ansible_host=10.10.110.123 ansible_port=22 ansible_user=root ansible_password=0 [server:children] dbserver webserver # 定义子组成员时，需要children关键字 # 和上面一样的配置，这是yaml风格的写法 all: children: server: children: dbserver: hosts: 10.10.110.122 webserver: hosts: 10.10.110.123 yaml格式配置的还是挺复杂的，可读性也差，建议使用ini方式来设置主机清单 默认组在主机清单中，ansible会自动的生成两个组 all: 所有的主机 ungrouped: 包含没有组的主机 尽管这两个组是永远存在的，但也有可能是隐藏的，不会出现group_names之类的组列表中 主机变量和组变量如果你不想在主机清单中定义主机的变量或者组的变量，ansible还支持在特定的目录中定义变量，变量文件必须以yaml语法定义。 默认在/etc/ansible/host_vars/ 目录中定义主机变量，文件名称以主机名称命名，结束可以用”.yml”,”.yaml”,”.json”三种格式。 cat /etc/ansible/host_vars/db1 ntp_server: acme.example.org database_server: storage.example.org 默认在 /etc/ansible/group_vars/ 目录中定义组变量，文件名称以组名称命名，结束可以用”.yml”,”.yaml”,”.json”三种格式。 cat /etc/ansible/group_vars/dbserver ntp_server: acme.example.org database_server: storage.example.org 变量优先级问题，如果在各个环节都设置了变量，到底哪个变量生效呢？优先顺序，all最低，host最高: all group parent group child group host 使用多个主机清单在命令参数中，使用多个 -i 就可以指定多个主机清单 ansible all -i staging -i production -m ping ansible all -i /tmp/staging -i /tmp/production -m ping 使用 ssh 秘钥连接主机# 生成秘钥 ssh-keygen -t rsa # 发送公钥文件到管理节点 ssh-copy-id -i /root/.ssh/id_rsa.pub -p 22 root@10.10.110.122 # 现在主机清单里不用再填写账号密码了","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible快速开始(3)","slug":"ansible快速开始(3)","date":"2020-05-09T01:12:59.000Z","updated":"2020-08-28T03:03:03.050Z","comments":true,"path":"post/bf783834.html","link":"","permalink":"https://www.missf.top/post/bf783834.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 Ansible快速开始环境信息control os: centos 7.7 x64 ansible version: 2.9.7 python version:2.7.5 任务在Control node上去连接Managed nodes 定义主机清单 定义一个简单的通过ssh认证的主机清单 cat /etc/ansible/hosts 10.10.110.122 ansible_user=root ansible_pass=0 ansible_port=22 主机清单的配置含义: ansible_host 定义管理节点ip地址 ansible_user 连接管理节点的用户 ansible_pass 连接管理节点的用户密码 ansible_port 连接端口号默认是22 执行ansible命令 测试Control node和Managed nodes的连接状态 ansible 10.10.110.122 -m ping # 命令中的含义 -192.168.77.135 用于匹配主机清单中的主机名称 -m ping 指定 ping 模块，用于测试与管理节点的连接状态 如果提示如下错误: 10.10.110.122 | FAILED! =&gt; { “msg”: “Using a SSH password instead of a key is not possible because Host Key checking is enabled and sshpass does not support this. Please add this host’s fingerprint to your known_hosts file to manage this host.”} 这是因为Control node和Managed nodes第一次连接需要先添加指纹信息，可以先使用ssh连接一次，如果机器太多的话，可以在ansible配置文件开启host_key_checking = False cat /etc/ansible/ansible.cfg host_key_checking = False 再次测试连接状态 ansible 10.10.110.122 -m ping 10.10.110.122 | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" } # 看到\"ping\": \"pong\"表示连接成功","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible安装(2)","slug":"ansible安装(2)","date":"2020-05-08T03:12:59.000Z","updated":"2020-08-28T03:02:48.526Z","comments":true,"path":"post/3ebd0a7f.html","link":"","permalink":"https://www.missf.top/post/3ebd0a7f.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 安装 Ansible 对管理主机的要求 目前,只要机器上安装了 Python 2（版本2.6或2.7）或Python 3（版本3.5及更高版本）都可以运行Ansible (windows系统不可以做管理主机) 管理主机的系统可以是 Red Hat, Debian, CentOS, macOS, BSD的各种版本。 对节点主机的要求 通常我们使用 ssh 与节点通信，默认使用 sftp. 如果 sftp 不可用，可在 ansible.cfg 配置文件中配置成 scp 的方式. 在节点上也需要安装Python 2（2.6或更高版本）或Python 3（3.5或更高版本） 如果节点启用了selinux, 在使用copy/file/template时需要安装libselinux-python包 在管理节点上安装Ansible# Centos/RHEL wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo yum install -y ansible # Ubuntu sudo apt update sudo apt install software-properties-common sudo apt-add-repository --yes --update ppa:ansible/ansible sudo apt install ansible bash命令行自动补全 在Ansible 2.9之后，就支持了命令行参数补齐功能 # Centos/RHEL yum install -y epel-release yum install -y python-argcomplete 将补全加入环境变量activate-global-python-argcomplete source /etc/profile","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible介绍(1)","slug":"ansible介绍(1)","date":"2020-05-07T08:12:59.000Z","updated":"2020-07-14T01:24:20.780Z","comments":true,"path":"post/c55d25e0.html","link":"","permalink":"https://www.missf.top/post/c55d25e0.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 Ansible介绍Ansible 是2012年推出的一种通用自动化工具，ansible也是我接触的第一个自动化运维工具，ansible可以帮助我们完成一些批量任务，或者完成一些经常性的重复工作，在服务器集群场景下，ansible是我们运维的利器，Ansible 在2015年时被Redhat公司收购。Ansible是用Python编写的，它使用SSH在不同的机器上执行命令。Ansible是无代理的，这使得入手更容易。您只需要在相关机器上安装SSH和Python。Ansible使用声明式YAML语言”playbook”将一组主机(“hosts”)映射到定义明确的角色 也许你会说，我写个shell脚本不也一样能实现批量服务器的管理吗？这里我想说的是，ansible支持一些优秀的特性: 支持幂等性 No Agent 支持palybook实现复杂的任务 使用yaml语言 先来说说什么是幂等性，假如我要在目标主机安装Nginx，但是我不确定这个主机是否已经安装了Nginx，当使用ansible完成这个任务时，问题就会变得简单，如果目标主机已经安装Nginx，则ansible不会进行任何操作，如果目标主机未安装Nginx，ansible才会开始工作，ansible是以导向为结果的，我们指定一个状态，ansible就会自动判断，把服务器的状态调整为我们指定的状态，我多次执行，结果都是一样的，这就是幂等性。 使用zabbix监控一百台服务器，这一百台服务器都需要安装zabbix agent，但是ansible是不需要在管理节点上安装客户端代理程序的，因为它基于ssh工作，只要Control node能通过ssh连接到Managed nodes就能通过ansible管理对应的管理节点了，还有就是ansible的控制节点不用单独启动服务，能直接运行命令。 Ansible的目标实现一切自动化 Ansible的应用场景自动化部署应用 自动化管理配置 自动化的持续交付 自动化的云服务管理 自动化网络设备管理 Ansible的工作原理 安装ansible到管理节点，定义好主机清单，编写好palybook，就能运行ansible批量管理管理节点。步骤如下: 1.在控制节点上安装ansible 2.配置主机清单: 将被控节点的连接信息配置到主机清单中 3.定义playbook: 指定运行主机和执行任务 对节点主机的要求通常我们使用 ssh 与节点通信，默认使用 sftp. 如果 sftp 不可用，可在 ansible.cfg 配置文件中配置成 scp 的方式. 在节点上也需要安装Python 2（2.6或更高版本）或Python 3（3.5或更高版本） Ansible的概念控制节点(Control node)任何装有Ansible的机器可称为 控制节点 。 您可以从任何控制节点运行命令和剧本，并调用/usr/bin/ansible或/usr/bin/ansible-playbook命令，您可以将任何安装了Python的计算机用作控制节点,笔记本电脑,共享桌面和服务器都可以运行Ansible。 但是不能将Windows计算机用作控制节点。您也可以有多个控制节点 管理节点(Managed nodes)使用Ansible管理的网络设备或服务器可称为 管理节点。 受管节点有时也称为 主机 。 受管节点上是不需要安装Ansible的 主机清单(Inventory)托管节点的列表。库存文件有时也称为主机文件。您的目录可以为每个托管节点指定诸如IP地址之类的信息。库存还可以组织托管节点，创建和嵌套组，以便于扩展 模块(Modules)Ansible执行的具体代码。每个模块都有特定的用途，从管理特定类型数据库的用户到管理特定类型网络设备上的VLAN接口。您可以使用任务调用单个模块，也可以调用剧本中的几个不同模块 任务(Tasks)Ansible的行动单位。tasks包含一组由module组成的任务列表, 您可以使用特别的命令一次性执行单个任务 剧本(Playbooks)保存了已排序的任务列表，因此可以按此顺序重复运行这些任务。剧本可以包括变量和任务。剧本是用 YAML 编写的，易于阅读、编写、共享和理解","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Python基础day07","slug":"Python基础day07","date":"2020-04-28T11:42:45.000Z","updated":"2020-06-09T01:36:26.399Z","comments":true,"path":"post/44a3d96e.html","link":"","permalink":"https://www.missf.top/post/44a3d96e.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 闭包一般情况下，如果一个函数结束，函数的内部所有东西都会释放掉，还给内存，局部变量都会消失。但是闭包是一种特殊情况，如果外函数在结束的时候发现有自己的临时变量将来会在内部函数中用到，就把这个临时变量绑定给了内部函数，然后自己再结束。 # 闭包 def outer(): a = 6 def inner(): b = 8 print(a) print(b) return inner if __name__ == '__main__': res = outer() res() 可迭代对象我们分析对可迭代对象进行迭代使用的过程，发现每迭代一次（即在for…in…中每循环一次）都会返回对象中的下一条数据，一直向后读取数据直到迭代了所有数据后结束。那么，在这个迭代过程中就应该有一个“记录员”去记录每次访问到了第几条数据，以便每次迭代都可以返回下一条数据。我们把这个能帮助我们进行数据迭代的“记录员”称为迭代器(Iterator)。可迭代对象的本质就是可以向我们提供一个这样的“记录员”即迭代器帮助我们对其进行迭代遍历使用 转化成迭代器# 内部含有\"__iter__\"并且含有\"__next__\"方法的就是迭代器，遵循迭代器协议 s2 = \"cdfv\" ol = s2.__iter__() # 可迭代对象通过__iter__或者iter()方法转化成迭代器 # print(ol) print(ol.__next__()) # 一个next对应一个值，一一对应 print(ol.__next__()) print(ol.__next__()) print(ol.__next__()) c d f v 判断对象是否为迭代器# 判断一个对象是否是可迭代对象，方法一 s1 = 'asdf' jo = iter(s1) # 将可迭代对象转化成迭代器 print(jo) print(\"__iter__\" in dir(jo) and \"__next__\" in dir(jo)) # 判断是否同时含有这两个方法 &lt;str_iterator object at 0x000000FE3E7E0898> True # 判断一个对象是否是可迭代对象，方法二 from collections.abc import Iterable,Iterator # 导入Iterable,Iterator方法 so = 'asdf' print(isinstance(so,Iterable)) # 判断对象是否是可迭代 print(isinstance(so,Iterator)) # 判断对象是否是迭代器 生成器生成器本质上是迭代器，生成器是自己用Python代码写的迭代器，平时我们用iter将一个迭代对象转化成迭代器，是调用iter方法底层的C代码实现的。 # 将一个函数变成生成器函数 def fun(): print(123) print(456) yield 789 fun() s = fun() # 将函数赋值使用next打印，不能使用fun()调用函数进行打印 print(next(s)) # 一个next去取一个yield的值，之所以打印三个值是函数内部打印的，next(s)只打印了789 123 456 789 生成器的send方法一个send对应一个yield，但是如果send中有传值，就会将这个值发送给上一个yield def func(): # 1.定义函数 a = yield 123 print(a) yield '有志青年' yield '好好学习' yield '天天向上' genor = func() # 2.函数赋值 print(genor.send(None)) # 3.取一个yield，打印123 print(genor.send('Alex')) # 4.取下一个yield，并将Alex赋值给上一个yield，先执行的a = Alex;print(a),再打印有志青年 生成器的yield fromdef func(): lst = ['努力','奋斗','向上','乐观'] yield lst # 将列表当成一个整体 genor = func() print(next(genor)) ['努力', '奋斗', '向上', '乐观'] def func(): lst = ['努力','奋斗','向上','乐观'] yield from lst # 将列表中的每个元素逐个输出 genor = func() # print(next(genor)) for i in genor: print(i) 努力 奋斗 向上 乐观 列表所有值+1info = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] for index,i in enumerate(info): # info[0] = 0 + 1 info[index] += 1 print(info) 列表推导式和生成器表达式列表推导式列表推导式就是用一行代码构建一个简单或者复杂的列表，减少代码量的同时又可以装逼 print([i for i in range(1,26)]) # 构建一个1 - 25的列表 print(['python%s期' % i for i in range(1,26)]) # 构建一个稍微复杂的列表 print([i for i in range(1,31) if i % 3 == 0]) # 构建一个30以内所有能被3整除的数 print([i ** 2 for i in range(1,31) if i % 3 == 0]) # 所有能被3整除的数的平方 print(['青年%s号' % i for i in range(1,31,2)]) print(['*' if i % 3 == 0 else i for i in range(1,21)]) # 如果i能被3整除就为*，否则从range里面取值 # 将列表中至少含有两个e的字符串放到一个列表中 names = [['Tefe','oIred','Edvl','fgte','vfeke','vfd'],['dcvr','vfer','vfree']] ll = [] for i in names: for name in i: if name.count('e') >= 2: ll.append(name) print(ll) print([name for i in names for name in i if name.count('e') >= 2]) # 列表推导式能一行代码完成 生成器表达式生成器表达式与列表推导式几乎一模一样，就是[]换成了(),但是生成器在内存方面更占优势，列表推导式是一次性将数据加载到内存，而生成器则是取一点生成一点，更加节省内存 genor = ('python%s期' % i for i in range(1,26)) print(genor) for i in genor: print(i) 字典推导式print({i:None for i in range(1,11)}) # 值为None，key从range(1,11)取 am = {'s':'cd','wf':10,'r5':'km'} print({value:key for key,value in am.items()}) # 将字典的键值对换 集合推导式lp = {12,-9,75} print({i ** 2 for i in lp}) 匿名函数# 匿名函数 def func(x,y): return x + y print(func(2,78)) # 针对这种自有返回值的函数，可以写成简化的匿名函数 func = lambda x,y:x * y # 只能写成一行 print(func(3,56)) suf = lambda x,y,z:x * y * z print(suf(45,4,2))","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day06","slug":"Python基础day06","date":"2020-04-27T05:45:29.000Z","updated":"2020-06-30T07:04:01.442Z","comments":true,"path":"post/33a4e9f8.html","link":"","permalink":"https://www.missf.top/post/33a4e9f8.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 函数思考:不能使用len方法去统计一个字符串的长度 s = 'cdvfdcmkcd' count = 0 for i in s: count += 1 print(count) d = [1,2,3,4,5,] count = 0 for i in d: count += 1 print(count) 可以实现，但如果我在多处使用就会有重复性的代码。初学者一定要培养一种对代码完美的偏执，其实这也是面向过程编程的缺点:代码重复性较多，代码的可读性差。 函数初识一个函数就是封装一个功能 d = [1,2,3,4,5,] def my_len(): # 定义函数名my_len count = 0 for i in d: count += 1 print(count) my_len() # 调用函数，不调用不会执行代码 函数返回值函数中遇到return直接结束，给函数的调用者返回一个值，不写默认为None def date(): print('我叫荒原饮露') print('我在学习Python') print('我在让自己变得更加优秀') return # 直接结束函数 print('我以后要...') # return后面的不会输出 date() print('加油') 我叫荒原饮露 我在学习Python 我在让自己变得更加优秀 加油 # 如果不写返回值，默认返回一个None df = date() print(df) 我叫荒原饮露 我在学习Python 我在让自己变得更加优秀 None # 返回多个值 def date(): return 'faker','doinb','jacklove' skt,fpx,ig = date() print(skt) print(fpx) print(ig) faker doinb jacklove 函数的参数def date(a,b): # 函数的定义:形式参数 print('faker') print(a,b) x = 2 y = 3 date(x,y) # 函数的执行者:实际参数,将实参x,y传递给形参a,b faker 2 3 位置参数def date(positon,sex): # 实参和形参的位置必须要对应 print('%s附近的%s' % (positon,sex)) date('深圳','女性') # 调用函数时，传入两个参数 深圳附近的女性 键值对参数def date(tq,name,dc): # 形式参数与实际参数的键对应，位置不需对应 print('我叫%s,我喜欢的季节是%s,我学习%s已经一个月了' % (name,tq,dc)) date(name=\"小马哥\",tq=\"秋季\",dc=\"Python\") # 以键值对的方式传入实际参数 混合参数# 注意:位置参数必须在关键字参数的前面，不然会报错 def date(cs,home,tq,name,dc): print('我叫%s,我喜欢的季节是%s,我学习%s已经一个月了' % (name,tq,dc)) print('%s赚钱%s花,一分别想带回%s' % (cs,cs,home)) date('深圳','家',name=\"小马哥\",tq=\"秋季\",dc=\"Python\") 默认参数def date(soft,posi,sex=\"女\"): # 默认参数需要放置位置参数的后面 print('打开%s软件,搜索%s附近的%s' % (soft,posi,sex)) date('约会',posi='深圳南山区') 万能参数# 万能参数：两个形式参数，接收所有的位置参数，关键字参数 def date(*args,**kwargs): print(args) # 位置参数 print(kwargs) # 关键字参数 date('南山区','18',posi='深圳',sex='laddyboy') ('南山区', '18') # 将位置参数返回为一个元组 {'posi': '深圳', 'sex': 'laddyboy'} # 将关键字参数返回为一个字典 *的魔性用法# *的魔性用法 def fun(*args,**kwargs): print(args,kwargs) fun(*(1,2,'alex'),*('mk,j'),**{'ed':'12'},**{'cds':'lkj'}) # 在调用函数时*是将多个元组的元素整合成一个元组，**是将多个字典整合成一个字典 (1, 2, 'alex', 'm', 'k', ',', 'j') {'ed': '12', 'cds': 'lkj'} 形参的顺序问题def fun(a,b,*args,sex='女',**kwargs): print(a) print(b) print(args) print(sex) print(kwargs) fun(1,2,3,'oi','cd',sex=\"男\",name=\"alex\") 1 2 男 (3, 'oi', 'cd') {'name': 'alex'} # 按照位置参数 *args 默认参数 **kwargs的顺序 判断数值大小def sum(a,b): # 定义两个形式参数，用来接收实际参数 if a > b: return a else: return b print(sum(1,5)) 三元运算符dc = \"A\" if 6 > 3 else \"B\" # 如果条件成立dc就等于A，否则等于B print(dc) A def max(a,b): return a if a > b else b # 如果a大于b，就return a否则return b df = max(150,48) print(df) 150 函数的命名空间# 函数的命名空间 name = 'alex' age = '23' def fun(): sex = '女' print(sex) fun() # 变量赋值时会在内存中开辟一个名称空间用来存放变量名和对应的值 # 定义函数时会在内存中开辟一个函数内存地址，但不会存放函数体的内容 # 但函数调用时会再开辟一个临时名称空间，存放函数体的内容，并且临时名称空间随着函数的调用结束而消失 在python解释器开始执行之后, 就会在内存中开辟一个空间, 每当遇到一个变量的时候, 就把变量名和值之间的关系记录下来, 但是当遇到函数定义的时候, 解释器只是把函数名读入内存, 表示这个函数存在了, 至于函数内部的变量和逻辑, 解释器是不关心的. 也就是说一开始的时候函数只是加载进来, 仅此而已, 只有当函数被调用和访问的时候, 解释器才会根据函数内部声明的变量来进行开辟变量的内部空间. 随着函数执行完毕, 这些函数内部变量占用的空间也会随着函数执行完毕而被清空 我们给这个存放名字与值的关系的空间起了一个名字——命名空间 全局名称空间:存放的是py文件中变量与值的对应关系 局部名称空间:存放的是函数体里面的变量与值的对应关系 内置名称空间:内置函数，关键字等 加载到内存的顺序内置名称空间 —&gt; 全局名称空间 —&gt; 局部名称空间(当函数执行时) 取值顺序# 取值顺序，就近原则 # 局部名称空间 ---> 全局名称空间 name = 'mwj' def fun(): name = 'lok' print(name) fun() lok globals和localsname = 'li' def fun(): name = 'alex' def inner(): name = 'qw' print(globals()) # 返回一个字典：包含全局作用域的所有内容 print(locals()) # 返回一个字典：当前作用域的所有内容 inner() fun() {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': &lt;_frozen_importlib_external.SourceFileLoader object at 0x0000009D39BA5860>, '__spec__': None, '__annotations__': {}, '__builtins__': &lt;module 'builtins' (built-in)>, '__file__': 'C:/Python3.7/Python_Scripts/t5.py', '__cached__': None, 'name': 'li', 'fun': &lt;function fun at 0x0000009D39B5C1E0>} {'name': 'qw'} 高阶函数# 高阶函数 def fun1(): print(111) def fun2(): print(222) fun1() def fun3(): print(333) fun2() print(555) fun3() print(666) # 555 333 222 111 666,代码从上至下执行，函数调用函数 def fun(): print(1) def inner(): print(2) def inner2(): print(3) print(4) inner() print(5) fun() # 1 4 2 5,从上至下执行，函数定义之后不调用则不会被输出 global nonlocal# global nonlocal def fun(): global name name = \"alex\" fun() print(name) # 可以在局部声明一个全局变量，如果不声明为全局变量，print(name)不输出alex # 原本内层函数不能对外层函数的变量只能引用不能修改 def war(): name = \"alex\" def inner(): nonlocal name # 使用nonlocal 可以使内层函数对外层函数进行修改 name += \"b\" print(name) inner() war() 局部作用域不能引用全局作用域变量count = 1 def fun(): count += 1 # 执行报错 print(count) # 可以打印 fun() # 执行会报错，是因为局部作用域不能对全局作用域的变量只能引用不能修改 # 通过global在局部作用域声明，可以进行修改 count = 1 def fun(): global count count += 1 print(count) fun() 函数名作为函数的参数def fun(x): print(x) print(\"in fun\") def fun1(): print(\"in fun1\") fun(fun1) # 调用fun函数并且将fun1作为参数，输出的是fun1函数的内存地址，fun1函数被作为参数时是一个变量 &lt;function fun1 at 0x00000055024C9620> in fun 函数名可以当做函数的返回值# 函数名可以当做函数的返回值 def fun(x): print(\"in fun\") return x def fun1(): print(\"in fun1\") re = fun(fun1) print(re) in fun &lt;function fun1 at 0x00000030B6739620>","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day05","slug":"Python基础day05","date":"2020-04-26T05:21:29.000Z","updated":"2020-06-02T07:51:22.011Z","comments":true,"path":"post/aaadb842.html","link":"","permalink":"https://www.missf.top/post/aaadb842.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 Python文件操作全部读取file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") # 文件路径，文件编码，操作方式 content = file1.read() # 将读取到文件的内容复制给content print(content) # 打印文件的内容 读取n个字符file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") content = file1.read(11) print(content) 按行读取file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") content = file1.readline() print(content) 返回列表file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") content = file1.readlines() print(content) # 返回一个列表，用原文件的每一行作为列表的每一个元素 for循环读取# 读取大文件时逐行读取防止内存崩溃，涉及到迭代器 file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") for line in file1: print(line.strip()) file1.close() 读取文件的方式 read() 全部读取 read(n) 读取n个字符 readline() 按行读取 readlines() 返回一个列表，列表的元素是原文件的每一行数据 for循环读取 读取大文件时逐行读取防止内存崩溃 写入文件的方式写入空文件f1 = open(\"file1\",encoding=\"utf-8\",mode=\"w\") # 打开文件句柄 content = f1.write(\"我也不知道写什么啊\") # 写入操作 f1.close() # 关闭文件句柄 # 如果写入文件不存在，open()将自动创建它 # 如果文件已存在已有内容，会清空再写入 写入多行f1 = open(\"file1\",encoding=\"utf-8\",mode=\"w\") f1.write(\"我也不知道写什么啊\") f1.write(\"我也不知道写什么啊\") f1.write(\"我也不知道写什么啊\") f1.close() # 加换行符 f1 = open(\"file1\",encoding=\"utf-8\",mode=\"w\") f1.write(\"我也不知道写什么啊\\n\") f1.write(\"我也不知道写什么啊\\n\") f1.close() # 在打开一个文件句柄后，可以重新写入多次而不被清空，只有在文件句柄被关闭后，下一次写入才会被清空 追加文件内容# 没有文件创建文件追加内容，有此文件则在原文件的末尾追加新内容 f1 = open(\"file1\",encoding=\"utf-8\",mode=\"a\") f1.write(\"我也不知道写什么啊\\n\") f1.write(\"我也不知道写什么啊\\n\") f1.close() 读写非文字类文件# 音视频或者图片类型的文件，以bytes读取和写入 f3 = open(\"tr.jpg\",mode=\"rb\") # 用rb模式打开一张图片 content = f3.read() # 以bytes读取原图片数据 f4 = open(\"ting.jpg\",mode=\"wb\") f4.write(content) # 将数据写到一个新文件图片 f3.close() f4.close() 读写模式先读后写f1 = open(\"file1\",encoding=\"utf-8\",mode=\"r+\") content = f1.read() # 读取内容 print(content) f1.write(\"alex\") # 写入内容，这里是以追加的方式写入，不会清空文件内容 f1.close() 调整光标写入f1 = open(\"file1\",encoding=\"utf-8\",mode=\"r+\") f1.seek(0) # 将光标调整到最前 f1.write(\"jkl\") # 在最前面写入jkl，会将原来前面的三个字符替换掉 f1.close() f1.seek(0,2) # 将光标调到最后面 f1.write(\"ooo\") # 在下一行写入ooo f1.close() 强制保存f1 = open(\"file1\",encoding=\"utf-8\",mode=\"r+\") f1.write(\"TES.123\") f1.flush() #强制保存，相当于Crtl + s f1.close() 判断文件句柄是否可读可写# readable writeable f2 = open(\"file\",encoding=\"utf-8\",mode=\"w\") # 写入模式 print(f2.read()) # 读取会报错 print(f2.readable()) # 由于是写入模式不能读 False print(f2.writable()) True 按照字节调整光标位置# tell seek f1 = open(\"file2\",encoding=\"utf-8\") ret = f1.read() # 读取文件，光标会移动到下一行 print(f1.tell()) # 获取当前文件指针的位置 f1.seek(3) # 移动指针到指定的位置 print(f1.read()) # 从指针位置往后读取 f1.close() 截取文件# truncate 只能在可写的模式下截取原文件，只能从头截取 f1 = open(\"file1\",encoding=\"utf-8\",mode=\"r+\") ret = f1.truncate(12) # 截取文件的前12个字节,文件其他内容会被清空，只保留截取到的字节 print(f1.read()) f1.close() 中华人民 # utf-8编码下，一个中文字符等于三个字节，如果是截取4个字节会报错 with open操作方式# 1.自动关闭文件句柄 with open(\"file4\",encoding=\"utf-8\") as f1: content = f1.read() print(content) # 2.同一语句可操作创建多个文件句柄 with open(\"file1\",encoding=\"utf-8\") as f1,open(\"file2\",encoding=\"utf-8\",mode=\"w\") as f2: print(f1.read()) # 对file1进行读取操作 f2.write(\"777\") # 对file2进行写入操作 # 3.with open 可能引起IO错误的操作 with open(\"file1\",encoding=\"utf-8\") as f1: f1.read() # 打开文件句柄f1进行读取操作，文件句柄自动关闭 with open(\"file1\",encoding=\"utf-8\",mode=\"w\") as f2: f1.write(\"777\") # 又打开文件句柄f2进行写操作，如果文件句柄f1没有及时关闭又打开了f2文件句柄程序就会报错 关于文件的修改文件的数据都是存放在硬盘上的，因此只存在覆盖，不存在修改一说，我们平时看到的修改文件，都是模拟出来的效果，修改file5文件中的Alex字符为Sb，并且将原文件复制为新文件file.bak，删除原文件，修改新文件的名字为file5，修改速度非常快，根本看不到生成的file5.bak文件，具体的说有两种实现方式 将硬盘存放的该文件的内容全部加载到内存，在内存中是可以修改的，修改完毕后，再由内存覆盖到硬盘 # file5文件内容 Alex是个屌丝，即使Alex有特斯拉也还是屌丝 你们真逗，Alex再牛逼，也掩饰不了资深屌丝的气息 import os with open(\"file5\",encoding=\"utf-8\") as f1,open(\"file5.bak\",encoding=\"utf-8\",mode=\"w\") as f2: # 打开两个文件句柄，f1只读，f2可写 old_content = f1.read() # 将f1内容赋值给old_content new_content = old_content.replace(\"Alex\",\"Sb\") # 将Alex替换为Sb的数据赋值给new_content f2.write(new_content) # 将新数据写入f2 os.remove(\"file5\") # 删除文件file5 os.rename(\"file5.bak\",\"file5\") # 将新文件命名为file5 # 这样有一个不好的地方，old_content = f1.read()这里是一次性将文件加载到内存中的 将硬盘存放的该文件的内容一行一行地读入内存，修改完毕就写入新文件，最后用新文件覆盖源文件 import os with open(\"file5\",encoding=\"utf-8\") as f1,open(\"file5.bak\",encoding=\"utf-8\",mode=\"w\") as f2: for line in f1: new_line = line.replace(\"Sb\",\"Alex\") # 将一行的数据替换完成赋值给新的一行 f2.write(new_line) # 逐行写入 os.remove(\"file5\") os.rename(\"file5.bak\",\"file5\") # 不会将文件一次加载到内存","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day04","slug":"Python基础day04","date":"2020-04-25T10:21:29.000Z","updated":"2020-06-02T07:51:22.006Z","comments":true,"path":"post/ddaa88d4.html","link":"","permalink":"https://www.missf.top/post/ddaa88d4.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 基础数据类型补充判断数值是否相等top1 = 'alex' top2 = 'alex' print(top1 == top2) True 内存地址# 打印mem会先找到mem的内存地址，然后再找到内存地址指向的数据 mem = 'mk' print(id(mem)) 170332332864 判断内存地址是否相同f = [1,2,3] g = [1,2,3] print(f == g) # True print(f is g) # False # 判断的是两个对象的内存地址是否相同,虽然f的值等于g，但是内存地址却不是指向同一个 数据类型 可变/不可变 整型 不可变 字符串 不可变 元组 不可变 列表 可变 集合 可变 字典 可变 代码块# 代码块 代码全都是基于代码块去运行的，一个文件就是一个代码块，不同的文件就是不同的代码块 # 代码块的缓存机制 Python在执行同一个代码块的初始化对象的命令时，会检查其值是否已经存在， 如果存在，会将其重用，如果有同样的记录那么它会重复使用这个字典中的值， 但是要注意的是，只有在同一个代码块下，才会实现这个缓存机制 满足此机制的数据类型:int str bool 优点：节省内存，提升性能 小数据池Python自动将-5~256的整数进行了缓存，当你将这些整数赋值给变量时，并不会重新创建对象，而是使用已经创建好的缓存对象。python会将一定规则的字符串在字符串驻留池中，创建一份，当你将这些字符串赋值给变量时，并不会重新创建对象， 而是使用在字符串驻留池中创建好的对象。 小数据(又称驻留机制、驻存机制) 能够应用于不同的代码块 适应的数据类型:int str bool int:-5 ~ 256 str:一定条件下的str满足小数据池 bool:全部 优点:节省内存 提升性能 编码进阶不同的编码之间不能互相识别（会出现报错或者乱码），文字通过网络传输，或者硬盘存储不能使用Unicode编码方式。 ASCII早期的密码本，英文字母，数字，特殊字符 8位(bit) == 1byte 在ascll码中,8位bit表示一个字节表示一个字符 hello = 01101000 01100101 01100111 0110011 01100101 Unicode万国码包含全世界所有的文字 32位bit表示4个字节表示一个字符 a:10001000 00010010 00100000 00010010 中:00000000 10010010 00000000 10010010 utf-8最少用8位表示一个字符 a:01000010,8位bit表示一个字节表示一个字符 欧洲文字:00000010 00100000 16位bit表示两个字节表示一个字符 中国文字:00000010 00000010 00000010 24位bit表示三个字节表示一个字符 gbk最包含英文和自己国家的语言 a:00000010 8位bit表示一个字节表示一个字符 中:00000010 0000001016 16位bit表示两个字节表示一个字符 在Python3x环境下，唯独str类型的内部编码方式是Unicode， 所以Python3x中的字符串不能用于直接的网络传输和文件存储 补充一个数据类型：bytes类型，与str类型是海尔兄弟， bytes内部编码方式为非Unicode，bytes类型能用于网络传输和文件存储，还拥有str的其他特性 但是bytes中文是16进制表示，看不懂，所以常用的还是str类型 bytes类型b1 = 'alex' b2 = b'alex' print(b1,type(b1)) alex &lt;class 'str'> print(b2,type(b2)) b'alex' &lt;class 'bytes'> 数据类型转换# str ---> gbk s0 = '荒原饮露' b1 = s0.encode('gbk') # 编码，将字符串转换为gbk print(b1) b'\\xbb\\xc4\\xd4\\xad\\xd2\\xfb\\xc2\\xb6' # 可以看到 一个中文两个字节 y2 = b1.decode('gbk') # 解码 print(y2) 荒原饮露 # str ---> utf-8 s2 = '努力奋斗' b2 = s2.encode('utf-8') print(b2) b'\\xe5\\x8a\\xaa\\xe5\\x8a\\x9b\\xe5\\xa5\\x8b\\xe6\\x96\\x97' # 一个中文三个字节 b3 = b2.decode('utf-8') print(b3) 努力奋斗 # gbk ---> utf-8 si = '编码' s1 = si.encode('gbk') print(s1) b'\\xb1\\xe0\\xc2\\xeb' # 得到gbk编码的bytes类型 1 = s1.decode('gbk') # 解码再加密 b2 = b1.encode('utf-8') print(b2) b'\\xe7\\xbc\\x96\\xe7\\xa0\\x81' # utf-8编码的bytes类型 深浅拷贝# 赋值运算 jk = [1,2,3] yu = jk # yu变量和jk变量都指向同一个内存地址 yu.append(789) # 修改这个列表的时候，两个变量的值都被修改 print(jk,yu) [1, 2, 3, 789] [1, 2, 3, 789] 浅拷贝lo = ['de',15,['er',4,2]] ko = lo.copy() # ko拷贝lo的列表，得到一样的数据，但是浅copy只会拷贝内存中的第一层数据 lo.append('lp') # lo往列表追加一个元素lp print(id(lo),lo) print(id(ko),ko) 205292790408 ['de', 15, ['er', 4, 2], 'lp'] 205293284808 ['de', 15, ['er', 4, 2]] # 可以看到两个列表的内存地址都是不一样的，往lo列表追加lp元素，ko列表是没有跟随lo列表追加lp元素的 lo[2].append('io') # 往lo列表的小列表里面追加io元素 print(lo,ko) ['de', 15, ['er', 4, 2, 'io'], 'lp'] ['de', 15, ['er', 4, 2, 'io']] # 可以看到，lo和ko列表的小列表都被追加了io元素，简而言之，列表里面的小列表里面的元素是共用的。ko拷贝lo的列表，只会拷贝lo外层列表，而不会拷贝lo的内层列表，lo外层列表发生改变ko不会跟随，但是lo内层列表发生改变ko会跟随，复制一个列表时，lo = ['de',15,['er',4,2]]，de和15元素的地址发生改变，['er',4,2]小列表的元素还是指向原来的地址 # 全切片是浅copy ki = ['cf',['ijni','678',15],90] ji = ki[:] ki[1].append('mk') print(ki,ji) ['cf', ['ijni', '678', 15, 'mk'], 90] ['cf', ['ijni', '678', 15, 'mk'], 90] 深拷贝# 深copy会在内存中对原列表以及列表里面的可变的数据类型重新创建一份，而列表中不可变得数据类型还是沿用原来的 import copy lo = ['fr','ty',['rt','km',12],45] ko = copy.deepcopy(lo) print(lo,ko) lo[2].append('test') print(lo,ko) ['fr', 'ty', ['rt', 'km', 12], 45] ['fr', 'ty', ['rt', 'km', 12], 45] ['fr', 'ty', ['rt', 'km', 12, 'test'], 45] ['fr', 'ty', ['rt', 'km', 12], 45] # 往lo小列表追加元素，ko的小列表的元素不是指向原来的地址，ko的小列表元素没有被改 深拷贝和浅拷贝的区别# 以下所有的内容都是基于内存地址来说的。 # 可变数据类型：当该数据类型的对应变量的值发生了改变，那么它对应的内存地址不发生改变，对于这种数据类型，就称可变数据类型 # 不可变数据类型：当该数据类型的对应变量的值发生了改变，那么它对应的内存地址也会发生改变，对于这种数据类型，就称不可变数据类型 # 总结：不可变数据类型更改后地址发生改变，可变数据类型更改地址不发生改变 深拷贝和浅拷贝的需要注意的点# 在浅拷贝时，拷贝出来的新对象的地址和原对象是不一样的，但是新对象里面的可变元素（如列表）的地址和原对象里的可变元素的地址是相同的，也就是说浅拷贝它拷贝的是浅层次的数据结构（不可变元素），对象里的可变元素作为深层次的数据结构并没有被拷贝到新地址里面去，而是和原对象里的可变元素指向同一个地址，所以在新对象或原对象里对这个可变元素做修改时，两个对象是同时改变的，但是深拷贝不会这样，这个是浅拷贝相对于深拷贝最根本的区别","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day03","slug":"Python基础day03","date":"2020-04-24T10:14:29.000Z","updated":"2020-06-02T07:51:22.009Z","comments":true,"path":"post/43ce1d77.html","link":"","permalink":"https://www.missf.top/post/43ce1d77.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 验证码# 代入验证码项目，输入姓名密码之后有空格也不会报错 username = input(\"请输入姓名:\").strip() passworrd = input(\"请输入密码:\").strip() code = 'AeTrd'.upper() your_code = input(\"请输入验证码:\").upper() if your_code == code: if username == 'alex' and passworrd == 'sb': print('登录成功') else: print('用户名或者密码错误') else: print('验证码不正确') 将一行字符串竖着打印# while循环 t = '荒原饮露cchkskhdiqwuey' s = len(t) # 先统计字符串的长度 # print(s) index = 0 # 设定一个索引值 while index &lt; s: # 如果索引值小于变量s则进入循环 print(t[index]) # 从0开始打印字符串的索引，直到index&lt;s不成立退出循环 index += 1 # index每次自增1 # for循环 t = '荒原饮露cchkskhdiqwuey' for i in t: print(i) # 还可以进行拼接，print(i+'lo') 猜数字# 猜数字,只有猜对了才会退出 num = 66 while True: cai = int(input(\"请输入你要猜的数字:\")) if cai > num: print(\"猜的数字大了！\") elif cai &lt; num: print(\"猜的数字小了\") else: print(\"猜对了！\") break # 三次猜测不对就退出 num = 66 i = 0 while i &lt; 3: j = int(input(\"请输入数字:\")) if j > num: print(\"数字大了!\") elif j &lt; num: print(\"数字小了!\") else: print(\"猜对了!\") break i += 1 计算器# 方式一 content = input(\"请输入内容:\").strip() # 将输入的字符串，去掉前后两端的空格 plus_index = content.find('+') # 找到加号位置，并返回加号的索引数 num1 = content[:plus_index].strip() # 取加号前面的区域并且去掉空格 num2 = content[plus_index+1:] # 取加号后面的区域也去掉空格 sum3 = int(num1) + int(num2) # 将取到的无空格值相加 print(sum3) # 方式二 content = input(\"请输入内容:\").strip() # 将输入的字符串，进行去前后两端的空格 li = content.split('+') # 将字符串转换为列表，指定以+进行分割 print(li) ['15 ', ' 16'] # 将得到的元素相加 sum1 = int(li[0]) + int(li[1]) # 将字符串类型的两个元素强制转换为int，会去掉空格 print(sum1) 列表为什么需要列表 字符串如果长度过于长取值时会很费劲，取出来的数据是字符串类型，使用不方便 字符串有长度限制(只能存储少量的字符串类型的数据) 基于以上原因Python提供了一个另外的数据类型:容器类数据类型 什么是列表 列表能存储大量的、不同的数据类型，列表存放什么数据类型，取出来之后还是什么数据类型 列表可以存放的数据类型:数字，字符串，布尔值，小列表，元组，字典，集合，对象 32位Python的限制是 536870912 64位Python的限制是 1152921504606846975 列表是有序的、有索引值的、可切片、方便取值 列表取值# 取第一个元素 sl = ['alex','荒原','154'] sl1 = print(sl[0],type(sl)) # 输出索引和索引类型 print(sl1) # alex &lt;class 'list'> 定义列表时是字符串 sl = ['alex','荒原','154'] sl1 = print(sl[0:2]) # 0 1 2，顾首不顾尾，只取前两个元素 print(sl1) # ['alex', '荒原'] # 反向取值 sl = ['alex','荒原','154'] sl1 = print(sl[-1:-4:-1]) print(sl1) # ['154', '荒原', 'alex'] 列表的增加sl.append(\"abc\") # 增加abc元素 print(sl) sl.append(True) # 增加布尔值 print(sl) name_list = [] # 空列表 while True: # 如果不执行break,则一直执行while True username = input(\"请输入姓名:\").strip() # 用户输入字符串 if username.upper() == 'Q':break # 如果输入是q，无论大小写都执行break name_list.append(username) # 判断到不是q则增加到列表 print(name_list) # 插入 lk = ['mjk','ctr','tpo',100] lk.insert(1,'yu') # 在索引1的位置，插入'yu',索引从零开始 print(lk) ['mjk', 'yu', 'ctr', 'tpo', 100] # 迭代者追加 lk = ['mjk','ctr','tpo',100] lk.extend('abc') print(lk) ['mjk', 'ctr', 'tpo', 100, 'a', 'b', 'c'] lk = ['mjk','ctr','tpo',100] lk.extend(['asd','cvf','cdd']) print(lk) ['mjk', 'ctr', 'tpo', 100, 'asd', 'cvf', 'cdd'] 列表的删除# 按照索引去删除 lk = ['mjk','ctr','tpo',100] ret = lk.pop(1) # 删除索引为1的元素 print(lk) ['mjk', 'tpo', 100] # 按照元素去删除 lk = ['mjk','ctr','tpo',100] lk.remove('tpo') # 指定删除那个 print(lk) ['mjk','ctr',100]. # 清空列表 lk = ['mjk','ctr','tpo',100] lk.clear() print(lk) [] # del 1.按照索引删除单个元素 lk = ['mjk','ctr','tpo',100] del lk[0] print(lk) ['ctr','tpo',100] 2.按照切片删除一部分元素 lk = ['mjk','ctr','tpo',100] del lk[:2] print(lk) ['tpo', 100] 3.按照切片（步长）删除一部分元素 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] s = lk[:5:2] # 取区域为0-5，步长为2 print(s) ['mjk', 'tpo', 'cff'] del lk[:5:2] # 取区域为0-5，步长为2，这些元素全部删除 print(lk) ['ctr', 100, 'ioo', 'tyy'] 列表的修改# 利用索引修改 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] lk[0] = 'we' # 利用索引定义要修改的元素的位置 print(lk) # 利用切片修改 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] lk[:2] = 'op' print(lk) ['o', 'p', 'tpo', 100, 'cff', 'ioo', 'tyy'] # 利用切片+步长修改 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] lk[:4:2] = 'op' # 注意步长的个数和修改后的字符串个数 print(lk) ['o', 'ctr', 'p', 100, 'cff', 'ioo', 'tyy'] 列表的查询# 按照索引查询 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] print(lk[1]) # 打印一个 # for 循环 for i in lk: print(i) # 输出列表所有元素 列表的其他操作# 计算列表元素的总个数 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy','cff'] print(len(lk)) 8 # 计算某个元素出现的个数 print(lk.count('cff')) 2 # 通过元素找索引，找到第一个返回，找不到就报错 print(lk.index('ctr')) 1 # 从小到大排列 fg = [2,9,4,6,7,1,8] fg.sort() print(fg) [1, 2, 4, 6, 7, 8, 9] # 从大到小排列 fg.sort(reverse=True) print(fg) [9, 8, 7, 6, 4, 2, 1] # 列表翻转 fg = [2,9,4,6,7,1,8] fg.reverse() print(fg) # 英文字符排序，按照元素首字母的ASCLL码的大小排序 fg = ['dfg','arfd','wer','fgv'] fg.sort() print(fg) ['arfd', 'dfg', 'fgv', 'wer'] 列表的嵌套ll = [1,2,'taibai',[1,'alex',3,]] # 列表里面有嵌套的小列表 # 将taibai改成大写 ll[2] = ll[2].upper() print(ll) # 往小列表追加元素'老男孩教育' ll[3] = ll.append('老男孩教育') print(ll) # 将alex改成alexsb ll[3][1] = ll[3][1] + 'sb' print(ll) # 打印嵌套列表元素 lj = ['wedi','lko','cjd',['dkd','oto'],'top'] for i in lj: if type(i) == list: # 加个判断如果某个元素类型为list，则再循环一遍，打印出来 for o in i: print(o) else: # 否则正常打印 print(i) 元组用来存放一些重要的信息，放在列表中不安全，需要一个容器类的数据类型，比如：个人信息，密码等。元组不能修改，但是元组里面的列表可以修改。 tu = (1,'alex',True,[1,2,3]) # 定义一个元组 tu[-1][2] = '12' # 往列表里面追加元素 print(tu) (1, 'alex', True, [1, 2, '12']) # 存放一些重要数据时，需要用元组存放 字典列表如果存储大量的数据，查询速度相对较慢，因为列表存储的数据一般没有什么关联性。针对这个问题，Python提供了一个基础数据类型：字典(dict) 回顾数据类型 分类 数据类型 容器型数据类型 list，tuple，dict，set 非容器型数据类型 str，bool，int 可变数据类型（不可哈希） list，dict，set 不可变数据类型（可哈希） str，bool，int，tuple 字典是由键值对形式存储的数据类型，字典的键必须是不可变的数据类型，唯一不重复的，字典的值可以是任意数据类型或者对象。基于字典的键是不可变的，字典的键会通过一种哈希算法，将键的值换算成内存地址，所以字典的查询速度非常快。字典在Python3.6之前是无序的，在3.6及以后字典会按照字典创建时的顺序排列。字典可以存储大量关联性数据。 字典的增加dic = {'name':'barry','age':18,'sex':'man'} # 用字典定义三个键值对 dic['dfgh'] = 150 # 没有则添加这个键值对 dic['age'] = 28 # 有age这个键就将值覆盖为28 print(dic) {'name': 'barry', 'age': 28, 'sex': 'man', 'dfgh': 150} dic.setdefault('port') # 没有这个键值对就会添加并赋值为空 dic.setdefault('name','yiyi') # 有name这个值则不修改，没有则增加 print(dic) {'name': 'barry', 'age': 18, 'sex': 'man', 'port': None} 字典的删除# pop 通过键去删除键值对 dic = {'name':'barry','age':18,'sex':'man'} ret = dic.pop('sex') print(dic) {'name': 'barry', 'age': 18} # 删除一个不存在的键就会报错 dic = {'name':'barry','age':18,'sex':'man'} ret1 = dic.pop('name2') # 为了程序能执行下去，想要不报错的话，可以添加一个返回值 dic = {'name':'barry','age':18,'sex':'man'} ty = dic.pop('re','没有此键') print(ty) 没有此键 # clear 清空 dic = {'name':'barry','age':18,'sex':'man'} dic.clear() print(dic) {} # popitem 删除最后一个键值对，3.5之前是随机删除，3.6删除最后一个键值对 dic = {'name':'barry','age':18,'sex':'man'} lo = dic.popitem() print(dic) {'name': 'barry', 'age': 18} # 删除整个字典 dic = {'name':'barry','age':18,'sex':'man'} del dic print(dic) 字典的修改# 改 dic = {'name':'barry','age':18,'sex':'man'} dic['age'] = 28 #重新定义age键的值 print(dic) # update 更新 dic1 = {'name':'barry','age':18,'sex':'man'} dic2 = {'name':'nji','age':'18','id':'001'} dic2.update(dic1) #将dic1字典中的键值对覆盖添加到dic2，dic1不变 print(dic2) {'name': 'barry', 'age': 18, 'id': '001', 'sex': 'man'} # update 正常添加 dic = {'name':'barry','age':18,'sex':'man'} dic.update(weight=150,high=175) #一次添加多个键值对 print(dic) {'name': 'barry', 'age': 18, 'sex': 'man', 'weight': 150, 'high': 175} 字典的查询# 查 dic = {'name':'barry','age':18,'sex':'man'} print(dic['name']) # 按键查对应的值，没有此键会报错 barry tr = dic.get('age1','没有此键') # 定义没有此键时的返回值 print(tr) 没有此键 字典的其他操作dic = {'name':'barry','age':18,'sex':'man'} print(dic.keys()) dict_keys(['name', 'age', 'sex']) print(dic.values()) dict_values(['barry', 18, 'man']) print(dic.items()) dict_items([('name', 'barry'), ('age', 18), ('sex', 'man')]) # for循环得到的是keys值 for i in dic: print(i) name age sex 字典的嵌套联系# 字典的嵌套练习 dic = { 'l1':['alex', '太白'], 'id':3, 1:{ 'data': 20181225, 'place': '深圳校区', 'class': 'python3期', 'name_list': ['awq', 'xx'], } } # 1.给小列表['alex', '太白'] alex后面插入一个字符串，'aaa' dic['l1'].insert(1,'aaa') print(dic) # 2.将id对应的3变成1 dic['id'] = 1 # 3.将1对应的字典的data的值变成20181224 dic[1]['data'] = 20181224 print(dic) # 4.将name_list对应的awq全部变成大写 dic[1]['name_list'][0] = dic[1]['name_list'][0].swapcase() print(dic) # 5.将name_list对应的xx删除 dic[1]['name_list'].pop(1) print(dic) 将字典数据格式化输出# 格式化输出 msg = '我叫%s,我身高%s，年龄%s' % ('ed',180,23) print(msg) # 将字典数据格式化输出 dic = {'name':'barry','age':18,'sex':'男'} mk = '我叫%(name)s,今年%(age)s,性别%(sex)s' % dic print(mk) 返回一个新的字典# 返回一个新的字典，键从可迭代对象里面获取，值不变 dic1 = dict.fromkeys('top','ed') dic2 = dict.fromkeys(['lop'],'努力') print(dic1) {'t': 'ed', 'o': 'ed', 'p': 'ed'} print(dic2) {'lop': '努力'} dicu = dict.fromkeys([1,2,3],['alex']) print(dicu) {1: ['alex'], 2: ['alex'], 3: ['alex']} # 坑:值如果是一个可变的数据类型，那么所有的值都是一个内存地址 dicu[1].append(000) print(dicu) {1: ['alex', 0], 2: ['alex', 0], 3: ['alex', 0]} # 给dicu[1]这个列表赋值000，所有列表的值都是000，因为列表所有的值都指向一个内存地址 数据类型的补充# 数据类型的补充 str ---> list split list ---> str join 0,'',[],{},(),set() ---> bool:false # 列表和元组的互换 # list &lt;---> tuple jk = [1,2,3] yu = tuple(jk) print(yu) uy = list(yu) print(uy) # dict ---> list dico = {'name':'kasha','ui':'io'} print(list(dico)) ['name', 'ui'] # dict ---> tuple dich = {'name':'yu','age':15} print(tuple(dich)) ('name', 'age') # 元组中只有一个元素并且没有逗号，则它不是元组，它与元素数据类型相同 t1 = (1,) t2 = ('al',) t3 = ([1,2,3],) print(t1,t2,t3) (1,) ('al',) ([1, 2, 3],) t1 = (1) t2 = ('al') t3 = ([1,2,3]) print(t1,t2,t3) 1 al [1, 2, 3] 将索引为奇数位的元素删除# 将索引为奇数位的元素删除,列表是不等长的 # 方法一 li = [11,36,56,48,79,45,21,65] del li[1::2] # 1-所有，步长为2 print(li) # 方法二 li = [11,36,56,48,79,45,21,65] new_li = [] # 定义一个空列表 for index in range(len(li)): # 循环 if index % 2 == 0: # 如果能被2整除 new_li.append(li[index]) # 如果能整除，就加入到new_li列表里面，这样索引是奇数位的元素就被删除了 li = new_li print(li) # 方法三 li = [11,36,56,48,79,45,21,65] for index in range(len(li)-1,-1,-1): if index % 2 == 1: li.pop(index) print(li) 将字典中键含有k元素的键值对删除# 将字典中键含有k元素的键值对删除 dict = {'ko':'ty','df':54,'13k':'hu','jl':'lp'} # 循环列表时不能改变字典的大小 lo = [] # 定义一个空的列表 for i in dict: # 将字典循环给i，赋值时是只将key赋值 if 'k' in i: # 如果k存在于i中 lo.append(i) # 则把这些有k元素的键值对添加到lo这个空字典 for y in lo: # 将lo字典循环给y dict.pop(y) # 通过键去删除键值对 print(dict) enumerate()# enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中 s1 = \"Hello\" for i,y in enumerate(s1,start=1): print(i,y) 1 H 2 e 3 l 4 l 5 o s2 = [\"top\",\"jun\",\"mid\",\"adc\",\"sup\"] for i,j in enumerate(s2,start=1): print(i,j) 1 top 2 jun 3 mid 4 adc 5 su 集合集合创建# 集合的创建 set1 = {\"er\",\"mk\",\"lk\"} print(set1) set2 = ('lk','oi',\"er\") # 不一定要{}或者(),只要是迭代对象就行 print(set2) 集合的无序特点# 集合是无序的 set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.add(\"fpx\") print(set1) {'rng', 'top', 'skt', 'fpx', 'we'} #增加一个元素，不会按照顺序添加，每一次执行代码，顺序都会改变 集合的迭代增加set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.update(\"fpx\") #迭代增加会把整个字符串拆分为多个字符进行增加 print(set1) {'skt', 'x', 'rng', 'top', 'f', 'p', 'we'} 集合的删除set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.remove(\"skt\") # 指定删除元素 print(set1) {'top', 'we', 'rng'} set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.pop() # 随机删除一个元素 print(set1) set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.clear() # 清空集合 print(set1) set() 集合的元素是不可变类型set1 = {\"we\",\"gb\",[\"rf\",\"gb\"]} print(set1) # 集合里面存在列表元素，执行会报错 set1 = {\"we\",\"gb\",(\"vf\",\"jin\",1)} print(set1) # 集合里面存在元组元素可以执行，因为元组是不可变类型 面试必考# 面试必考 list1 = [1,2,3,4,5] list2 = [2,3,4,5,6] # 将list1和list2的元素集合起来并去重 new_list = list1 + list2 print(new_list) new_set = list(set(new_list)) #将new_list转换为集合，再转换为list print(new_set) [1, 2, 3, 4, 5, 2, 3, 4, 5, 6] [1, 2, 3, 4, 5, 6] 电影投票# 电影投票:程序先给出几个目前正在上映的电影列表. 由用户给每个电影投票. # 最终将该用户投票信息公布出来 lst = ['北京遇上西雅图', '解救吴先生', '美国往事', '西西里的美丽传说'] lst = ['北京遇上西雅图', '解救吴先生', '美国往事', '西西里的美丽传说'] # print(lst) dic = dict.fromkeys(lst,0) #定义一个字典，key来自lst列表，值是0 while True: for num,name in enumerate(lst,start=1): #定义电影序号和电影来自lst列表 print('{}\\t{}'.format(num,name)) #列出电影序号和电影 name_num = input('请输入你喜欢的电影序号，或者q/Q退出:').strip() #记录用户所喜欢的电影序号 if name_num.isdigit(): #如果用户输入的是数字则进入，否则输出206行的：你输入有误，请重新输入 name_num = int(name_num) #用户输入的必须是整数 if 0 &lt; name_num &lt; len(lst): #控制用户输入数字的范围必须是比0大，比列表总长度小 dic[lst[name_num-1]] += 1 #将用户输入的值记录到dic空字典，lst[name_num-1] == dic字典的第一元素，是0 print('已成功为%s投票' %(lst[name_num-1])) #提示用户投票成功 else: print(\"没有该序号的电影，请重新输入\") #如果输入的范围不对，提示没有这个序号的电影 elif name_num.upper() == 'Q': #如果用户输入q就退出 break else: print(\"你输入有误，请重新输入\") for movie_name,total_num in dic.items(): #以列表返回可遍历的键值 print(\"%s电影的总得票数%s\" %(movie_name,total_num))","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day02","slug":"Python基础day02","date":"2020-04-24T04:14:29.000Z","updated":"2020-06-02T07:51:22.008Z","comments":true,"path":"post/34c92de1.html","link":"","permalink":"https://www.missf.top/post/34c92de1.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 格式化输出# 格式化输出 name = input(\"请输入姓名：\") age = input(\"请输入年龄：\") job = input(\"请输入职业：\") hobby = input(\"请输入爱好\") msg = \"\"\"------ info of %s ------ Name : %s Age : %s job : %s Hobbie : %s ------ end ------\"\"\" % (name,name,age,job,hobby) print(msg) # 坑:单个%号默认被当成一个占位符，如果想单纯的表示%号，请使用%% msg = '我叫%s,今年%s岁,python入门1%%.' % ('荒原饮露','23') print(msg) 运算符 运算符 描述 实例 = 简单的赋值运算符 c = a + b 将 a + b 的运算结果赋值给c += 加法赋值运算符 c += a 等效于 c = c + a -= 减法赋值运算符 c -= a 等效于 c = c - a *= 乘法赋值运算符 c *= a 等效于 c = c * a /= 除法赋值运算符 c /= a 等效于 c = c / a %= 取模赋值运算符 c %= a 等效于 c = c % a **= 幂赋值运算符 c *= a 等效于 c = c * a //= 取整赋值运算符 c //= a 等效于 c = c // a and “与”，如果 x 为False，x and y 返回False，否则返回y的计算值 两边为True才为True or “或”， 如果 x 为True，返回True，否则它返回y的计算值 一边为True则为True not “非”， 如果 x 为True，返回False，如果 x 为False，返回True True则False，反之 逻辑运算符的优先级() > not > and > or and 两个条件必须同时成立才为True or 两个条件有一个成立则为True not 条件为True则结果为False，条件为False则结果为True 运算符的不等式计算print(2 > 1 and 3 > 4) 两边式子同时成立，才会为True，否则为False print(2 > 1 and 3 > 4 or 4 &lt; 5 and 6 &lt; 7) 先计算and，式子为False or True，结果则为True print(1 > 2 and 3 &lt; 4 or 4 > 5 and 2 > 1 or 9 &lt; 8) 先计算and，式子为False or False or False，结果为False 运算符数字计算x or y # if x is True，return x else return y.如果x为True则返回X，否则返回y print(1 or 2) 1 print(3 or 2) 3 print(0 or 2) 2 # x and y和x or y是相反的 print(1 and 2) 2 print(8 and 0) 0 print(-100 and 2) 2 print(1 and 2 or 3 and 5) == print(2 or 5) 2 编码初识ASCII ASCII:早期的密码本，只包含英文字母，数字，特殊字符与01的对应关系 采用 8位比特（bit） == 1byte（字节） 在ascll编码中 8位比特表示一个字节表示一个字符 h e l l o = 01101000 01100101 01100111 0110011 01100101 缺点:只为英文使用者考虑，不能处理中文和其他国家的文字 GBK 由于ASCII编码，于是每个国家都提出了不同的编码来适应自己的语言 GBK 只包含本国文字（以及英文字母，数字，特殊字符）与01对应关系 GBK是采用单双字节变长编码，英文使用单字节编码，完全兼容ASCII字符编码，中文部分采用双字节编码 a 太 白 = 01101000 01100101 01100111 0110011 01100101 # 1个英文占1个字节，1个中文字符占2个字节，共5字节 UNICODE 由于ASCII编码的局限性，unicode应运而生 unicode:万国码，将全世界所有的文字都统一到一套编码里面 采用32位比特(bit)== 4byte 在unicode编码中 32位比特表示4个字节表示一个字符 a：00000000 00010010 00000000 00010010 中：00000000 10010010 00000000 10010010 缺点:如果使用unicode编码来存储英文，这会大量浪费空间，因为我们知道一个英文字符只占一个字节，而另外三个字节就浪费掉了，这样在存储和传输上非常不划算 UTF-8 utf-8:包含全世界所有的文字与二进制01的对应关系,最少用8位表示一个字符 utf-8是一种针对Unicode的可变长度字符编码,是对Unicode编码的压缩和优化，将所有的字符和符号进行分类 英文: 00000010 8位表示一个字节表示一个字符 欧洲文字: 00000010 00100000 16位表示两个字节表示一个字符 中国(亚洲): 00000010 00000010 00000010 24位表示三个字节表示一个字符 例子 'old男孩' GBK:7个字节 utf-8:9个字节 十进制转换为二进制关键要点:除二取余，倒序排列，高位补零。 将十进制数42不断除以2，得到的余数非别是:010101，然后倒序排列，42所对应的二进制就是101010，然后高位补零就是:00101010 负整数转换为二进制，以-42为例，先得到42的二进制，然后取反(0变1，1变0)再加一，就是11010101 + 1，结果为11010110 二进制转换成十进制 1 0 0 1 0 1 1 0 1 * 2^7 0 * 2^6 0 * 2^5 1 * 2^4 0 * 2^3 1 * 2^2 1 * 2^1 0 * 2^0 将这些数相加，得到的就是10010110这个二进制数的十进制数 128 + 0 + 0 + 16 + 0 + 4 + 2 + 0 = 150 数据类型之间的转换int（整数） --> bool（布尔值） 非零即True bool（布尔值） --> int（整数） True 1 False 0 str（字符串） --> bool（布尔值） 非空即True str（字符串） --> int（整数） str（13 ）转换为整数，会强制去掉空格变成int（13） bool（布尔值） --> str（字符串） 还是True，但是str类型的True，失去True的意义 y = True u = str(y) print(u,type(u)) True &lt;class 'str'> # 由于是str数据类型的True，下面的3 + u会报错，如果是bool数据类型的True可以与数字相加 print(3 + u) 字符串的切片字符串索引示意图请记住切片原则:顾首不顾尾 按照索引取值s = 'python骑士计划第三期' s1 = s[0] s2 = s[-1] print(s1) # p print(s2) # 期 按照切片取值s = 'python骑士计划第三期' # 照切片取值，顾首不顾尾，s5 = s[6:-3] 6就是第六个字符以后，-3就是倒数第三个字符以前 s3 = s[0:6] # 是从零开始数。取整个字符串可以写成s3 = s[:6],取整个字符串是s3 = s[:] print(s3) # python s4 = s[:6] # 相当于s[0:6]，0可以不写，默认从零开始 print(s4) # python s5 = s[6:-3] print(s5) # 骑士计划 s6 = s[6:10] print(s6) # 骑士计划 切片加步长取值# 步长就是每一步的长度，取pto字符串，要先划分区域，再定义隔几个字符去取 s = 'python骑士计划第三期' s7 = s[:6:2] # 划分区域为 0-6（区域为:python，从首个字符串开始取），步长为2 print(s7) # pto s8 = s[7::2] # 划分区域为 7-最后（区域为:士计划第三期，从第七个字符之后开始取），步长为2 print(s8) # 士划三 s9 = s[-1:-4:-1] # 倒叙取值要加上反向步长 print(s9) # 期三第 print(s[:5:-1]) # 后面是-1所以是反向取值，区域定义为 0-5（python），但是区域也是反向的，所以是从期到n的区域里面取 骑士计划第三期 字符串的常用操作capitalize() 首字母大写s = 'faker' s1 = s.capitalize() print(s) # faker print(s1) # Faker center() 将字符串居中s = 'missf.top' s1 = s.center(50) print(s1) missf.top # 设置50的长度并把字符串居中 s2 = s.center(50,'*') print(s2) ********************missf.top********************* # 设置50的长度定义填充物并把字符串居中 swapcase() 大小写翻转sr = 'KubeRnEteS' print(sr.swapcase()) kUBErNeTEs title() 非字母隔开单词的首字母大写s = 'tpshow9nohup@mid' # 注意：第一个字母也会变成大写 print(s.title()) Tpshow9Nohup@Mid upper() 不区分大小写# 用途:验证码不区分大小写 username = input(\"请输入姓名:\") passworrd = input(\"请输入密码:\") code = 'AeTrd'.upper() your_code = input(\"请输入验证码:\").upper() if your_code == code: if username == 'alex' and passworrd == 'sb': print('登录成功') else: print('用户名或者密码错误') else: print('验证码不正确') startswich() endswith() 判断以什么为开头和结尾s = 'mowenjieadcarry' print(s.startswith('o')) False # 字符串不是以o开头，结果为False print(s.startswith('mo')) True # 字符串以mo开头，结果为True print(s.startswith('j',5)) # 切割五个字符之后是否是j开头，结果为True True print(s.endswith('ry')) # 判断以什么为结尾 True find() index() 通过元素找索引s = 'mowenjieadcarry' print(s.find('a')) 8 # 返回a元素前面的索引数 print(s.find('a',9,)) 11 # 从第九个字符后面开始找，找到的是第二个a # find和index功能几乎一样，区别只有find找不到会返回-1,index会报错 strip() 默认去除字符串前后的空格/换行符/制表符# strip() 默认去除字符串前后两端的空格，换行符，制表符 s = '\\n barry \\t \\n' print(s.strip()) # barry # strip 去除字符串两边的字符 s = 'kkohuang yuan yin lure' print(s.strip('kore')) # 会把kore切割成最小单位，从前后两边逐个去除 huang yuan yin lu # lstrip 只从前面去除 print(s.lstrip('k')) ohuang yuan yin lure # rstrip() 只从后面去除 print(s.rstrip('re')) kkohuang yuan yin lu split() 将字符串转化为列表s = 'kkohuang yuan yin lure' print(s.split()) # 默认以空格分割元素 ['kkohuang', 'yuan', 'yin', 'lure'] t = 'top:mid:adc' print(t.split(':')) # 指定以冒号进行分割 ['top', 'mid', 'adc'] print(t.split(':',1)) # 指定以冒号进行分割,分割一次 ['top', 'mid:adc'] t = ':mid:adc' # 只有两个分割符，但是转换成列表之后参数个数是n+1 print(t.split(':')) ['', 'mid', 'adc'] join() 列表转化为字符串t = ':mid:adc' s9 = '-'.join(t) # 将每个字符通过指定的连接符连接在一起 print(s9) :-m-i-d-:-a-d-c t1 = ['liz','zsd','awa'] s10 = ' '.join(t1) # 以空格为分隔符 print(s10) liz zsd awa # 将列表的多个元素转换回字符串 replace() 字符串替换t = 'faker是世界第一中单，faker也是一个屌丝，faker' s11 = t.replace('faker','55开',2) # 可以指定替换的次数，不指定次数则全部替换 print(s11) 55开是世界第一中单，55开也是一个屌丝，faker format() 格式化输出# 第一种 s = '我叫{}，我玩{}，我主玩的位置是{}'.format('bang','英雄联盟','adc') print(s) # 我叫bang，我玩英雄联盟，我主玩的位置是adc # 第二种 s = '我叫{0}，今年{1}，性别{2}，我依然叫{0}'.format('小明','20','女') print(s) # 我叫小明，今年20，性别女，我依然叫小明 # 第三种 s = \"\"\" 我叫{name}，今年{age}，性别{sex}，我依然叫{name} \"\"\".format(age=20,sex='女',name='小明') print(s) # 我叫小明，今年20，性别女，我依然叫小明 is 判断字符串和数字组成name ='huanyuan135' print(name.isalnum()) # 判断字符串由字母或数字组成 True print(name.isalpha()) # 判断字符串只由字母组成 False print(name.isdigit()) # 判断字符串只由数字组成 False count 计算字符串中某个字符出现的次数s = 'cdcdcdcdcdjvnjfnvjfn:jsvnsvpojwpd' print(s.count('f')) # 计算这个字符串f字符出现的次数 2 print(s.count('d')) 6 print(s.count('d',0,8)) # 切片，顾首不顾尾，从零开始到第八个字符的前面截断 4 print(s.count('d',8)) # 从零开始数，第八个字符到结束 2 len 统计字符串长度s = 'cdcdcdcdcdjvnjfnvjfn:jsvnsvpojwpd' print(len(s)) # 内置函数 33","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day01","slug":"Python基础day01","date":"2020-04-23T04:14:29.000Z","updated":"2020-06-30T07:03:45.687Z","comments":true,"path":"post/adc07c5b.html","link":"","permalink":"https://www.missf.top/post/adc07c5b.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 Python发展史 创始人:Guido，国人叫龟叔，在1989年的圣诞节写出来的 2005 - 2012，龟叔去了谷歌工作，谷歌大量使用Python 2005年国内第一家使用Python的公司—豆瓣 2012年国内兴起云计算的热潮，Python借助OpenStack又火了一把 2014年AI兴起，大量的公司使用Python去写算法 直到2017年Python才真正进入大众的视野 Python的应用领域 WEB开发:最火的Python web框架Django，还有支持异步高并发的Tornado，短小精悍的flask 网络编程:支持高并发的Twisted网络框架 爬虫:Python在爬虫领域几乎是霸主地位，具有非常多的爬虫模块支持 云计算:著名的云计算框架OpenStack就是用Python写的 人工智能和数据分析:Python是目前人工智能和数据分析领域公认的必备语言 自动化运维:在Linux运维领域，Python能做很多事情，特别是处理数据的能力非常出色 游戏开发:Python能做游戏开发，但是使用Python开发游戏的公司可能没有这么多 编译型语言核心:通过编译器将人类写出来的代码一次性全部编译成机器语言让计算机可以识别和执行 代表语言：c，c++，golang，java 优点:执行效率高 缺点:开发效率低，不可以跨平台 一般多用于研究所、研究院，对执行效率要求高，大数据的计算、底层的开发 解释型语言核心:解释器逐行解释代码，再逐行执行（python是解释器，java中叫虚拟机） 代表语言:Python，php，Java，ruby 优点:开发效率高，可以跨平台，可移植性强 缺点:执行效率相对编译型语言慢 Python的优缺点优点 Python是一门高级语言，不用关心底层内存指针等等 由于Python开源的本质，Python已经被移植到许多平台，具备非常高的可移植性 Python可以嵌入c语言的代码，c语言也可以嵌入Python的代码，具备可嵌入性 大量现有的第三方库和模块的支持，使得开发效率大大提高 缺点 执行速度比编译型语言慢，如果运行Python花了0.1s，同样的代码c语言花了0.01秒，这样c就比Python快了十倍 Python源码是以明文形式存放的，如果项目要求源代码必须是加密的，一开始就不应该选择Python 线程不能利用多核CPU的问题，这也是Python被人诟病最多的一个缺点 变量官方解释:将程序中一些中间结果暂时存到内存中，供后面程序调用 变量命名规则 变量必须由数字，字母，下划线任意组合 不能是数字开头 不能使用Python中的关键字（具体关键字后面再介绍） 变量要具有描述性 变量不能过长 变量不能使用中文 尽量使用驼峰体 定义Python变量age1 = 12 age2 = age1 age3 = age2 age2 = 24 print (age1,age2,age3) 12 24 12 # 注意：程序中会大量的出现和使用变量，变量中会暂存一些少量的数据，给其他变量代指 Python常量常量，用于定义不变的值。例如:身份证号，圆周率，历史记载，新中国成立时间:1949101 使用常量Python中的常量可以改变（不像c改变常量会报错），但约定俗成Python中将变量全部变成大写，就是表示常量，将一些不想让别人改变的量设置成常量，放在文件最上面 Python注释对某一段代码做解释说明，一般是精简的代码，别人可能看不懂，需要做简单的解释 单行注释#好好学习，天天向上 多行注释'''被注释的内容''' \"\"\" 被注释的内容 \"\"\" 基础数据类型初识int 整型i1 = 10 i2 = 20 print (i1 * i2) # 200 str 字符串python中凡是用引号引起来的内容就是字符串数据类型 ret1 = '荒原饮露' ret2 = \"荒原饮露\" ret3 = \"\"\"荒原饮露\"\"\" ret4 = '''荒原饮露''' print (ret1,ret2,ret3,ret4) bool 布尔值true # 真 false # 假 用于判断条件，逻辑语句真假 单双引号搭配使用msg = \"I' m huangyuanyinlu,18 year\" print (msg) # I' m huangyuanyinlu,18 year 字符串相加相乘a1 = 'Alex' a2 = 'sb' print (a1 + a2) # Alexsb print (a1 * 10) # AlexAlexAlexAlexAlexAlexAlexAlexAlexAlex input 用户交互让用户输入用户名密码，得到用户输入的数据，起到了人与程序的交互作用 name = input(\"请输入你的名字：\") age = input(\"请输入你的年龄：\") sex = input(\"请输入你的性别：\") print (name,age,sex) # 这里注意一点:凡是input得到的值，都是字符串数据类型 将用户输入的变量进行拼接name = input(\"请输入你的名字：\") age = input(\"请输入你的年龄：\") sex = input(\"请输入你的性别：\") msg = '我的姓名是' + name + ',' + '我的年龄是' + age + ',' + '我的性别是' + sex + '.' print (msg) # 我的姓名是荒原饮露,我的年龄是23,我的性别是男 if 流程控制语句if 单分支age = input (\"请输入年龄:\") age = int(age) # Python3x之后，input得到的数据都是字符串类型 print (age,type(age)) # 输出变量的数据类型 if age > 10: print('你已经不是10岁的小孩了'） if 多分支jineng = input('请输入你的技能:') if jineng == '三分球': print('可以参加三分球大赛') elif jineng == '中投': print('可以参加中距离投篮') elif jineng == '突破': print('可以参加1V1对抗赛') else: print('买票进场吧') if 嵌套# 登陆示例 username = input('请输入用户名：') password = input('请输入密码：') if username == '荒原饮露': if password == '123': print('登录成功') else: print('密码错误') else: print('用户名不存在') # 买票示例 has_ticket = int(input('请输入车票号码:')) knife_length = int(input('请输入刀的长度:')) if has_ticket == 23: print('车票检查通过，准备开始安检') if knife_length &lt; 20: print('刀不超过20厘米，允许上车') else: print('刀超过20厘米，不允许上车') else: print(\"没有车票\") while 循环单次循环flag = True while flag: print('麦迪') print('科比') print('杜兰特') flag = False print('詹姆斯') # flag = False后面的依然会输出，因为运行到最后才会重新回到while 打印1到100# 方法一 count = 1 flag = True while flag: print(count) count = count + 1 if count == 101: flag = False # 方法二 count = 1 while count &lt; 101: print(count) count = count + 1 # 不要见方法二代码少就不去理解方法一，因为方法一包含flag = True的编程思想 计算1加到100count = 1 sum = 0 while count &lt;= 101: sum = sum + count count = count + 1 if count == 101: break print(sum) # break是直接终止循环 continue打印1到10，但是跳过7 count = 0 while count &lt; 10: count = count + 1 if count == 7: continue # continue是跳出本次循环，继续执行下一个循环 print(count) count = 0 while count &lt; 10: count = count + 1 if count == 7: # 判断count的值，直接+1 count = count + 1 print(count) 打印100以内的偶数# 利用对2取余去判断是否偶数 count = 0 while count &lt; 101: if count % 2 == 0: print(count) count = count + 1 # 每次自加2去打印偶数，虽然这样的做法不专业，但是也是体现灵活编程思维的一种方式 count = 0 while count &lt; 101: print(count) count = count + 2 while else# while else :只有在while循环被break打断时，才不会执行else程序，否则循环完之后一定会执行else程序 count = 0 while count &lt;= 5: count = count + 1 if count == 3:break print(\"Loop\",count) else: print(\"循环正常执行\") count = 0 while count &lt;= 5: count = count + 1 print(\"Loop\",count) else: print(\"循环正常执行\") # while循环没有被打断，打印完Loop1-6之后还是会打印循环正常执行","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Hello World","slug":"Hello World","date":"2019-03-28T04:14:29.000Z","updated":"2020-06-02T07:51:22.003Z","comments":true,"path":"post/4a17b156.html","link":"","permalink":"https://www.missf.top/post/4a17b156.html","excerpt":"","text":"所有无法深入问题本质的那些人，最终都将离开这个行业。","categories":[{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/categories/Hello-World/"}],"tags":[{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/tags/Hello-World/"}]},{"title":"我在人间凑数的日子","slug":"我在人间凑数的日子","date":"2019-03-28T04:14:29.000Z","updated":"2020-09-09T02:44:24.619Z","comments":true,"path":"post/world.html","link":"","permalink":"https://www.missf.top/post/world.html","excerpt":"","text":"语言这东西，在表达爱意的时候如此无力，在表达伤害的时候，却如此锋利。 你住的城市下雨了，想问你有没有带伞，可我不敢。因为我怕你说没带，而我又无能为力，就像是我爱你，却给不了你想要的。 十年太长，什么都会变。一辈子太短，一件事也有可能做不完。回忆永远站在背后，你无法抛弃，只能拥抱。 没有回音的山谷不值得纵身一跃。 世界上只有一种英雄、看透了生活的真相，却依然热爱生活。 你联系我，我就听你说，你不联系我，我就顺其自然；实不相瞒，我很想你，但我能控制，因为这样很酷。 我不知道凌晨五点该说晚安还是早安，也不知道这个年龄是该说爱还是喜欢。 曾经我发誓要把生命献给爱情，后来我没死，只是青春替我偿了命。 我与春风皆过客，你携秋水揽星河。 我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 从此无心爱良夜，任他明月下西楼。 仅一夜之间，我的心判若两人。 真正的离别没有长亭古道，也没有劝君更尽一杯酒，只是在一个和往常一样的清晨，有的人留在昨天了。 我吹过你吹过的晚风，那我们算不算相拥。 明智的放弃胜过盲目的执着，去吹吹风吧，能清醒的话，感冒也没关系。 以后不见面的日子要按年算了。 没有特别挚爱的东西，没有一定要得到的人，也没有非做不可的事。 艺术，值得为之痛苦。 我于杀戮之中盛放，亦如黎明中的花朵。 生如蝼蚁，当立鸿鹄之志，命薄如纸，应有不屈之心。 好像什么都还来得及，又好像什么都无能为力。 旧时王谢堂前燕，飞入寻常百姓家。 越过山丘，才发现无人等候。 没有好好告别的人一定会重逢。 如果不是刻意相见，原来真的不会遇见。 有时候生活没那么好，有时候生活也没那么坏。 可能给不了你世间所有温柔，但有个词叫尽我所能。 真正爱你的人会督促你变的优秀，而不是蹉跎你的青春。 人间忽晚，山河已秋。 人间度日，何缘其身。我喜欢这种孤身只影的感觉，它让我孤独得像一个死去多年的人。 我原本可以接受所有的黑暗，如果我不曾见过光明。 我最遗憾的是，从未拥有过一个女孩的青春。 逢人不必言深，孤独本是常态。 种下一棵树最好的时间是十年前，其次是现在。 巅峰产生虚伪的拥护，黄昏见证真正的使徒。 所有命运馈赠的礼物，都早已在暗中标好了价格。 如不抽出时间来创造自己想要的生活，你最终将不得不花费大量的时间来应付自己不想要的生活。 往往最简单的东西里面，藏着最深刻的道理。 俄罗斯方块让我明白，成功会消失，错误会积累；贪吃蛇让我明白，越到后面越危险，最大的敌人是自己。 从来没有什么岁月静好，只不过是有人在替你负重前行！ 书上说，如果有一天你梦见了一个很久没见的人，代表她正在遗忘你。 虽然分手是我提的，但我很清楚是谁要走。 真实发生在身边的事情，让我瞬间明白了许多道理。 Make me feel the warmth,Make me feel the cold. 总有人会洗去生来的泥土，站在云端与诸神共舞。 等人是会上瘾的，因为等着等着，你会发现，如果你不等了，不是放弃了对方，而是背叛了自己。 人难免天生有自怜情绪，唯有时刻保持清醒，才能看清真正的价值在哪里。 可能是未来的架构师，也可能送外卖。 永恒燃烧的羽翼，带我脱离凡间的沉沦。 这世人的喧嚣之上，我追寻着荣光飞翔。 我拿起了母亲的剑，还有她的决心。","categories":[{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/categories/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"}],"tags":[{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/tags/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"},{"name":"记忆","slug":"记忆","permalink":"https://www.missf.top/tags/%E8%AE%B0%E5%BF%86/"},{"name":"语录","slug":"语录","permalink":"https://www.missf.top/tags/%E8%AF%AD%E5%BD%95/"}]}],"categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"},{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"},{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"},{"name":"coding","slug":"coding","permalink":"https://www.missf.top/categories/coding/"},{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"},{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/categories/Hello-World/"},{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/categories/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"},{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"},{"name":"coding","slug":"coding","permalink":"https://www.missf.top/tags/coding/"},{"name":"持续集成","slug":"持续集成","permalink":"https://www.missf.top/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"},{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/tags/Hello-World/"},{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/tags/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"},{"name":"记忆","slug":"记忆","permalink":"https://www.missf.top/tags/%E8%AE%B0%E5%BF%86/"},{"name":"语录","slug":"语录","permalink":"https://www.missf.top/tags/%E8%AF%AD%E5%BD%95/"}]}