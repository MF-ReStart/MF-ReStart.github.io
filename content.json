{"meta":{"title":"荒原饮露","subtitle":"青春不是隔岸观火啊","description":"","author":"荒原饮露","url":"https://www.missf.top","root":"/"},"pages":[{"title":"","date":"2020-06-02T02:12:04.531Z","updated":"2020-04-13T10:37:51.000Z","comments":false,"path":"categories/index.html","permalink":"https://www.missf.top/categories/index.html","excerpt":"","text":""},{"title":"","date":"2020-06-02T02:12:04.533Z","updated":"2020-04-13T10:37:41.000Z","comments":false,"path":"tags/index.html","permalink":"https://www.missf.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Docker企业级镜像仓库Harbor(7)","slug":"Dockerfile企业级镜像仓库Harbor(7)","date":"2020-07-08T05:33:50.000Z","updated":"2020-07-08T09:13:21.816Z","comments":true,"path":"post/d46af348.html","link":"","permalink":"https://www.missf.top/post/d46af348.html","excerpt":"","text":"Harbor 概述Harbor是由VMWare公司开源的容器镜像仓库。事实上，Harbor是在Docker Registry上进行了相应的企业级扩展，从而获得了更加广泛的应用，这些新的企业级特性包括：管理用户界面，基于角色的访问控制 ，AD/LDAP集成以及审计日志等，足以满足基本企业需求。 Harbor 官网 Harbor GitHub 地址 Harbor 部署条件服务器硬件配置最低要求:CPU2核/内存4G/硬盘40GB 推荐:CPU4核/内存8G/硬盘160GB 软件Docker 17.06版本+ Docker Compose 1.18版本+ 安装方式在线安装:从Docker Hub下载Harbor相关镜像，因此安装软件包非常小 离线安装:安装包包含部署的相关镜像，因此安装包比较大 docker-compose安装下载二进制文件https://github.com/docker/compose/releases # docker-compose下载地址 # 下载docker-compose-Linux-x86_64这个二进制文件配置二进制文件mv docker-compose-Linux-x86_64 /usr/bin/docker-compose chmod +x /usr/bin/docker-compose docker-compose --help # 安装完成harbor HTTP部署下载Harbor安装包wget https://github.com/goharbor/harbor/releases/download/v2.0.1/harbor-offline-installer-v2.0.1.tgz解压安装包tar xf harbor-offline-installer-v2.0.1.tgz修改配置文件cp harbor.yml.tmpl harbor.yml vim harbor.yml hostname: reg.missf.com # 修改Harbor默认域名 https: # 先注释https相关配置 harbor_admin_password: MF-yihan # 修改Harbor的密码部署Harbor./prepare # 做一系列的准备工作 ./install.sh # 利用docker-compose拉取一系列的镜像","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Dockerfile定制容器镜像(6)","slug":"Dockerfile定制容器镜像(6)","date":"2020-06-30T05:33:50.000Z","updated":"2020-07-08T03:56:27.276Z","comments":true,"path":"post/44241b5a.html","link":"","permalink":"https://www.missf.top/post/44241b5a.html","excerpt":"","text":"Dockerfile 介绍Dockerfile是由一行一行的命令语句组成，并且从上到下执行，支持以#注释行。一般Dockerfile的内容分为四个部分，基础镜像信息、维护者信息、镜像操作指令、容器启动时执行指令。 Dockerfile 常用指令 指令 描述 FROM 指定构建新镜像时是基于那个镜像，Dockerfile的第一条指令必须为FROM指令，如果在同一个Dockerfile中创建多个镜像可以使用多个FROM指令 LABEL 为镜像添加标签 RUN 每条RUN指令将在当前镜像的基础上执行指定shell命令，并提交为新的镜像 COPY 拷贝宿主机(Dockerfile所在目录的相对路径)的文件或目录到镜像中 ADD 复制指定的&lt;src&gt;到容器中的&lt;dest&gt;，&lt;src&gt;可以是Dockerfile所在目录的文件或目录，可以是一个URL，还可以是一个tar文件(自动解压缩) ENV 指定一个环境变量，会被后续RUN指令使用，并在容器运行时保持 USER 指定运行容器时的用户名或UID，后续的RUN也会使用指定用户 EXPOSE 声明容器运行的服务端口，启动容器时可以将这些端口转发到宿主机或者指定宿主机那个端口映射过来 WORKDIR 为后续的RUN、CMD、ENTRYPOINT指令配置工作目录 VOLUME 在镜像中创建挂载点，这样只要通过该镜像创建的容器都有了挂载点，查看容器详细信息可以看到容器挂载点映射到宿主机的目录 CMD 容器启动时执行指令，每个Dockerfile只能有一条CMD指令，如果有多个CMD指令只有最后一个生效 ENTRYPOINT ENTRYPOINT如果与CMD一起使用，CMD将作为ENTRYPOINT的默认参数，如果有多个ENTRYPOINT指令只有最后一个生效 构建镜像Dockerfile demo# This dockerfile demo for project build to docker images FROM centos:7 LABEL maintainer www.missf.top USER root RUN yum install -y nginx EXPOSE 80 443 VOLUME [\"/usr/local/nginx/\"] CMD [\"/usr/local/nginx/bin\"] Docker build构建镜像# 在Dockerfile所在的目录下构建镜像,后面的\".\"表示当前目录 docker build -t demo:1.0 . # 构建过程如下 Sending build context to Docker daemon 2.048kB Step 1/8 : FROM centos:7 7: Pulling from library/centos 524b0c1e57f8: Pull complete Digest: sha256:e9ce0b76f29f942502facd849f3e468232492b259b9d9f076f71b392293f1582 Status: Downloaded newer image for centos:7 ---> b5b4d78bc90c Step 2/8 : LABEL maintainer mownejie ---> Running in 7dbcab7ef3ce Removing intermediate container 7dbcab7ef3ce ---> 4db1e9da6977 Step 3/8 : ENV JAVA_HOME /usr/local/java ---> Running in b896cedee458 Removing intermediate container b896cedee458 ---> f8991838d97e Step 4/8 : USER root ---> Running in 8252457198f0 Removing intermediate container 8252457198f0 ---> 96ef213928ad Step 5/8 : RUN yum install -y nginx ---> Running in 8807973810c5...... # -t 指定这个镜像的tag # -f 指定这个Dockerfile文件的位置 CMD 与 ENTRYPOINT 区别CMD用法# exec形式,首选形式,传参不支持引用变量 CMD [\"executable\", \"param1\", \"param2\"] # CMD作为ENTRYPOINT的默认参数 CMD [\"param1\", \"param2\"] # Shell形式 CMD command param1 param2 ENTRYPOINT用法ENTRYPOINT [\"executable\", \"param1\", \"param2\"] # 假如配合CMD一起使用,那么[\"param1\", \"param2\"]可以写在CMD作为ENTRYPOINT的默认参数 ENTRYPOINT command param1 param2 总结1. CMD和ENTRYPOINT指令都可以用来定义运行容器时所使用的命令 2. Dockerfile至少指定一个CMD或ENTRYPOINT 3. CMD可以用作ENTRYPOINT默认参数，或者用作容器的默认命令 4. docker run启动容器时指定，将会覆盖dockerfile定义的CMD 构建Nginx容器镜像dockerfile内容FROM centos:7.7.1908 LABEL maintainer www.missf.top RUN yum install -y gcc gcc-c++ make \\ openssl-devel pcre-devel gd-devel \\ iproute net-tools telnet wget curl && \\ yum clean all && rm -rf /var/cache/yum/* ADD nginx-1.16.1.tar.gz / RUN cd nginx-1.16.1 && \\ ./configure --user=nginx --group=nginx \\ --prefix=/usr/local/nginx \\ --with-http_stub_status_module \\ --with-http_ssl_module \\ --with-http_gzip_static_module \\ --with-http_sub_module && \\ make -j4 && make install && \\ mkdir /usr/local/nginx/conf/vhost && \\ cd / && rm -rf nginx* && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime RUN useradd -s /sbin/nologin nginx ENV PATH $PATH:/usr/local/nginx/sbin ENV LANG=\"en_US.utf8\" COPY nginx.conf /usr/local/nginx/conf/nginx.conf COPY php.conf /usr/local/nginx/conf/vhost/php.conf WORKDIR /usr/local/nginx EXPOSE 80 443 CMD [\"nginx\", \"-g\", \"daemon off;\"] 目录结构[root@localhost /Dockerfile/nginx]# ll total 1028 -rw-r--r-- 1 root root 890 Jul 6 18:58 Dockerfile -rw-r--r-- 1 root root 1032630 Jan 14 09:53 nginx-1.16.1.tar.gz -rw-r--r-- 1 root root 3297 Jul 6 18:46 nginx.conf -rw-r--r-- 1 root root 362 Jul 6 20:13 php.conf -rw-r--r-- 1 root root 128 Jul 6 18:51 start 构建PHP容器镜像dockerfile内容FROM centos:7.7.1908 LABEL maintainer www.missf.top RUN yum install -y epel-release && \\ yum install -y sqlite-devel libmcrypt-devel mhash-devel libxslt-devel \\ libjpeg-devel libpng libpng-devel freetype freetype-devel \\ libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel libjpeg \\ glib2 glib2-develbzip2 bzip2-devel ncurses ncurses-devel \\ curl-devel e2fsprogs e2fsprogs-devel krb5 gcc krb5-devel libidn \\ openssl-devel libsqlite3x-devel oniguruma-devel openssl libidn-devel \\ iproute net-tools telnet wget curl && \\ yum clean all && rm -rf /var/cache/yum/* ADD php-7.4.0.tar.gz / RUN cd /php-7.4.0 && \\ ./configure --prefix=/usr/local/php \\ --with-config-file-path=/usr/local/php/etc \\ --enable-opcache --with-curl --enable-fpm \\ --enable-gd --with-iconv --enable-mbstring \\ --with-mysqli --with-openssl --enable-static \\ --enable-sockets --enable-inline-optimization \\ --with-zlib --disable-ipv6 --disable-fileinfo \\ --with-mcrypt --enable-hash --with-jpeg-dir --with-png-dir \\ --with-freetype-dir --with-pdo-mysql --disable-debug && \\ make -j 4 && make install && \\ cp /php-7.4.0/php.ini-production /usr/local/php/etc/php.ini && \\ cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf && \\ cp /usr/local/php/etc/php-fpm.d/www.conf.default /usr/local/php/etc/php-fpm.d/www.conf && \\ sed -i \"90a \\daemonize = no\" /usr/local/php/etc/php-fpm.conf && \\ mkdir /usr/local/php/log && \\ cd / && rm -rf php* && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime ENV PATH $PATH:/usr/local/php/sbin ENV LANG=\"en_US.utf8\" COPY php.ini /usr/local/php/etc/ COPY php-fpm.conf /usr/local/php/etc/ COPY www.conf /usr/local/php/etc/php-fpm.d/ WORKDIR /usr/local/php EXPOSE 9000 CMD [\"php-fpm\"] 目录结构[root@localhost /Dockerfile/php]# ll total 16144 -rw-r--r-- 1 root root 1758 Jul 6 18:53 Dockerfile -rw-r--r-- 1 root root 16418792 Jul 1 10:39 php-7.4.0.tar.gz -rw-r--r-- 1 root root 5394 Jul 1 21:51 php-fpm.conf -rw-r--r-- 1 root root 72953 Jul 1 22:09 php.ini -rw-r--r-- 1 root root 93 Jul 6 18:56 start -rw-r--r-- 1 root root 19616 Jul 6 18:53 www.conf 容器化搭建个人博客自定义网络docker network create lnmp # 将多个容器加入到一个自定义网络 创建MySQL容器docker volume create mysql docker run -e MYSQL_ROOT_PASSWORD=mwj123456 -e MYSQL_DATABASE=wordpress -p 53306:3306 --name \"mysql\" --network lnmp --mount src=mysql,dst=/var/lib/mysql/ -d mysql:5.7 # 将MySQL数据库的数据持久化到mysql这个数据卷 创建PHP容器docker volume create nginx docker run --name php --network lnmp --mount src=nginx,dst=/usr/local/nginx/html/ -d php:1.0 # 这里先启动PHP容器再启动Nginx容器,因为Nginx要去连接PHP容器,如果PHP容器没有启动,那Nginx就因为无法连接到PHP所有退出了 # 这里需要把Nginx代码也挂载到PHP容器内,而且容器内的路径要与Nginx配置文件路径一致 # 因为Nginx配置文件将所有*.php的请求都通过fastcgi_pass代理到PHP容器去处理,所有需要把代码也挂载到PHP容器内,不然访问php文件会提示未找到文件 创建Nginx容器docker container run --name \"nginx\" --mount src=nginx,dst=/usr/local/nginx/html --network lnmp -p 80:80 -p 443:443 -d nginx:1.0 部署WordPress代码docker volume inspect nginx # 先查看数据卷在宿主机上的目录,然后把代码解压到对应的目录下 tar xf wordpress-5.4.2-zh_CN.tar.gz -C /var/lib/docker/volumes/nginx/_data/ # 这时候通过访问宿主机的IP就能看到WordPress的安装页面了,如果无法对wp-config.php文件写入,就手动创建并写入 构建Tomcat容器镜像dockerfile内容FROM centos:7.7.1908 LABEL maintainer www.missf.top ADD jdk-8u211-linux-x64.tar.gz /usr/local/ ADD apache-tomcat-8.5.57.tar.gz /usr/local/ RUN mv /usr/local/jdk1.8.0_211 /usr/local/jdk && \\ mv /usr/local/apache-tomcat-8.5.57 /usr/local/tomcat && \\ rm -rf /usr/local/tomcat/webapps/* ENV JAVA_HOME /usr/local/jdk ENV CLASSPATH ${JAVA_HOME}/lib/dt.jar:${JAVA_HOME}/lib/tools.jar ENV CATALINA_HOME /usr/local/tomcat ENV PATH $PATH:${JAVA_HOME}/bin:${CATALINA_HOME}/lib:${CATALINA_HOME}/bin RUN sed -i '1a JAVA_OPTS=\"-Djava.security.egd=file:/dev/./urandom\"' ${CATALINA_HOME}/bin/catalina.sh && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime WORKDIR ${CATALINA_HOME} EXPOSE 8080 CMD [\"catalina.sh\", \"run\"] 目录结构[root@localhost /Dockerfile/tomcat]# ll total 200568 -rw-r--r-- 1 root root 10379806 Jul 7 11:19 apache-tomcat-8.5.57.tar.gz -rw-r--r-- 1 root root 728 Jul 7 19:41 Dockerfile -rw-r--r-- 1 root root 194990602 Jul 2 2019 jdk-8u211-linux-x64.tar.gz 部署测试代码docker volume inspect tomcat # 查看Tomcat容器代码目录持久化到宿主机的目录 ll /var/lib/docker/volumes/tomcat/_data # 放到这个目录的war包会被自动解压 total 17840 drwxr-x--- 4 root root 37 Jul 7 21:34 ROOT -rw-r--r-- 1 root root 18265402 Jun 20 13:08 ROOT.war 构建java微服务项目镜像dockerfile内容# 一个容器内只跑一个jar包 FROM java:8-jdk-alpine LABEL maintainer www.missf.top ENV JAVA_OPTS=\"$JAVA_OPTS -Dfile.encoding=UTF8 -Duser.timezone=GMT+08 -Xms512m -Xmx512m\" RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories && \\ apk add -U tzdata && \\ mkdir /projects && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime COPY hello.jar /projects/ EXPOSE 8888 CMD [\"/bin/sh\", \"-c\", \"java -jar $JAVA_OPTS /projects/hello.jar\"] Dockerfile 最佳实践减少镜像层一次RUN指令形成新的一层镜像，shell命令尽量写在一行，减少镜像层 优化镜像大小在形成新的一层镜像之后，如果没有在同一层删除缓存或者没用的文件，那么这些文件都会被带到下一层，所有要在每一层清理对应的残留数据，减少镜像大小 减少网络传输例如镜像所需要下载的软件包，mvn仓库 多阶段构建代码编译、部署在一个Dockerfile完成，只会保留部署阶段产生的数据 选择最小的基础镜像例如alpine","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker容器网络(5)","slug":"Docker容器网络(5)","date":"2020-06-23T01:49:44.000Z","updated":"2020-07-08T06:57:21.804Z","comments":true,"path":"post/bc1d2f66.html","link":"","permalink":"https://www.missf.top/post/bc1d2f66.html","excerpt":"","text":"容器的四种网络模式bridge 模式当启动docker进程之后，docker会默认创建一个名为docker0的虚拟网桥，创建容器时如果不指定网络，默认就是添加到这个网桥中。这样docker主机上的所有容器都可以通过交换机的方式连接在一个二层网络中。创建容器时，docker会先创建容器的虚拟网卡，容器的虚拟网卡去连接docker主机的docker0虚拟网桥，相当于用一根网线将容器和docker主机连接起来。虚拟网卡连接到docker0子网后，由docker0虚拟网桥分配IP给容器的虚拟网卡使用，并设置docker0虚拟网桥的IP地址为容器的默认网关。除了docker启动时默认创建的bridge默认网络，我们还可以自定义bridge网络。相比默认的具备内部DNS发现，bridge网络模式还可以通过容器名去实现容器之间的网络通信。 查看docker宿主机上的docker0虚拟网桥，默认网段是172.17.0.1，安装docker之后默认创建的 ip a s docker0 3: docker0: mtu 1500 qdisc noqueue state UP group default link/ether 02:42:9f:dc:ee:74 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:9fff:fedc:ee74/64 scope link valid_lft forever preferred_lft forever 查看默认定义好的网络模式,这里没有container模式是因为container是启动容器时直接指定的 docker network ls NETWORK ID NAME DRIVER SCOPE a42d2b0e12ec bridge bridge local 168bbf4b0447 host host local ec481d03e2a1 none null local 21be62f7b97e webserver bridge local 查看bridge网络模式的详细信息 docker network inspect bridge [ { \"Name\": \"bridge\", \"Id\": \"a42d2b0e12ec0e039e7c4686099468585b88c8df8b639eaa780700980adb9e1b\", \"Created\": \"2020-06-23T17:16:25.717600267+08:00\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [ { \"Subnet\": \"172.17.0.0/16\", \"Gateway\": \"172.17.0.1\" } ] }, \"Internal\": false, \"Attachable\": false, \"Ingress\": false, \"ConfigFrom\": { \"Network\": \"\" }, \"ConfigOnly\": false, \"Containers\": { \"253d0d8f196182eccaa52238068513cebfbf2abe69d2a7980e40d8c136b53960\": { \"Name\": \"nginx\", \"EndpointID\": \"7fd4576f90bc1d0fd966ed5794710dd43461d077ea32f99e54a8b3c56ba1de08\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" }, \"8652448b6f9a99d9b9a6c70277ea23924b21df57289d4deb29a146974ad4c4dd\": { \"Name\": \"centos7\", \"EndpointID\": \"e112927463f07a606a3a019f3af7400c711b9a903fec19c130b27c7d5f53d359\", \"MacAddress\": \"02:42:ac:11:00:03\", \"IPv4Address\": \"172.17.0.3/16\", \"IPv6Address\": \"\" } }, \"Options\": { \"com.docker.network.bridge.default_bridge\": \"true\", \"com.docker.network.bridge.enable_icc\": \"true\", \"com.docker.network.bridge.enable_ip_masquerade\": \"true\", \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\", \"com.docker.network.bridge.name\": \"docker0\", \"com.docker.network.driver.mtu\": \"1500\" }, \"Labels\": {} } ] 安装网桥管理工具包 yum install -y bridge-utils.x86_64 查看虚拟网桥上的接口信息 brctl show docker0 bridge name bridge id STP enabled interfaces docker0 8000.02429fdcee74 no veth81bdc19 vetha8f66a7 创建类型为bridge的自定义网桥 docker network create webserver 21be62f7b97ebfc9ce6f6a1aaaffd59a4a220c6b778f36a98c72162023b5c5e5 启动容器时指定使用自定义创建的webserver网桥(具备DNS发现) docker container run -itd --name \"app1\" --network webserver centos:7.7.1908 98efd7fb3c63c0bd487039b7ef00925d786e0499f10d76003afa2277cc93b404 docker container run -itd --name \"app2\" --network webserver centos:7.7.1908 c81e58db50ca74111d46f460ff322378b45414a36804738597559ec3c06cf542 docker container run -itd --name \"app3\" --network webserver centos:7.7.1908 41fb1a7dd161c03a158a104da54dcfa3b226035feceecabd003f7a18e91bff61 查看容器的IP地址 docker inspect --format='{{.NetworkSettings.Networks.webserver.IPAddress}}' app1 172.18.0.2 docker inspect --format='{{.NetworkSettings.Networks.webserver.IPAddress}}' app2 172.18.0.3 docker inspect --format='{{.NetworkSettings.Networks.webserver.IPAddress}}' app3 172.18.0.4 容器之间的通信测试，自定义的bridge网桥相比默认的bridge网桥具备内部DNS发现， IP和主机名都是可以PING通 ping 172.18.0.2 PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data. 64 bytes from 172.18.0.2: icmp_seq=1 ttl=64 time=0.203 ms 64 bytes from 172.18.0.2: icmp_seq=2 ttl=64 time=0.085 ms ping 98efd7fb3c63 # 如果启动容器时不指定自定义的网桥,那就会使用默认的bridge模式,这样是不能PING通主机名的 PING 98efd7fb3c63 (172.18.0.2) 56(84) bytes of data. 64 bytes from app1.webserver (172.18.0.2): icmp_seq=1 ttl=64 time=0.402 ms 64 bytes from app1.webserver (172.18.0.2): icmp_seq=2 ttl=64 time=0.100 ms host模式如果启动容器时指定host模式，那么这个容器将不会获得一个独立的Network namespace，而是和宿主机共用一个Network namespace。容器不会虚拟出自己的网卡，而是使用宿主机的IP和端口。这种无需NAT转换的网络模式无需再映射容器与宿主机之间的端口，在提高网络传输性能的同时，造成了网络环境隔离性弱化。容器之间不再拥有隔离独立的网络，docker host上已使用的端口就不能再用了。 启动一个nginx容器，再查看宿主机上的80端口是否被使用 docker container run -itd --name \"host_nginx\" --network=host nginx:1.1 查看宿主机上的80端口是否被nginx容器所使用 netstat -lntup | grep 80 tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 7358/nginx: master 查看宿主机上nginx进程的父进程是否为docker ps -afx | grep containerd -A 1 1100 ? Ssl 1:18 /usr/bin/containerd 7341 ? Sl 0:00 \\_ containerd-shim -namespace moby -workdir /var/lib/containerd/io.containerd.runtime.v1.linux/moby/adf66250b1fcd95c2531f04f8504bea614dd90903f4f074e150ce6202895a023 -address /run/containerd/containerd.sock -containerd-binary /usr/bin/containerd -runtime-root /var/run/docker/runtime-runc 7358 pts/0 Ss+ 0:00 \\_ nginx: master process nginx -g daemon off; # 这个nginx进程是容器中启动的nginx进程,这也正如我们前面所说,使用host模式启动容器,容器会和宿主机共用一个Network namespace 进入容器中查看网卡信息，可以看到宿主机上的网卡也会显示，这就是共用了一个Network namespace的结果 ifconfig br-21be62f7b97e: flags=4099 mtu 1500 inet 172.18.0.1 netmask 255.255.0.0 broadcast 172.18.255.255 inet6 fe80::42:6fff:fe77:c9f0 prefixlen 64 scopeid 0x20 ether 02:42:6f:77:c9:f0 txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 docker0: flags=4099 mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:9fff:fedc:ee74 prefixlen 64 scopeid 0x20 ether 02:42:9f:dc:ee:74 txqueuelen 0 (Ethernet) RX packets 3 bytes 114 (114.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 8 bytes 677 (677.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ens32: flags=4163 mtu 1500 inet 10.10.110.150 netmask 255.255.255.0 broadcast 10.10.110.255 inet6 fe80::20c:29ff:fec4:cbac prefixlen 64 scopeid 0x20 ether 00:0c:29:c4:cb:ac txqueuelen 1000 (Ethernet) RX packets 91694 bytes 118390130 (112.9 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 41857 bytes 2875558 (2.7 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73 mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10 loop txqueuelen 1000 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 none模式容器启动时指定none模式是获取独立的Network namespace，但不为容器进行任何网络配置。容器内部只有loopback网络设备不会再有其他的网络资源，将网络创建的责任完全交给用户。作为 Docker 开发者，才能在这基础做其他无限多可能的网络定制开发，这种方式可以实现更加灵活复杂的网络，同时也体现了Docker设计理念的开放。 启动一个none模式的容器 docker container run -itd --name \"none_centos\" --network=none centos:7.7.1908 进入容器查看网卡设备信息 docker container exec -it none_centos /bin/bash ifconfig # 这里只有一个回环口地址,因为none模式不会对容器进行任何网络配置 lo: flags=73 mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10 loop txqueuelen 1000 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 container模式创建新的容器时指定和已存在的容器共享一个Network namespace，这些容器之间共享IP、端口范围等网络配置，容器之间传输效率高。两个容器除了网络资源共享之外，其他资源还是隔离的。虽然多个容器共享网络环境，但是多个容器形成的整体依然与宿主机以及其他容器形成网络隔离。 启动一个名为server1的容器 docker container run -itd --name \"server1\" centos:7.7.1908 再启动两个容器，把它们加入到server1这个容器的Network namespace docker container run -itd --name \"server2\" --network=container:server1 centos:7.7.1908 docker container run -itd --name \"server3\" --network=container:server1 centos:7.7.1908 查看各个容器的IP地址 docker inspect --format='{{.NetworkSettings.Networks.bridge.IPAddress}}' server1 172.17.0.3 docker inspect --format='{{.NetworkSettings.Networks.bridge.IPAddress}}' server2 docker inspect --format='{{.NetworkSettings.Networks.bridge.IPAddress}}' server3 这里我们在查看server2和server3容器IP时，显示为&lt;no value&gt;，其实它们是和server1共用一个Network namespace的 docker container exec -it server2 /bin/bash [root@41436b0be6f7 /]# ifconfig eth0: flags=4163 mtu 1500 inet 172.17.0.3 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:03 txqueuelen 0 (Ethernet) RX packets 10969 bytes 20985758 (20.0 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 6234 bytes 344851 (336.7 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 docker container exec -it server3 /bin/bash [root@41436b0be6f7 /]# ifconfig eth0: flags=4163 mtu 1500 inet 172.17.0.3 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:03 txqueuelen 0 (Ethernet) RX packets 10969 bytes 20985758 (20.0 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 6234 bytes 344851 (336.7 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 # 两个容器的IP、主机名都相同 容器虚拟网卡和docker0网桥的veth pair配对veth是成对出现的虚拟网络设备， 发送到veth一端虚拟设备的请求会从另一端的虚拟设备中发出。创建一个容器的同时会为这个容器创建一对虚拟网卡veth pair，这个成对出现的虚拟网卡veth pair，分别放到宿主机和容器中，宿主机一端桥接到默认的docker0或者自定义的网桥上，容器一端放到新创建容器的Network namespace中，并把名字修改为eth0。虚拟网卡veth pair就像是一根网线，将宿主机的docker0和容器连接起来。 docker container run -itd --name \"server1\" centos:7.7.1908 # 创建容器 brctl show docker0 # 查看宿主机上的docker0网桥 bridge name bridge id STP enabled interfaces docker0 8000.02429fdcee74 no veth7459cf7 ip a s veth7459cf7 # 这是虚拟网卡veth pair在宿主机上的一端 34: veth7459cf7@if33: mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 86:54:3c:c6:70:6b brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::8454:3cff:fec6:706b/64 scope link valid_lft forever preferred_lft forever [root@ec94bfbd724f /]# ifconfig # 容器内部的eth0网卡是虚拟网卡veth pair在容器中的一端 eth0: flags=4163 mtu 1500 inet 172.17.0.2 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:02 txqueuelen 0 (Ethernet) RX packets 5495 bytes 10346440 (9.8 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 3386 bytes 186731 (182.3 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 容器网络访问原理图 容器网络实现的核心技术: iptablesdocker容器的跨网络隔离与通信，是使用iptables去实现的 源IP地址变换规则docker在安装完成后，将默认在宿主机上增加一些iptables规则，以用于docker容器和容器之间的隔离与通信，可以使用使用iptables-save命令查看 iptables-save | grep docker -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE 参数说明: -s:源地址172.17.0.0/16 -o:指定数据报文流出接口为docker0 -j:动作为MASQUERADE(地址伪装) 上面这条规则关系着docker容器和外界的通信，含义是源地址为172.17.0.0/16的数据包(即docker容器发出的数据)，当不是从docker0网卡发出时做SNAT(源地址转换)。这样使得docker容器访问外网的流量，在外界看来就是从宿主机上发出的，外界感觉不到docker容器的存在 目标IP地址变换规则从docker容器访问外网的流量，在外部看来就是从宿主机上发出的，外部感觉不到docker容器的存在。其实这也是由相应的iptables规则去实现的 docker container run -itd --name \"nginx\" -p 80:80 nginx:1.17 查看创建容器之后生成的iptables规则 iptables-save | grep docker -A DOCKER ! -i docker0 -p tcp -m tcp --dport 80 -j DNAT --to-destination 172.17.0.2:80 -A DOCKER -d 172.17.0.2/32 ! -i docker0 -o docker0 -p tcp -m tcp --dport 80 -j ACCEPT 这两条规则将访问宿主机的80端口的流量转发到了172.17.0.2的80端口上(即真正提供服务的docker容器的IP+端口)，所以外界访问docker容器是通过iptables做DNAT(目的地址转换)实现的 etcd 和 flannel 实现 docker 跨主机通信flannel是一种基于overlay网络的跨主机容器网络解决方案，也就是将TCP数据包封装在另一种网络包里面进行路由转发和通信，flannel是CoreOS团队针对Kubernetes设计的一个网络规划服务，让集群中的不同节点主机创建的容器都具有全集群唯一的虚拟ip地址，flannel使用go语言编写。 实现原理flannel为每个host分配一个subnet，容器从这个subnet中分配ip，这些ip可以在host间路由，容器间无需使用nat和端口映射即可实现跨主机通信。每个subnet都是从一个更大的ip池中划分的，flannel会在每个主机上运行一个叫flanneld的agent，其职责就是从池子中分配subnet。etcd相当于一个数据库，flannel使用etcd存放网络配置、已分配的subnet、host的IP等信息。 实验环境 节点 安装软件 系统 内核版本 docker版本 10.10.110.150(master) etcd、flannel、docker CentOS7.7.1908 3.10.0-1062.el7.x86_64 19.03.12 10.10.110.151(slave) flannel、docker CentOS7.7.1908 3.10.0-1062.el7.x86_64 19.03.12 master节点配置安装配置etcdyum install -y etcd # 安装etcd,由于不配置etcd集群,所以只在10.10.110.150节点安装etcd就行了 sed -i \"s/localhost/10.10.110.150/g\" /etc/etcd/etcd.conf # 修改etcd配置文件 systemctl start etcd.service # 启动etcd 安装配置flannelyum install -y flannel sed -i \"s/127.0.0.1/10.10.110.150/g\" /etc/sysconfig/flanneld # flannel连接到etcd,slave连接也是填写master的IP etcdctl --endpoints=\"http://10.10.110.150:2379\" set /atomic.io/network/config '{ \"Network\":\"172.17.0.0/16\", \"Backend\": {\"Type\": \"vxlan\"}} ' # 配置etcd的子网,如果这一步不配置,那么etcd无法启动 systemctl start flanneld.service # 启动flannel slave节点配置安装配置flannelyum install -y flannel sed -i \"s/127.0.0.1/10.10.110.150/g\" /etc/sysconfig/flanneld # 这里是填写master节点的IP,让slave连接到master的etcd,多slave也一样 systemctl start flanneld.service # 确保slave节点能连接到master节点的etcd,如果不关闭防火墙,那必须打开2379端口 配置docker使用flannel的网络master节点vim /usr/lib/systemd/system/docker.service EnvironmentFile=/run/flannel/docker # 加载这个文件里面的变量,这个文件记录了flannel分配给master节点的子网信息(slave也会有自己的子网) ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock $DOCKER_NETWORK_OPTIONS # 这个变量是上面文件中定义的,意思是在启动容器时指定使用flannel分配的子网去配置容器的网络 iptables -P FORWARD ACCEPT # 开启iptables转发,如不开启即使配置成功也不能通信 systemctl daemon-reload systemctl restart flanneld.service # 这里必须先重启flannel再重启docker,这时候启动容器就会使用flannel去配置容器的网络 systemctl restart docker.service slave节点配置vim /usr/lib/systemd/system/docker.service EnvironmentFile=/run/flannel/docker # 查看slave节点上这个文件,网段是和master节点不一样的 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock $DOCKER_NETWORK_OPTIONS iptables -P FORWARD ACCEPT systemctl daemon-reload systemctl restart flanneld.service systemctl restart docker.service 查看宿主机的IP变化master节点docker0虚拟网卡和flannel虚拟网卡已经在同一网段，这时候说明配置成功 ip a 3: docker0: mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:e3:89:96:4e brd ff:ff:ff:ff:ff:ff inet 172.17.98.1/24 brd 172.17.98.255 scope global docker0 valid_lft forever preferred_lft forever 4: flannel.1: mtu 1450 qdisc noqueue state UNKNOWN group default link/ether 02:6f:fa:71:67:f7 brd ff:ff:ff:ff:ff:ff inet 172.17.98.0/32 scope global flannel.1 valid_lft forever preferred_lft forever inet6 fe80::6f:faff:fe71:67f7/64 scope link valid_lft forever preferred_lft forever slave节点ip a 3: docker0: mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:f2:30:ba:34 brd ff:ff:ff:ff:ff:ff inet 172.17.75.1/24 brd 172.17.75.255 scope global docker0 valid_lft forever preferred_lft forever 4: flannel.1: mtu 1450 qdisc noqueue state UNKNOWN group default link/ether f6:ae:d1:c0:e1:a7 brd ff:ff:ff:ff:ff:ff inet 172.17.75.0/32 scope global flannel.1 valid_lft forever preferred_lft forever inet6 fe80::f4ae:d1ff:fec0:e1a7/64 scope link valid_lft forever preferred_lft forever 在两个节点创建容器相互ping验证master节点docker run -it busybox sh / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:62:02 inet addr:172.17.98.2 Bcast:172.17.98.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1450 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:656 (656.0 B) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # ping 172.17.75.2 PING 172.17.75.2 (172.17.75.2): 56 data bytes 64 bytes from 172.17.75.2: seq=0 ttl=62 time=0.492 ms 64 bytes from 172.17.75.2: seq=1 ttl=62 time=0.353 ms 64 bytes from 172.17.75.2: seq=2 ttl=62 time=0.342 ms slave节点docker run -it busybox sh / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:4B:02 inet addr:172.17.75.2 Bcast:172.17.75.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1450 Metric:1 RX packets:6 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:516 (516.0 B) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # ping 172.17.98.2 PING 172.17.98.2 (172.17.98.2): 56 data bytes 64 bytes from 172.17.98.2: seq=0 ttl=62 time=1.945 ms 64 bytes from 172.17.98.2: seq=1 ttl=62 time=0.344 ms 64 bytes from 172.17.98.2: seq=2 ttl=62 time=0.384 ms 注意:如果不能ping通，先重启flannel再重启docker试试","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"ansible的jinja2模板(16)","slug":"ansible的jinja2模板(16)","date":"2020-06-22T01:52:52.000Z","updated":"2020-06-24T08:37:55.280Z","comments":true,"path":"post/62ac8f71.html","link":"","permalink":"https://www.missf.top/post/62ac8f71.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的jinja2模板我们在多个管理节点部署服务时，很多服务的配置文件都是需要监听服务所在主机的IP地址，这时候就需要使用到ansible的jinja2模板去分发动态的配置文件。我们先创建一份模板文件，将IP配置部分使用ansible变量进行替换，然后使用template模块对模版文件进行渲染，将根据我们定义的变量而生成不同的配置文件发送到对应的管理节点。 下面我们以安装redis为示例，为不同的管理节点分发动态配置文件 cat /etc/redis/conf/redis.conf bind {{ ansible_host }} # 将默认的127.0.0.1改为管理节点本机的IP，这样就能生成各自的管理节点的配置文件 准备模板配置文件之后，下面就来编写一个playbook，完成模板配置文件的渲染和分发 --- - hosts: all remote_user: root tasks: - template: src: /root/playbook/redis.conf # 控制节点上的模板文件,定义好变量,通过template模块进行渲染 dest: /etc/redis.conf # 管理节点上这个文件将被控制节点上的模板文件所替换 jinja2语法Ansible使用Jinja2模板来启用动态表达式和对变量的访问，就是说ansible使用Jinja模板对含有动态表达式和变量的文件进行解析个渲染。 变量&amp;表达式可以使用点.来访问变量的属性，也可以使用下标语法[]，下面2种方式效果是一样的 {{ foo.bar }} {{ foo['bar'] }} # 如果变量或属性不存在，会返回一个未定义值。 除了变量， {{}} 中还可以包含一些表达式 {{ 1 == 1 }} {{ 2 != 3 }} {{ 2 > 3 }} {{ 4 &lt;= 3 }} # 根据对应的表达式返回true或false {{ 3 + 2 }} {{ 3 - 4 }} {{ 3 * 5 }} {{ 2 ** 3 }} # 2的3次方 # 根据算术运算返回结果 # 字符串、数值、列表、元组、字典、布尔值等数据类型均可在\"{{ }}\"使用 控制用来装载控制语句，比如 if 控制结构，for循环控制结构 {% for item in seq %} ``` ## 注释 要把模板中一行的部分注释掉 ```yaml {# 这是被注释的内容 #} ``` ## 转义 简单的使用单引号('')进行转义，对于较大的段落，使用raw进行转义 ```yaml {% raw %} &lt;ul> {% for item in seq %} &lt;li>{{ item }}&lt;/li> {% endfor %} &lt;/ul> {% endraw %} 执行命令时传入变量cat /root/test.j2 my blog is {{ site }} ansible dbserver -m template -e \"site=missf.top\" -a \"src=/root/test.j2 dest=/opt/test\" cat /opt/test my blog is missf.top if{% if num > 3 %} gtfr derew pllu {% endif %} 使用template模板进行渲染 ansible dbserver -m template -e \"num=4\" -a \"src=/root/test.j2 dest=/opt/test\" # 渲染后的输出结果 cat /opt/test gtfr derew pllu forjinja2模板的for语法示例 {% if num > 3 %} {% for i in [5,65,7,23] %} {{ i }} {% endfor %} 使用template模板进行渲染 ansible dbserver -m template -a \"src=/root/test.j2 dest=/opt/test\" # 渲染后的输出结果 cat /opt/test 5 65 7 23 控制空白从for循环的结果看出，使用template模板进行渲染时不会去处理空格或者换行符，在开始或结束放置一个减号(-)，可以移除块前或块后的空白 {% for i in [5,65,7,23] -%} {{ i }} # 这里可以使用{{ i }}{{' '}}定义分割符 {%- endfor %} ansible dbserver -m template -a \"src=/root/test.j2 dest=/opt/test\" cat /opt/test 565723 # 将换行符和空白都移除了 5 65 7 23 # 定义分割符的效果 ​ 我要去重新学习梳理Docker了，Ansible就先到这里吧！等到有空了，再重启吧。","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的include(15)","slug":"ansible的include(15)","date":"2020-06-20T07:23:27.000Z","updated":"2020-06-23T05:56:41.875Z","comments":true,"path":"post/fa9ef74f.html","link":"","permalink":"https://www.missf.top/post/fa9ef74f.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的include在所有的编程语言中，在处理重复代码的时候，都会将重复的代码提取出来作为一个逻辑单元，这个逻辑单元通常被称为函数或者方法，这样可以让我们更加方便的、重复的调用这段代码。而且如果需要修改这段代码，只需要修改这段代码本身，那么在调用这段代码的地方的逻辑就会随之改变。同时，使用函数的方式编写代码，能让我们的逻辑更清晰，通过函数的名称，大概能推算出程序的主体作用和逻辑。 在ansible中，其实也有类似的功能，这种功能被称之为include。通过include，我们可以在playbook中包含另一个文件，以便实现我们刚才所说的函数效果。 在配置环境的时候，我们经常会有一些需要重复使用的playbook，就像下面的LAMP环境和LNMP环境 cat lamp.yaml --- - hosts: dbserver remote_user: root tasks: - name: install lamp yum: name: - mysql - php-fpm - httpd state: present cat lnmp.yaml --- - hosts: dbserver remote_user: root tasks: - name: install lnmp yum: name: - mysql - php-fpm - nginx state: present 我们可以把上面的两个playbook改写层下面这样，便于我们直接调用 cat lamp.yaml - yum: name: - mysql - php-fpm - httpd state: present cat lnmp.yaml - yum: name: - mysql - php-fpm - nginx state: present 当我们需要执行这两个playbook时，直接使用include调用，playbook中的任务就会在被调用处执行 cat lamp_lnmp.yaml - hosts: webserver remote_user: root tasks: - name: install lamp include_tasks: lamp.yaml # 这里执行的是lamp.yaml的内容 - hosts: dbserver remote_user: root tasks: - name: install lnmp include_tasks: lnmp.yaml 给include文件传参cat baidu.yaml - shell: ping -c 3 \"{{ baidu }}\" # 在include文件使用变量 cat include_baidu.yaml --- - hosts: dbserver remote_user: root vars: baidu: \"www.baidu.com\" # 定义include文件所需要的变量 tasks: - name: ping baidu include_tasks: baidu.yaml # 调用执行include文件 import_playbook我们使用include关键字可以调用任务列表，但如果想要调用整个playbook，则需要import_playbook模块代替include模块 cat import_test.yaml --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"test task cat import_test.yaml\" - import_playbook: intest7.yaml # 调用intest7.yaml整个yaml cat intest7.yaml --- - hosts: webserver remote_user: root tasks: - debug: msg: \"test task cat intest7.yaml\"","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的lookups插件(14)","slug":"ansible的lookups插件(14)","date":"2020-06-19T07:19:51.000Z","updated":"2020-06-23T05:56:32.317Z","comments":true,"path":"post/de181bd8.html","link":"","permalink":"https://www.missf.top/post/de181bd8.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的lookups插件过滤器其实是ansible中的一种插件，除了过滤器之外，ansible中还有很多其他种类的插件。而且我们一直都在使用这些插件，比如我们在配置ansible的主机清单时，就用到了Inventory种类的插件。lookups其实也是插件的一种，lookups的所有操作都是在控制节点上进行的，与管理节点无关。ansible官网为我们总结了各个插件的作用，并且按照这些插件功能进行了分类。官网插件地址 lookups filefile插件可以读取文件，插件的源码是使用Python读取文件然后把结果返回给变量 --- - hosts: dbserver remote_user: root vars: contents: \"{{ lookup('file','/etc/hostname') }}\" tasks: - name: debug lookup file debug: msg: \"the contents is {{ contents }}\" 如果不想将所有文件的内容变成一整个字符串，而是获取一个字符串列表，可以使用wantlist参数 --- - hosts: dbserver remote_user: root vars: contents: \"{{ lookup('file','/etc/hostname',wantlist=true) }}\" tasks: - name: debug lookup file debug: msg: \"the contents is {{ contents }}\" lookups passwordpasswd插件会对传入的内容进行加密处理 --- - hosts: dbserver vars: contents: \"{{ lookup('password','ansible') }}\" # 将ansible这个字符串进行加密处理 tasks: - name: debug lookups debug: msg: \"the contents is {{ contents }}\" lookups pipepipe插件运行命令并返回结果，pipe这个插件底层是使用Python的subprocess库实现的 --- - hosts: dbserver remote_user: root vars: contents: \"{{ lookup('pipe','hostname') }}\" tasks: - name: debug lookup pipe debug: msg: \"the contents is {{ contents }}\" lookups redis_kvredis_kv插件是用来从本地redis中读取数据的 --- - hosts: dbserver remote_user: root vars: contents: \"{{ lookup('redis_kv', 'redis://127.0.0.1:6379,ansible') }}\" # 获取本地redis数据库ansible这个键的值 tasks: - name: debug lookup redis_kv debug: msg: \"the contents is {{ contents }}\" lookups dictdict插件是用来获取变量的键值对 --- - hosts: dbserver vars: users: alice: female bob: male tasks: - debug: msg: \"{{ item.key }} = {{ item.value }}\" loop: \"{{ lookup('dict',users) }}\" lookups envenv插件可以获取ansible主机中指定变量的值 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ lookup('env','PATH') }}\" lookups first_foundfirst_found插件可以获取列表中第一个找到的文件，如果列表中的所有文件都没有找到，可以添加errors=ignore忽略报错 - hosts: master remote_user: root tasks: - name: debug lookup first found debug: msg: \"{{ lookup('first_found',looklist,errors='ignore') }}\" vars: looklist: - \"/abc.txt\" - \"/tmp/str.txt\" lookups digdig插件可以获取指定域名的IP地址，需要Python安装dnspython库 --- - hosts: master remote_user: root tasks: - debug: msg: \"{{ lookup('dig','www.baidu.com',wantlist=true) }}\"","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Docker容器数据持久化(4)","slug":"Docker容器数据持久化(4)","date":"2020-06-19T02:14:10.000Z","updated":"2020-07-08T03:57:13.634Z","comments":true,"path":"post/a7b8d397.html","link":"","permalink":"https://www.missf.top/post/a7b8d397.html","excerpt":"","text":"容器数据持久化的三种方式由于容器的镜像分层机制，我们在容器里面创建文件或者修改文件，结果都会保存在容器的可读写层中，一旦容器被销毁，那么这个读写层也会随着容器销毁而消失。而且当一个容器需要和其他容器的读写层进行数据交互时，也会显得非常困难。于是在将容器数据持久化到宿主机方面，docker为我们提供了三种持久化的方式。 volumesvolumes由docker负责创建、管理。用户可以显式的调用命令docker volume create创建volume，也可以通过container、service的启动隐式创建。 docker创建的volumes本质上还是宿主机文件系统中的一个目录，一个volumes可以供多个容器使用，即使没有容器使用此volumes，它也不会自动删除，除非用户明确删除它 如果用户显式创建volumes则需要给它一个名称，如果是隐式创建volumes则docker会为它分配一个在宿主机范围内唯一的名字 通过使用第三方提供的volume driver，用户可以将数据持久到远程主机或者云存储中，也就是说存储空间可以不由宿主机提供。 # 创建volumes docker volume create nginx_volumes # 查看volumes docker volume ls # 查看卷详细信息 docker volume inspect nginx_volumes [ { \"CreatedAt\": \"2020-06-19T18:47:49+08:00\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/nginx_volumes/_data\", # 这是volumes在宿主机上的真实路径 \"Name\": \"nginx_volumes\", \"Options\": {}, \"Scope\": \"local\" } ] # 清理volumes docker volume rm nginx_volumes 将nginx容器的html目录映射到宿主机的nginx_volumes目录 # 创建数据持久化的容器,如果卷不存在则自动创建 docker container run -itd --name \"nginx1\" -p 80:80 -v nginx_volumes:/usr/share/nginx/html nginx:1.17 # -v方式 docker container run -itd --name \"nginx1\" -p 80:80 --mount src=nginx_volumes,dst=/usr/share/nginx/html nginx:1.17 # --mount方式 # 查看nginx_volumes在宿主机的真实目录 ll /var/lib/docker/volumes/nginx_volumes/_data total 8 -rw-r--r-- 1 root root 494 Apr 14 22:19 50x.html # 这时候nginx容器内部的文件已经被映射到宿主机上了 -rw-r--r-- 1 root root 612 Apr 14 22:19 index.html # 修改宿主机上的index.html文件 echo \"nginx_volumes test \" > /var/lib/docker/volumes/nginx_volumes/_data/index.html # 访问宿主机的80端口(前面启动容器时将容器的80端口绑定到宿主机的80端了) curl 10.10.110.150 nginx_volumes test # nginx容器内的文件确实被修改成功 bind mountsbind mounts本质上是容器共享宿主机文件系统，比如docker将宿主机的/etc/resov.conf文件bind mount到容器里，两者会使用相同的dns服务器。 # 创建容器,将宿主机的/nginx/app绑定到容器的/usr/share/nginx/html目录 docker container run -itd --name \"nginx1\" --mount type=bind,src=/nginx/app,dst=/usr/share/nginx/html nginx:1.17 docker container run -itd --name \"nginx1\" -v /nginx/app:/usr/share/nginx/html nginx:1.17 # 查看宿主机和容器的目录 ls /nginx/app docker exec -it nginx1 ls /usr/share/nginx/html # 两个目录都为空,这是因为bind mounts是将宿主机的目录绑定到容器的目录,容器目录已有的内容会被隐藏(bind mounts以宿主机目录为主) 注意: 如果源文件或源目录不存在，则不会自动创建。如果容器目录为非空目录，则容器目录现有内容会被宿主机目录内容所隐藏。 tmpfs出于安全原因，或者容器性能优化的原因有时候不需要容器的数据长久保存时可以使用这种方式。将容器数据挂载存储在宿主机的内存中，避免写入容器可写层，提高容器性能。 volumes 和 bind mounts 的使用场景和区别volumes适合多个容器需要共享数据、将数据保存到远程主机或云上等场景。bind mounts适合将宿主机的系统配置文件共享给容器。volumes是将容器内部的数据映射到宿主机对应的volumes目录，如果容器内部是一个非空目录，volumes目录也是一个非空目录，那么两个目录的文件会合并。而bind mounts是将宿主机上任意位置的目录或文件挂载到容器中，如果宿主机的目录非空，那么容器目录的数据将会被宿主机目录的数据隐藏，容器内的数据要卸除挂载后才会恢复。 Bind mounts和volumes都可以通过使用标志-v或–volume来挂载到容器中，只是格式有些许不同。然而，在Docker17.06及其以上版本中，我们推荐使用–mount来对容器或服务进行这三种方式的挂载，因为这种格式更加清晰。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker容器管理(3)","slug":"Docker容器管理(3)","date":"2020-06-17T08:23:38.000Z","updated":"2020-07-08T03:57:25.897Z","comments":true,"path":"post/39a5b294.html","link":"","permalink":"https://www.missf.top/post/39a5b294.html","excerpt":"","text":"创建容器常用选项 选项 描述 -i, –interactive 交互式 -t, –tty 分配一个伪终端 -d, –detach 运行容器到后台 -e, –env 设置环境变量 -p, –publish list 发布容器端口到主机 -P, –publish-all 发布容器所有EXPOSE的端口到宿主机随机端口 –name string 指定容器名称 -h, –hostname 设置容器主机名 –ip string 指定容器IP,只能用于自定义网络 –network 连接容器到一个网络 –mount mount 将文件系统附加到容器 -v, –volume list 绑定挂载一个卷 –restart string 容器退出时重启策略,默认no,可选值:[always|on-failure] 创建容器示例# 启动一个nginx容器,指定名字、映射端口、设置重启 # 如果不加-it分配一个交互式的伪终端,容器就会直接退出了,容器内的第一个程序必须一直处于前台运行(必须hang住) docker container run -itd --name \"nginx\" -p 80:80 --restart always nginx:1.17 容器资源限制 选项 描述 -m，–memory 容器可以使用的最大内存量 –memory-swap 允许交换到磁盘的内存量 –memory-swappiness=&lt;0-100&gt; 容器使用SWAP分区交换的百分比(0-100，默认为-1) –oom-kill-disable 禁用OOM Killer –cpus 可以使用的CPU数量 –cpuset-cpus 限制容器使用特定的CPU核心，如(0-3, 0,1) –cpu-shares CPU共享(相对权重) 内存限额示例# 允许容器最多使用500M内存和600M的swap,并禁用OOM Killer docker container run -d --name \"nginx1\" --memory=\"500M\" --memory-swap=\"600M\" --oom-kill-disable nginx:1.17 CPU限额示例# 允许容器最多使用两个的CPU docker container run -d --name \"nginx2\" --cpus=\"2\" nginx:1.17 # 允许容器最多使用50%的CPU docker container run -d --name \"nginx3\" --cpus=\".5\" nginx:1.17 容器资源配额扩容# 容器资源可更新选项 docker update --help Usage: docker update [OPTIONS] CONTAINER [CONTAINER...] Update configuration of one or more containers Options: --blkio-weight uint16 Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0) --cpu-period int Limit CPU CFS (Completely Fair Scheduler) period --cpu-quota int Limit CPU CFS (Completely Fair Scheduler) quota --cpu-rt-period int Limit the CPU real-time period in microseconds --cpu-rt-runtime int Limit the CPU real-time runtime in microseconds -c, --cpu-shares int CPU shares (relative weight) --cpus decimal Number of CPUs --cpuset-cpus string CPUs in which to allow execution (0-3, 0,1) --cpuset-mems string MEMs in which to allow execution (0-3, 0,1) --kernel-memory bytes Kernel memory limit -m, --memory bytes Memory limit --memory-reservation bytes Memory soft limit --memory-swap bytes Swap limit equal to memory plus swap: '-1' to enable unlimited swap --pids-limit int Tune container pids limit (set -1 for unlimited) --restart string Restart policy to apply when a container exits # 更新正在运行中的容器内存限额 docker update --memory=\"400M\" --memory-swap=\"500M\" --restart=\"on-failure\" 4e860294d239 管理容器常用命令 选项 描述 ls 列出容器 inspect 查看一个或多个容器详细信息 exec 在运行容器中执行命令 commit 创建一个新镜像来自一个容器 cp 拷贝文件/文件夹到一个容器 logs 获取一个容器日志 port 列出或指定容器端口映射 top 显示一个容器运行的进程 stats 显示容器资源使用统计 stop/start/restart 停止/启动一个或多个容器 rm 删除一个或多个容器 prune 移除已停止的容器 管理容器示例# 列出真正运行的所有容器 docker container ls -a # 获取一个容器日志 docker container logs --tail=\"5\" nginx # 仅列出最新N条容器log信息 docker container logs -f nginx # 跟踪log信息输出 docker logs --since=\"2020-06-18\" --tail=\"10\" nginx # 显示某个时间之后的最新十条log信息 # 进入正在运行的容器中执行命令 docker container exec -it nginx /bin/bash # 显示一个容器运行的进程 docker container top nginx # 删除一个或删除全部容器 docker container rm -f nginx docker container rm -f $(docker container ls -q) 容器实现核心技术: Namespace在容器化中，一台物理计算机可以运行多个不同操作系统(一个容器就类似于一个系统)，那就需要解决”隔离性”，让彼此感知不到对方的存在，出现问题也互不影响。 Linux内核从2.4.19版本开始引入了namespace概念，其目的是将特定的全局系统资源通过抽象方法使得namespace中的进程看起来拥有自己隔离的资源。Docker就是借助这个机制实现了容器资源隔离。 Linux的namespace机制提供了6种不同的命名空间 IPC: 隔离进程间通信 MOUNT: 隔离文件系统挂载点 NET: 隔离网络协议栈 PID: 隔离进程号，容器命名空间对父进程空间可见 USER: 隔离用户 UTS: 隔离主机名和域名 容器实现核心技术: CGroupsDocker利用namespace实现了容器之间资源隔离，但是namespace不能对容器资源限制，比如CPU、内存。如果某一个容器属于CPU密集型任务，那么会影响其他容器使用CPU，导致多个容器相互影响并且抢占资源。如何对多个容器的资源使用进行限制就成了容器化的主要问题。所以容器引入了Control Groups(简称CGroups)，限制容器资源。 CGroups 以某种标准讲一组进程为目标进行资源分配和控制，例如CPU、内存、带宽等，并且可以动态配置 限制进程组使用的资源数量(Resource limitation ):可以为进程组设定资源使用上限，例如内存 进程组优先级控制( Prioritization):可以为进程组分配特定CPU、磁盘IO吞吐量 记录进程组使用的资源数量(Accounting ):例如使用记录某个进程组使用的CPU时间 进程组控制(Control ):可以将进程组挂起和恢复 查看cgroups可控制的资源 资源 描述 blkio 对块设备的IO进行限制 cpu 限制CPU时间片的分配，与cpuacct挂载同一目录 cpuacct 生成cgroup中的任务占用CPU资源的报告，与cpu挂载同一目录 cpuset 给cgroup中的任务分配独立的CPU(多核处理器)和内存节点 devices 允许或者拒绝 cgroup 中的任务访问设备 freezer 暂停/恢复 cgroup 中的任务 hugetlb 限制使用的内存页数量 memory 对cgroup中任务的可用内存进行限制，并自动生成资源占用报告 net_cls 使用等级识别符(classid)标记网络数据包，这让 Linux 流量控制程序(tc)可以识别来自特定从cgroup任务的数据包，并进行网络限制 net_prio 允许基于cgroup设置网络流量的优先级 perf_event 允许使用perf工具来监控cgroup pids 限制任务的数量 资源控制在容器中的实际位置ll /sys/fs/cgroup/\"资源名\"/docker/\"容器ID\"/ Docker核心组件之间关系我们使用docker client运行一个容器，其实容器运行时底层是需要依赖一系列组件的，我们完全可以通过调用这些组件去启动一个容器，而不使用docker引擎的方式去启动。主要的组件有docker client、docker daemon、containerd、container-shim、runC。 docker clientdocker客户端程序，负责发送用户的请求给docker daemon。 docker daemondocker daemon守护进程，也称docker engine，负责处理docker client的请求，并返回处理结果。 containerdcontainerd是一个工业级标准的容器运行时，它强调简单性、健壮性和可移植性。Containerd可以在宿主机中管理完整的容器生命周期:容器镜像的传输和存储、容器的执行和管理、存储和网络等。为docker daemon提供接口去管理容器，docker对容器的管理和操作基本都是通过containerd完成的。但是要注意的是:containerd被设计成嵌入到一个更大的系统中，而不是直接由开发人员或终端用户使用。 container-shimcontainer-shim是containerd的组件，是容器的运行时载体，我们在docker宿主机上看到的shim也正是代表着一个个通过调用containerd启动的docker容器。 ps axf | grep docker -A 1 10191 ? Sl 0:01 \\_ containerd-shim -namespace moby -workdir /var/lib/containerd/io.containerd.runtime.v1.linux/moby/4dffa5d5861899400770d6470618e4e051c5f1bf0c53034999b13821fc3fe93f -address /run/containerd/containerd.sock -containerd-binary /usr/bin/containerd -runtime-root /var/run/docker/runtime-runc 10208 ? Ss 0:00 \\_ nginx: master process nginx -g daemon off; -- 4215 ? Ssl 2:06 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock runCRunC 是一个轻量级的工具，它是用来运行容器的。我们可以认为它就是个命令行小工具，可以不用通过 docker 引擎，直接运行容器。事实上runC 是标准化的产物，它根据 OCI 标准来创建和运行容器。而 OCI(Open Container Initiative)组织，旨在围绕容器格式和运行时制定一个开放的工业化标准。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker镜像管理(2)","slug":"Docker镜像管理(2)","date":"2020-06-16T07:00:10.000Z","updated":"2020-07-03T06:15:34.344Z","comments":true,"path":"post/ce2c2968.html","link":"","permalink":"https://www.missf.top/post/ce2c2968.html","excerpt":"","text":"什么是镜像镜像是一个分层存储的文件 镜像就是一个软件的运行环境 一个镜像可以重复使用，创建无数个容器 一个不包含Linux内核而又精简的Linux操作系统 镜像是一种标准化的交付，镜像内包含代码以及软件的运行环境 配置镜像加速阿里云为每一个开通容器镜像服务的用户免费提供一个镜像加速地址 # 配置镜像加速 tee /etc/docker/daemon.json < EOF { \"registry-mirrors\": [\"https://265wemgl.mirror.aliyuncs.com\"] } EOF systemctl daemon-reload systemctl restart docker.servicetar归档文件-->镜像 save &amp; load如果你的应用是使用docker-compose.yml编排的多个镜像组合，但你要部署的客户服务器并不能连外网。这时，你可以使用docker save将用到的镜像打个包，然后拷贝到客户服务器上使用docker load载入。 save:将镜像导出为tar归档文件,该命令也可以作用于容器,但导出的是容器背后的images load:将tar归档文件导入为镜像 注意: save命令生成的tar包比export命令生成的tar包大很多，两组命令不可交叉互用","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker核心概念与安装(1)","slug":"Docker核心概念与安装(1)","date":"2020-06-15T02:56:03.000Z","updated":"2020-07-08T03:57:50.406Z","comments":true,"path":"post/f7aff4ce.html","link":"","permalink":"https://www.missf.top/post/f7aff4ce.html","excerpt":"","text":"为什么使用容器提供简单轻量的建模方式，非常容易上手，运行速度非常快 使开发和运维的职责分离，开发只需要关心容器中的程序，运维只需要管理容器 快速高效的开发生命周期，开发环境和生产环境一致，避免了额外的调试有效缩短上线时间 鼓励使用面向服务的架构，docker推荐单个容器只运行一个应用程序，使分布式扩展和调试变得简单 Docker 是什么容器技术想要了解docker，首先要知道什么是容器。最早的容器技术来自于BSD的jail技术(jail一词是监狱的意思，这个技术的隔离思想来源于监狱的启发)，目的就是为了实现进程隔离，使得一个进程被攻陷后不会影响到其他进程，这是出于安全的目的。 使用最为广泛的开源容器引擎在近几年来，docker是一个非常火的名词。事实上docker只是众多容器引擎其中一款优秀的容器引擎，但是它却几乎成为了容器的代名词。许多业外人士觉得docker就是容器，这里大家要明白，docker只是属于容器技术的一种。 容器是一种操作系统级别的虚拟化技术使用docker创建的容器，以特殊进程的方式在宿主机上运行，运行一个容器就像运行一个进程一样，宿主机上可以运行多个容器，容器间的资源是互相隔离的。 依赖于Linux内核特性 Namespace &amp; Cgroups容器之间运行的是一个隔离的环境，也可以理解类似于一个沙盒，使用Namespace进行资源的隔离，使用Cgroups进行资源的控制。 Docker 基本组成Docker Client 客户端docker采用C/S架构 docker客户端和docker服务器之间的通信访问可以是本地方式也可以是远程方式 docker客户端向守护进程发送请求，守护进程的执行结果会传回给客户端 Docker Daemon 守护进程docker采用C/S架构 docker客户端和docker服务器之间的通信访问可以是本地方式也可以是远程方式 docker客户端向守护进程发送请求，守护进程的执行结果会传回给客户端 Docker Image 镜像 镜像是容器的基石，镜像包含了容器启动的一切条件，容器基于镜像去启动。镜像是层叠的只读文件系统，底层是bootfs引导文件系统，rootfs文件系统永远是只读状态，使用同一个镜像无论启动多少个容器，或者容器被如何修改，镜像都不会被改变。一个镜像可以放到一个镜像的顶部，最下面的镜像称为基础镜像，就是图中的centos/Ubuntu层。这里使用了写时复制技术(copy on write)，即通过一个镜像启动一个容器实例，这个镜像是以只读形式挂载的，即不允许任何修改操作，当在容器实例中修改一个文件时，会首先从镜像里把这个文件拷贝到可写层，然后执行更新操作。 Docker Container 容器容器通过镜像启动 docker守护进程执行命令就是在容器实例中执行 应用部署在容器中 在启动容器时会在镜像的最上层创建一个读写层，读写层加上下面的多个只读层从而构成一个容器 Docker Registry 仓库随着我们项目的增加，我们构建的镜像也会越来越多。而镜像也是像代码一样的，需要一个镜像仓库来进行管理的，镜像仓库里面保存着我们构建的镜像。镜像仓库还分为公有仓库和私有仓库。公有仓库一般指Docker Hub，Docker Hub 是一个由 Docker 公司运行和管理的基于云的存储库，它是一个在线存储库，Docker 镜像可以由其他用户发布和使用。而私有仓库一般是我们公司的组织内部拥有的一个私有仓库，仅允许公司内部用户使用。 容器的关系图 容器 VS 虚拟机虚拟机是系统级别的虚拟化，而容器是进程级别的虚拟化，这是虚拟机和容器最核心的区别。虚拟机提供了物理机硬件级别的操作系统隔离，使用虚拟机部署应用，除了应用和应用依赖的库文件，还需要虚拟完整的操作系统，每个虚拟机拥有自己独立的内核，这会大量占用系统的硬件资源。而容器是进程级别的虚拟化，当我们运行docker容器时，此时容器本身只是操作系统中的一个进程，利用了Linux系统的内核特性(Namespace &amp; Cgroups)实现了进程之间网络、空间、权限等隔离，使多个容器进程互相不知道彼此的存在。在这个追求速度的互联网时代，容器在许多方面要比虚拟机优秀。但是不意味着传统的虚拟机技术就过时了，虚拟机的操作系统级别隔离是容器无法替代的，容器的意义在于运行单个应用，如果在容器里面添加越来越多的功能，那不如一开始就直接使用虚拟机。 虚拟技术的核心区别 容器 VS 虚拟机详细对比 Container VM 启动速度 秒级 分钟级 运行性能 接近原生 5%左右损失 磁盘占用 MB GB 数量 成百上千 一般几十台 隔离性 进程级 系统级(更彻底) 操作系统 主要支持Linux 几乎所有 封装程度 只打包项目代码和依赖关系，共享宿主机内核 完整的操作系统 Docker应用场景应用程序打包和发布 应用程序环境隔离 持续集成 部署微服务 快速搭建测试环境 提供Pass产品(平台即服务) Linux 安装 Docker# 安装依赖包 yum install -y yum-utils device-mapper-persistent-data lvm2 # 添加Docker软件源 yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo # 安装Docker CE yum install -y docker-ce # 启动Docker服务并设置开机启动 systemctl start docker systemctl enable docker # 查看docker版本 docker --version Docker version 19.03.11, build 42e35e61f3 # 查看更详细的信息 docker info","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"ansible的过滤器(13)","slug":"ansible的过滤器(13)","date":"2020-06-09T11:46:58.000Z","updated":"2020-06-22T05:39:49.352Z","comments":true,"path":"post/40656090.html","link":"","permalink":"https://www.missf.top/post/40656090.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的过滤器过滤器可以帮助我们对数据进行处理，例如将获取到的变量值中的所有字母都变成大写，过滤器能帮我们实现这样的需求。 --- - hosts: dbserver remote_user: root vars: testvar: fesf1dEcd tasks: - debug: msg: \"{{ testvar | upper }}\" # 执行playbook ok: [dbserver] => { \"msg\": \"FESF1DECD\" } 过滤器是一种能够帮助我们处理数据的工具，ansible中的过滤器功能来自于jinja2模板引擎，我们可以借助jinja2的过滤器功能在ansible中对数据进行各种处理，而上例中的upper就是一种过滤器，这个过滤器的作用就是将小写字母变成大写。当然还有很多其他的过滤器，这些过滤器有些是jinja2内置的，有些是ansible特有的，如果这些过滤器都不能满足你的需求，jinja2也支持自定义过滤器。 字符串操作相关的过滤器--- - hosts: dbserver remote_user: root vars: testvar: fesf1dEcd tasks: - debug: msg: \"{{ testvar | upper }}\" # 将全部字母转换成大写 - debug: msg: \"{{ testvar | lower }}\" # 将全部字母转换成小写 - debug: msg: \"{{ testvar | capitalize }}\" # 首字母大写,其他小写 - debug: msg: \"{{ testvar | reverse }}\" # 将字符串反转 - debug: msg: \"{{ testvar | first }}\" # 返回字符串的第一个字符 - debug: msg: \"{{ testvar | last }}\" # 返回字符串的最后一个字符 - debug: msg: \"{{ testvar | trim }}\" # 将字符串开头和结尾的空格去除 - debug: msg: \"{{ testvar | center(width=30) }}\" # 将字符串居中并设置字符串的长度为30,字符串两边用空格填充 - debug: msg: \"{{ testvar | length }}\" # 返回字符串长度,length与count等效,可以写为count - debug: msg: \"{{ testvar | list }}\" # 将字符串转换成列表,每个字符作为一个元素 - debug: msg: \"{{ testvar | shuffle }}\" # 将字符串转换成列表,每个字符作为一个元素,并且随机打乱顺序(洗牌) 数字操作相关的过滤器--- - hosts: dbserver remote_user: root vars: tes: -8 tasks: - debug: msg: \"{{ 5 + ('8' | int) }}\" # 把字符串类型的'8'转换为整形后再作计算 - debug: msg: \"{{ '9' | int(default=6) }}\" # 把字符串类型的'a'转换为整形,如果无法转换则返回6 - debug: msg: \"{{ '8' | float }}\" # 将对应的值转换为浮点型,如果无法转换则默认返回'0.0' - debug: msg: \"{{ 'a' | float(8.88) }}\" # 当对应的值无法返回时则返回指定的'8.88' - debug: msg: \"{{ tes | abs }}\" # 获取这个变量的绝对值 - debug: msg: \"{{ 15.2 | round }}\" # 四舍五入 - debug: msg: \"{{ 3.14159 | round(2) }}\" # 保留小数点后两位 - debug: msg: \"{{ 100 | random }}\" # 从0到100中返回一个随机数 - debug: msg: \"{{ 10 | random(start=5) }}\" # 从5到10中返回一个随机数 - debug: msg: \"{{ 15 | random(start=5,step=2) }}\" # 从5到15中返回一个随机数,步长为2 - debug: msg: \"{{ 15 | random(step=5) }}\" # 从0到10中返回一个随机数,这个数是5的倍数 列表操作相关的过滤器--- - hosts: dbserver remote_user: root tasks: vars: var1: [32,45,63,76,58] var2: [23,[34,65],34,80] var3: [23,'r',87] var4: ['fr',['po','qE'],'tT','IO'] var5: ['bc',1,5,'b','c'] var6: ['bc',5,'b','g'] tasks: - debug: msg: \"{{ var1 | length }}\" # 返回列表长度,length与count等效 - debug: msg: \"{{ var1 | first }}\" # 返回列表中的第一个值 - debug: msg: \"{{ var1 | last }}\" # 返回列表中的最后一个值 - debug: msg: \"{{ var1 | min }}\" # 返回列表中最小的值 - debug: msg: \"{{ var1 | max }}\" # 返回列表中最大的值 - debug: msg: \"{{ var1 | sort }}\" # 将列表升序排序输出 - debug: msg: \"{{ var1 | sort(reverse=true) }}\" # 将列表降序排序输出 - debug: msg: {{ var1 | sum }}\" # 返回纯数字非嵌套列表中所有数字的和 - debug: msg: \"{{ var2| flatten }}\" # 如果列表中包含列表,就把列表拉平为一个列表 - debug: msg: \"{{ var2 | flatten(levels=1) }}\" # 如果列表中嵌套了多层列表,就把第一层列表拉平 - debug: msg: \"{{ var2 | flatten | max }}\" # 将嵌套列表拉平之后取列表中的最大值 - debug: msg: \"{{ var3 | join }}\" # 将列表中的元素连接成一个字符串 - debug: msg: \"{{ var3 | join(',') }}\" # 将列表中的元素以','分割连接成一个字符串 - debug: msg: \"{{ var3 | random }}\" # 从列表中返回一个随机值 - debug: msg: \"{{ var3 | shuffle }}\" # 随机打乱列表元素的顺序 - debug: msg: \"{{ var4 | upper }}\" # 将列表中的每个元素变成纯大写 - debug: msg: \"{{ var4 | lower }}\" # 将列表中的每个元素变成纯小写 - debug: msg: \"{{ var5 | unique }}\" # 去掉列表中重复的元素,重复的元素只留一个 - debug: msg: \"{{ var5 | union(var6) }}\" # 合并列表,重复元素只留一个(并集) - debug: msg: \"{{ var5 | intersect(var6) }}\" # 取出两个列表的交集元素,重复的元素只留一个 变量未定义相关的过滤器--- - hosts: dbserver remote_user: root vars: var1: '' tasks: - debug: msg: \"{{ var0 | default('missf.top') }}\" # 如果变量没有定义则返回一个默认值,如果定义了变量即使变量值为空还是会输出变量值 - debug: msg: \"{{ var1 | default('coding',boolean=true) }}\" # 如果变量未定义或者变量值为空,则返回默认值 - debug: \"{{ var0 | mandatory }}\" # 如果变量未定义,则报出\"Mandatory variable 'var0' not defined\"错误而不是默认错误 常用过滤器--- - hosts: dbserver remote_user: root vars: users: - name: mj age: 15 hobby: - egm - book - name: mk age: 17 hobby: - pq - jk tasks: - debug: msg: \"{{ users | map(attribute='name') | list }}\" # 从users列表中获取到每个元素所共有的某个属性的值,并将这些值组成一个列表 - debug: msg: \"{{ (name == 'missf') | ternary('Mr','Ms') }}\" # 如果name变量的值是missf,那么对应的值则为Mr,否则则为Ms vars: name: 'missf' - debug: msg: \"{{ tg | basename }}\" # 可以获取到一个路径字符串中的文件名 vars: tg: \"/etc/hosts\" - debug: msg: \"{{ win | win_basename }}\" # 可以获取到windows路径字符串中的文件名 vars: win: \"C:\\studio\\missf\" - debug: msg: \"{{ path | realpath }}\" # 可以获取软链接文件所指向的真正文件 vars: path: \"/tmp/linkfile\" - debug: msg: \"{{ path | splitext }}\" # 可以将文件名后缀带有'.'的部分分开 vars: path: \"/etc/yum.conf\" - debug: msg: \"{{ path | splitext | last }}\" # 将字符串以'.'分开后取最后一个 vars: path: \"/etc/yum.conf\" - debug: msg: \"{{ vt | to_uuid }}\" # 为字符串生成uuid vars: vt: \"this is test\" - debug: msg: \"{{ sk | bool }}\" # 字符串内容为'yes','1','True','true'则返回true,内容为其他则返回false vars: sk: \"yes\" - debug: msg: \"{{ ('2016-08-16 12:00:49' | to_datetime) - ('2012-03-25 19:03:15' | to_datetime) }}\" # 使用to_datetime关键字计算时间差,默认转换的字符串的格式必须是'%Y-%m-%d %H:%M:%S' - debug: msg: \"{{ ('20160814'| to_datetime('%Y%m%d')) - ('2012-12-25 19:00:00' | to_datetime) }}\" # 如果对应的字符串不是这种格式,则需要在to_datetime中指定与字符串相同的时间格式,才能正确的转换为时间类型 - debug: msg: \"{{ '123456' | hash('sha1') }}\" # 使用sha1算法对字符串进行哈希 - debug: msg: \"{{ '123456' | password_hash('md5','ffsfsfsfsfscs') }}\" # 使用md5算法加密，指定字符串作为盐值 密码验证示例--- - hosts: dbserver remote_user: root vars_prompt: - name: username prompt: \"input username\" # 用户输入用户名 - name: password prompt: \"input password\" # 用户输入密码 tasks: - debug: msg: \"{{ username | hash('md5') }}\" # 将用户名hash register: username_md5 - debug: msg: \"{{ password | hash('md5') }}\" # 将密码hash register: password_md5 - debug: msg: \"username yes\" when: username_md5.msg == 'fac2db1a64bc2a16887e9bdf17e15f8e' # 通过比对(用户输入的用户名)和(剧本写死的MD5值)确认密码 - debug: msg: \"password yes\" when: password_md5.msg == 'e10adc3949ba59abbe56e057f20f883e'","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的条件判断(12)","slug":"ansible的条件判断(12)","date":"2020-06-08T10:27:28.000Z","updated":"2020-06-19T09:02:27.283Z","comments":true,"path":"post/3d533130.html","link":"","permalink":"https://www.missf.top/post/3d533130.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的条件判断绝大数语言中，都使用if作为条件判断的方法，而在ansible中，条件判断使用关键字when。 简单示例使用when关键字指明条件是: ansible_distribution == “CentOS”，这里的ansible_distribution是facts信息中的一个key，我们在调用ansible_distribution变量时并没有为它添加{{}}，这是在when关键字中引用变量时，不需要加{{}}。如果ansible_distribution == &quot;CentOS&quot;这个条件成立，那么就调用debug模块，打印msg的内容，如果不成立则不执行debug模块。 # 简单示例 --- - hosts: dbserver remote_user: root tasks: - debug: msg: 'system release is centos' when: ansible_distribution == \"CentOS\" 配合循环进行判断定义条件为item &gt; 1，只有条件成立时item才会被打印，而with_items会循环列表中的值，item变量的值不断变化 --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_items: - 1 - 2 - 3 when: item > 1 条件判断通配符 运算符 条件 结果 == 两个值是否相等 相等则为真 != 两个值是否不相等 不等则为真 &gt; 左边的值大于右边的值 则为真 &lt; 左边的值小于右边的值 则为真 &gt;= 左边的值大于或等于右边的值 则为真 &lt;= 左边的值小于或等于右边的值 则为真 逻辑运算符 运算符 条件 结果 and 当左边与右边同时为真 则返回真 or 当左边与右边有任意一个为真 则返回真 not 对一个操作取反 () 将一组操作包装在一起 逻辑运算和分组示例--- - hosts: dbserver remote_user: root tasks: - debug: msg: 'System release is centos6 or centos7' when: ansible_distribution == \"CentOS\" and (ansible_distribution_major_version == \"6\" or ansible_distribution_major_version == \"7\") 判断模块执行返回的信息我们在执行shell命令时，通常需要获取命令的返回信息，这样才能够根据返回的信息，判断之后的操作如何进行下去。 --- - hosts: dbserver remote_user: root tasks: - name: touch file1 shell: \"touch /file1\" register: returnmsg - name: debug file1 debug: msg: \"Command execution successful\" when: returnmsg.rc == 0 # 命令执行成功的返回值中rc的值为0 - name: debug file2 debug: msg: \"Command execution failed\" when: returnmsg.rc != 0 跳过执行遇到的错误有些时候我们的tasks执行到一半时，遇到错误之后就不再继续往下执行了，我们可以使用ignore_errors关键字去跳过这个错误，让剧本继续往下执行 --- - hosts: dbserver remote_user: root tasks: - name: touch file1 shell: \"ls /file123\" register: returnmsg ignore_errors: true - name: debug file1 debug: msg: \"Command execution successful\" when: returnmsg.rc == 0 - name: debug file2 debug: msg: \"Command execution failed\" when: returnmsg.rc != 0 条件判断与testsLinux系统中可以使用一些常用的判断操作，例如使用test命令判断文件或者目录是否存在 test /etc/ echo $? 0 ansible中也有类似用于判断文件和目录的方法，注意这个是判断控制节点上的文件和目录，”is exists“ | “is not exists“ --- - hosts: dbserver remote_user: root vars: testpath: /etc tasks: - debug: msg: \"file exist\" when: testpath is exists # 判断testpath变量这个路径是否存在，存在则为真，打印msg内容 ok: [dbserver] => { \"msg\": \"file exist\" } 判断变量的tests defined:判断变量是否已经定义，已经定义则返回真 undefind: 判断变量是否已经定义，未定义则返回真 none: 判断变量值是否为空，如果变量已经定义，但是变量值为空，则返回真 定义变量f1赋值为test，定义h2但不赋值，debug模块根据对应的条件是否为真打印具体msg内容 --- - hosts: dbserver remote_user: root tasks: vars: f1: 'test' h2: tasks: - debug: msg: 'varf1 is undefined' when: f1 is undefined - debug: msg: 'The variable is defined, but there is no value' when: h2 is none 判断执行结果的tests *success 或 succeeded: *通过任务的返回信息判断任务的执行状态，任务执行成功则返回真 failure 或 failed: 通过任务的返回信息判断任务的执行状态，任务执行失败则返回真 change 或 changed: 通过任务的返回信息判断任务的执行状态，任务执行状态为changed则返回真 skip 或 skipped: 通过任务的返回信息判断任务的执行状态，当任务没有满足条件而被跳过执行时，则返回真 使用shell模块执行一条命令，并且使用register将返回值存进returnmsg变量，如果命令执行报错就跳过继续往下执行，下面再判断这个变量的执行结果 --- - hosts: dbserver remote_user: root tasks: - shell: \"ls /etc/hosts\" register: returnmsg ignore_errors: true - debug: msg: \"success\" when: returnmsg is success - debug: msg: \"failed\" when: returnmsg is failure - debug: msg: \"changed\" when: returnmsg is changed - debug: msg: \"skip\" when: \"returnmsg is skip\" 判断路径的tests file: 判断路径是否是一个文件，如果是则返回真 directory: 判断路径是否是一个目录，如果是则返回真 link: 判断路径是否是一个软链接，如果是则返回真 mount: 判断路径是否是一个挂载点，如果是则返回真 exists: 判断路径是否存在，如果存在则返回真 判断字符串的tests lower: 判断包含字母的字符串中的字母是否是纯小写，如果是则返回真 upper: 判断包含字母的字符串中的字母是否是纯大写，如果是则返回真 判断整除的tests even: 判断数值是否是偶数，如果是则返回真 odd: 判断数值是否是奇数，如果是则返回真 divisibleby(num): 判断是否可以整除指定的数值，如果可以整除则返回真 条件判断与block想要在条件成立时，执行多个任务，我们不需要在每个任务中都加入判断条件，我们可以使用block关键字将多个任务整合成一个块 --- - hosts: dbserver remote_user: root tasks: - shell: \"ls /loo\" ignore_errors: true - block: # 这个block块有两个任务 - debug: msg: \"run command failed\" - file: path: \"/oo\" state: touch when: 2 > 1 # 条件成立就执行block块的任务 block与rescue的错误处理我们在处理某些复杂的任务时，需要使用到错误处理的判断，使我们的playbook更加灵活。例如我需要执行多个任务，这多个任务中只要有一个执行失败，就会触发错误处理，执行我们提前定义好的救援任务进行补救 --- - hosts: dbserver remote_user: root tasks: - block: - shell: \"ls /123\" - debug: msg: \"tcodmf\" - file: path: \"/loo\" state: touch rescue: - debug: msg: \"error\" # 只要block块里面的三个任务有一个执行失败就会执行rescue定义好的任务 block和always的错误处理如果block中的任务执行出错，那么就会执行rescue中的任务，如果block中的任务执行没有出错，那么rescue中的任务就不会执行，但是always中的任务是无论如何都会执行的，不管block中的内容是否出错 --- - hosts: dbserver remote_user: root tasks: - block: - debug: msg: \"echo 123\" - command: cat /etc/hosts | wc -l # command模块不能执行带特殊字符的命令，第一次出错 - debug: msg: \"echo 456\" rescue: - debug: msg: \"echo error1\" - command: cat /etc/hosts | wc -l # command模块不能执行带特殊字符的命令，第二次出错 always: - debug: msg: \"echo error2\" # 最后执行always 条件判断与错误处理我们有时候需要在判断条件成立时，执行退出的指令，使playbook中断执行，这里我们需要使用到fail模块。我们知道，在执行playbook时，如果playbook中的任意一个任务执行失败，playbook都会终止执行，而fail模块就是天生用来执行失败的模块。只要playbook中执行fail模块，playbook就会认为有任务执行失败了。 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"123\" - debug: msg: \"456\" - fail: # 执行fail模块中断playbook执行,后面的任务不再执行 - debug: msg: \"789\" 使用fail模块终止playbook，默认打印”Failed as requested from task”的错误提示，这个我们可以自定义fail模块的错误提示 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"123\" - debug: msg: \"456\" - fail: msg: \"stop operation playbook\" - debug: msg: \"789\" 利用条件判断去控制fail模块的执行--- - hosts: dbserver remote_user: root tasks: - shell: \"echo 'This is a string for testing--error'\" register: return_value # 取到shell模块执行的返回值 - fail: msg: \"stop operation playbook\" when: \"'error' in return_value.stdout\" # 判断字符串是否存在于return_value.stdout这个输出信息 - debug: msg: \"playbook has stopped\" # 由于fail模块执行而中断playbook,这个将不会执行 failed_when关键字--- - hosts: dbserver remote_user: root tasks: - debug: msg: \"123456\" - shell: \"echo 'This is a string for testing--error'\" register: return_value failed_when: '\"error\" in return_value.stdout' # 如果条件成立,那么failed_when就会提示所对应的shell模块执行失败 - debug: msg: \"654321\" # 不会被打印 failed_changed关键字正常情况下，debug模块正常执行的情况下只能是”ok”状态，我们可以使用failed_changed关键字改变执行后的状态定义为changed --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"test message\" changed_when: 2 > 1 changed: [dbserver] => { \"msg\": \"test message\" }","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的循环(11)","slug":"ansible的循环(11)","date":"2020-06-01T02:47:20.000Z","updated":"2020-06-20T06:42:47.646Z","comments":true,"path":"post/167e62f3.html","link":"","permalink":"https://www.missf.top/post/167e62f3.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的循环我们在编写playbook的时候，不可避免的要执行一些重复性操作，比如指定安装软件包，批量创建用户，操作某个目录下的所有文件等。ansible一门简单的自动化语言，所以流程控制、循环语句这些编程语言的基本元素它同样都具备。 Ansible提供了两个用于创建循环的关键字: loop和with_&lt;lookup&gt;，ansible 2.5中添加了loop，但它还不是with_&lt;lookup&gt;的完全替代品。在官方推荐使用loop，但我们现在还可以在大多数用例中使用with_&lt;lookup&gt;，但是随着loop语法的不断改进，with_&lt;lookup&gt;以后可能会失效。 标准循环使用with_items关键字创建一个循环的列表，with_items会把列表的每一条信息，单独放到item变量里面，然后循环打印每次item变量的值 # 方式1 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" with_items: - 1 - 2 - 3 # 方式2 --- - hosts: dbserver remote_user: root tasks: - debug: msg={{ item }} with_items: [1,2,3] # 方式3 --- - hosts: dbserver remote_user: root vars: list: - a - b - c tasks: - debug: msg={{ item }} with_items: '{{ list }}' # 方式4 --- - hosts: dbserver remote_user: root vars: list: [1,2,3] tasks: - debug: msg={{ item }} with_items: '{{ list }}' # 添加多个用户 --- - hosts: dbserver remote_user: root tasks: - name: add server users user: name: \"{{ item }}\" state: present groups: server with_items: - server1 - server2 定义稍微复杂的列表自定义列表中的每一个键值对都是一个对象，我们可以通过对象的属性对应的”键”，获取到对应的”值”，执行下面的playbook之后，mm和nn都会被输出 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item.name }}\" with_items: - { name: mm, age: 23} - { name: nn, age: 24} ansible-playbook item.yaml # 执行playbook ok: [dbserver] => (item={u'age': 23, u'name': u'mm'}) => { \"msg\": \"mm\" } ok: [dbserver] => (item={u'age': 24, u'name': u'nn'}) => { \"msg\": \"nn\" } 利用循环创建多个文件# 没学习循环之前可能这样创建多个文件 --- - hosts: dbserver remote_user: root gather_facts: no tasks: - file: path: '/opt/a' state: touch - file: path: '/opt/b' state: touch - file: path: '/opt/c' state: touch - file: path: '/opt/d' state: touch # 使用循环的方式 --- - hosts: dbserver remote_user: root gather_facts: no vars: dirs: - '/opt/a' - '/opt/b' - '/opt/c' - '/opt/d' tasks: - file: path: '{{ item }}' state: touch with_items: '{{ dirs }}' 利用循环多次调用模块不使用循环的情况下调用模块，返回的信息是这样的 --- - hosts: dbserver remote_user: root tasks: - shell: 'ls /etc' register: returnvalue - debug: var: returnvalue ansible-playbook item.yaml ok: [dbserver] => { \"returnvalue\": { \"changed\": true, \"cmd\": \"ls /etc\", \"delta\": \"0:00:00.025062\", \"end\": \"2020-06-02 01:06:34.741709\", \"failed\": false, \"rc\": 0, \"start\": \"2020-06-02 01:06:34.716647\", \"stderr\": \"\", \"stderr_lines\": [],这里省略...... } 我们使用循环重复调用了shell模块两次，分别执行了两条命令，然后将shell模块的返回值存放到了returnvalue变量中，最后使用debug模块输出了returnvalue变量的值。当使用了循环之后，每次shell模块执行后的返回值都会放入一个名为results的序列中，其实，results也是一个返回值，当模块中使用了循环时，模块每次执行的返回值都会追加存放到results这个返回值中，所以，我们可以通过results关键字获取到每次模块执行后的返回值 --- - hosts: dbserver remote_user: root tasks: - shell: '{{ item }}' with_items: - 'ls /etc' - 'ls /var' register: returnvalue - debug: var: returnvalue ansible-playbook item.yaml ok: [dbserver] => { \"returnvalue\": { \"changed\": true, \"msg\": \"All items completed\", \"results\": [ { \"ansible_loop_var\": \"item\", \"changed\": true, \"cmd\": \"ls /etc\", \"delta\": \"0:00:00.026532\", \"end\": \"2020-06-02 01:08:22.264277\", \"failed\": false, \"invocation\": { 这里省略...... } 先使用循环重复的调用了shell模块，然后将shell模块每次执行后的返回值注册到了变量returnvalue中，之后，在使用debug模块时，通过返回值results获取到了之前每次执行shell模块的返回值(shell每次执行后的返回值已经被放入到item变量中)，最后又通过返回值stdout获取到了每次shell模块执行后的标准输出 --- - hosts: dbserver remote_user: root tasks: - shell: '{{ item }}' with_items: - 'ls /etc' - 'ls /var' register: returnvalue - debug: msg: '{{ item.stdout }}' with_items: '{{ returnvalue.results}}' 打印序列中的序列with_items块序列下面有一个自定义列表[1,2,3]，执行playbook会循环打印[1,2,3]列表里的每一个值 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" with_items: [1,2,3] ok: [dbserver] => (item=1) => { \"msg\": 1 } ok: [dbserver] => (item=2) => { \"msg\": 2 } ok: [dbserver] => (item=3) => { \"msg\": 3 } with_items块序列下面有两个自定义列表，执行playbook还是会循环打印两个列表里的每一个值 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" with_items: - [1,2,3] - [4,5,6] ok: [dbserver] => (item=1) => { \"msg\": 1 } ok: [dbserver] => (item=2) => { \"msg\": 2 } ok: [dbserver] => (item=3) => { \"msg\": 3 } ok: [dbserver] => (item=4) => { \"msg\": 4 } ok: [dbserver] => (item=5) => { \"msg\": 5 } ok: [dbserver] => (item=6) => { \"msg\": 6 } 当with_items块序列下面有两个自定义的列表时，我们如何让debug模块将每个小列表作为一个小整体输出，而不应该输出小列表中的每个元素呢？我们可以使用with_list关键字，替换上例playbook中的with_items关键字。 --- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" with_list: - [1,2,3] - [4,5,6] ok: [dbserver] => (item=[1, 2, 3]) => { # with_list块序列只会循环最外层的每一项,而with_items则是循环处理每一个元素 \"msg\": [ 1, 2, 3 ] } ok: [dbserver] => (item=[4, 5, 6]) => { \"msg\": [ 4, 5, 6 ] } 元素对齐合并with_together可以将两个列表中的元素对齐合并，如果两个列表元素不一致，缺少的元素值为null --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_together: - [1,2,3] - [a,b,c] ok: [dbserver] => (item=[1, u'a']) => { \"msg\": [ 1, \"a\" ] } ok: [dbserver] => (item=[2, u'b']) => { \"msg\": [ 2, \"b\" ] } ok: [dbserver] => (item=[3, u'c']) => { \"msg\": [ 3, \"c\" ] } 元素两两组合需求: 我们需要创建三个目录，这三个目录下面都有相同的子目录，我们使用ansible-playbook的方式去循环创建，需要用到with_cartesian这个关键字 # 需要创建的目录结构如下: dir1/sofm dir1/bin dir2/sofm dir2/bin dir3/sofm dir3/bin --- - hosts: dbserver remote_user: root tasks: - file: state: directory path: '/{{ item[0] }}/{{ item[1] }}' with_cartesian: - [dir1,dir2,dir3] - [sofm,bin] 执行playbook会将两个列表的元素两两组合，使用item[0]和item[1]来获取每一次循环的值 PLAY [dbserver] ****************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] TASK [file] ********************************************************************************************************************** changed: [dbserver] => (item=[u'dir1', u'sofm']) changed: [dbserver] => (item=[u'dir1', u'bin']) changed: [dbserver] => (item=[u'dir2', u'sofm']) changed: [dbserver] => (item=[u'dir2', u'bin']) changed: [dbserver] => (item=[u'dir3', u'sofm']) changed: [dbserver] => (item=[u'dir3', u'bin']) PLAY RECAP *********************************************************************************************************************** dbserver : ok=2 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 列表元素添加索引编号使用with_indexed_items关键字可以为列表的每一个元素添加索引编号，索引编号从0开始，我们可以在出来列表每一项元素的时候获取到索引编号 --- - hosts: dbserver remote_user: root tasks: - debug: msg: 'index is {{ item[0] }},value is {{ item[1] }}' with_indexed_items: - index1 - index2 - index3 ok: [dbserver] => (item=[0, u'index1']) => { \"msg\": \"index is 0,value is index1\" } ok: [dbserver] => (item=[1, u'index2']) => { \"msg\": \"index is 1,value is index2\" } ok: [dbserver] => (item=[2, u'index3']) => { \"msg\": \"index is 2,value is index3\" } 生成数字序列假如需要在管理节点创建dir2,dir4,dir6这样的目录，我们该如何使用循环去创建呢，这里就需要使用到with_sequence这个关键字去生成数字序列。debug模块被调用了4次，从2开始，到8结束，每一次增加2(步长)，看到这是不是有了Python的感觉呢？ --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_sequence: start=2 end=8 stride=2 ok: [dbserver] => (item=2) => { \"msg\": \"2\" } ok: [dbserver] => (item=4) => { \"msg\": \"4\" } ok: [dbserver] => (item=6) => { \"msg\": \"6\" } ok: [dbserver] => (item=8) => { \"msg\": \"8\" } 创建dir2,dir4,dir6这样不连续的目录 --- - hosts: dbserver remote_user: root tasks: - file: path: /dir{{ item }} state: directory with_sequence: start=2 end=6 stride=2 输出更简单的连续序列--- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_sequence: count=5 注意: 当我们不指定start的值时，start的值默认为1，但是当end的值小于start时则必须指定stride，而且stride的值必须是负数 返回一个随机值使用with_random_choice这个关键字可以让我们从一个列表的多个值中随机返回一个值 --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_random_choice: - qwe - rtd - fdv - oki ok: [dbserver] => (item=oki) => { \"msg\": \"oki\" # 随机返回列表中的一个值 } 使用循环去操作字典这里我们学习一个叫with_dict的字典关键字，下面来看看字典的使用场景。 定义一个users变量，users有两个用户，我们使用with_dict关键字处理这个字典格式的变量 --- - hosts: dbserver remote_user: root vars: users: alix: feom boo: mair tasks: - debug: msg: '{{ item }}' with_dict: '{{ users }}' ok: [dbserver] => (item={'value': u'feom', 'key': u'alix'}) => { \"msg\": { \"key\": \"alix\", # users变量经过with_dict处理之后，键值对分别被放入key和value关键字中 \"value\": \"feom\" } } ok: [dbserver] => (item={'value': u'mair', 'key': u'boo'}) => { \"msg\": { \"key\": \"boo\", # 我们可以通过key关键字和value关键字分别获取到字典中键值对的键和值 \"value\": \"mair\" } } 字典定义和取值--- - hosts: dbserver remote_user: root vars: users: alix: name: feom gender: female phone: 155464615 boo: name: mair gender: male phone: 179444684 tasks: - debug: msg: '{{ item }} alix phone is {{ item.value.phone }}' # 使用item.value.phone的方法取某一项的值 with_dict: '{{ users }}' ok: [dbserver] => (item={'value': {u'gender': u'female', u'name': u'feom', u'phone': 155464615}, 'key': u'alix'}) => { \"msg\": \"{'key': u'alix', 'value': {u'gender': u'female', u'name': u'feom', u'phone': 155464615}} alix phone \\\\n is 155464615\" } ok: [dbserver] => (item={'value': {u'gender': u'male', u'name': u'mair', u'phone': 179444684}, 'key': u'boo'}) => { \"msg\": \"{'key': u'boo', 'value': {u'gender': u'male', u'name': u'mair', u'phone': 179444684}} alix phone \\\\n is 179444684\" } 遍历每一项子元素users变量列表中有两个块序列，这两个块序列分别代表两个用户，bob和alice，变量users经过with_subelements处理时还指定一个hobby属性，hobby属性正是users变量中每个用户的子属性 --- - hosts: dbserver remote_user: root vars: users: - name: bob gender: male hobby: - skateboard - videogame - name: alice gender: female hobby: - music - name: qwe hobby: - da tasks: - debug: msg: \"{{ item }}\" with_subelements: - \"{{ users }}\" - hobby 上面的playbook执行后得到如下结果，我们在使用with_subelements处理变量users时指定了hobby属性，hobby属性中的每一个子元素都被当做一个整体，而其他的子元素作为另一个整体，组成了键值对 ok: [dbserver] => (item=[{u'gender': u'male', u'name': u'bob'}, u'skateboard']) => { \"msg\": [ { \"gender\": \"male\", \"name\": \"bob\" }, \"skateboard\" ] } ok: [dbserver] => (item=[{u'gender': u'male', u'name': u'bob'}, u'videogame']) => { \"msg\": [ { \"gender\": \"male\", \"name\": \"bob\" }, \"videogame\" ] } ok: [dbserver] => (item=[{u'gender': u'female', u'name': u'alice'}, u'music']) => { \"msg\": [ { \"gender\": \"female\", \"name\": \"alice\" }, \"music\" ] } ok: [dbserver] => (item=[{u'name': u'qwe'}, u'da']) => { \"msg\": [ { \"name\": \"qwe\" }, \"da\" ] } 获取控制节点的文件内容我想要获取控制节点上的几个文件的内容，那么可以使用with_file关键字，循环获取到文件的内容，这里hosts指定的是dbserver这个管理节点，但是无论管理节点写的是什么都不影响，因为我们读取的是管理节点的文件 --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_file: - /etc/passwd - /etc/hosts ok: [dbserver] => (item=root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin sync:x:5:0:sync:/sbin:/bin/sync shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown halt:x:7:0:halt:/sbin:/sbin/halt mail:x:8:12:mail:/var/spool/mail:/sbin/nologin operator:x:11:0:operator:/root:/sbin/nologin games:x:12:100:games:/usr/games:/sbin/nologin ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin nobody:x:99:99:Nobody:/:/sbin/nologin systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin dbus:x:81:81:System message bus:/:/sbin/nologin polkitd:x:999:998:User for polkitd:/:/sbin/nologin sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin postfix:x:89:89::/var/spool/postfix:/sbin/nologin ntp:x:38:38::/etc/ntp:/sbin/nologin) => { \"msg\": \"root:x:0:0:root:/root:/bin/bash\\nbin:x:1:1:bin:/bin:/sbin/nologin\\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\\nadm:x:3:4:adm:/var/adm:/sbin/nologin\\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\\nsync:x:5:0:sync:/sbin:/bin/sync\\nshutdown:x:6:0:shutdown:/sbin:/sbin/shutdown\\nhalt:x:7:0:halt:/sbin:/sbin/halt\\nmail:x:8:12:mail:/var/spool/mail:/sbin/nologin\\noperator:x:11:0:operator:/root:/sbin/nologin\\ngames:x:12:100:games:/usr/games:/sbin/nologin\\nftp:x:14:50:FTP User:/var/ftp:/sbin/nologin\\nnobody:x:99:99:Nobody:/:/sbin/nologin\\nsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologin\\ndbus:x:81:81:System message bus:/:/sbin/nologin\\npolkitd:x:999:998:User for polkitd:/:/sbin/nologin\\nsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin\\npostfix:x:89:89::/var/spool/postfix:/sbin/nologin\\nntp:x:38:38::/etc/ntp:/sbin/nologin\" } ok: [dbserver] => (item=127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6) => { \"msg\": \"127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4\\n::1 localhost localhost.localdomain localhost6 localhost6.localdomain6\" } 匹配控制节点的文件我们可以通过通配符去匹配控制节点上的文件，这里需要使用到with_fileglob这个关键字。注意with_fileglob只能是匹配到文件 --- - hosts: dbserver remote_user: root tasks: - debug: msg: '{{ item }}' with_fileglob: - /etc/* - /tmp/* # 这里写成/dir/的话是匹配不到文件的，需要使用*通配符 ok: [dbserver] => (item=/etc/fstab) => { \"msg\": \"/etc/fstab\" } ok: [dbserver] => (item=/etc/crypttab) => { \"msg\": \"/etc/crypttab\" } ok: [dbserver] => (item=/etc/mtab) => { \"msg\": \"/etc/mtab\" } ok: [dbserver] => (item=/etc/resolv.conf) => { \"msg\": \"/etc/resolv.conf\" } ok: [dbserver] => (item=/etc/magic) => { \"msg\": \"/etc/magic\" }...... ansible的loop循环在2.5版本之前的ansible中，大多数人习惯使用”with_X”风格的关键字操作循环，从2.6版本开始，官方开始推荐使用”loop”关键字代替”with_X”风格的关键字。现在就来聊聊这种新的方式，以便能够更好的从老版本的使用习惯过渡过来。 loop标准循环--- - hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ item }}\" loop: - abc - cde loop循环安装软件--- - hosts: dbserver remote_user: root tasks: - name: install packages yum: name: \"{{ item }}\" state: latest loop: - rsync - sl - psmisc loop批量创建用户--- - hosts: dbserver remote_user: tasks: - name: \"add user\" user: name: \"{{ item.name }}\" state: present groups: \"{{ item.groups }}\" loop: - {name: \"abc\",groups: \"root\"} - {name: \"cde\",groups: \"root\"}","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的变量(10)","slug":"ansible的变量(10)","date":"2020-05-28T02:13:41.000Z","updated":"2020-06-11T07:51:00.508Z","comments":true,"path":"post/4736d6b2.html","link":"","permalink":"https://www.missf.top/post/4736d6b2.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的变量在ansible中使用变量，能让我们的工作变得更加灵活。 变量定义规则 变量名应该由字母、数字、下划线组成 变量名需要以字母开头 ansible内置的关键字不能作为变量名 在playbook中使用变量使用vars关键字定义名为package1值为nginx的变量，在task中使用进行调用 --- - hosts: all vars: package1: nginx remote_user: root tasks: - name: task1 yum: name: \"{{ package1 }}\" state: installed 使用块序列化语法定义变量vars: - testvar1: a1 - testvar2: b2 使用属性的方式定义变量--- - hosts: all remote_user: root vars: nginx: # 定义两个变量 conf80: /etc/nginx/conf.d/80.conf conf8080: /etc/nginx/conf.d/8080.conf tasks: - name: task1 file: path: \"{{ nginx.conf80 }}\" # 第一种调用方法 state: touch - name: task2 file: path: \"{{ nginx['conf8080']}}\" # 第二种调用方法 注意: 如果引用变量时，变量处于开头的位置，那么变量必须要用双引号引起来，否则语法会报错 - name: task2 file: path: \"{{ nginx['conf8080']}}\" # 引用这种变量处于开头位置的必须使用引号引起来 - name: task2 file: path: /root/{{ nginx['conf8080']}} # 这样的不用 引入文件内的变量创建nginx_vars.yaml文件，直接在文件中以自己喜欢的方式定义变量 testvar1: zxc testvar2: qwe - testvar3: rty - testvar4: poi nginx: conf1: /usr/local/nginx/conf/nginx1.conf conf2: /usr/local/nginx/conf/nginx2.conf 在playbook中以vars_files关键字引入文件中的变量 --- - hosts: all remote_user: root vars: # vars关键字和vars_files关键字可以同时使用 - /root/vars.yaml vars_files: - /playbook/nginx_vars.yaml tasks: - name: task1 file: path: \"{{ nginx.conf80 }}\" state: touch - name: task2 file: path: \"{{ nginx['conf8080']}}\" 变量与setup模块前面我们说过在执行playbook的时候，默认都会运行一个名为Gathering Facts的任务，这个任务会收集管理节点的相关信息(例如管理节点的IP地址，主机名，系统版本，硬件配置等信息)，这些被收集到的信息都会保存在对应的变量中，我们想要使用这些信息时，可以获取对应的变量，从而使用这些信息。关于setup模块具体查看前面ansible模块学习。 查看从管理节点收集到的所有相关信息ansible all -m setup # 由于返回信息的比较多，这里不作示例 查看管理节点的内存使用情况ansible all -m setup -a 'filter=ansible_memory_mb' 在管理节点创建自定义变量除了ansible默认收集的信息以外，我们还能够在管理节点写入一些自定义变量，这些自定义变量也是可以被setup模块收集到。 首先在管理节点创建自定义变量的文件hello.fact，此类文件必须以*.fact命名 # 管理节点 mkdir -p /etc/ansible/facts.d vim /etc/ansible/facts.d/hello.fact [info] name: mwj age: 24 # 控制节点 ansible dbserver -m setup -a \"filter=ansible_local\" # 使用ansible_local关键字过滤信息得到管理节点的自定义变量 10.10.110.122 | SUCCESS => { \"ansible_facts\": { \"ansible_local\": { \"hello\": { \"info\": { \"age\": \"24\", \"name\": \"mwj\" } } }, \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false } 注意: 管理节点上的hello.fact文件必须不是可执行文件，不然这个文件不会被成功读取，具体可查看ansible官方文档有详细说明。 在管理节点的/etc/ansible/facts.d/这个目录是使用ansible_local关键字过滤时的默认路径，如果想要自定义路径可以使用fact_path关键字定义 ansible dbserver -m setup -a \"fact_path=/tmp/facts.d/\" 变量与debug模块debug模块是帮我们进行调试的，可以把对我们有用的信息输出到控制台上，以便能够定位问题。 playbook中使用debug模块--- - hosts: all remote_user: root tasks: - name: touch file file: path: /tmp/debug.txt state: touch - name: debug demo debug: msg: this is debug info,File created successfully 运行playbook模块查看信息如下图所示，在touch文件之后会输出我们定义好的debug信息 PLAY [all] *********************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] ok: [webserver] TASK [touch file] **************************************************************************************************************** changed: [webserver] changed: [dbserver] TASK [debug demo] **************************************************************************************************************** ok: [webserver] => { \"msg\": \"this is debug info,File created successfully\" } ok: [dbserver] => { \"msg\": \"this is debug info,File created successfully\" } PLAY RECAP *********************************************************************************************************************** dbserver : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 webserver : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 使用debug模块输出变量信息debug模块除了能够使用msg参数输出自定义的信息，还能够使用var参数直接输出变量中的信息 --- - hosts: all remote_user: root vars: testvar: this is a debug variable tasks: - name: debug demo debug: var: testvar 使用debug模块的msg参数一样可以打印变量信息 --- - hosts: all remote_user: root tasks: - name: debug demo debug: msg: \"Remote host memory information: {{ ansible_memory_mb }}\" 执行结果如下 PLAY [all] *********************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] ok: [webserver] TASK [debug demo] **************************************************************************************************************** ok: [webserver] => { \"msg\": \"Remote host memory information: {u'real': {u'total': 216, u'used': 213, u'free': 3}, u'swap': {u'cached': 0, u'total': 1023, u'free': 1022, u'used': 1}, u'nocache': {u'used': 163, u'free': 53}}\" } ok: [dbserver] => { \"msg\": \"Remote host memory information: {u'real': {u'total': 216, u'used': 212, u'free': 4}, u'swap': {u'cached': 0, u'total': 1023, u'free': 1013, u'used': 10}, u'nocache': {u'used': 170, u'free': 46}}\" } PLAY RECAP *********************************************************************************************************************** dbserver : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 webserver : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 ansible_memory_mb其中其实包含了 “nocache”、”real”、 “swap”三个部分的信息，我们只想获得”real”部分的信息，在playbook中引用变量时可以使用如下示例: msg: \"Remote host memory information: {{ ansible_memory_mb.real }}\" msg: \"Remote host memory information: {{ ansible_memory_mb['real'] }}\" 注册变量ansible的模块运行之后都会返回一些返回值，只是默认情况下，这些返回值并不会显示而已，我们可以把这些返回值写入到某个变量中，这样我们就能够通过引用对应的变量从而获取到这些返回值了，这种将模块的返回值写入到变量中的方法被称为注册变量。 下面这个playbook有两个任务，第一个任务使用shell模块执行了一条命令，然后在这个任务下使用register注册了一个testvar的变量，第二个任务是使用debug模块的var参数打印这个变量，最后输出shell模块的返回值。 --- - hosts: dbserver remote_user: root tasks: - name: test shell shell: \"echo test > /tmp/test\" register: testvar - name: shell module return values debug: var: testvar playbook执行的结果如下图，返回的是一个json格式的数据，我们还可以使用&lt;!–￼11–&gt;或者&lt;!–￼12–&gt;指定key来获取某一项特定的值 PLAY [dbserver] ****************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] TASK [test shell] **************************************************************************************************************** changed: [dbserver] TASK [shell module return values] ************************************************************************************************ ok: [dbserver] => { \"testvar\": { \"changed\": true, \"cmd\": \"echo test > /tmp/test\", \"delta\": \"0:00:00.025987\", \"end\": \"2020-06-02 22:34:36.185101\", \"failed\": false, \"rc\": 0, \"start\": \"2020-06-02 22:34:36.159114\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": [] } } PLAY RECAP *********************************************************************************************************************** dbserver : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 如果你想要查看模块对应的返回值，可以先查找官方手册，但并不是所有模块的官方手册中都对模块的返回值进行了描述，你可以自己去官网查看模块的返回值，这些返回值不仅仅能够用于输出，通常我们会利用到这些返回值，比如通过模块的返回值决定之后的一些动作，所以注册变量在playbook中还是会被经常用到的，在之后的文章中我们会给出示例。 变量与用户交互信息在运行shell脚本时，有些时候需要用户输入信息，脚本再根据用户输入的信息决定下一步的动作，这种交互是必须的。我们也可以在playbook中实现这种交互，首先提示用户输入信息，然后将用户输入的信息存放到指定的变量中，当我们需要使用这些信息时，只要引用对应的变量即可。 下面我们使用vars_prompt关键字定义了两个变量，变量名为别为your_name和your_age，变量下面是提示用户输入时的信息 --- - hosts: dbserver remote_user: root vars_prompt: - name: \"your_name\" prompt: \"what is your name\" - name : \"your_age\" prompt: \"how old are you\" tasks: - name: output vars debug: msg: your name is {{your_name}},you are {{your_age}} years old. playbook执行如下图，提示用户输入信息时默认是不显示信息的，这和输入密码的场景类似 what is your name: how old are you: PLAY [dbserver] ****************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] TASK [output vars] ************************************************************************************************************** ok: [dbserver] => { \"msg\": \"your name is mwj,you are 24 years old.\" } PLAY RECAP *********************************************************************************************************************** dbserver : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 如果想要用户输入信息时显示信息内容，可以将private参数设置为no --- - hosts: dbserver remote_user: root vars_prompt: - name: \"your_name\" prompt: \"what is your name\" - name : \"your_age\" prompt: \"how old are you\" private: no # 显示用户输入的内容 tasks: - name: output vars debug: msg: your name is {{your_name}},you are {{your_age}} years old. 我们还可以为提示信息设置默认值，如果用户不输入任何信息就将默认值赋予变量，如果用户输入信息，就把输入的信息赋值给变量 --- - hosts: dbserver remote_user: root vars_prompt: - name: \"your_name\" prompt: \"what is your name\\n\" private: no default: mike tasks: - name: output vars debug: msg: your name is {{your_name}} 上面playbook的执行过程如下，中括号内的内容是我们设置的默认值，如果用户直接回车那就将中括号内的内容直接赋值给变量 what is your name [mike]: mwj PLAY [dbserver] ****************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [dbserver] TASK [output vars] ************************************************************************************************************** ok: [dbserver] => { \"msg\": \"your name is mwj\" } PLAY RECAP *********************************************************************************************************************** dbserver : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 通过命令行传入变量我们可以在执行playbook时直接传入需要使用到的变量。编写一个playbook，打印一个passwd的变量 --- - hosts: dbserver remote_user: root tasks: - name: \"passing in variables from the command line\" debug: msg: \"{{ passwd }}\" 执行playbook时传入变量ansible-playbook --extra-vars \"passwd=mdf123456\" passwd.yaml # --extra-vars参数可以简写成-e，还可以一次性传入多个变量，用空格隔开 ansible-playbook -e \"passwd=mdf123456 username=ewe\" passwd.yaml 注意: 如果playbook中并没有定义passwd变量，在执行playbook时也没有传入passwd变量，则会报错。如果在playbook中事先定义好了passwd变量，在执行时再次传入名字相同的变量，最终还是以传入的变量值为准，命令行传入的变量的优先级要高于playbook中的变量。 不仅ansible-playbook可以使用-e传递变量，ansible命令行一样可以，在执行ad-hoc命令时可以使用下面的方法传入变量 ansible dbserver -e \"name=mwj\" -m shell -a \"echo my name in {{ name }}\" json格式传入变量除了以键值对的方式传入变量，我们还可以传入json格式的变量 ansible-playbook passwd.yaml -e '{\"username\":\"mwj\",\"passwd\":\"123456\"}' ansible-playbook passwd.yaml -e '{\"countlist\":[\"one\",\"two\",\"three\",\"four\"]}' # {{countlist[0]}}或{{countlist.0}}引用变量 执行playbook时传入变量文件编写变量文件，可以是json格式或者yaml格式的文件 namevar: mwj countlist: - one - two - three - four playbook内容调用变量 --- - hosts: dbderver remote_user: root tasks: - name: \"name\" debug: msg: \"{{ namevar }} {{ countlist[0] }}\" 命令行传入对应的文件，使用@符号加上变量文件的路径，变量文件中的所有变量都可以在playbook中引用 ansible-playbook test.yaml -e '@/ansible/var1' 在主机清单中配置变量在主机清单中，可以配置我们的管理节点，也可以将部分管理节点分为一组，其实，在配置清单时还可以为主机或主机组设置变量 主机变量在主机清单中配置变量时，可以同时为管理节点配置对应的变量，当操作这个主机时，即可直接使用对应的变量，而其他主机不能引用到这个变量 # ini风格 dbserver ansible_host=10.1.1.70 name: mwj age: 24 # yaml风格 all: children: server: hosts: dbserver: ansible_host: 10.10.110.122 ansible_port: 22 name: mwj age: 24 webserver: ansible_host: 10.10.110.123 ansible_port: 22 可以在命令行引用主机变量，也可以在playbook中引用主机变量 ansible dbserver -m shell -a 'echo {{name}}' 使用层级关系定义更复杂的主机变量 all: children: server: hosts: dbserver: ansible_host: 10.10.110.122 ansible_port: 22 name: n1: mike n2: masha n3: laki # 引用时使用{{ name.n1 }}或{{ name['n1'] }} 主机组变量 在主机清单中，我们可以将多个主机分为一组，这样方便我们同时去操作同一组的管理节点，我们可以为这个主机组定义变量，组内的所有主机都可以使用 # ini风格 [webserver] web01 ansible_host: 10.10.110.121 web02 ansible_host: 10.10.110.122 web03 ansible_host: 10.10.110.123 [webserver:vars] path=\"/usr/local/nginx/html/\" user=\"root\" # yaml格式 all: children: server: hosts: dbserver: ansible_host: 10.10.110.122 ansible_port: 22 webserver: ansible_host: 10.10.110.123 ansible_port: 22 vars: user: \"root\" path: \"/usr/local/nginx/html/\" set_fact定义变量set_fact是一个模块，我们可以通过set_fact模块在tasks中定义变量testvar1，然后打印这个变量 --- - hosts: dbserver remote_user: root tasks: - set_fact: testvar1: mid - debug: msg: \"{{ testvar1 }}\" set_fact定义变量的特殊性通过set_fact模块创建的变量还有一个特殊性，过set_fact创建的变量就像主机上的facts信息一样，可以在之后的play中被引用。而我们使用vars关键字创建的变量则不能被其他playbook所引用到。 下面这个playbook有两个play，第一个play中有两个变量分别是ts1和ts2，它们分别用vars和set_fact定义，只有使用set_fact定义的ts2变量，才能被下面这个play所引用，而使用vars定义的ts1变量则不能被下面的play所引用。 --- - hosts: dbserver remote_user: root vars: ts1: team1 tasks: - set_fact: ts2: team2 - debug: msg: \"{{ ts1 }}---{{ ts2 }}\" - hosts: webserver remote_user: root tasks: - name: get ts1 # 这里引用会报错 debug: msg: \"{{ ts1 }}\" - name: get ts2 debug: msg: \"{{ ts2 }}\" 注意: set_fact变量类似于管理节点的全局变量，可以跨play获取变量，注册变量也能被之后的play所引用。 内置变量除了我们各种各样的定义变量之外，ansible还有一些内置的变量供我们使用，这些内置变量的变量名是被ansible所保留的，我们定义变量时不能使用这些变量名。 内置变量ansible_version查看ansible的版本 ansible all -m debug -a 'msg={{ansible_version}}' 内置变量hostvarshostvars可以帮助我们在操作当前管理节点时获取到其他管理节点中的信息。下面playbook有两个play，第一个没有任何task，只是将webserver主机的信息收集起来，供后面的play调用。第二个play则是使用了debug模块打印了webserver的内置变量hostvars，输出了webserver的IP地址，这就是在操作dbserver管理节点时获取了webserver管理节点的信息。 --- - name: \"gather facts of webserver\" hosts: webserver remote_user: root - name: \"get facts webserver\" hosts: dbserver remote_user: root tasks: - debug: msg: \"{{ hostvars['webserver'].ansible_ens32.ipv4 }}\" # 如果没有第一个play，在执行时调用[Gathering Facts]任务，将webserver的信息收集起来，后面dbserver调用这个变量就会报错 内置变量inventory_hostname通过inventory_hostname变量可以获取到管理节点的当前主机名称，注意这个不是指Linux系统的主机名，而是对应管理节点在控制节点的主机清单中的配置名称。 # 主机清单 [abc] 10.10.110.122 dbserver ansible_host: 10.10.110.123 使用内置变量inventory_hostname获取各个主机的对应的主机名 ansible abc -m debug -a 'msg={{inventory_hostname}}' 10.10.110.122 | SUCCESS => { \"msg\": \"10.10.110.122\" } dbserver | SUCCESS => { \"msg\": \"dbserver\" } # 定义是IP则返回IP，定义是别名则返回别名 内置变量inventory_hostname_short与内置变量inventory_hostname类似，通过inventory_hostname_short也可以获取当前play操作的管理节点在清单中对应的名称，但是这个名称更加简短， [abc] 10.10.110.122 dbserver.com ansible_host=10.10.110.123 按上面主机清单的配置，我们可以使用inventory_hostname_short获取到管理节点的简短名称 ansible all -m debug -a 'msg={{inventory_hostname_short}}' 10.10.110.122 | SUCCESS => { \"msg\": \"10\" } dbserver.com | SUCCESS => { \"msg\": \"dbserver\" } # 可以看到无论是IP还是主机名，inventory_hostname_short都会取得主机名中第一个\".\"之前的字符作为主机的简短名称 内置变量play_hosts通过内置变量play_hosts可以获取到当前play所操作的所有管理节点的主机名列表 --- - hosts: 10.10.110.122,dbserver.com remote_user: root tasks: - name: debug debug: msg: \"{{ play_hosts }}\" # 返回的是所操作的所有管理节点的主机名列表 ok: [10.10.110.122] => { \"msg\": [ \"10.10.110.122\", \"dbserver.com\" ] } ok: [dbserver.com] => { \"msg\": [ \"10.10.110.122\", \"dbserver.com\" ] } 内置变量inventory_dir我们可以通过inventory_dir变量获取到ansible主机中清单文件的存放路径 ansible all -m debug -a 'msg={{inventory_dir}}' 10.10.110.122 | SUCCESS => { \"msg\": \"/etc/ansible\" } dbserver.com | SUCCESS => { \"msg\": \"/etc/ansible\" } 重新加载变量文件我们先来看一个小示例。假如playbook中有三个任务，第一个任务调用了控制节点的一个变量文件，第二个任务在变量文件中新增了一个变量，第三个任务在变量文件中引用新增的那个变量，看看结果会如何。 cat /root/playbook/var_file.yaml # 变量文件已有v1变量 v1: 111 --- - hosts: master remote_user: root tasks: vars_files: - /root/playbook/var_file.yaml tasks: - debug: msg: \"{{ v1 }}\" - lineinfile: path: \"/root/playbook/var_file.yaml\" line: \"v2: 222\" # 往变量文件新增v2变量 - debug: msg: \"{{ v1 }},{{ v2 }}\" # 输出v1和v2变量,这里输出v2变量会出错 fatal: [master]: FAILED! => {\"msg\": \"The task includes an option with an undefined variable. The error was: 'v2' is undefined\\n\\nThe error appears to be in '/root/playbook/include.yaml': line 13, column 5, but may\\nbe elsewhere in the file depending on the exact syntax problem.\\n\\nThe offending line appears to be:\\n\\n line: \\\"v2: 222\\\"\\n - debug:\\n ^ here\\n\"} 上面的示例中，其实v2变量已经成功添加到变量文件中了，但是由于我们是先读取了变量文件，再写入v2变量到文件，这时候我们没有重新读取变量文件，那么就会报错v2变量未定义了，我们可以使用include_vars关键字从新加载变量文件。 --- - hosts: master remote_user: root tasks: vars_files: - /root/playbook/var_file.yaml tasks: - debug: msg: \"{{ v1 }}\" - lineinfile: path: \"/root/playbook/var_file.yaml\" line: \"v2: 222\" - include_vars: \"/root/playbook/var_file.yaml\" # 重新加载变量文件 - debug: msg: \"{{ v1 }},{{ v2 }}\" # 这时候输出v2变量就不会出错","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的tags(9)","slug":"ansible的tags(9)","date":"2020-05-27T02:38:40.000Z","updated":"2020-06-02T07:51:22.023Z","comments":true,"path":"post/dd3a7968.html","link":"","permalink":"https://www.missf.top/post/dd3a7968.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的tags用法我们学习ansible，以后都是要编写各种各样的playbook的。假如我们有一天，写了一个很长很长的playbook，其中包含了非常多的任务，这其实没有什么问题，但是我有时候可能只是需要执行这个playbook的一部分任务而已，而非每一次都执行playbook的全部任务，这个时候我们可以借助tags实现这个需求。 --- - hosts: all remote_user: root tasks: - name: task1 file: path: /tmp/task1 state: touch tags: t1 - name: task2 file: path: /tmp/task2 state: touch tags: t2 上面定义了两个task任务，每个任务有自己的tags，我们可以在执行playbook时借助标签指定只执行那些任务，而忽略其他任务。 ansible-playbook --tags=t2 testtags.yaml # 只执行t2标签的task任务 ansible-playbook --skip-tags=t1 testtags.yaml # 跳过t1标签任务，其他的任务都会执行 tags的三种语法语法一: tags: - t1 - t2 语法二: tags: t1,t2 语法三: tags: ['t1','t2'] 我们可以为一个任务添加多个标签,下面两个task任务都有一个共同的tag1标签，当执行时指定tag1标签，下面两个任务都会执行 --- - hosts: all remote_user: root tasks: - name: task1 file: path: /tmp/task1 state: touch tags: t1,tag1 - name: task2 file: path: /tmp/task2 state: touch tags: ['t2','tag1'] 具有共同标签的任务，可以将共同标签从task中提取出来写在play中，下面的两个task任务分别有自己的t1和t2标签，同时又具有共同的t3标签，tags写在tasks上面时，tasks会继承当前play中的tags。 --- - hosts: all remote_user: root tags: t3 tasks: - name: task1 file: path: /tmp/task1 state: touch tags: t1 - name: task2 file: path: /tmp/task2 state: touch tags: t2 调用标签时，可以一次性指定多个标签，调用多个标签需要用逗号隔开 ansible-playbook --tags=t1,t2 testtags.yaml 我们还可以在调用标签时先概览一下playbook中的标签 ansible-playbook --list-tags testtags.yaml tags的五个内置标签 always: 当把任务的tags的值指定为always时，那么这个任务就总是会被执行，除非你使用’–skip-tags’选项明确指定跳过这个任务 never: 当把任务的tags的值指定为never时，那么这个任务就总是不会被执行，2.5版本中新加入的特殊tag tagged: 调用标签时使用的，只执行有标签的任务，没有任何标签的任务不会被执行 untagged: 只执行没有标签的任务，但是如果某些任务包含always标签，那么这些任务也会被执行 all: 执行所有标签 只执行有标签的任务，没有任何标签的任务不会被执行 ansible-playbook --tags tagged testtag.yml 跳过包含标签的任务，即使对应的任务包含always标签，也会被跳过 ansible-playbook --skip-tags tagged testtag.yml 只执行没有标签的任务，但是如果某些任务包含always标签，那么这些任务也会被执行 ansible-playbook --tags untagged testtag.yml","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的handlers(8)","slug":"ansible的handlers(8)","date":"2020-05-26T07:13:48.000Z","updated":"2020-06-02T07:51:22.020Z","comments":true,"path":"post/b93ea0db.html","link":"","permalink":"https://www.missf.top/post/b93ea0db.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的handlers用法许多的Linux服务在修改配置文件后都是需要重启服务的，以便能够重新读取配置文件，使新的配置能够生效。那怎么用playbook实现这个简单的功能呢？下面我们来编写一个修改nginx端口的playbook，并且在修改完之后重启nginx。 --- - hosts: all remote_user: root tasks: - name: modify config replace: path: /etc/nginx/nginx.conf regexp: \"listen(.*)80;\" # 替换nginx端口为8080 replace: \"listen 8080;\" backup: yes - name: restart nginx # 重启nginx服务 service: name: nginx state: restarted 注意思考: 这个playbook虽然可以帮助我们成功修改nginx端口并重启nginx服务，但是大家请注意如果我再次执行这个playbook的话，nginx端口已经是8080了，由于ansible幂等性的缘故，所以modify config这个task没有发生状态的改变，所以这一步返回了绿色的信息，但是nginx的服务还是被重启了，其实我们并没有真正去改变nginx的配置文件，但是却还是重启了nginx服务，这是因为重启服务这个任务是写死了的。这种多余的重启是不需要的。那么在playbook中就是使用handlers来解决这种问题的，下面我们就继续以nginx服务这个小例子来学习playbook的handlers用法。 --- - hosts: all remote_user: root tasks: - name: modify config replace: path: /etc/nginx/nginx.conf regexp: \"listen(.*)80;\" replace: \"listen 8080;\" backup: yes notify: # 在modify config这个任务调用handlers任务列表的restart nginx任务(认真理解这句话) restart nginx handlers: # 定义一个handlers任务列表 - name: restart nginx service: name: nginx state: restarted 上面示例我们使用handlers用法，如果modify config这个task的状态被真正修改过了，notify就会调用handlers任务列表的restart nginx任务，就会执行重启nginx服务，这样就能达到只有nginx配置文件被真正修改了，才会去重启nginx服务。 handlers是一种任务列表在playbook中handlers和tasks是同级别的，这是因为handlers也是任务列表的一种。只不过handlers中的任务是被用于tasks任务列表的notify调用罢了。 --- - hosts: all remote_user: root tasks: - name: make testfile1 file: path: /testdir/testfile1 state: directory notify: ht2 - name: make testfile2 file: path: /testdir/testfile2 state: directory notify: ht1 handlers: - name: ht1 file: path: /testdir/ht1 state: touch - name: ht2 file: path: /testdir/testfile2 state: touch 上面playbook的执行过程如下: PLAY [all] *********************************************************************************************************************** TASK [Gathering Facts] *********************************************************************************************************** ok: [webserver] ok: [dbserver] TASK [make testfile1] ************************************************************************************************************ changed: [webserver] changed: [dbserver] TASK [make testfile2] ************************************************************************************************************ changed: [webserver] changed: [dbserver] RUNNING HANDLER [ht1] ************************************************************************************************************ changed: [webserver] changed: [dbserver] RUNNING HANDLER [ht2] ************************************************************************************************************ changed: [dbserver] changed: [webserver] PLAY RECAP *********************************************************************************************************************** dbserver : ok=5 changed=4 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 webserver : ok=5 changed=4 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 默认情况下，所有task执行完毕后，才会执行各个handler，而且handler的执行顺序与handler在playbook中的定义顺序是相同的，与handler被notify调用的顺序无关，这一点大家要注意。如果你想要在执行完某些task以后立即执行对应的handler，则需要使用meta模块。 --- - hosts: all remote_user: root tasks: - name: make testfile1 file: path: /testdir/testfile1 state: directory notify: ht2 - meta: flush_handlers # 定义一个meta任务，表示立即执行之前task任务对应的handlers - name: make testfile3 file: path: /testdir/testfile3 state: directory notify: ht1 handlers: - name: ht1 file: path: /testdir/testfile4 state: touch - name: ht2 file: path: /testdir/testfile2 state: touch 大家可以看到下图的执行顺序，是执行了make testfile1这个task之后，立即执行它所对应的ht2这个handlers handlers分组我们可以将handlers任务列表分组，将多个handlers任务组成一个组，然后在task任务列表notify一个handlers组，这时候task任务执行完之后就会一次性执行多个handlers任务 --- - hosts: all remote_user: root tasks: - name: make testfile1 file: path: /testdir/testfile1 state: directory notify: handlers group1 - meta: flush_handlers handlers: - name: ht1 listen: handlers group1 file: path: /testdir/testfile4 state: touch - name: ht2 listen: handlers group1 file: path: /testdir/testfile2 state: touch 将ht1和ht2这两个handlers任务都监听handlers group1这一个组，这时候在task任务列表notify “handlers group1”这个组名时，就执行这个组的所有handlers任务。","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的playbook(7)","slug":"ansible的playbook(7)","date":"2020-05-24T06:24:36.000Z","updated":"2020-06-02T07:51:22.021Z","comments":true,"path":"post/1b138d79.html","link":"","permalink":"https://www.missf.top/post/1b138d79.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 Ansible playbook初识前一章我们学习了ansible的模块，在控制节点上使用了很多ansible的命令对管理节点进行配置和管理，但是在我们真正的工作场景中，如果需要配置一个nginx服务，其实并不是在控制节点执行ansible命令去实现的，你可以想象一下，如果我们需要对管理节点做大量的操作，是不是就是要在控制节点执行非常多的命令呢，而且直接执行命令的方式对管理不同的管理节点时，命令又是需要修改的，这并不是我们想要的。其实ansible是可以写成”脚本”的，注意这里所说的脚本，并不是说将大量的ansible命令放到shell脚本里面去，ansible在部署较为复杂的任务时，有自己的一套执行流程，称为”剧本”，剧本翻译过来就是我们所说的playbook。编写playbook需要遵循yaml语法，那什么又是yaml语法呢，它是为了方便人类读写而设计出来的一种通用的数据串行化格式。 编写第一个playbookplaybook文件都以”yaml”或”yml”作为文件后缀，这里我们创建一个名为first.yaml的playbook文件 # 将下面的ansible命令转化为playbook ansible all -m ping ansible all -m file -a 'path=/etc/nodes state=directory' # playbook的写法: --- - hosts: all remote_user: root tasks: - name: ping nodes ping: - name: mkdir directory file: path: /etc/nodes state: directory 第一行: 使用三个横杠作为开始，在YAML语法中，”—“表示文档开始 第二行: 使用”-“作为开头表示一个块序列的节点，后面使用hosts关键字指定了要操作的主机 第三行: 使用remote_user关键字可以指定在管理节点进行操作时使用哪个用户进行操作 第四行: 使用tasks关键字指明要进行操作的任务列表，之后的行都属于tasks键值对中的值 tasks之后的行都属于任务列表的任务，可以看出任务列表一共有两个任务，每个任务以”-“开头，每个任务都有自己的名字，任务名字使用name关键字进行指定，第一个任务使用ping模块，ping模块在使用时不需要指定任何参数。第二个任务使用file模块，使用file模块时，指定了path参数和state参数的值。 运行playbook[root@localhost ~/playbook]# ansible-playbook first.yaml PLAY [all] ********************************************************************************************************************************************************* TASK [Gathering Facts] ********************************************************************************************************************************************* ok: [10.10.110.123] ok: [10.10.110.122] TASK [ping nodes] ************************************************************************************************************************************************** ok: [10.10.110.123] ok: [10.10.110.122] TASK [mkdir directory] ********************************************************************************************************************************************* ok: [10.10.110.122] ok: [10.10.110.123] PLAY RECAP ********************************************************************************************************************************************************* 10.10.110.122 : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 10.10.110.123 : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 如上所示，playbook执行后返回了一些信息，这些信息是这次剧本运行的概况。PLAY [all]表示这次运行的playbook有一个’play’是针对所有主机运行的，一个playbook可以是由一个或者多个play组成的。这个play包含了三个任务，这三个任务分别是TASK [Gathering Facts]，TASK [ping nodes]，TASK [mkdir directory]。我们只创建了两个任务，为什么却执行了三个任务呢？其实每个paly在执行前都会执行一个默认任务，这个默认任务就是TASK [Gathering Facts]，它会收集当前play对应的目标主机的相关信息，收集完这些基础信息后，才会执行我们指定的任务，这里它是收集我们这个play的所有主机的信息，然后返回主机的IP地址。第二个任务是用ping模块去测试管理节点的状态，给我们返回的是绿色的信息，表示管理节点的状态没有发生改变。第三个任务是创建目录，这里如果管理节点没有/etc/nodes目录，则会返回黄色的信息，表示在管理节点上创建了目录，管理节点的状态发生了改变。这是再次执行playbook，发现创建目录任务的返回信息变成了绿色的，是因为已经创建过目录了，由于幂等性的原因，管理节点的状态没有发生改变。返回信息的最后一个PLAY RECAP中可以对所有主机的执行情况进行回顾。 检查playbook语法ansible-playbook --syntax-check first.yaml 如果执行语法检查命令之后，只返回了playbook的名称，就表示没有语法错误。 模拟执行playbookansible-playbook --check first.yaml 除了对playbook进行语法测试，我们还能够模拟执行playbook，模拟执行并不是真正的执行，只是假装执行一下，playbook中的任务并不会真正在目标主机中运行，所以你可以放心大胆的进行模拟，模拟运行功能可以帮助我们’预估’playbook是否能够正常执行。 注意: 使用上述命令进行模拟时，一些任务可能会报错，这可能是因为报错的任务在执行时需要依赖之前的其他任务的完成结果，但是因为是模拟执行，所以之前的任务并不会真正的执行，既然之前的任务没有真正的执行，自然不会产生对应的结果，所以后面的任务就报错了。也就是说，我们并不能完全以模拟的反馈结果作为playbook是否能够正常运行的判断依据，只能通过模拟大概的预估一下而已。 使用playbook安装nginx目录文件规划tree /root/playbook/ /root/playbook/ ├── index.html.j2 ├── nginx.conf └── nginx.yaml 编写playbook--- - hosts: all remote_user: root vars: # 定义变量，可以在nginx.conf文件中调用 http_port: 80 max_clients: 65535 tasks: - name: ensure nginx is at the latest version yum: name: nginx state: installed - name: write the nginx config file template: # 模板模块，将当前目录下的nginx.conf文件(文件里面定义的变量会自动赋值再拷贝)拷贝到管理节点 src: nginx.conf dest: /etc/nginx/nginx.conf - name: write the site file template: src: index.html.j2 dest: /usr/share/nginx/html/index.html notify: - restart nginx - name: ensure nginx is running service: name: nginx state: started handlers: - name: restart nginx service: name=nginx state=restarted 编写nginx配置文件#user nobody; worker_processes auto; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections {{ max_clients }}; # 调用nginx.yaml中定义的变量 } http { include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server { listen {{ http_port }}; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root /usr/share/nginx/html/; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht { # deny all; #} } } 编写index.html.j2文件Hello Ansible! This is {{ansible_all_ipv4_addresses}} 在ansible控制节点上查看curl 10.10.110.122 Hello Ansible! This is [u'10.10.110.122'] # 这个是可变变量 curl 10.10.110.123 Hello Ansible! This is [u'10.10.110.123']","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible的yaml基本语法(6)","slug":"ansible的yaml基本语法(6)","date":"2020-05-23T08:37:52.000Z","updated":"2020-06-06T07:55:10.856Z","comments":true,"path":"post/b39d16c2.html","link":"","permalink":"https://www.missf.top/post/b39d16c2.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 ansible的yaml基本语法 大小写敏感 使用缩进表示层级关系 缩进时不允许使用Tab键，只允许使用空格 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可 yaml文件以”—“作为文档的开始，”…”作为文档的结束 # 表示注释，从这个字符一直到行尾，都会被解析器忽略 相同缩进级别的行以”-“(破折号和空格)开头的组成一个列表 yaml支持的三种数据结构 数组: 一组按次序排列的值，又称为序列（sequence） / 列表（list） 对象: 键值对的集合，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary） 纯量: 单个的、不可再分的值 数组相同缩进级别的行以“- ”（破折号和空格）开头组成一个列表就是数组 --- fruits: - Apple - Banana - orange - melon # 行内表示法 fruits: ['Apple', 'Banana', 'orange', 'melon'] 对象对象的一组键值对，使用冒号结构表示(冒号后面要有个空格) sb: name: Alex job: python skill: brag # 行内表示法 sb: {name: Alex, job: python, skill: brag} 纯量数值number: 12 float: 15.20 布尔值表示true的值 true, True, TRUE, yes, Yes, YES, on, On, ON, y, Y 表示false的值 false, False, FALSE, no, No, NO, off, Off, OFF, n, N 强制类型转换yaml 允许使用两个感叹号，强制转换数据类型 a: !!str 123 d: !!str true # 这个true的数据类型不再是布尔值，而是str类型 字符串字符串默认不使用引号表示 str: 这是字符串 s1: '内容\\n字符串' # 如果字符之中包含空格和特殊字符，需要放在引号之中，单引号和双引号都可以使用，双引号不会对特殊字符转义 空值null: 用~表示 parent: ~ 引用&amp;用来建立锚点(defaults)，&lt;&lt;表示合并到当前数据，*****用来引用锚点 defaults: &amp;defaults adapter: postgres host: localhost development: database: myapp_development &lt;&lt;: *defaults test: database: myapp_test &lt;&lt;: *defaults # 上面的写法等同于下面的代码: defaults: adapter: postgres host: localhost development: database: myapp_development adapter: postgres host: localhost test: database: myapp_test adapter: postgres host: localhost 参考palybooks更多的yaml语法请参考: http://docs.ansible.com/YAMLSyntax.html","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"使用coding持续集成Java项目","slug":"使用coding持续集成Java项目","date":"2020-05-18T07:42:59.000Z","updated":"2020-06-06T08:54:05.106Z","comments":true,"path":"post/1b979c3e.html","link":"","permalink":"https://www.missf.top/post/1b979c3e.html","excerpt":"","text":"coding介绍在说到持续集成这方面，相信所有做运维的小伙伴都知道Jenkins，就是那个拿着托盘的老头子。但是说到coding，可能很多人都没听说过。什么是coding呢？coding涵盖了软件开发从构想到交付的一切所需，使研发团队在云端高效协同，实践敏捷开发与 DevOps，提升软件交付质量与速度。这是来自官网的介绍，下面就让我们一起学习coding吧！ 第一次接触coding在去年的七月份，我有幸参加了腾讯的724运维分享日，就在那时候接触到了coding。 这是腾讯滨海大厦四楼，现在看着还历历在目，但是当年的sz number one却散落在天涯！ 一群运维小伙伴看着这个墙哈哈大笑… 和一群志同道合的人在一起时，即使不认识也会有莫名的亲切感啊。 第一次看到coding的介绍时都不知道说的啥，现在回头看时才觉得自己成长了。 (就如Alex吹牛逼说的: 如果你不觉得一年前的自己是傻逼，那就说明你这一年都没有成长) 下图是coding创始人张海龙先生 额…扯远了，下面就让我们来学习coding吧！ 注册codingcoding所有的东西都是在这个云平台上实现的，所谓的使研发团队在云端高效协同说的就是这个吧！ 创建项目选择DevOps项目模板 填写项目基本信息 下载若依的源码若依源码gitee地址 配置若依数据库 将若依自带的两个SQL文件导入到ry数据库 初始化本地仓库git init git add . git commit -m \"第一次提交\" 配置coding SSH秘钥在Windows电脑生成ssh密钥对，然后将id_rsa.pub公钥添加到coding SSH公钥 推送本地仓库到coding 注意: 如果已经在coding配置了ssh秘钥，git添加远程仓库的时候不要使用https的地址，不然还是会提示需要输入coding的账号密码 git remote add origin git@e.coding.net:missf/RuoYi.git # 配置了SSH秘钥的，一定要填写项目的git地址 git push -u origin master # 这样推送时就不需要输入账号密码啦 持续集成创建持续集成任务 新建构建计划 录入项目凭据在服务器生成SSH秘钥对，将私钥录入到coding的凭据管理，coding就能持续集成部署代码到服务器 编写静态配置的 Jenkinsfile 配置环境变量 这里附上完整Jenkinsfile pipeline { agent any stages { stage('检出') { steps { checkout([$class: 'GitSCM', branches: [[name: env.GIT_BUILD_REF]], userRemoteConfigs: [[url: env.GIT_REPO_URL, credentialsId: env.CREDENTIALS_ID]]]) } } stage('构建') { steps { echo '构建中...' sh 'java -version' sh 'mvn package' echo '构建完成.' } } stage('压缩jar包') { steps { echo '压缩中...' sh 'cd /root/workspace/ruoyi-admin/target/ && tar -zcf /tmp/ruoyi-admin.tar.gz ruoyi-admin.jar' echo '压缩完成.' } } stage('部署') { steps { echo '部署中...' script { def remote = [:] remote.name = 'java-server' remote.allowAnyHosts = true remote.host = \"${env.REMOTE_HOST}\" remote.port = 50312 remote.user = \"${env.REMOTE_USER_NAME}\" // 把「CODING 凭据管理」中的「凭据 ID」填入 credentialsId，而 id_rsa 无需修改 withCredentials([sshUserPrivateKey(credentialsId: \"${env.REMOTE_CRED}\", keyFileVariable: 'id_rsa')]) { remote.identityFile = id_rsa // SSH 上传文件到服务器 sshPut remote: remote, from: '/tmp/ruoyi-admin.tar.gz', into: '/tmp/' // 解压缩 sshCommand remote: remote, sudo: false, command: \"tar -zxf /tmp/ruoyi-admin.tar.gz -C /home/ruoyi/\" // 执行Java应用启停脚本 sshCommand remote: remote, sudo: true, command: \"sh /home/ruoyi/start.sh stop && sh /home/ruoyi/start.sh start\" } } echo '部署完成' } } } } 触发规则本地仓库推送代码到master分支时就会自动触发持续集成任务 开启缓存目录开启缓存目录后可以大大提升构建的速度 立即构建 查看构建过程构建失败可以查看完整日志分析失败原因 服务器的启停脚本[root@java-server ~]# cd /home/ruoyi/ [root@java-server ruoyi]# ll total 65080 drwxr-xr-x 2 root root 4096 May 18 10:18 logs -rw-r--r-- 1 root root 67 May 18 17:04 nohup.out -rw-r--r-- 1 root root 66627886 May 18 17:04 ruoyi-admin.jar -rwxr-xr-x 1 root root 760 May 18 14:29 start.sh [root@java-server ruoyi]# cat start.sh #!/bin/bash WORKSPACE=/home/ruoyi if [ -d \"${WORKSPACE}\" ]; then cd ${WORKSPACE} else echo \"${WORKSPACE} directory does not exist\" exit 1 fi APP_NAME='ruoyi-admin.jar' USE_JAVA_HOME='/usr/local/jdk1.8.0_211' JVM_OPTS='-Xms512m -Xmx512m' CONFIG_OPTS='' if [ $1 == 'start' ]; then echo 'start service '$APP_NAME nohup java -jar ${JVM_OPTS} ${APP_NAME} > ${WORKSPACE}/nohup.out 2>&1 & elif [ $1 == 'stop' ]; then echo 'stop service '$APP_NAME PID=$(ps -ef | grep -v grep | grep ${APP_NAME} | awk '{print $2}') if [ -z ${PID} ]; then echo ${APP_NAME} ' had stopped' else kill ${PID} sleep 2 if [ $? -ne 0 ]; then echo ${APP_NAME} ' stop failed' exit 1 fi fi fi 查看持续集成的效果","categories":[{"name":"coding","slug":"coding","permalink":"https://www.missf.top/categories/coding/"}],"tags":[{"name":"coding","slug":"coding","permalink":"https://www.missf.top/tags/coding/"},{"name":"持续集成","slug":"持续集成","permalink":"https://www.missf.top/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"}]},{"title":"ansible模块学习(5)","slug":"ansible模块学习(5)","date":"2020-05-12T03:12:59.000Z","updated":"2020-06-22T06:36:15.116Z","comments":true,"path":"post/cd036e92.html","link":"","permalink":"https://www.missf.top/post/cd036e92.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 setup模块setup模块主要用于获取主机信息，每个管理节点在接收控制节点命令之前，会将主机的信息告知控制节点 filter: 用于进行条件过滤，如果设置，仅返回匹配过滤条件的信息 关键字 说明 返回值例子 ansible_nodename 节点名 “6-dns-1.hunk.tech” ansible_fqdn FQDN名 “6-dns-1.hunk.tech” ansible_hostname 主机短名称 “6-dns-1” ansible_domain 主机域名后缀 “hunk.teh” ansible_memtotal_mb 总物理内存 “ansible_memtotal_mb”: 222 ansible_swaptotal_mb SWAP总大小 “1023” ansible_processor CPU信息 Intel(R) Core(TM) i5-5200U CPU @ 2.20GHz ansible_processor_cores CPU核心数量 4 ansible_processor_vcpus CPU逻辑核心数量 2 ansible_all_ipv4_addresses 有所IPV4地址 192.168.0.200 ansible_all_ipv6_addresses 所有IPV6地址 ansible_default_ipv4 默认网关的网卡配置信息 ansible_eth2 具体某张网卡信息 不同系统名称需要变化 ansible_dns DNS设置信 ansible_architecture 系统架构 x86_64 ansible_machine 主机类型 x86_64 ansible_kernel 内核版本 “2.6.32-696.el6.x86_64” ansible_distribution 发行版本 “CentOS” ansible_distribution_major_version 操作系统主版本号 “6” ansible_distribution_release 发行版名称 “Final” ansible_distribution_version 完整版本号 “7.4.1708” ansible_pkg_mgr 软件包管理方式 “yum” ansible_service_mgr 进行服务方式 “systemd” ansible_os_family 家族系列 “RedHat” ansible_cmdline 内核启动参数 ansible_selinux SElinux状态 “disabled” ansible_env 当前环境变量参数 ansible_date_time 时间相关 ansible_python_version python版本 “2.6.6” ansible_lvm LVM卷相关信息 ansible_mounts 所有挂载点 ansible_device_links 所有挂载的设备的UUID和卷标名 ansible_devices 所有/dev/下的正在使用的设备的信息 ansible_user_dir 执行用户的家目录 “/root” ansible_user_gecos 执行用户的描述信息 “The root “ ansible_user_gid 执行用户的的GID 0 ansible_user_id 执行用户的的用户名 “root” ansible_user_shell 执行用户的shell类型 “/bin/bash” ansible_user_uid 执行用户的UID 0 查看管理节点的python版本信息 ansible all -m setup -a 'filter=ansible_python_version' 查看管理节点的发行版本 ansible all -m setup -a 'filter=ansible_distribution' command模块ansible的默认模块，可以不用-m指定，-a是command的参数 free_form: 其实没有名为“free form”的实际参数，command模块接受自由格式的命令运行 chdir: 在执行对应的命令之前，会先进入到chdir参数指定的目录中 creates: 如果指定的文件存在时，就不执行对应命令 removes: 当指定的文件不存在时，就不执行对应命令 查看管理节点/etc/目录下的hosts文件内容 ansible all -a \"chdir=/etc cat hosts\" 查看管理节点/etc/目录下的hosts文件内容，如果存在/etc/passwd文件则不执行 ansible all -a \"chdir=/etc creates=/etc/passwd cat hosts\" command模块不支持调用$HOME这样的变量，还有像&lt;, &gt;, |, ;, &amp;这些正则和通配符都将不可用，但是command 模块更安全，因为他不受用户环境的影响。 也很大的避免了潜在的shell注入风险。 shell模块shell 模块可以帮助我们在远程主机上执行命令。与command模块不同的是，shell模块在远程主机中执行命令时，会经过远程主机上的 /bin/sh 程序处理，能够使用&lt;, &gt;, |, ;, &amp;这些符号和环境变量。 free_form: 其实没有名为“free form”的实际参数，command模块接受自由格式的命令运行 chdir: 在执行对应的命令之前，会先进入到chdir参数指定的目录中 creates: 如果指定的文件存在时，就不执行对应命令 removes: 当指定的文件不存在时，就不执行对应命令 executable: 默认shell模块会调用远程主机中的/bin/sh去执行对应的命令，也可以指定shell，需要使用绝对路径 shell模块在管理节点上执行命令时，支持管道和重定向等符号 ansible all -m shell -a 'chdir=/etc executable=/bin/bash cat hosts >/tmp/hosts.bak' script模块script模块可以帮助我们在管理节点上执行控制节点上的脚本，也就是说在管理节点上执行脚本不需要把脚本拷贝过去 free_form: 指定需要执行的脚本，其实没有名为“free form”的实际参数 chdir: 在执行对应的脚本之前，会先进入到chdir参数指定的目录中 creates: 如果指定的文件存在时，就不执行脚本 removes: 当指定的文件不存在时，就不执行脚本 在管理节点上执行控制节点的/root/test.sh脚本，执行之前切换到/opt目录 ansible all -m script -a 'chdir=/opt /root/test.sh' copy模块copy模块的作用就是将Control node的文件拷贝到Managed nodes scr: 用于指定控制节点上被copy的文件或目录 dest: 用于指定文件将被拷贝到管理节点的路径，dest为必须参数 content: 当不使用src指定拷贝的文件时，可以使用content直接指定文件内容，src与content两个参数必有其一 force: 当管理节点的目标路径存在同名文件，并且两个文件内容不同，是否强制覆盖，可选值有yes和no，默认值为yes backup: 当管理节点的目标路径存在同名文件，并且两个文件内容不同，是否对管理节点的文件进行备份，可选值有yes和no owner: 指定文件拷贝到管理节点后的属主，但是管理节点上必须有对应的用户 group: 指定文件拷贝到管理节点后的属组，但是管理节点上必须有对应的组 mode: 指定文件拷贝到管理节点后的权限，可以使用mode=0644表示，也使用mode=u+x表示 将控制节点的/etc/hosts文件复制到管理节点的/root目录下，如果管理节点的/root目录已经存在文件，则会默认覆盖 ansible all -m copy -a \"src=/etc/hosts dest=/root/\" # 如无意外这里你看到的字体颜色是黄色的，这是成功执行并且状态发生了改变的 复制文件，指定文件的属主和属组，需要注意的是管理节点必须存在对应的用户和组 ansible all -m copy -a \"src=/etc/hosts dest=/tmp/ owner=mwj group=mwj\" 复制文件，如果管理节点的目标路径已存在同名文件且内容不相同，则对管理节点的文件先进行备份，再把控制节点的文件复制到管理节点 ansible all -m copy -a \"src=/etc/hosts dest=/tmp/ backup=yes\" # 在返回的结果列表能看到: \"backup_file\": \"/tmp/hosts.15575.2020-05-12@22:28:50~\" # ansibel是用哈希值去校验两个文件的内容是否一致的 file模块file模块可以完成对文件增删查改的基本操作 path: 用于指定要操作的文件或目录，必须参数 state: ansible无法从path=/test/a/b得知我们想要创建目录还是文件，所以需要使用state参数配和path来声明操作的类型 state=directory 创建的是目录 state=touch 创建的是文件 state=link 创建的是软连接文件 state=hard 创建的是硬链接文件 state=absent 删除文件或者目录，absent意为”缺席” src: 当state设置为link或者hard时，我们必须指明软硬链链接到哪个文件，通过src参数即可指定链接源 force: 当state=link的时候，可配合force=yes参数强制创建链接文件，但是强制创建会有两种情况 情况一: 当要创建的链接文件所指向的源文件并不存在时，使用此参数可以先强制创建出链接文件 情况二: 当要创建链接文件的路径中已经存在与链接文件同名的文件时，将force设置为yes，会将同名文件覆盖为链接文件 owner: 用于指定被操作文件或目录的属主 group: 用于指定被操作文件或目录的属组 mdoe: 用于指定被操作文件或目录的权限，使用mode=755，设置特殊权限则可以使用mode=4700 recurse: 当要操作的对象为目录，将recurse设置为yes，可以递归的修改目录中文件的属性 在管理节点上创建一个名为testdir的目录，如果目录已存在则不进行任何操作 ansible all -m file -a \"path=/testdir/ state=directory\" 在管理节点上创建一个名为testfile的文件，如果文件已存在则会更新文件的时间戳 ansible all -m file -a \"path=/testdir/testfile state=touch\" 在管理节点创建一个名为/testdir/linkfile的链接文件，链接的源文件/testdir/testfile已存在 ansible all -m file -a \"path=/testdir/linkfile state=link src=/testdir/testfile\" 在管理节点上删除指定的文件或目录 ansible all -m file -a \"path=/testdir/testfile state=absent\" fetch模块从管理节点拉取文件到控制节点 dest: 用来存放从管理节点拉取到的文件 src: 管理节点被拉取的文件，必须是文件不能是目录 flat: 默认为no，会将拉取到控制节点的文件以hostname/file的命名存放在dest目录，如果为yes，则直接按文件名存放 Validate_checksum: 拉取文件之后进行MD5检查 拉取管理节点的/etc/hosts文件到控制节点的/data/目录 ansible all -m fetch -a \"src=/etc/hosts dest=/data/\" # 这里flat默认为no，所以拉取之后存放的方式是这样的 tree /data/ /data/ ├── 10.10.110.122 │ └── etc │ └── hosts └── 10.10.110.123 └── etc └── hosts ansible all -m fetch -a \"src=/etc/hosts dest=/data/ flat=yes\" # flat=yes是直接按文件名存放 tree /data/ /data/ └── hosts # 只有一个hosts文件是因为第一个hosts被覆盖掉了 blockinfile模块blockinfile模块可以帮助我们在指定的文件中插入”一段文本”，这段文本是被标记过的，我们在这段文本上做了记号，以便在以后的操作中可以通过”标记”找到这段文本，然后修改或者删除它 path: 指定要操作的文件 block: 此参数用于指定我们想要插入的那”一段文本”，此参数有一个别名叫”content”，使用content或block的作用是相同的 marker: 自定义开始和结束的标记，marker=#{mark}test:开始为# BEGIN test，结束为# END test insertafter: 在插入一段文本时，默认会在文件的末尾插入文本，如果你想要将文本插入在某一行的后面，可以使用此参数指定对应的行 insertbefore: 在插入一段文本时，默认会在文件的末尾插入文本，如果你想要将文本插入在某一行的前面，可以使用此参数指定对应的行 backup: 是否在修改文件之前对文件进行备份 create: 当要操作的文件并不存在时，是否创建对应的文件 在管理节点的/testdir/rc.local文件末尾插入一行systemctl start mariadb ansible all -m blockinfile -a 'path=/testdir/rc.local block=\"systemctl start mariadb\"' 自定义插入的开始和结束的标记 ansible all -m blockinfile -a 'path=/testdir/rc.local block=\"systemctl restart mysqld\\nnginx -s reload\" marker=\"#{mark} serivce to start\"' # 查看被插入的文本 #BEGIN serivce to start systemctl restart mysqld nginx -s reload #END serivce to start 使用create参数，如果指定的文件不存在则创建它 ansible all -m blockinfile -a 'path=/testdir/date block=\"今天是5月12号\\n汶川地震12周年\" marker=\"#{mark} 日期记录\" create=yes' 使用backup参数，可以在操作修改文件之前对文件进行备份 ansible all -m blockinfile -a 'path=/testdir/date block=\"今天是5月12号\\n汶川地震12周年\" marker=\"#{mark} 日期记录\" backup=yes' lineinfile模块我们可以借助lineinfile模块，确保”某一行文本”存在于指定的文件中，还可以根据正则表达式替换”某一行文本” path: 指定要操作的文件 line: 使用此参数指定文本内容 regexp: 使用正则表达式匹配对应的行 state: 当想要删除对应的文本时，需要将state参数的值设置为absent backrefs: 开启后向引用，line参数中就能对regexp参数中的分组进行后向引用了 insertafter: 借助insertafter参数可以将文本插入到“指定的行”之后 insertbefore: 借助insertbefore参数可以将文本插入到“指定的行”之前 backup: 是否在修改文件之前对文件进行备份 create: 当要操作的文件并不存在时，是否创建对应的文件 确保”test lineinfile”这行文本存在于/testdir/date文件中，如果存在则不做任何操作，如果不存在则在末尾插入 ansible all -m lineinfile -a 'path=/testdir/date line=\"test lineinfile\"' 根据正则表达式替换”某一行”，如果多行能够匹配正则，只有最后匹配的行才会被替换，如果没有匹配到则会在末尾插入line的内容 ansible all -m lineinfile -a 'path=/testdir/date regexp=\"^test\" line=\"被替换后的内容\"' 根据正则匹配删除对应的行，如果文件多行都与正则匹配，则删除多行 ansible all -m lineinfile -a 'path=/testdir/date regexp=\"^#.*-$\" state=absent' # 删除#开头-结尾中间有任意个字符的行 在管理节点的/testdir/date文件的”#Hello saltstack,Hiiii”这一行之后插入123 ansible all -m lineinfile -a 'path=/testdir/date line=\"123\" insertafter=\"#Hello saltstack,Hiiii\"' find模块find模块可以帮助我们在管理节点中查找符合条件的文件，就像find命令一样 paths: 必须参数，指定在哪个目录中查找文件，可以指定多个路径，路径间用逗号隔开 recurse: 默认只会在指定的目录中查找文件，当recurse参数设置为yes时，表示会递归的查找文件 hidden: 默认不会去查找隐藏文件，只有当hidden参数的值设置为yes时才会查找隐藏文件 file_type: 默认只会根据条件查找”文件”，可以通过file_type指定文件类型，any | directory | file | link patterns: 使用此参数指定需要查找的文件名称，支持使用shell(比如通配符)或者正则表达式去匹配文件名称 use_regex: 当use_regex设置为yes时，表示使用python正则解析patterns参数中的表达式 contains: 使用此参数可以根据文章内容查找文件，此参数的值为一个正则表达式 age: 用此参数可以根据时间范围查找文件，默认以文件的mtime为标准与指定的时间进行对比 age_stamp: 文件的时间属性中有三个时间种类:atime、ctime、mtime，当我们根据时间范围查找文件时，可以指定以哪个时间种类为准 size: 使用此参数可以根据文件大小查找文件 get_checksum: 当有符合查找条件的文件被找到时，会同时返回对应文件的sha1校验码 在管理节点的/etc目录中查找包含www字符串的文件，不进行递归并忽略隐藏文件 ansible all -m find -a 'paths=/etc contains=\".*www.*\"' 在管理节点的/etc目录查找以.sh结尾的文件，包括隐藏文件并进行递归查找 ansible all -m find -a 'paths=/etc patterns=\"*.sh\" hidden=yes recurse=yes' 在管理节点的/etc目录查找链接文件，包括隐藏文件并进行递归查找 ansible all -m find -a 'paths=/etc file_type=link hidden=yes recurse=yes' 在管理节点的/etc目录查找以.sh结尾的文件，只不过patterns对应的表达式为正则表达式，包括所有文件类型 ansible all -m find -a 'paths=/etc patterns=\"\\*.sh\" file_type=any use_regex=yes' 在管理节点的/etc目录递归查找mtime在4天以内的文件 ansible all -m find -a 'paths=/etc age=-4d recurse=yes' 在管理节点的/etc目录递归查找大于2G的文件 ansible all -m find -a 'paths=/etc size=2g recurse=yes' 在管理节点的/etc目录递归查找.conf结尾的文件，并且返回符合条件的文件的sha1校验码 ansible all -m find -a 'paths=/etc patterns=\"*.conf\" recurse=yes get_checksum=yes' replace模块replace模块可以根据我们指定的正则表达式替换文件中的字符串，文件中所有被正则匹配到的字符串都会被替换 path: 必须参数，指定要操作的文件，别名:dest | destfile | name regexp: 必须参数，指定一个python正则表达式，文件中与正则匹配的字符串将会被替换 replace: 指定最终要替换成的字符串 backup: 是否在修改文件之前对文件进行备份，最好设置为yes 将管理主机的/testdir/date文件中所有的ansible替换为saltstack，操作前进行文件备份 ansible all -m replace -a 'path=/testdir/date regexp=\"ansible\" replace=saltstack backup=yes' cron模块cron模块可以帮助我们配置管理节点的计划任务，功能相当于crontab命令 minute: 用于设置分钟值，格式为minute=5，如不指定此参数，则分钟值默认为 * hour: 用于设置小时值，格式为hour=5，如不指定此参数，则小时值默认为 * day: 用于设置日值，如不指定此参数，则日值默认为 * month: 用于设置月值，如不指定此参数，则月值默认为 * weekday: 用于设置周值，如不指定此参数，则月值默认为 * special_time: 时间设定格式为@reboot或者@hourly，这种@开头的时间设定格式则需要使用special_time参数进行设置 注意: 如果以上参数都不设置，则默认使用 * * * * * ，表示每分钟都执行一次。我们应该谨慎设置时间参数 user: 设置当前计划任务属于哪个用户，不指定则默认为管理员用户 job: 执行计划任务中需要实际执行的命令或脚本 name: 设置计划任务的名称，方便我们以后根据名称修改或者删除计划任务 state: 可以根据已有名称的计划任务进行修改和删除，当删除时需要将state的值设置为absent disabled: 可以将已有名称的计划任务注释，但使用此参数除了指定任务名称还需要指定job以及时间的设定，否则注释任务时，任务的时间会被修改 backup: 当此参数设置为yes，那么修改和删除计划任务时，会在管理节点的tmp目录下创建备份文件 在管理节点创建名为test cron计划任务，每天的12点5分，任务内容为将test重定向到/tmp/test ansible all -m cron -a 'name=\"test cron\" minute=5 hour=12 job=\"echo test > /tmp/test\"' # 管理节点的计划任务构建如下: #Ansible: test cron 5 12 * * * echo test > /tmp/test 在管理节点创建名为day cron计划任务，每三天执行一次。与执行当天的14点5分开始执行，任务内容为输出test ansible all -m cron -a 'name=\"day cron\" minute=5 hour=14 day=*/3 job=\"echo test\"' # 管理节点的计划任务构建如下: #Ansible: day cron 5 14 */3 * * echo test 在管理节点创建名为day cron计划任务，任务在重启时执行，任务内容为输出test ansible all -m cron -a 'name=\"day cron\" special_time=reboot job=\"echo test\"' # 由于已存在day cron任务，ansible就会认为我们是需要修改这个任务，计划任务被修改为: #Ansible: day cron @reboot echo test 在管理节点注释掉我们之前创建的test cron任务，注释时进行备份 ansible all -m cron -a 'name=\"test cron\" minute=5 hour=12 job=\"echo test > /tmp/test\" disabled=yes backup=yes' # 符合注释条件的计划任务就会被注释掉: #Ansible: test cron #5 12 * * * echo test > /tmp/test 如果你注释计划任务时，设置了错误的时间和job，那么注释对应任务时(以name去对应)，时间和job的设定也会发生改变 ansible all -m cron -a 'name=\"test cron\" hour=23 job=\"echo test > /tmp/test\" disabled=yes backup=yes' #Ansible: test cron #* 23 * * * echo test > /tmp/test # 注释的同时，时间设定也会改变 service模块service模块可以对管理节点上的服务进行管理，例如启动或停止管理节点的nginx服务。但前提是这个服务必须被BSD init | OpenRC | SysV | Solaris SMF | systemd | upstart中的任意一种所管理，意思就是这个服务在centos6管理节点能以service nginx start启动，在centos7管理节点能以systemctl start nginx启动。如果管理节点上的服务无法通过这样的方式启动，那么service模块也无法对它进行管理。 name: 用于指定操作的服务名称，例如name=nginx state: 用户指定服务的状态，可用值有started | stopped | restarted | reloaded enabled: 用于指定是否将服务设置为开机启动项，设置为yes则表示开机启动，设置为no表示不会开机启动 在管理节点上启动nginx服务 ansible all -m service -a 'name=nginx state=started' 在管理节点上启动mysql服务并设置为开机启动 ansible all -m service -a 'name=mysql state=started enabled=yes' user模块user模块可用帮助我们在管理节点上创建用户、修改用户、删除用户、为用户创建密钥对等操作 name: 必须参数，用于指定要操作的用户名称 group: 用于指定用户所在的基本组 shell: 用于指定用户的默认shell uid: 用于指定用户的uid号 expires: 用于指定用户的过期时间 comment: 用于指定用户的注释信息 state: 用于指定用户是否存在于远程主机中，默认值为present，表示用户需要存在，当设置为absent时表示删除用户 remove: 默认值为no，表示删除用户时不会删除家目录，设置为yes则表示删除用户时删除用户家目录 password: 用于指定用户的密码，但是这个密码不能是明文的密码 generate_ssh_key: 默认值为no，如果设置为yes则表示为用户在家目录的.ssh下创建密钥对，如果对应的路径已有同名密钥对则不进行任何操作 *ssh_key_file: *默认值为yes，使用此参数自定义生成ssh私钥的路径和名称 ssh_key_passph rase: 当generate_ssh_key参数的值为yes时，在创建证书时使用此参数设置私钥的密码 ssh_key_type: 当generate_ssh_key参数的值为yes时，在创建证书时使用此参数设置密钥对的类型 在管理节点上创建mis用户，并把用户添加到root组，如果用户已存在则不做任何操作 ansible all -m user -a 'name=mis group=root' 在管理节点上删除mis用户，同时把用户家目录也删除 ansible all -m user -a 'name=mis state=absent remove=yes' 在管理节点上创建mis用户，指定用户的注释信息，设置用户过期时间是2020-06-15 ansible all -m user -a 'name=mis comment=\"missf.top\" expires=1592150400' # 先使用\"date -d 2020-06-15 +%s\"命令得到Unix时间戳 在管理节点上为mis用户设置密码，加密字符串可以使用python得到 ansible all -m user -a 'name=mis password=\"$6$d62UFoKtSRA9Yaq4$qtvyr5atLdoXgvXOhktU.baVqbtlcaWc9dizmM41Bc9XOaTZW/Pqaxb8pofS5Wo4n5Nu/CEk8GEsKnC2zTfEl1\"' 可以使用 import crypt; crypt.crypt(\"123456\") 得到123456加密之后的字符串 在管理节店上为mis用户生成密钥对，同时指定私钥密码为123456，密钥对的类型为dsa，如不指定密钥对类型默认为rsa ansible all -m user -a 'name=mis generate_ssh_key=yes ssh_key_passphrase=\"123456\" ssh_key_type=dsa' group模块group模块可以帮助我们在管理节点上管理用户组 name: 用于指定操作的服务名称，例如name=nginx state: 用户指定服务的状态，可用值有started | stopped | restarted | reloaded enabled: 用于指定是否将服务设置为开机启动项，设置为yes则表示开机启动，设置为no表示不会开机启动 确保管理节点上存在mkd组，如果没有则创建，如果已存在则不做任何操作 ansible all -m group -a 'name=mkd' 在管理节点上删除mkd组，前提是不能有用户把被删除的组当成主组，不然不能成功删除 ansible all -m group -a 'name=mkd state=absent' yum_repository模块yum_repository模块可以帮助我们在管理节点上管理yum仓库 name: 必须参数，指定要操作的唯一仓库ID，repo配置文件中括号的仓库ID baseurl: 用于设置yum仓库的baseurl description: 用于设置仓库的注释信息，repo配置文件中name字段对应的内容 file: 用户设置仓库的配置文件名称，就是repo配置文件的前缀，如不指定则默认以仓库ID命名 enabled: 用于设置是否激活对应的yum源 gpgcheck: 用于设置是否开启rpm包验证功能，默认值为no表示不开启包验证，设置为yes表示开启 gpgcakey: 当开启包验证功能时，使用此参数指定验证包所需的公钥 state: 默认值为present，设置为absent表示删除对应的yum源 在管理节点上创建前缀为aliepel的repo文件，设置注释信息和不验证包功能 ansible all -m yum_repository -a 'name=aliepel description=\"alibaba_epel\" baseurl=https://mirrors.aliyun.com/epel/$releasever\\Server/$basearch/ gpgcheck=no' 在管理节点创建指定名称为ali的repo文件，但是不启用它 ansible all -m yum_repository -a 'name=aliepel description=\"alibaba_epel\" file=ali baseurl=https://mirrors.aliyun.com/epel/$releasever\\Server/$basearch/ gpgcheck=no enabled=no' yum模块yum模块可以帮助我们在管理节点上管理软件包 name: 必须参数，用于指定需要管理的软件包名字 state: 用户指定软件包的状态，默认是present，表示确认已安装软件包，installed与present等效，absent和removed等效，表示删除对应的软件包 disable_gpg_check: 用于禁用对rpm包的公钥gpg验证，默认值为no表示不禁用验证，设置为yes表示禁用验证，如果yum源没有开启验证需要将此参数设置为yes enablerepo: 用于安装软件包时临时启用yum源，想要从A源安装软件，但是A源没有启用时，这个参数设置为yes表示临时启用 disablerepo: 用于安装软件包时临时禁用yum源，当多个源中同时存在软件包时，可以临时禁用某个源 确保管理节点上安装了nginx，禁用rpm包验证 ansible all -m yum -a 'name=nginx state=installed disable_gpg_check=yes' 确保管理节点上安装了Telnet，并禁用rpm包验证和临时禁用local源 ansible all -m yum -a 'name=telnet disable_gpg_check=yes disablerepo=local' template模块 src: 控制节点上的模板文件 dest: 管理节点上将被控制节点上的模板文件所替换的文件 owner: 指定控制节点拷贝到管理节点的文件属主 group: 指定控制节点拷贝到管理节点的文件属组 mode: 指定控制节点拷贝到管理节点的文件权限 force: 如果管理节点已存在同名文件并且内容不同时，是否强制覆盖，默认值为yes表示覆盖 backup: 如果管理节点已存在同名文件并且内容不同时，是否对管理节点源文件进行备份 将控制节点配置好的模板文件分发到管理节点的/etc/redis.conf，设置不强制覆盖 ansible all -m template -a 'src=/root/redis.conf dest=/etc/redis.conf force=no'","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible主机清单(4)","slug":"ansible主机清单(4)","date":"2020-05-10T02:12:59.000Z","updated":"2020-06-02T07:51:22.024Z","comments":true,"path":"post/334c7279.html","link":"","permalink":"https://www.missf.top/post/334c7279.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 认识主机清单Ansible可同时操作属于一个组的多台主机， 组和主机之间的关系通过 inventory 文件配置. 默认的文件路径为 /etc/ansible/hosts，执行命令的时候使用 -i 参数即可指定主机清单。 主机清单示例主机清单文件主要有 ini 和 yaml 格式两种语法格式 mail.example.com # 定义主机fqdn地址, 需要已经与控制节点ssh互信 localhost ansible_connection=local # ansible_connection可以定义连接类型, local是在本地执行,默认是smart host4 ansible_host=10.10.110.123 ansible_port=50312 ansible_user=root ansible_password=12345 # 指定别名，定义主机ssh连接信息 www[1:50].example.com # 定义 1-50范围内的主机 www-[a:d].example.com # 定义 a-d 范围内的主机 [dbservers] three.example.com ansible_python_interpreter=/usr/local/bin/python3 # 定义python执行ansible，这个是指定被控节点的python 192.168.77.123 ansible_ruby_interpreter=/usr/bin/ruby.1.9.3 # 定义ruby执行文件 webservers:vars] # 定义webservers组的变量 ntp_server=ntp.example.com proxy=proxy.example.com [server:children] # 定义server组的子成员，执行server组时，webservers和dbservers组内的管理节点也会执行 webservers dbservers ini和yaml格式对比# 先写出ini风格 [dbserver] db1 ansible_host=10.10.110.122 ansible_port=22 ansible_user=root ansible_password=0 [webserver] web1 ansible_host=10.10.110.123 ansible_port=22 ansible_user=root ansible_password=0 [server:children] dbserver webserver # 定义子组成员时，需要children关键字 # 和上面一样的配置，这是yaml风格的写法 all: children: server: children: dbserver: hosts: 10.10.110.122 webserver: hosts: 10.10.110.123 yaml格式配置的还是挺复杂的，可读性也差，建议使用ini方式来设置主机清单。 默认组在主机清单中，ansible会自动的生成两个组。 all 所有的主机 ungrouped 包含没有组的主机 尽管这两个组是永远存在的，但也有可能是隐藏的，不会出现group_names之类的组列表中。 主机变量和组变量如果你不想在主机清单中定义主机的变量或者组的变量，ansible还支持在特定的目录中定义变量，变量文件必须以yaml语法定义。 默认在/etc/ansible/host_vars/ 目录中定义主机变量，文件名称以主机名称命名，结束可以用”.yml”,”.yaml”,”.json”三种格式。 cat /etc/ansible/host_vars/db1 ntp_server: acme.example.org database_server: storage.example.org 默认在 /etc/ansible/group_vars/ 目录中定义组变量，文件名称以组名称命名，结束可以用”.yml”,”.yaml”,”.json”三种格式。 cat /etc/ansible/group_vars/dbserver ntp_server: acme.example.org database_server: storage.example.org 变量优先级问题，如果在各个环节都设置了变量，到底哪个变量生效呢？优先顺序，all最低，host最高: all group parent group child group host 使用多个主机清单在命令参数中，使用多个 -i 就可以指定多个主机清单 ansible all -i staging -i production -m ping ansible all -i /tmp/staging -i /tmp/production -m ping 使用 ssh 秘钥连接主机# 生成秘钥 ssh-keygen -t rsa # 发送公钥文件到管理节点 ssh-copy-id -i /root/.ssh/id_rsa.pub -p 22 root@10.10.110.122 # 现在主机清单里不用再填写账号密码了","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible快速开始(3)","slug":"ansible快速开始(3)","date":"2020-05-09T01:12:59.000Z","updated":"2020-06-02T07:51:22.033Z","comments":true,"path":"post/bf783834.html","link":"","permalink":"https://www.missf.top/post/bf783834.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 Ansible快速开始环境信息control os: centos 7.7 x64 ansible version: 2.9.7 python version:2.7.5 任务在Control node上去连接Managed nodes 定义主机清单 定义一个简单的通过ssh认证的主机清单 cat /etc/ansible/hosts 10.10.110.122 ansible_user=root ansible_pass=0 ansible_port=22 主机清单的配置含义: ansible_host 定义管理节点ip地址 ansible_user 连接管理节点的用户 ansible_pass 连接管理节点的用户密码 ansible_port 连接端口号默认是22 执行ansible命令 测试Control node和Managed nodes的连接状态 ansible 10.10.110.122 -m ping # 命令中的含义 -192.168.77.135 用于匹配主机清单中的主机名称 -m ping 指定 ping 模块，用于测试与管理节点的连接状态 如果提示如下错误: 10.10.110.122 | FAILED! =&gt; { “msg”: “Using a SSH password instead of a key is not possible because Host Key checking is enabled and sshpass does not support this. Please add this host’s fingerprint to your known_hosts file to manage this host.”} 这是因为Control node和Managed nodes第一次连接需要先添加指纹信息，可以先使用ssh连接一次，如果机器太多的话，可以在ansible配置文件开启host_key_checking = False cat /etc/ansible/ansible.cfg host_key_checking = False 再次测试连接状态 ansible 10.10.110.122 -m ping 10.10.110.122 | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": false, \"ping\": \"pong\" } # 看到\"ping\": \"pong\"表示连接成功","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible安装(2)","slug":"ansible安装(2)","date":"2020-05-08T03:12:59.000Z","updated":"2020-06-02T07:51:22.013Z","comments":true,"path":"post/3ebd0a7f.html","link":"","permalink":"https://www.missf.top/post/3ebd0a7f.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 安装 Ansible 对管理主机的要求 目前,只要机器上安装了 Python 2（版本2.6或2.7）或Python 3（版本3.5及更高版本）都可以运行Ansible (windows系统不可以做管理主机) 管理主机的系统可以是 Red Hat, Debian, CentOS, macOS, BSD的各种版本。 对节点主机的要求 通常我们使用 ssh 与节点通信，默认使用 sftp. 如果 sftp 不可用，可在 ansible.cfg 配置文件中配置成 scp 的方式. 在节点上也需要安装Python 2（2.6或更高版本）或Python 3（3.5或更高版本） 如果节点启用了selinux, 在使用copy/file/template时需要安装 libselinux-python 包。 在管理节点上安装Ansible# Centos/RHEL wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo yum install -y ansible # Ubuntu sudo apt update sudo apt install software-properties-common sudo apt-add-repository --yes --update ppa:ansible/ansible sudo apt install ansible bash命令行自动补全 在Ansible 2.9之后，就支持了命令行参数补齐功能 # Centos/RHEL yum install -y epel-release yum install -y python-argcomplete 将补全加入环境变量activate-global-python-argcomplete source /etc/profile","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"ansible介绍(1)","slug":"ansible介绍(1)","date":"2020-05-07T08:12:59.000Z","updated":"2020-06-15T03:06:19.372Z","comments":true,"path":"post/c55d25e0.html","link":"","permalink":"https://www.missf.top/post/c55d25e0.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 Ansible介绍Ansible 是2012年推出的一种通用自动化工具，ansible也是我接触的第一个自动化运维工具，ansible可以帮助我们完成一些批量任务，或者完成一些经常性的重复工作，在服务器集群场景下，ansible是我们运维的利器，Ansible 在2015年时被Redhat公司收购。Ansible是用Python编写的，它使用SSH在不同的机器上执行命令。Ansible是无代理的，这使得入手更容易。您只需要在相关机器上安装SSH和Python。Ansible使用声明式YAML语言”playbook”将一组主机(“hosts”)映射到定义明确的角色。 也许你会说，我写个shell脚本不也一样能实现批量服务器的管理吗？这里我想说的是，ansible支持一些优秀的特性: 支持幂等性 No Agent 支持palybook实现复杂的任务 使用yaml语言 先来说说什么是幂等性，假如我要在目标主机安装Nginx，但是我不确定这个主机是否已经安装了Nginx，当使用ansible完成这个任务时，问题就会变得简单，如果目标主机已经安装Nginx，则ansible不会进行任何操作，如果目标主机未安装Nginx，ansible才会开始工作，ansible是以导向为结果的，我们指定一个状态，ansible就会自动判断，把服务器的状态调整为我们指定的状态，我多次执行，结果都是一样的，这就是幂等性。 使用zabbix监控一百台服务器，这一百台服务器都需要安装zabbix agent，但是ansible是不需要在管理节点上安装客户端代理程序的，因为它基于ssh工作，只要Control node能通过ssh连接到Managed nodes就能通过ansible管理对应的管理节点了，还有就是ansible的控制节点不用单独启动服务，能直接运行命令。 Ansible的目标实现一切自动化 Ansible的应用场景 自动化部署应用 自动化管理配置 自动化的持续交付 自动化的云服务管理 自动化网络设备管理 Ansible的工作原理 安装ansible到管理节点，定义好主机清单，编写好palybook，就能运行ansible批量管理管理节点。步骤如下: 在控制节点上安装ansible 配置主机清单: 将被控节点的连接信息配置到主机清单中 定义playbook: 指定运行主机和执行任务 对节点主机的要求通常我们使用 ssh 与节点通信，默认使用 sftp. 如果 sftp 不可用，可在 ansible.cfg 配置文件中配置成 scp 的方式. 在节点上也需要安装Python 2（2.6或更高版本）或Python 3（3.5或更高版本） Ansible的概念控制节点(Control node)任何装有Ansible的机器可称为 控制节点 。 您可以从任何控制节点运行命令和剧本，并调用/usr/bin/ansible或/usr/bin/ansible-playbook命令，您可以将任何安装了Python的计算机用作控制节点,笔记本电脑,共享桌面和服务器都可以运行Ansible。 但是不能将Windows计算机用作控制节点。您也可以有多个控制节点。 管理节点(Managed nodes)使用Ansible管理的网络设备或服务器可称为 管理节点。 受管节点有时也称为 主机 。 受管节点上是不需要安装Ansible的。 主机清单(Inventory)托管节点的列表。库存文件有时也称为主机文件。您的目录可以为每个托管节点指定诸如IP地址之类的信息。库存还可以组织托管节点，创建和嵌套组，以便于扩展。 模块(Modules)Ansible执行的具体代码。每个模块都有特定的用途，从管理特定类型数据库的用户到管理特定类型网络设备上的VLAN接口。您可以使用任务调用单个模块，也可以调用剧本中的几个不同模块。 任务(Tasks)Ansible的行动单位。tasks包含一组由module组成的任务列表, 您可以使用特别的命令一次性执行单个任务。 剧本(Playbooks)保存了已排序的任务列表，因此可以按此顺序重复运行这些任务。剧本可以包括变量和任务。剧本是用 YAML 编写的，易于阅读、编写、共享和理解。","categories":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"}]},{"title":"Python基础day07","slug":"Python基础day07","date":"2020-04-28T11:42:45.000Z","updated":"2020-06-09T01:36:26.399Z","comments":true,"path":"post/44a3d96e.html","link":"","permalink":"https://www.missf.top/post/44a3d96e.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 闭包一般情况下，如果一个函数结束，函数的内部所有东西都会释放掉，还给内存，局部变量都会消失。但是闭包是一种特殊情况，如果外函数在结束的时候发现有自己的临时变量将来会在内部函数中用到，就把这个临时变量绑定给了内部函数，然后自己再结束。 # 闭包 def outer(): a = 6 def inner(): b = 8 print(a) print(b) return inner if __name__ == '__main__': res = outer() res() 可迭代对象我们分析对可迭代对象进行迭代使用的过程，发现每迭代一次（即在for…in…中每循环一次）都会返回对象中的下一条数据，一直向后读取数据直到迭代了所有数据后结束。那么，在这个迭代过程中就应该有一个“记录员”去记录每次访问到了第几条数据，以便每次迭代都可以返回下一条数据。我们把这个能帮助我们进行数据迭代的“记录员”称为迭代器(Iterator)。可迭代对象的本质就是可以向我们提供一个这样的“记录员”即迭代器帮助我们对其进行迭代遍历使用 转化成迭代器# 内部含有\"__iter__\"并且含有\"__next__\"方法的就是迭代器，遵循迭代器协议 s2 = \"cdfv\" ol = s2.__iter__() # 可迭代对象通过__iter__或者iter()方法转化成迭代器 # print(ol) print(ol.__next__()) # 一个next对应一个值，一一对应 print(ol.__next__()) print(ol.__next__()) print(ol.__next__()) c d f v 判断对象是否为迭代器# 判断一个对象是否是可迭代对象，方法一 s1 = 'asdf' jo = iter(s1) # 将可迭代对象转化成迭代器 print(jo) print(\"__iter__\" in dir(jo) and \"__next__\" in dir(jo)) # 判断是否同时含有这两个方法 &lt;str_iterator object at 0x000000FE3E7E0898> True # 判断一个对象是否是可迭代对象，方法二 from collections.abc import Iterable,Iterator # 导入Iterable,Iterator方法 so = 'asdf' print(isinstance(so,Iterable)) # 判断对象是否是可迭代 print(isinstance(so,Iterator)) # 判断对象是否是迭代器 生成器生成器本质上是迭代器，生成器是自己用Python代码写的迭代器，平时我们用iter将一个迭代对象转化成迭代器，是调用iter方法底层的C代码实现的。 # 将一个函数变成生成器函数 def fun(): print(123) print(456) yield 789 fun() s = fun() # 将函数赋值使用next打印，不能使用fun()调用函数进行打印 print(next(s)) # 一个next去取一个yield的值，之所以打印三个值是函数内部打印的，next(s)只打印了789 123 456 789 生成器的send方法一个send对应一个yield，但是如果send中有传值，就会将这个值发送给上一个yield def func(): # 1.定义函数 a = yield 123 print(a) yield '有志青年' yield '好好学习' yield '天天向上' genor = func() # 2.函数赋值 print(genor.send(None)) # 3.取一个yield，打印123 print(genor.send('Alex')) # 4.取下一个yield，并将Alex赋值给上一个yield，先执行的a = Alex;print(a),再打印有志青年 生成器的yield fromdef func(): lst = ['努力','奋斗','向上','乐观'] yield lst # 将列表当成一个整体 genor = func() print(next(genor)) ['努力', '奋斗', '向上', '乐观'] def func(): lst = ['努力','奋斗','向上','乐观'] yield from lst # 将列表中的每个元素逐个输出 genor = func() # print(next(genor)) for i in genor: print(i) 努力 奋斗 向上 乐观 列表所有值+1info = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] for index,i in enumerate(info): # info[0] = 0 + 1 info[index] += 1 print(info) 列表推导式和生成器表达式列表推导式列表推导式就是用一行代码构建一个简单或者复杂的列表，减少代码量的同时又可以装逼 print([i for i in range(1,26)]) # 构建一个1 - 25的列表 print(['python%s期' % i for i in range(1,26)]) # 构建一个稍微复杂的列表 print([i for i in range(1,31) if i % 3 == 0]) # 构建一个30以内所有能被3整除的数 print([i ** 2 for i in range(1,31) if i % 3 == 0]) # 所有能被3整除的数的平方 print(['青年%s号' % i for i in range(1,31,2)]) print(['*' if i % 3 == 0 else i for i in range(1,21)]) # 如果i能被3整除就为*，否则从range里面取值 # 将列表中至少含有两个e的字符串放到一个列表中 names = [['Tefe','oIred','Edvl','fgte','vfeke','vfd'],['dcvr','vfer','vfree']] ll = [] for i in names: for name in i: if name.count('e') >= 2: ll.append(name) print(ll) print([name for i in names for name in i if name.count('e') >= 2]) # 列表推导式能一行代码完成 生成器表达式生成器表达式与列表推导式几乎一模一样，就是[]换成了(),但是生成器在内存方面更占优势，列表推导式是一次性将数据加载到内存，而生成器则是取一点生成一点，更加节省内存 genor = ('python%s期' % i for i in range(1,26)) print(genor) for i in genor: print(i) 字典推导式print({i:None for i in range(1,11)}) # 值为None，key从range(1,11)取 am = {'s':'cd','wf':10,'r5':'km'} print({value:key for key,value in am.items()}) # 将字典的键值对换 集合推导式lp = {12,-9,75} print({i ** 2 for i in lp}) 匿名函数# 匿名函数 def func(x,y): return x + y print(func(2,78)) # 针对这种自有返回值的函数，可以写成简化的匿名函数 func = lambda x,y:x * y # 只能写成一行 print(func(3,56)) suf = lambda x,y,z:x * y * z print(suf(45,4,2))","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day06","slug":"Python基础day06","date":"2020-04-27T05:45:29.000Z","updated":"2020-06-30T07:04:01.442Z","comments":true,"path":"post/33a4e9f8.html","link":"","permalink":"https://www.missf.top/post/33a4e9f8.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 函数思考:不能使用len方法去统计一个字符串的长度 s = 'cdvfdcmkcd' count = 0 for i in s: count += 1 print(count) d = [1,2,3,4,5,] count = 0 for i in d: count += 1 print(count) 可以实现，但如果我在多处使用就会有重复性的代码。初学者一定要培养一种对代码完美的偏执，其实这也是面向过程编程的缺点:代码重复性较多，代码的可读性差。 函数初识一个函数就是封装一个功能 d = [1,2,3,4,5,] def my_len(): # 定义函数名my_len count = 0 for i in d: count += 1 print(count) my_len() # 调用函数，不调用不会执行代码 函数返回值函数中遇到return直接结束，给函数的调用者返回一个值，不写默认为None def date(): print('我叫荒原饮露') print('我在学习Python') print('我在让自己变得更加优秀') return # 直接结束函数 print('我以后要...') # return后面的不会输出 date() print('加油') 我叫荒原饮露 我在学习Python 我在让自己变得更加优秀 加油 # 如果不写返回值，默认返回一个None df = date() print(df) 我叫荒原饮露 我在学习Python 我在让自己变得更加优秀 None # 返回多个值 def date(): return 'faker','doinb','jacklove' skt,fpx,ig = date() print(skt) print(fpx) print(ig) faker doinb jacklove 函数的参数def date(a,b): # 函数的定义:形式参数 print('faker') print(a,b) x = 2 y = 3 date(x,y) # 函数的执行者:实际参数,将实参x,y传递给形参a,b faker 2 3 位置参数def date(positon,sex): # 实参和形参的位置必须要对应 print('%s附近的%s' % (positon,sex)) date('深圳','女性') # 调用函数时，传入两个参数 深圳附近的女性 键值对参数def date(tq,name,dc): # 形式参数与实际参数的键对应，位置不需对应 print('我叫%s,我喜欢的季节是%s,我学习%s已经一个月了' % (name,tq,dc)) date(name=\"小马哥\",tq=\"秋季\",dc=\"Python\") # 以键值对的方式传入实际参数 混合参数# 注意:位置参数必须在关键字参数的前面，不然会报错 def date(cs,home,tq,name,dc): print('我叫%s,我喜欢的季节是%s,我学习%s已经一个月了' % (name,tq,dc)) print('%s赚钱%s花,一分别想带回%s' % (cs,cs,home)) date('深圳','家',name=\"小马哥\",tq=\"秋季\",dc=\"Python\") 默认参数def date(soft,posi,sex=\"女\"): # 默认参数需要放置位置参数的后面 print('打开%s软件,搜索%s附近的%s' % (soft,posi,sex)) date('约会',posi='深圳南山区') 万能参数# 万能参数：两个形式参数，接收所有的位置参数，关键字参数 def date(*args,**kwargs): print(args) # 位置参数 print(kwargs) # 关键字参数 date('南山区','18',posi='深圳',sex='laddyboy') ('南山区', '18') # 将位置参数返回为一个元组 {'posi': '深圳', 'sex': 'laddyboy'} # 将关键字参数返回为一个字典 *的魔性用法# *的魔性用法 def fun(*args,**kwargs): print(args,kwargs) fun(*(1,2,'alex'),*('mk,j'),**{'ed':'12'},**{'cds':'lkj'}) # 在调用函数时*是将多个元组的元素整合成一个元组，**是将多个字典整合成一个字典 (1, 2, 'alex', 'm', 'k', ',', 'j') {'ed': '12', 'cds': 'lkj'} 形参的顺序问题def fun(a,b,*args,sex='女',**kwargs): print(a) print(b) print(args) print(sex) print(kwargs) fun(1,2,3,'oi','cd',sex=\"男\",name=\"alex\") 1 2 男 (3, 'oi', 'cd') {'name': 'alex'} # 按照位置参数 *args 默认参数 **kwargs的顺序 判断数值大小def sum(a,b): # 定义两个形式参数，用来接收实际参数 if a > b: return a else: return b print(sum(1,5)) 三元运算符dc = \"A\" if 6 > 3 else \"B\" # 如果条件成立dc就等于A，否则等于B print(dc) A def max(a,b): return a if a > b else b # 如果a大于b，就return a否则return b df = max(150,48) print(df) 150 函数的命名空间# 函数的命名空间 name = 'alex' age = '23' def fun(): sex = '女' print(sex) fun() # 变量赋值时会在内存中开辟一个名称空间用来存放变量名和对应的值 # 定义函数时会在内存中开辟一个函数内存地址，但不会存放函数体的内容 # 但函数调用时会再开辟一个临时名称空间，存放函数体的内容，并且临时名称空间随着函数的调用结束而消失 在python解释器开始执行之后, 就会在内存中开辟一个空间, 每当遇到一个变量的时候, 就把变量名和值之间的关系记录下来, 但是当遇到函数定义的时候, 解释器只是把函数名读入内存, 表示这个函数存在了, 至于函数内部的变量和逻辑, 解释器是不关心的. 也就是说一开始的时候函数只是加载进来, 仅此而已, 只有当函数被调用和访问的时候, 解释器才会根据函数内部声明的变量来进行开辟变量的内部空间. 随着函数执行完毕, 这些函数内部变量占用的空间也会随着函数执行完毕而被清空 我们给这个存放名字与值的关系的空间起了一个名字——命名空间 全局名称空间:存放的是py文件中变量与值的对应关系 局部名称空间:存放的是函数体里面的变量与值的对应关系 内置名称空间:内置函数，关键字等 加载到内存的顺序内置名称空间 —&gt; 全局名称空间 —&gt; 局部名称空间(当函数执行时) 取值顺序# 取值顺序，就近原则 # 局部名称空间 ---> 全局名称空间 name = 'mwj' def fun(): name = 'lok' print(name) fun() lok globals和localsname = 'li' def fun(): name = 'alex' def inner(): name = 'qw' print(globals()) # 返回一个字典：包含全局作用域的所有内容 print(locals()) # 返回一个字典：当前作用域的所有内容 inner() fun() {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': &lt;_frozen_importlib_external.SourceFileLoader object at 0x0000009D39BA5860>, '__spec__': None, '__annotations__': {}, '__builtins__': &lt;module 'builtins' (built-in)>, '__file__': 'C:/Python3.7/Python_Scripts/t5.py', '__cached__': None, 'name': 'li', 'fun': &lt;function fun at 0x0000009D39B5C1E0>} {'name': 'qw'} 高阶函数# 高阶函数 def fun1(): print(111) def fun2(): print(222) fun1() def fun3(): print(333) fun2() print(555) fun3() print(666) # 555 333 222 111 666,代码从上至下执行，函数调用函数 def fun(): print(1) def inner(): print(2) def inner2(): print(3) print(4) inner() print(5) fun() # 1 4 2 5,从上至下执行，函数定义之后不调用则不会被输出 global nonlocal# global nonlocal def fun(): global name name = \"alex\" fun() print(name) # 可以在局部声明一个全局变量，如果不声明为全局变量，print(name)不输出alex # 原本内层函数不能对外层函数的变量只能引用不能修改 def war(): name = \"alex\" def inner(): nonlocal name # 使用nonlocal 可以使内层函数对外层函数进行修改 name += \"b\" print(name) inner() war() 局部作用域不能引用全局作用域变量count = 1 def fun(): count += 1 # 执行报错 print(count) # 可以打印 fun() # 执行会报错，是因为局部作用域不能对全局作用域的变量只能引用不能修改 # 通过global在局部作用域声明，可以进行修改 count = 1 def fun(): global count count += 1 print(count) fun() 函数名作为函数的参数def fun(x): print(x) print(\"in fun\") def fun1(): print(\"in fun1\") fun(fun1) # 调用fun函数并且将fun1作为参数，输出的是fun1函数的内存地址，fun1函数被作为参数时是一个变量 &lt;function fun1 at 0x00000055024C9620> in fun 函数名可以当做函数的返回值# 函数名可以当做函数的返回值 def fun(x): print(\"in fun\") return x def fun1(): print(\"in fun1\") re = fun(fun1) print(re) in fun &lt;function fun1 at 0x00000030B6739620>","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day05","slug":"Python基础day05","date":"2020-04-26T05:21:29.000Z","updated":"2020-06-02T07:51:22.011Z","comments":true,"path":"post/aaadb842.html","link":"","permalink":"https://www.missf.top/post/aaadb842.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 Python文件操作全部读取file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") # 文件路径，文件编码，操作方式 content = file1.read() # 将读取到文件的内容复制给content print(content) # 打印文件的内容 读取n个字符file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") content = file1.read(11) print(content) 按行读取file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") content = file1.readline() print(content) 返回列表file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") content = file1.readlines() print(content) # 返回一个列表，用原文件的每一行作为列表的每一个元素 for循环读取# 读取大文件时逐行读取防止内存崩溃，涉及到迭代器 file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") for line in file1: print(line.strip()) file1.close() 读取文件的方式 read() 全部读取 read(n) 读取n个字符 readline() 按行读取 readlines() 返回一个列表，列表的元素是原文件的每一行数据 for循环读取 读取大文件时逐行读取防止内存崩溃 写入文件的方式写入空文件f1 = open(\"file1\",encoding=\"utf-8\",mode=\"w\") # 打开文件句柄 content = f1.write(\"我也不知道写什么啊\") # 写入操作 f1.close() # 关闭文件句柄 # 如果写入文件不存在，open()将自动创建它 # 如果文件已存在已有内容，会清空再写入 写入多行f1 = open(\"file1\",encoding=\"utf-8\",mode=\"w\") f1.write(\"我也不知道写什么啊\") f1.write(\"我也不知道写什么啊\") f1.write(\"我也不知道写什么啊\") f1.close() # 加换行符 f1 = open(\"file1\",encoding=\"utf-8\",mode=\"w\") f1.write(\"我也不知道写什么啊\\n\") f1.write(\"我也不知道写什么啊\\n\") f1.close() # 在打开一个文件句柄后，可以重新写入多次而不被清空，只有在文件句柄被关闭后，下一次写入才会被清空 追加文件内容# 没有文件创建文件追加内容，有此文件则在原文件的末尾追加新内容 f1 = open(\"file1\",encoding=\"utf-8\",mode=\"a\") f1.write(\"我也不知道写什么啊\\n\") f1.write(\"我也不知道写什么啊\\n\") f1.close() 读写非文字类文件# 音视频或者图片类型的文件，以bytes读取和写入 f3 = open(\"tr.jpg\",mode=\"rb\") # 用rb模式打开一张图片 content = f3.read() # 以bytes读取原图片数据 f4 = open(\"ting.jpg\",mode=\"wb\") f4.write(content) # 将数据写到一个新文件图片 f3.close() f4.close() 读写模式先读后写f1 = open(\"file1\",encoding=\"utf-8\",mode=\"r+\") content = f1.read() # 读取内容 print(content) f1.write(\"alex\") # 写入内容，这里是以追加的方式写入，不会清空文件内容 f1.close() 调整光标写入f1 = open(\"file1\",encoding=\"utf-8\",mode=\"r+\") f1.seek(0) # 将光标调整到最前 f1.write(\"jkl\") # 在最前面写入jkl，会将原来前面的三个字符替换掉 f1.close() f1.seek(0,2) # 将光标调到最后面 f1.write(\"ooo\") # 在下一行写入ooo f1.close() 强制保存f1 = open(\"file1\",encoding=\"utf-8\",mode=\"r+\") f1.write(\"TES.123\") f1.flush() #强制保存，相当于Crtl + s f1.close() 判断文件句柄是否可读可写# readable writeable f2 = open(\"file\",encoding=\"utf-8\",mode=\"w\") # 写入模式 print(f2.read()) # 读取会报错 print(f2.readable()) # 由于是写入模式不能读 False print(f2.writable()) True 按照字节调整光标位置# tell seek f1 = open(\"file2\",encoding=\"utf-8\") ret = f1.read() # 读取文件，光标会移动到下一行 print(f1.tell()) # 获取当前文件指针的位置 f1.seek(3) # 移动指针到指定的位置 print(f1.read()) # 从指针位置往后读取 f1.close() 截取文件# truncate 只能在可写的模式下截取原文件，只能从头截取 f1 = open(\"file1\",encoding=\"utf-8\",mode=\"r+\") ret = f1.truncate(12) # 截取文件的前12个字节,文件其他内容会被清空，只保留截取到的字节 print(f1.read()) f1.close() 中华人民 # utf-8编码下，一个中文字符等于三个字节，如果是截取4个字节会报错 with open操作方式# 1.自动关闭文件句柄 with open(\"file4\",encoding=\"utf-8\") as f1: content = f1.read() print(content) # 2.同一语句可操作创建多个文件句柄 with open(\"file1\",encoding=\"utf-8\") as f1,open(\"file2\",encoding=\"utf-8\",mode=\"w\") as f2: print(f1.read()) # 对file1进行读取操作 f2.write(\"777\") # 对file2进行写入操作 # 3.with open 可能引起IO错误的操作 with open(\"file1\",encoding=\"utf-8\") as f1: f1.read() # 打开文件句柄f1进行读取操作，文件句柄自动关闭 with open(\"file1\",encoding=\"utf-8\",mode=\"w\") as f2: f1.write(\"777\") # 又打开文件句柄f2进行写操作，如果文件句柄f1没有及时关闭又打开了f2文件句柄程序就会报错 关于文件的修改文件的数据都是存放在硬盘上的，因此只存在覆盖，不存在修改一说，我们平时看到的修改文件，都是模拟出来的效果，修改file5文件中的Alex字符为Sb，并且将原文件复制为新文件file.bak，删除原文件，修改新文件的名字为file5，修改速度非常快，根本看不到生成的file5.bak文件，具体的说有两种实现方式 将硬盘存放的该文件的内容全部加载到内存，在内存中是可以修改的，修改完毕后，再由内存覆盖到硬盘 # file5文件内容 Alex是个屌丝，即使Alex有特斯拉也还是屌丝 你们真逗，Alex再牛逼，也掩饰不了资深屌丝的气息 import os with open(\"file5\",encoding=\"utf-8\") as f1,open(\"file5.bak\",encoding=\"utf-8\",mode=\"w\") as f2: # 打开两个文件句柄，f1只读，f2可写 old_content = f1.read() # 将f1内容赋值给old_content new_content = old_content.replace(\"Alex\",\"Sb\") # 将Alex替换为Sb的数据赋值给new_content f2.write(new_content) # 将新数据写入f2 os.remove(\"file5\") # 删除文件file5 os.rename(\"file5.bak\",\"file5\") # 将新文件命名为file5 # 这样有一个不好的地方，old_content = f1.read()这里是一次性将文件加载到内存中的 将硬盘存放的该文件的内容一行一行地读入内存，修改完毕就写入新文件，最后用新文件覆盖源文件 import os with open(\"file5\",encoding=\"utf-8\") as f1,open(\"file5.bak\",encoding=\"utf-8\",mode=\"w\") as f2: for line in f1: new_line = line.replace(\"Sb\",\"Alex\") # 将一行的数据替换完成赋值给新的一行 f2.write(new_line) # 逐行写入 os.remove(\"file5\") os.rename(\"file5.bak\",\"file5\") # 不会将文件一次加载到内存","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day04","slug":"Python基础day04","date":"2020-04-25T10:21:29.000Z","updated":"2020-06-02T07:51:22.006Z","comments":true,"path":"post/ddaa88d4.html","link":"","permalink":"https://www.missf.top/post/ddaa88d4.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 基础数据类型补充判断数值是否相等top1 = 'alex' top2 = 'alex' print(top1 == top2) True 内存地址# 打印mem会先找到mem的内存地址，然后再找到内存地址指向的数据 mem = 'mk' print(id(mem)) 170332332864 判断内存地址是否相同f = [1,2,3] g = [1,2,3] print(f == g) # True print(f is g) # False # 判断的是两个对象的内存地址是否相同,虽然f的值等于g，但是内存地址却不是指向同一个 数据类型 可变/不可变 整型 不可变 字符串 不可变 元组 不可变 列表 可变 集合 可变 字典 可变 代码块# 代码块 代码全都是基于代码块去运行的，一个文件就是一个代码块，不同的文件就是不同的代码块 # 代码块的缓存机制 Python在执行同一个代码块的初始化对象的命令时，会检查其值是否已经存在， 如果存在，会将其重用，如果有同样的记录那么它会重复使用这个字典中的值， 但是要注意的是，只有在同一个代码块下，才会实现这个缓存机制 满足此机制的数据类型:int str bool 优点：节省内存，提升性能 小数据池Python自动将-5~256的整数进行了缓存，当你将这些整数赋值给变量时，并不会重新创建对象，而是使用已经创建好的缓存对象。python会将一定规则的字符串在字符串驻留池中，创建一份，当你将这些字符串赋值给变量时，并不会重新创建对象， 而是使用在字符串驻留池中创建好的对象。 小数据(又称驻留机制、驻存机制) 能够应用于不同的代码块 适应的数据类型:int str bool int:-5 ~ 256 str:一定条件下的str满足小数据池 bool:全部 优点:节省内存 提升性能 编码进阶不同的编码之间不能互相识别（会出现报错或者乱码），文字通过网络传输，或者硬盘存储不能使用Unicode编码方式。 ASCII早期的密码本，英文字母，数字，特殊字符 8位(bit) == 1byte 在ascll码中,8位bit表示一个字节表示一个字符 hello = 01101000 01100101 01100111 0110011 01100101 Unicode万国码包含全世界所有的文字 32位bit表示4个字节表示一个字符 a:10001000 00010010 00100000 00010010 中:00000000 10010010 00000000 10010010 utf-8最少用8位表示一个字符 a:01000010,8位bit表示一个字节表示一个字符 欧洲文字:00000010 00100000 16位bit表示两个字节表示一个字符 中国文字:00000010 00000010 00000010 24位bit表示三个字节表示一个字符 gbk最包含英文和自己国家的语言 a:00000010 8位bit表示一个字节表示一个字符 中:00000010 0000001016 16位bit表示两个字节表示一个字符 在Python3x环境下，唯独str类型的内部编码方式是Unicode， 所以Python3x中的字符串不能用于直接的网络传输和文件存储 补充一个数据类型：bytes类型，与str类型是海尔兄弟， bytes内部编码方式为非Unicode，bytes类型能用于网络传输和文件存储，还拥有str的其他特性 但是bytes中文是16进制表示，看不懂，所以常用的还是str类型 bytes类型b1 = 'alex' b2 = b'alex' print(b1,type(b1)) alex &lt;class 'str'> print(b2,type(b2)) b'alex' &lt;class 'bytes'> 数据类型转换# str ---> gbk s0 = '荒原饮露' b1 = s0.encode('gbk') # 编码，将字符串转换为gbk print(b1) b'\\xbb\\xc4\\xd4\\xad\\xd2\\xfb\\xc2\\xb6' # 可以看到 一个中文两个字节 y2 = b1.decode('gbk') # 解码 print(y2) 荒原饮露 # str ---> utf-8 s2 = '努力奋斗' b2 = s2.encode('utf-8') print(b2) b'\\xe5\\x8a\\xaa\\xe5\\x8a\\x9b\\xe5\\xa5\\x8b\\xe6\\x96\\x97' # 一个中文三个字节 b3 = b2.decode('utf-8') print(b3) 努力奋斗 # gbk ---> utf-8 si = '编码' s1 = si.encode('gbk') print(s1) b'\\xb1\\xe0\\xc2\\xeb' # 得到gbk编码的bytes类型 1 = s1.decode('gbk') # 解码再加密 b2 = b1.encode('utf-8') print(b2) b'\\xe7\\xbc\\x96\\xe7\\xa0\\x81' # utf-8编码的bytes类型 深浅拷贝# 赋值运算 jk = [1,2,3] yu = jk # yu变量和jk变量都指向同一个内存地址 yu.append(789) # 修改这个列表的时候，两个变量的值都被修改 print(jk,yu) [1, 2, 3, 789] [1, 2, 3, 789] 浅拷贝lo = ['de',15,['er',4,2]] ko = lo.copy() # ko拷贝lo的列表，得到一样的数据，但是浅copy只会拷贝内存中的第一层数据 lo.append('lp') # lo往列表追加一个元素lp print(id(lo),lo) print(id(ko),ko) 205292790408 ['de', 15, ['er', 4, 2], 'lp'] 205293284808 ['de', 15, ['er', 4, 2]] # 可以看到两个列表的内存地址都是不一样的，往lo列表追加lp元素，ko列表是没有跟随lo列表追加lp元素的 lo[2].append('io') # 往lo列表的小列表里面追加io元素 print(lo,ko) ['de', 15, ['er', 4, 2, 'io'], 'lp'] ['de', 15, ['er', 4, 2, 'io']] # 可以看到，lo和ko列表的小列表都被追加了io元素，简而言之，列表里面的小列表里面的元素是共用的。ko拷贝lo的列表，只会拷贝lo外层列表，而不会拷贝lo的内层列表，lo外层列表发生改变ko不会跟随，但是lo内层列表发生改变ko会跟随，复制一个列表时，lo = ['de',15,['er',4,2]]，de和15元素的地址发生改变，['er',4,2]小列表的元素还是指向原来的地址 # 全切片是浅copy ki = ['cf',['ijni','678',15],90] ji = ki[:] ki[1].append('mk') print(ki,ji) ['cf', ['ijni', '678', 15, 'mk'], 90] ['cf', ['ijni', '678', 15, 'mk'], 90] 深拷贝# 深copy会在内存中对原列表以及列表里面的可变的数据类型重新创建一份，而列表中不可变得数据类型还是沿用原来的 import copy lo = ['fr','ty',['rt','km',12],45] ko = copy.deepcopy(lo) print(lo,ko) lo[2].append('test') print(lo,ko) ['fr', 'ty', ['rt', 'km', 12], 45] ['fr', 'ty', ['rt', 'km', 12], 45] ['fr', 'ty', ['rt', 'km', 12, 'test'], 45] ['fr', 'ty', ['rt', 'km', 12], 45] # 往lo小列表追加元素，ko的小列表的元素不是指向原来的地址，ko的小列表元素没有被改 深拷贝和浅拷贝的区别# 以下所有的内容都是基于内存地址来说的。 # 可变数据类型：当该数据类型的对应变量的值发生了改变，那么它对应的内存地址不发生改变，对于这种数据类型，就称可变数据类型 # 不可变数据类型：当该数据类型的对应变量的值发生了改变，那么它对应的内存地址也会发生改变，对于这种数据类型，就称不可变数据类型 # 总结：不可变数据类型更改后地址发生改变，可变数据类型更改地址不发生改变 深拷贝和浅拷贝的需要注意的点# 在浅拷贝时，拷贝出来的新对象的地址和原对象是不一样的，但是新对象里面的可变元素（如列表）的地址和原对象里的可变元素的地址是相同的，也就是说浅拷贝它拷贝的是浅层次的数据结构（不可变元素），对象里的可变元素作为深层次的数据结构并没有被拷贝到新地址里面去，而是和原对象里的可变元素指向同一个地址，所以在新对象或原对象里对这个可变元素做修改时，两个对象是同时改变的，但是深拷贝不会这样，这个是浅拷贝相对于深拷贝最根本的区别","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day03","slug":"Python基础day03","date":"2020-04-24T10:14:29.000Z","updated":"2020-06-02T07:51:22.009Z","comments":true,"path":"post/43ce1d77.html","link":"","permalink":"https://www.missf.top/post/43ce1d77.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 验证码# 代入验证码项目，输入姓名密码之后有空格也不会报错 username = input(\"请输入姓名:\").strip() passworrd = input(\"请输入密码:\").strip() code = 'AeTrd'.upper() your_code = input(\"请输入验证码:\").upper() if your_code == code: if username == 'alex' and passworrd == 'sb': print('登录成功') else: print('用户名或者密码错误') else: print('验证码不正确') 将一行字符串竖着打印# while循环 t = '荒原饮露cchkskhdiqwuey' s = len(t) # 先统计字符串的长度 # print(s) index = 0 # 设定一个索引值 while index &lt; s: # 如果索引值小于变量s则进入循环 print(t[index]) # 从0开始打印字符串的索引，直到index&lt;s不成立退出循环 index += 1 # index每次自增1 # for循环 t = '荒原饮露cchkskhdiqwuey' for i in t: print(i) # 还可以进行拼接，print(i+'lo') 猜数字# 猜数字,只有猜对了才会退出 num = 66 while True: cai = int(input(\"请输入你要猜的数字:\")) if cai > num: print(\"猜的数字大了！\") elif cai &lt; num: print(\"猜的数字小了\") else: print(\"猜对了！\") break # 三次猜测不对就退出 num = 66 i = 0 while i &lt; 3: j = int(input(\"请输入数字:\")) if j > num: print(\"数字大了!\") elif j &lt; num: print(\"数字小了!\") else: print(\"猜对了!\") break i += 1 计算器# 方式一 content = input(\"请输入内容:\").strip() # 将输入的字符串，去掉前后两端的空格 plus_index = content.find('+') # 找到加号位置，并返回加号的索引数 num1 = content[:plus_index].strip() # 取加号前面的区域并且去掉空格 num2 = content[plus_index+1:] # 取加号后面的区域也去掉空格 sum3 = int(num1) + int(num2) # 将取到的无空格值相加 print(sum3) # 方式二 content = input(\"请输入内容:\").strip() # 将输入的字符串，进行去前后两端的空格 li = content.split('+') # 将字符串转换为列表，指定以+进行分割 print(li) ['15 ', ' 16'] # 将得到的元素相加 sum1 = int(li[0]) + int(li[1]) # 将字符串类型的两个元素强制转换为int，会去掉空格 print(sum1) 列表为什么需要列表 字符串如果长度过于长取值时会很费劲，取出来的数据是字符串类型，使用不方便 字符串有长度限制(只能存储少量的字符串类型的数据) 基于以上原因Python提供了一个另外的数据类型:容器类数据类型 什么是列表 列表能存储大量的、不同的数据类型，列表存放什么数据类型，取出来之后还是什么数据类型 列表可以存放的数据类型:数字，字符串，布尔值，小列表，元组，字典，集合，对象 32位Python的限制是 536870912 64位Python的限制是 1152921504606846975 列表是有序的、有索引值的、可切片、方便取值 列表取值# 取第一个元素 sl = ['alex','荒原','154'] sl1 = print(sl[0],type(sl)) # 输出索引和索引类型 print(sl1) # alex &lt;class 'list'> 定义列表时是字符串 sl = ['alex','荒原','154'] sl1 = print(sl[0:2]) # 0 1 2，顾首不顾尾，只取前两个元素 print(sl1) # ['alex', '荒原'] # 反向取值 sl = ['alex','荒原','154'] sl1 = print(sl[-1:-4:-1]) print(sl1) # ['154', '荒原', 'alex'] 列表的增加sl.append(\"abc\") # 增加abc元素 print(sl) sl.append(True) # 增加布尔值 print(sl) name_list = [] # 空列表 while True: # 如果不执行break,则一直执行while True username = input(\"请输入姓名:\").strip() # 用户输入字符串 if username.upper() == 'Q':break # 如果输入是q，无论大小写都执行break name_list.append(username) # 判断到不是q则增加到列表 print(name_list) # 插入 lk = ['mjk','ctr','tpo',100] lk.insert(1,'yu') # 在索引1的位置，插入'yu',索引从零开始 print(lk) ['mjk', 'yu', 'ctr', 'tpo', 100] # 迭代者追加 lk = ['mjk','ctr','tpo',100] lk.extend('abc') print(lk) ['mjk', 'ctr', 'tpo', 100, 'a', 'b', 'c'] lk = ['mjk','ctr','tpo',100] lk.extend(['asd','cvf','cdd']) print(lk) ['mjk', 'ctr', 'tpo', 100, 'asd', 'cvf', 'cdd'] 列表的删除# 按照索引去删除 lk = ['mjk','ctr','tpo',100] ret = lk.pop(1) # 删除索引为1的元素 print(lk) ['mjk', 'tpo', 100] # 按照元素去删除 lk = ['mjk','ctr','tpo',100] lk.remove('tpo') # 指定删除那个 print(lk) ['mjk','ctr',100]. # 清空列表 lk = ['mjk','ctr','tpo',100] lk.clear() print(lk) [] # del 1.按照索引删除单个元素 lk = ['mjk','ctr','tpo',100] del lk[0] print(lk) ['ctr','tpo',100] 2.按照切片删除一部分元素 lk = ['mjk','ctr','tpo',100] del lk[:2] print(lk) ['tpo', 100] 3.按照切片（步长）删除一部分元素 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] s = lk[:5:2] # 取区域为0-5，步长为2 print(s) ['mjk', 'tpo', 'cff'] del lk[:5:2] # 取区域为0-5，步长为2，这些元素全部删除 print(lk) ['ctr', 100, 'ioo', 'tyy'] 列表的修改# 利用索引修改 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] lk[0] = 'we' # 利用索引定义要修改的元素的位置 print(lk) # 利用切片修改 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] lk[:2] = 'op' print(lk) ['o', 'p', 'tpo', 100, 'cff', 'ioo', 'tyy'] # 利用切片+步长修改 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] lk[:4:2] = 'op' # 注意步长的个数和修改后的字符串个数 print(lk) ['o', 'ctr', 'p', 100, 'cff', 'ioo', 'tyy'] 列表的查询# 按照索引查询 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] print(lk[1]) # 打印一个 # for 循环 for i in lk: print(i) # 输出列表所有元素 列表的其他操作# 计算列表元素的总个数 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy','cff'] print(len(lk)) 8 # 计算某个元素出现的个数 print(lk.count('cff')) 2 # 通过元素找索引，找到第一个返回，找不到就报错 print(lk.index('ctr')) 1 # 从小到大排列 fg = [2,9,4,6,7,1,8] fg.sort() print(fg) [1, 2, 4, 6, 7, 8, 9] # 从大到小排列 fg.sort(reverse=True) print(fg) [9, 8, 7, 6, 4, 2, 1] # 列表翻转 fg = [2,9,4,6,7,1,8] fg.reverse() print(fg) # 英文字符排序，按照元素首字母的ASCLL码的大小排序 fg = ['dfg','arfd','wer','fgv'] fg.sort() print(fg) ['arfd', 'dfg', 'fgv', 'wer'] 列表的嵌套ll = [1,2,'taibai',[1,'alex',3,]] # 列表里面有嵌套的小列表 # 将taibai改成大写 ll[2] = ll[2].upper() print(ll) # 往小列表追加元素'老男孩教育' ll[3] = ll.append('老男孩教育') print(ll) # 将alex改成alexsb ll[3][1] = ll[3][1] + 'sb' print(ll) # 打印嵌套列表元素 lj = ['wedi','lko','cjd',['dkd','oto'],'top'] for i in lj: if type(i) == list: # 加个判断如果某个元素类型为list，则再循环一遍，打印出来 for o in i: print(o) else: # 否则正常打印 print(i) 元组用来存放一些重要的信息，放在列表中不安全，需要一个容器类的数据类型，比如：个人信息，密码等。元组不能修改，但是元组里面的列表可以修改。 tu = (1,'alex',True,[1,2,3]) # 定义一个元组 tu[-1][2] = '12' # 往列表里面追加元素 print(tu) (1, 'alex', True, [1, 2, '12']) # 存放一些重要数据时，需要用元组存放 字典列表如果存储大量的数据，查询速度相对较慢，因为列表存储的数据一般没有什么关联性。针对这个问题，Python提供了一个基础数据类型：字典(dict) 回顾数据类型 分类 数据类型 容器型数据类型 list，tuple，dict，set 非容器型数据类型 str，bool，int 可变数据类型（不可哈希） list，dict，set 不可变数据类型（可哈希） str，bool，int，tuple 字典是由键值对形式存储的数据类型，字典的键必须是不可变的数据类型，唯一不重复的，字典的值可以是任意数据类型或者对象。基于字典的键是不可变的，字典的键会通过一种哈希算法，将键的值换算成内存地址，所以字典的查询速度非常快。字典在Python3.6之前是无序的，在3.6及以后字典会按照字典创建时的顺序排列。字典可以存储大量关联性数据。 字典的增加dic = {'name':'barry','age':18,'sex':'man'} # 用字典定义三个键值对 dic['dfgh'] = 150 # 没有则添加这个键值对 dic['age'] = 28 # 有age这个键就将值覆盖为28 print(dic) {'name': 'barry', 'age': 28, 'sex': 'man', 'dfgh': 150} dic.setdefault('port') # 没有这个键值对就会添加并赋值为空 dic.setdefault('name','yiyi') # 有name这个值则不修改，没有则增加 print(dic) {'name': 'barry', 'age': 18, 'sex': 'man', 'port': None} 字典的删除# pop 通过键去删除键值对 dic = {'name':'barry','age':18,'sex':'man'} ret = dic.pop('sex') print(dic) {'name': 'barry', 'age': 18} # 删除一个不存在的键就会报错 dic = {'name':'barry','age':18,'sex':'man'} ret1 = dic.pop('name2') # 为了程序能执行下去，想要不报错的话，可以添加一个返回值 dic = {'name':'barry','age':18,'sex':'man'} ty = dic.pop('re','没有此键') print(ty) 没有此键 # clear 清空 dic = {'name':'barry','age':18,'sex':'man'} dic.clear() print(dic) {} # popitem 删除最后一个键值对，3.5之前是随机删除，3.6删除最后一个键值对 dic = {'name':'barry','age':18,'sex':'man'} lo = dic.popitem() print(dic) {'name': 'barry', 'age': 18} # 删除整个字典 dic = {'name':'barry','age':18,'sex':'man'} del dic print(dic) 字典的修改# 改 dic = {'name':'barry','age':18,'sex':'man'} dic['age'] = 28 #重新定义age键的值 print(dic) # update 更新 dic1 = {'name':'barry','age':18,'sex':'man'} dic2 = {'name':'nji','age':'18','id':'001'} dic2.update(dic1) #将dic1字典中的键值对覆盖添加到dic2，dic1不变 print(dic2) {'name': 'barry', 'age': 18, 'id': '001', 'sex': 'man'} # update 正常添加 dic = {'name':'barry','age':18,'sex':'man'} dic.update(weight=150,high=175) #一次添加多个键值对 print(dic) {'name': 'barry', 'age': 18, 'sex': 'man', 'weight': 150, 'high': 175} 字典的查询# 查 dic = {'name':'barry','age':18,'sex':'man'} print(dic['name']) # 按键查对应的值，没有此键会报错 barry tr = dic.get('age1','没有此键') # 定义没有此键时的返回值 print(tr) 没有此键 字典的其他操作dic = {'name':'barry','age':18,'sex':'man'} print(dic.keys()) dict_keys(['name', 'age', 'sex']) print(dic.values()) dict_values(['barry', 18, 'man']) print(dic.items()) dict_items([('name', 'barry'), ('age', 18), ('sex', 'man')]) # for循环得到的是keys值 for i in dic: print(i) name age sex 字典的嵌套联系# 字典的嵌套练习 dic = { 'l1':['alex', '太白'], 'id':3, 1:{ 'data': 20181225, 'place': '深圳校区', 'class': 'python3期', 'name_list': ['awq', 'xx'], } } # 1.给小列表['alex', '太白'] alex后面插入一个字符串，'aaa' dic['l1'].insert(1,'aaa') print(dic) # 2.将id对应的3变成1 dic['id'] = 1 # 3.将1对应的字典的data的值变成20181224 dic[1]['data'] = 20181224 print(dic) # 4.将name_list对应的awq全部变成大写 dic[1]['name_list'][0] = dic[1]['name_list'][0].swapcase() print(dic) # 5.将name_list对应的xx删除 dic[1]['name_list'].pop(1) print(dic) 将字典数据格式化输出# 格式化输出 msg = '我叫%s,我身高%s，年龄%s' % ('ed',180,23) print(msg) # 将字典数据格式化输出 dic = {'name':'barry','age':18,'sex':'男'} mk = '我叫%(name)s,今年%(age)s,性别%(sex)s' % dic print(mk) 返回一个新的字典# 返回一个新的字典，键从可迭代对象里面获取，值不变 dic1 = dict.fromkeys('top','ed') dic2 = dict.fromkeys(['lop'],'努力') print(dic1) {'t': 'ed', 'o': 'ed', 'p': 'ed'} print(dic2) {'lop': '努力'} dicu = dict.fromkeys([1,2,3],['alex']) print(dicu) {1: ['alex'], 2: ['alex'], 3: ['alex']} # 坑:值如果是一个可变的数据类型，那么所有的值都是一个内存地址 dicu[1].append(000) print(dicu) {1: ['alex', 0], 2: ['alex', 0], 3: ['alex', 0]} # 给dicu[1]这个列表赋值000，所有列表的值都是000，因为列表所有的值都指向一个内存地址 数据类型的补充# 数据类型的补充 str ---> list split list ---> str join 0,'',[],{},(),set() ---> bool:false # 列表和元组的互换 # list &lt;---> tuple jk = [1,2,3] yu = tuple(jk) print(yu) uy = list(yu) print(uy) # dict ---> list dico = {'name':'kasha','ui':'io'} print(list(dico)) ['name', 'ui'] # dict ---> tuple dich = {'name':'yu','age':15} print(tuple(dich)) ('name', 'age') # 元组中只有一个元素并且没有逗号，则它不是元组，它与元素数据类型相同 t1 = (1,) t2 = ('al',) t3 = ([1,2,3],) print(t1,t2,t3) (1,) ('al',) ([1, 2, 3],) t1 = (1) t2 = ('al') t3 = ([1,2,3]) print(t1,t2,t3) 1 al [1, 2, 3] 将索引为奇数位的元素删除# 将索引为奇数位的元素删除,列表是不等长的 # 方法一 li = [11,36,56,48,79,45,21,65] del li[1::2] # 1-所有，步长为2 print(li) # 方法二 li = [11,36,56,48,79,45,21,65] new_li = [] # 定义一个空列表 for index in range(len(li)): # 循环 if index % 2 == 0: # 如果能被2整除 new_li.append(li[index]) # 如果能整除，就加入到new_li列表里面，这样索引是奇数位的元素就被删除了 li = new_li print(li) # 方法三 li = [11,36,56,48,79,45,21,65] for index in range(len(li)-1,-1,-1): if index % 2 == 1: li.pop(index) print(li) 将字典中键含有k元素的键值对删除# 将字典中键含有k元素的键值对删除 dict = {'ko':'ty','df':54,'13k':'hu','jl':'lp'} # 循环列表时不能改变字典的大小 lo = [] # 定义一个空的列表 for i in dict: # 将字典循环给i，赋值时是只将key赋值 if 'k' in i: # 如果k存在于i中 lo.append(i) # 则把这些有k元素的键值对添加到lo这个空字典 for y in lo: # 将lo字典循环给y dict.pop(y) # 通过键去删除键值对 print(dict) enumerate()# enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中 s1 = \"Hello\" for i,y in enumerate(s1,start=1): print(i,y) 1 H 2 e 3 l 4 l 5 o s2 = [\"top\",\"jun\",\"mid\",\"adc\",\"sup\"] for i,j in enumerate(s2,start=1): print(i,j) 1 top 2 jun 3 mid 4 adc 5 su 集合集合创建# 集合的创建 set1 = {\"er\",\"mk\",\"lk\"} print(set1) set2 = ('lk','oi',\"er\") # 不一定要{}或者(),只要是迭代对象就行 print(set2) 集合的无序特点# 集合是无序的 set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.add(\"fpx\") print(set1) {'rng', 'top', 'skt', 'fpx', 'we'} #增加一个元素，不会按照顺序添加，每一次执行代码，顺序都会改变 集合的迭代增加set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.update(\"fpx\") #迭代增加会把整个字符串拆分为多个字符进行增加 print(set1) {'skt', 'x', 'rng', 'top', 'f', 'p', 'we'} 集合的删除set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.remove(\"skt\") # 指定删除元素 print(set1) {'top', 'we', 'rng'} set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.pop() # 随机删除一个元素 print(set1) set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.clear() # 清空集合 print(set1) set() 集合的元素是不可变类型set1 = {\"we\",\"gb\",[\"rf\",\"gb\"]} print(set1) # 集合里面存在列表元素，执行会报错 set1 = {\"we\",\"gb\",(\"vf\",\"jin\",1)} print(set1) # 集合里面存在元组元素可以执行，因为元组是不可变类型 面试必考# 面试必考 list1 = [1,2,3,4,5] list2 = [2,3,4,5,6] # 将list1和list2的元素集合起来并去重 new_list = list1 + list2 print(new_list) new_set = list(set(new_list)) #将new_list转换为集合，再转换为list print(new_set) [1, 2, 3, 4, 5, 2, 3, 4, 5, 6] [1, 2, 3, 4, 5, 6] 电影投票# 电影投票:程序先给出几个目前正在上映的电影列表. 由用户给每个电影投票. # 最终将该用户投票信息公布出来 lst = ['北京遇上西雅图', '解救吴先生', '美国往事', '西西里的美丽传说'] lst = ['北京遇上西雅图', '解救吴先生', '美国往事', '西西里的美丽传说'] # print(lst) dic = dict.fromkeys(lst,0) #定义一个字典，key来自lst列表，值是0 while True: for num,name in enumerate(lst,start=1): #定义电影序号和电影来自lst列表 print('{}\\t{}'.format(num,name)) #列出电影序号和电影 name_num = input('请输入你喜欢的电影序号，或者q/Q退出:').strip() #记录用户所喜欢的电影序号 if name_num.isdigit(): #如果用户输入的是数字则进入，否则输出206行的：你输入有误，请重新输入 name_num = int(name_num) #用户输入的必须是整数 if 0 &lt; name_num &lt; len(lst): #控制用户输入数字的范围必须是比0大，比列表总长度小 dic[lst[name_num-1]] += 1 #将用户输入的值记录到dic空字典，lst[name_num-1] == dic字典的第一元素，是0 print('已成功为%s投票' %(lst[name_num-1])) #提示用户投票成功 else: print(\"没有该序号的电影，请重新输入\") #如果输入的范围不对，提示没有这个序号的电影 elif name_num.upper() == 'Q': #如果用户输入q就退出 break else: print(\"你输入有误，请重新输入\") for movie_name,total_num in dic.items(): #以列表返回可遍历的键值 print(\"%s电影的总得票数%s\" %(movie_name,total_num))","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day02","slug":"Python基础day02","date":"2020-04-24T04:14:29.000Z","updated":"2020-06-02T07:51:22.008Z","comments":true,"path":"post/34c92de1.html","link":"","permalink":"https://www.missf.top/post/34c92de1.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 格式化输出# 格式化输出 name = input(\"请输入姓名：\") age = input(\"请输入年龄：\") job = input(\"请输入职业：\") hobby = input(\"请输入爱好\") msg = \"\"\"------ info of %s ------ Name : %s Age : %s job : %s Hobbie : %s ------ end ------\"\"\" % (name,name,age,job,hobby) print(msg) # 坑:单个%号默认被当成一个占位符，如果想单纯的表示%号，请使用%% msg = '我叫%s,今年%s岁,python入门1%%.' % ('荒原饮露','23') print(msg) 运算符 运算符 描述 实例 = 简单的赋值运算符 c = a + b 将 a + b 的运算结果赋值给c += 加法赋值运算符 c += a 等效于 c = c + a -= 减法赋值运算符 c -= a 等效于 c = c - a *= 乘法赋值运算符 c *= a 等效于 c = c * a /= 除法赋值运算符 c /= a 等效于 c = c / a %= 取模赋值运算符 c %= a 等效于 c = c % a **= 幂赋值运算符 c *= a 等效于 c = c * a //= 取整赋值运算符 c //= a 等效于 c = c // a and “与”，如果 x 为False，x and y 返回False，否则返回y的计算值 两边为True才为True or “或”， 如果 x 为True，返回True，否则它返回y的计算值 一边为True则为True not “非”， 如果 x 为True，返回False，如果 x 为False，返回True True则False，反之 逻辑运算符的优先级() > not > and > or and 两个条件必须同时成立才为True or 两个条件有一个成立则为True not 条件为True则结果为False，条件为False则结果为True 运算符的不等式计算print(2 > 1 and 3 > 4) 两边式子同时成立，才会为True，否则为False print(2 > 1 and 3 > 4 or 4 &lt; 5 and 6 &lt; 7) 先计算and，式子为False or True，结果则为True print(1 > 2 and 3 &lt; 4 or 4 > 5 and 2 > 1 or 9 &lt; 8) 先计算and，式子为False or False or False，结果为False 运算符数字计算x or y # if x is True，return x else return y.如果x为True则返回X，否则返回y print(1 or 2) 1 print(3 or 2) 3 print(0 or 2) 2 # x and y和x or y是相反的 print(1 and 2) 2 print(8 and 0) 0 print(-100 and 2) 2 print(1 and 2 or 3 and 5) == print(2 or 5) 2 编码初识ASCII ASCII:早期的密码本，只包含英文字母，数字，特殊字符与01的对应关系 采用 8位比特（bit） == 1byte（字节） 在ascll编码中 8位比特表示一个字节表示一个字符 h e l l o = 01101000 01100101 01100111 0110011 01100101 缺点:只为英文使用者考虑，不能处理中文和其他国家的文字 GBK 由于ASCII编码，于是每个国家都提出了不同的编码来适应自己的语言 GBK 只包含本国文字（以及英文字母，数字，特殊字符）与01对应关系 GBK是采用单双字节变长编码，英文使用单字节编码，完全兼容ASCII字符编码，中文部分采用双字节编码 a 太 白 = 01101000 01100101 01100111 0110011 01100101 # 1个英文占1个字节，1个中文字符占2个字节，共5字节 UNICODE 由于ASCII编码的局限性，unicode应运而生 unicode:万国码，将全世界所有的文字都统一到一套编码里面 采用32位比特(bit)== 4byte 在unicode编码中 32位比特表示4个字节表示一个字符 a：00000000 00010010 00000000 00010010 中：00000000 10010010 00000000 10010010 缺点:如果使用unicode编码来存储英文，这会大量浪费空间，因为我们知道一个英文字符只占一个字节，而另外三个字节就浪费掉了，这样在存储和传输上非常不划算 UTF-8 utf-8:包含全世界所有的文字与二进制01的对应关系,最少用8位表示一个字符 utf-8是一种针对Unicode的可变长度字符编码,是对Unicode编码的压缩和优化，将所有的字符和符号进行分类 英文: 00000010 8位表示一个字节表示一个字符 欧洲文字: 00000010 00100000 16位表示两个字节表示一个字符 中国(亚洲): 00000010 00000010 00000010 24位表示三个字节表示一个字符 例子 'old男孩' GBK:7个字节 utf-8:9个字节 十进制转换为二进制关键要点:除二取余，倒序排列，高位补零。 将十进制数42不断除以2，得到的余数非别是:010101，然后倒序排列，42所对应的二进制就是101010，然后高位补零就是:00101010 负整数转换为二进制，以-42为例，先得到42的二进制，然后取反(0变1，1变0)再加一，就是11010101 + 1，结果为11010110 二进制转换成十进制 1 0 0 1 0 1 1 0 1 * 2^7 0 * 2^6 0 * 2^5 1 * 2^4 0 * 2^3 1 * 2^2 1 * 2^1 0 * 2^0 将这些数相加，得到的就是10010110这个二进制数的十进制数 128 + 0 + 0 + 16 + 0 + 4 + 2 + 0 = 150 数据类型之间的转换int（整数） --> bool（布尔值） 非零即True bool（布尔值） --> int（整数） True 1 False 0 str（字符串） --> bool（布尔值） 非空即True str（字符串） --> int（整数） str（13 ）转换为整数，会强制去掉空格变成int（13） bool（布尔值） --> str（字符串） 还是True，但是str类型的True，失去True的意义 y = True u = str(y) print(u,type(u)) True &lt;class 'str'> # 由于是str数据类型的True，下面的3 + u会报错，如果是bool数据类型的True可以与数字相加 print(3 + u) 字符串的切片字符串索引示意图请记住切片原则:顾首不顾尾 按照索引取值s = 'python骑士计划第三期' s1 = s[0] s2 = s[-1] print(s1) # p print(s2) # 期 按照切片取值s = 'python骑士计划第三期' # 照切片取值，顾首不顾尾，s5 = s[6:-3] 6就是第六个字符以后，-3就是倒数第三个字符以前 s3 = s[0:6] # 是从零开始数。取整个字符串可以写成s3 = s[:6],取整个字符串是s3 = s[:] print(s3) # python s4 = s[:6] # 相当于s[0:6]，0可以不写，默认从零开始 print(s4) # python s5 = s[6:-3] print(s5) # 骑士计划 s6 = s[6:10] print(s6) # 骑士计划 切片加步长取值# 步长就是每一步的长度，取pto字符串，要先划分区域，再定义隔几个字符去取 s = 'python骑士计划第三期' s7 = s[:6:2] # 划分区域为 0-6（区域为:python，从首个字符串开始取），步长为2 print(s7) # pto s8 = s[7::2] # 划分区域为 7-最后（区域为:士计划第三期，从第七个字符之后开始取），步长为2 print(s8) # 士划三 s9 = s[-1:-4:-1] # 倒叙取值要加上反向步长 print(s9) # 期三第 print(s[:5:-1]) # 后面是-1所以是反向取值，区域定义为 0-5（python），但是区域也是反向的，所以是从期到n的区域里面取 骑士计划第三期 字符串的常用操作capitalize() 首字母大写s = 'faker' s1 = s.capitalize() print(s) # faker print(s1) # Faker center() 将字符串居中s = 'missf.top' s1 = s.center(50) print(s1) missf.top # 设置50的长度并把字符串居中 s2 = s.center(50,'*') print(s2) ********************missf.top********************* # 设置50的长度定义填充物并把字符串居中 swapcase() 大小写翻转sr = 'KubeRnEteS' print(sr.swapcase()) kUBErNeTEs title() 非字母隔开单词的首字母大写s = 'tpshow9nohup@mid' # 注意：第一个字母也会变成大写 print(s.title()) Tpshow9Nohup@Mid upper() 不区分大小写# 用途:验证码不区分大小写 username = input(\"请输入姓名:\") passworrd = input(\"请输入密码:\") code = 'AeTrd'.upper() your_code = input(\"请输入验证码:\").upper() if your_code == code: if username == 'alex' and passworrd == 'sb': print('登录成功') else: print('用户名或者密码错误') else: print('验证码不正确') startswich() endswith() 判断以什么为开头和结尾s = 'mowenjieadcarry' print(s.startswith('o')) False # 字符串不是以o开头，结果为False print(s.startswith('mo')) True # 字符串以mo开头，结果为True print(s.startswith('j',5)) # 切割五个字符之后是否是j开头，结果为True True print(s.endswith('ry')) # 判断以什么为结尾 True find() index() 通过元素找索引s = 'mowenjieadcarry' print(s.find('a')) 8 # 返回a元素前面的索引数 print(s.find('a',9,)) 11 # 从第九个字符后面开始找，找到的是第二个a # find和index功能几乎一样，区别只有find找不到会返回-1,index会报错 strip() 默认去除字符串前后的空格/换行符/制表符# strip() 默认去除字符串前后两端的空格，换行符，制表符 s = '\\n barry \\t \\n' print(s.strip()) # barry # strip 去除字符串两边的字符 s = 'kkohuang yuan yin lure' print(s.strip('kore')) # 会把kore切割成最小单位，从前后两边逐个去除 huang yuan yin lu # lstrip 只从前面去除 print(s.lstrip('k')) ohuang yuan yin lure # rstrip() 只从后面去除 print(s.rstrip('re')) kkohuang yuan yin lu split() 将字符串转化为列表s = 'kkohuang yuan yin lure' print(s.split()) # 默认以空格分割元素 ['kkohuang', 'yuan', 'yin', 'lure'] t = 'top:mid:adc' print(t.split(':')) # 指定以冒号进行分割 ['top', 'mid', 'adc'] print(t.split(':',1)) # 指定以冒号进行分割,分割一次 ['top', 'mid:adc'] t = ':mid:adc' # 只有两个分割符，但是转换成列表之后参数个数是n+1 print(t.split(':')) ['', 'mid', 'adc'] join() 列表转化为字符串t = ':mid:adc' s9 = '-'.join(t) # 将每个字符通过指定的连接符连接在一起 print(s9) :-m-i-d-:-a-d-c t1 = ['liz','zsd','awa'] s10 = ' '.join(t1) # 以空格为分隔符 print(s10) liz zsd awa # 将列表的多个元素转换回字符串 replace() 字符串替换t = 'faker是世界第一中单，faker也是一个屌丝，faker' s11 = t.replace('faker','55开',2) # 可以指定替换的次数，不指定次数则全部替换 print(s11) 55开是世界第一中单，55开也是一个屌丝，faker format() 格式化输出# 第一种 s = '我叫{}，我玩{}，我主玩的位置是{}'.format('bang','英雄联盟','adc') print(s) # 我叫bang，我玩英雄联盟，我主玩的位置是adc # 第二种 s = '我叫{0}，今年{1}，性别{2}，我依然叫{0}'.format('小明','20','女') print(s) # 我叫小明，今年20，性别女，我依然叫小明 # 第三种 s = \"\"\" 我叫{name}，今年{age}，性别{sex}，我依然叫{name} \"\"\".format(age=20,sex='女',name='小明') print(s) # 我叫小明，今年20，性别女，我依然叫小明 is 判断字符串和数字组成name ='huanyuan135' print(name.isalnum()) # 判断字符串由字母或数字组成 True print(name.isalpha()) # 判断字符串只由字母组成 False print(name.isdigit()) # 判断字符串只由数字组成 False count 计算字符串中某个字符出现的次数s = 'cdcdcdcdcdjvnjfnvjfn:jsvnsvpojwpd' print(s.count('f')) # 计算这个字符串f字符出现的次数 2 print(s.count('d')) 6 print(s.count('d',0,8)) # 切片，顾首不顾尾，从零开始到第八个字符的前面截断 4 print(s.count('d',8)) # 从零开始数，第八个字符到结束 2 len 统计字符串长度s = 'cdcdcdcdcdjvnjfnvjfn:jsvnsvpojwpd' print(len(s)) # 内置函数 33","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day01","slug":"Python基础day01","date":"2020-04-23T04:14:29.000Z","updated":"2020-06-30T07:03:45.687Z","comments":true,"path":"post/adc07c5b.html","link":"","permalink":"https://www.missf.top/post/adc07c5b.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 Python发展史 创始人:Guido，国人叫龟叔，在1989年的圣诞节写出来的 2005 - 2012，龟叔去了谷歌工作，谷歌大量使用Python 2005年国内第一家使用Python的公司—豆瓣 2012年国内兴起云计算的热潮，Python借助OpenStack又火了一把 2014年AI兴起，大量的公司使用Python去写算法 直到2017年Python才真正进入大众的视野 Python的应用领域 WEB开发:最火的Python web框架Django，还有支持异步高并发的Tornado，短小精悍的flask 网络编程:支持高并发的Twisted网络框架 爬虫:Python在爬虫领域几乎是霸主地位，具有非常多的爬虫模块支持 云计算:著名的云计算框架OpenStack就是用Python写的 人工智能和数据分析:Python是目前人工智能和数据分析领域公认的必备语言 自动化运维:在Linux运维领域，Python能做很多事情，特别是处理数据的能力非常出色 游戏开发:Python能做游戏开发，但是使用Python开发游戏的公司可能没有这么多 编译型语言核心:通过编译器将人类写出来的代码一次性全部编译成机器语言让计算机可以识别和执行 代表语言：c，c++，golang，java 优点:执行效率高 缺点:开发效率低，不可以跨平台 一般多用于研究所、研究院，对执行效率要求高，大数据的计算、底层的开发 解释型语言核心:解释器逐行解释代码，再逐行执行（python是解释器，java中叫虚拟机） 代表语言:Python，php，Java，ruby 优点:开发效率高，可以跨平台，可移植性强 缺点:执行效率相对编译型语言慢 Python的优缺点优点 Python是一门高级语言，不用关心底层内存指针等等 由于Python开源的本质，Python已经被移植到许多平台，具备非常高的可移植性 Python可以嵌入c语言的代码，c语言也可以嵌入Python的代码，具备可嵌入性 大量现有的第三方库和模块的支持，使得开发效率大大提高 缺点 执行速度比编译型语言慢，如果运行Python花了0.1s，同样的代码c语言花了0.01秒，这样c就比Python快了十倍 Python源码是以明文形式存放的，如果项目要求源代码必须是加密的，一开始就不应该选择Python 线程不能利用多核CPU的问题，这也是Python被人诟病最多的一个缺点 变量官方解释:将程序中一些中间结果暂时存到内存中，供后面程序调用 变量命名规则 变量必须由数字，字母，下划线任意组合 不能是数字开头 不能使用Python中的关键字（具体关键字后面再介绍） 变量要具有描述性 变量不能过长 变量不能使用中文 尽量使用驼峰体 定义Python变量age1 = 12 age2 = age1 age3 = age2 age2 = 24 print (age1,age2,age3) 12 24 12 # 注意：程序中会大量的出现和使用变量，变量中会暂存一些少量的数据，给其他变量代指 Python常量常量，用于定义不变的值。例如:身份证号，圆周率，历史记载，新中国成立时间:1949101 使用常量Python中的常量可以改变（不像c改变常量会报错），但约定俗成Python中将变量全部变成大写，就是表示常量，将一些不想让别人改变的量设置成常量，放在文件最上面 Python注释对某一段代码做解释说明，一般是精简的代码，别人可能看不懂，需要做简单的解释 单行注释#好好学习，天天向上 多行注释'''被注释的内容''' \"\"\" 被注释的内容 \"\"\" 基础数据类型初识int 整型i1 = 10 i2 = 20 print (i1 * i2) # 200 str 字符串python中凡是用引号引起来的内容就是字符串数据类型 ret1 = '荒原饮露' ret2 = \"荒原饮露\" ret3 = \"\"\"荒原饮露\"\"\" ret4 = '''荒原饮露''' print (ret1,ret2,ret3,ret4) bool 布尔值true # 真 false # 假 用于判断条件，逻辑语句真假 单双引号搭配使用msg = \"I' m huangyuanyinlu,18 year\" print (msg) # I' m huangyuanyinlu,18 year 字符串相加相乘a1 = 'Alex' a2 = 'sb' print (a1 + a2) # Alexsb print (a1 * 10) # AlexAlexAlexAlexAlexAlexAlexAlexAlexAlex input 用户交互让用户输入用户名密码，得到用户输入的数据，起到了人与程序的交互作用 name = input(\"请输入你的名字：\") age = input(\"请输入你的年龄：\") sex = input(\"请输入你的性别：\") print (name,age,sex) # 这里注意一点:凡是input得到的值，都是字符串数据类型 将用户输入的变量进行拼接name = input(\"请输入你的名字：\") age = input(\"请输入你的年龄：\") sex = input(\"请输入你的性别：\") msg = '我的姓名是' + name + ',' + '我的年龄是' + age + ',' + '我的性别是' + sex + '.' print (msg) # 我的姓名是荒原饮露,我的年龄是23,我的性别是男 if 流程控制语句if 单分支age = input (\"请输入年龄:\") age = int(age) # Python3x之后，input得到的数据都是字符串类型 print (age,type(age)) # 输出变量的数据类型 if age > 10: print('你已经不是10岁的小孩了'） if 多分支jineng = input('请输入你的技能:') if jineng == '三分球': print('可以参加三分球大赛') elif jineng == '中投': print('可以参加中距离投篮') elif jineng == '突破': print('可以参加1V1对抗赛') else: print('买票进场吧') if 嵌套# 登陆示例 username = input('请输入用户名：') password = input('请输入密码：') if username == '荒原饮露': if password == '123': print('登录成功') else: print('密码错误') else: print('用户名不存在') # 买票示例 has_ticket = int(input('请输入车票号码:')) knife_length = int(input('请输入刀的长度:')) if has_ticket == 23: print('车票检查通过，准备开始安检') if knife_length &lt; 20: print('刀不超过20厘米，允许上车') else: print('刀超过20厘米，不允许上车') else: print(\"没有车票\") while 循环单次循环flag = True while flag: print('麦迪') print('科比') print('杜兰特') flag = False print('詹姆斯') # flag = False后面的依然会输出，因为运行到最后才会重新回到while 打印1到100# 方法一 count = 1 flag = True while flag: print(count) count = count + 1 if count == 101: flag = False # 方法二 count = 1 while count &lt; 101: print(count) count = count + 1 # 不要见方法二代码少就不去理解方法一，因为方法一包含flag = True的编程思想 计算1加到100count = 1 sum = 0 while count &lt;= 101: sum = sum + count count = count + 1 if count == 101: break print(sum) # break是直接终止循环 continue打印1到10，但是跳过7 count = 0 while count &lt; 10: count = count + 1 if count == 7: continue # continue是跳出本次循环，继续执行下一个循环 print(count) count = 0 while count &lt; 10: count = count + 1 if count == 7: # 判断count的值，直接+1 count = count + 1 print(count) 打印100以内的偶数# 利用对2取余去判断是否偶数 count = 0 while count &lt; 101: if count % 2 == 0: print(count) count = count + 1 # 每次自加2去打印偶数，虽然这样的做法不专业，但是也是体现灵活编程思维的一种方式 count = 0 while count &lt; 101: print(count) count = count + 2 while else# while else :只有在while循环被break打断时，才不会执行else程序，否则循环完之后一定会执行else程序 count = 0 while count &lt;= 5: count = count + 1 if count == 3:break print(\"Loop\",count) else: print(\"循环正常执行\") count = 0 while count &lt;= 5: count = count + 1 print(\"Loop\",count) else: print(\"循环正常执行\") # while循环没有被打断，打印完Loop1-6之后还是会打印循环正常执行","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Hello World","slug":"Hello World","date":"2019-03-28T04:14:29.000Z","updated":"2020-06-02T07:51:22.003Z","comments":true,"path":"post/4a17b156.html","link":"","permalink":"https://www.missf.top/post/4a17b156.html","excerpt":"","text":"所有无法深入问题本质的那些人，最终都将离开这个行业。","categories":[{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/categories/Hello-World/"}],"tags":[{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/tags/Hello-World/"}]},{"title":"我在人间凑数的日子","slug":"我在人间凑数的日子","date":"2019-03-28T04:14:29.000Z","updated":"2020-07-08T09:13:11.272Z","comments":true,"path":"post/world.html","link":"","permalink":"https://www.missf.top/post/world.html","excerpt":"","text":"语言这东西，在表达爱意的时候如此无力，在表达伤害的时候，却如此锋利。 你住的城市下雨了，想问你有没有带伞，可我不敢。因为我怕你说没带，而我又无能为力，就像是我爱你，却给不了你想要的温暖。 十年太长，什么都会变。一辈子太短，一件事也有可能做不完。回忆永远站在背后，你无法抛弃，只能拥抱。 没有回音的山谷不值得纵身一跃。 世界上只有一种英雄、看透了生活的真相，却依然热爱生活。 你联系我，我就听你说，你不联系我，我就顺其自然；实不相瞒，我很想你，但我能控制，因为这样很酷。 我不知道凌晨五点该说晚安还是早安，也不知道这个年龄是该说爱还是喜欢。 曾经我发誓要把生命献给爱情，后来我没死，只是青春替我偿了命。 我与春风皆过客，你携秋水揽星河。 我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 从此无心爱良夜，任他明月下西楼。 仅一夜之间，我的心判若两人。 真正的离别没有长亭古道，也没有劝君更尽一杯酒，只是在一个和往常一样的清晨，有的人留在昨天了。 我吹过你吹过的晚风，那我们算不算相拥。 明智的放弃胜过盲目的执着，去吹吹风吧，能清醒的话，感冒也没关系。 以后不见面的日子要按年算了。 没有特别挚爱的东西，没有一定要得到的人，也没有非做不可的事。 艺术，值得为之痛苦。 我于杀戮之中盛放，亦如黎明中的花朵。 生如蝼蚁，当立鸿鹄之志，命薄如纸，应有不屈之心。 好像什么都还来得及，又好像什么都无能为力。 旧时王谢堂前燕，飞入寻常百姓家。 越过山丘，才发现无人等候。 没有好好告别的人一定会重逢。","categories":[{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/categories/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"}],"tags":[{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/tags/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"},{"name":"记忆","slug":"记忆","permalink":"https://www.missf.top/tags/%E8%AE%B0%E5%BF%86/"},{"name":"语录","slug":"语录","permalink":"https://www.missf.top/tags/%E8%AF%AD%E5%BD%95/"}]}],"categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"},{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/categories/ansible/"},{"name":"coding","slug":"coding","permalink":"https://www.missf.top/categories/coding/"},{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"},{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/categories/Hello-World/"},{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/categories/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"ansible","slug":"ansible","permalink":"https://www.missf.top/tags/ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.missf.top/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"},{"name":"coding","slug":"coding","permalink":"https://www.missf.top/tags/coding/"},{"name":"持续集成","slug":"持续集成","permalink":"https://www.missf.top/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"},{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/tags/Hello-World/"},{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/tags/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"},{"name":"记忆","slug":"记忆","permalink":"https://www.missf.top/tags/%E8%AE%B0%E5%BF%86/"},{"name":"语录","slug":"语录","permalink":"https://www.missf.top/tags/%E8%AF%AD%E5%BD%95/"}]}