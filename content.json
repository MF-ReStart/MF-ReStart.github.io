{"meta":{"title":"荒原饮露","subtitle":"可能是未来的架构师，也可能送外卖。","description":"","author":"荒原饮露","url":"https://www.missf.top","root":"/"},"pages":[{"title":"","date":"2020-09-11T10:56:09.202Z","updated":"2020-09-11T10:56:09.202Z","comments":false,"path":"categories/index.html","permalink":"https://www.missf.top/categories/index.html","excerpt":"","text":""},{"title":"","date":"2020-06-02T02:12:04.533Z","updated":"2020-04-13T10:37:41.000Z","comments":false,"path":"tags/index.html","permalink":"https://www.missf.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"MySQL 配置主从复制","slug":"MySQL 配置主从复制","date":"2020-09-10T08:47:49.000Z","updated":"2020-09-11T11:07:30.787Z","comments":true,"path":"post/4a05c739.html","link":"","permalink":"https://www.missf.top/post/4a05c739.html","excerpt":"","text":"环境准备mysql master: 10.10.110.180 mysql slave1: 10.10.110.181 mysql slave2: 10.10.110.182 MySQL主从同步原理当mysql master服务器上的数据发生改变时(增、删、改)，则将其改变写入binlog二进制日志中。slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开启一个I/O 线程请求master二进制事件，同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从库本地的中继日志中，从库将启动SQL线程从中继日志中读取二进制日志，在本地回放，使得从库数据和主库的数据保持一致，最后IO线程和SQL线程将进入睡眠状态，等待下一次被唤醒 主从同步的前提 master一定要开启binlog二进制日志，授予slave远程连接权限 mysql主从复制至少需要两个mysql实例，可以分布在不同服务器，也可以在同一台服务器 最好master实例和slave实例的mysql版本相同(如果不同，那么master实例版本需要低于slave实例) master实例和slave实例之间时间需同步 配置MySQL Master节点1.下载MySQL5.7的源安装包 wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm 2.安装MySQL5.7源 yum localinstall -y mysql57-community-release-el7-8.noarch.rpm 3.安装MySQL服务 yum install -y mysql-community-server 4.启动MySQL服务 systemctl start mysqld.service &amp;&amp; systemctl enable mysqld.service 5.查看密码 grep 'temporary password' /var/log/mysqld.log 6.登录MySQL修改密码 ALTER USER 'root'@'localhost' IDENTIFIED BY '!missf3T'; FLUSH PRIVILEGES; 7.授予slave实例远程连接权限 GRANT ALL PRIVILEGES ON *.* TO 'slave'@'%' IDENTIFIED BY '!missf3T' WITH GRANT OPTION; FLUSH PRIVILEGES; 8.修改MySQL配置文件 ... log-bin=mysql-bin server_id=180 port=53306 default-time_zone='+8:00' character-set-server=utf8mb4 wait_timeout=60 ... 9.重启MySQL systemctl restart mysqld 10.查看binlog记录日志信息的偏移量position mysql> show master status; +------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+-------------------+ | mysql-bin.000001 | 154 | | | | +------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 配置MySQL Slave节点1.安装MySQL,指定不与主库相同的server_id ... server_id=181 ... 2.指定主库信息,master信息会存到/var/lib/mysql/master.info文件中 mysql> change master to -> master_host=\"10.10.110.180\", -> master_user=\"slave\", -> master_password=\"!missf3T\", -> master_port=53306, -> master_log_file=\"mysql-bin.000001\", -> master_log_pos=154; Query OK, 0 rows affected, 2 warnings (0.01 sec) 3.启动slave线程,若要更改指定的主库信息,需先执行stop slave,修改完成后执行start slave mysql> start slave; Query OK, 0 rows affected (0.04 sec) 4.查看slave状态 mysql> show slave status\\G *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.10.110.180 Master_User: slave Master_Port: 53306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 154 Relay_Log_File: localhost-relay-bin.000005 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 154 Relay_Log_Space: 697 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0 Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 180 Master_UUID: ce5675fc-f34e-11ea-bd8e-000c29321c87 Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 1 row in set (0.00 sec) 验证主从同步效果在mysql master上创建测试数据，然后在mysql slave上查看数据是否已经同步成功 mysql> create database test; Query OK, 1 row affected (0.00 sec) mysql> use test; Database changed mysql> create table test(name varchar(25),city varchar(30),age int); Query OK, 0 rows affected (0.05 sec) mysql> insert into test.test values(\"mysql\",\"china\",11); Query OK, 1 row affected (0.39 sec) mysql> select * from test.test; +-------+-------+------+ | name | city | age | +-------+-------+------+ | mysql | china | 11 | +-------+-------+------+ 1 row in set (0.00 sec) mysql> 开启并行复制mysql的主从复制都是单线程的操作，就是说Slave_IO_Running和Slave_SQL_Running都是单线程的。主库所有DDL和DML的操作都是顺序写入到binlog中，从库的Slave_SQL_Running线程将主库的DDL和DML操作在从库回放。由于Slave_SQL_Running是单线程的缘故，如果从库有一个DDL需要执行十分钟，那么所有之后的DDL会等待这个DDL执行完才会继续执行，这就导致了延时，而mysql master节点可以并发执行，Slave_SQL_Running线程却不可以，这是主从同步出现延迟的关键原因 但是mysql5.7版本已经支持真正的并行复制功能，官方引入了基于组提交的并行复制Enhanced Multi-threaded Slaves(简称MTS)，因此复制延迟问题已经得到了极大的改进 # mysql5.7开启并行复制 slave-parallel-type=LOGICAL_CLOCK slave-parallel-workers=16 master_info_repository=TABLE relay_log_info_repository=TABLE relay_log_recovery=ON slave-parallel-type：默认值为DATABASE是基于库的并行复制方式。修改为LOGICAL_CLOCK是基于组提交的并行复制方式，因为组提交的事务都是可以并行回放，数据不会相互影响 slave-parallel-workers：因为引入了基于组提交的并行复制，可以开启多个worker线程并发执行relay log中主库提交的事务 查看并行复制是否配置成功 mysql> show variables like 'slave_parallel_%'; +------------------------+---------------+ | Variable_name | Value | +------------------------+---------------+ | slave_parallel_type | LOGICAL_CLOCK | | slave_parallel_workers | 16 | +------------------------+---------------+ 2 rows in set (0.00 sec)","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.missf.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.missf.top/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"Elastic 收集Java日志(9)","slug":"Elastic 收集Java日志(9)","date":"2020-09-08T10:20:14.000Z","updated":"2020-09-09T07:19:56.742Z","comments":true,"path":"post/5a1ae96.html","link":"","permalink":"https://www.missf.top/post/5a1ae96.html","excerpt":"","text":"安装Tomcattomcat属于java应用，这里收集tomcat日志作为示例 # 下载软件包 wget -P /server/tools/https://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.5.53/bin/apache-tomcat-8.5.53.tar.gz # 解压 tar xf apache-tomcat-8.5.53.tar.gz -C /usr/local/ &amp;&amp; mv /usr/local/apache-tomcat-8.5.53/ /usr/local/tomcat # 启动tomcat /usr/local/tomcat/bin/startup.sh 编写Filebeat pipelinefilebeat获取所有不以”[“开头的行，并将它们合并到上一行以”[“开头的行之后 filebeat.inputs: - type: log enabled: true paths: - /usr/local/tomcat/logs/catalina.out tags: [\"catalina\"] fields: server: tomcat type: tomcat-catalina fields_under_root: true multiline: pattern: '^\\[' negate: true match: after #output.console: output.redis: hosts: [\"10.10.110.194:56379\"] password: \"123456\" key: \"tomcat\" db: 0 datatype: list 模拟Tomcat报错日志往tomcat的日志写入错误信息，模拟报错信息 cat > /usr/local/tomcat/logs/catalina.out &lt;&lt; EOF Sep 09, 2020 5:50:33 PM org.apache.catalina.startup.Catalina stopServer SEVERE: Catalina.stop: org.xml.sax.SAXParseException; systemId: file:/usr/local/tomcat/conf/server.xml; lineNumber: 22; columnNumber: 45; Attribute name \"dda\" associated with an element type \"Server\" must be followed by the ' = ' character. at java.xml/com.sun.org.apache.xerces.internal.parsers.AbstractSAXParser.parse(AbstractSAXParser.java:1243) at java.xml/com.sun.org.apache.xerces.internal.jaxp.SAXParserImpl$JAXPSAXParser.parse(SAXParserImpl.java:635) at org.apache.tomcat.util.digester.Digester.parse(Digester.java:1495) at org.apache.catalina.startup.Catalina.stopServer(Catalina.java:485) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.apache.catalina.startup.Bootstrap.stopServer(Bootstrap.java:389) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:479) EOF 编写Logstash pipelineinput { redis { host => \"10.10.110.194\" port => 56379 password => \"123456\" db => \"0\" data_type => \"list\" key => \"tomcat\" } } output { if [type] == \"tomcat-catalina\" { if [tags][0] == \"catalina\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-tomcat-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Kibana展示数据这里展示数据是不显示完全的，我们可以指定字段查看更详细的信息 指定message字段，查看被合并成一行的tomcat报错日志","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic 收集Nginx日志(8)","slug":"Elastic 收集Nginx日志(8)","date":"2020-08-25T06:27:22.000Z","updated":"2020-09-09T04:03:07.084Z","comments":true,"path":"post/baa98a96.html","link":"","permalink":"https://www.missf.top/post/baa98a96.html","excerpt":"","text":"Nginx配置Json格式日志修改Nginx配置文件，定义输出json格式的日志，便于filebeat和logstash收集 http { log_format main '{\"@timestamp\": \"$time_iso8601\", ' '\"clientRealIp\": \"$remote_addr\", ' '\"scheme\": \"$scheme\", ' '\"method\": \"$request_method\", ' '\"host\": \"$host\", ' '\"url\": \"$request_uri\", ' '\"size\": $body_bytes_sent, ' '\"referrer\": \"$http_referer\", ' '\"agent\": \"$http_user_agent\", ' '\"upstream_addr\": \"$upstream_addr\", ' '\"request_time\": $request_time, ' '\"request_length\": $request_length, ' '\"upstream_connect_time\": \"$upstream_connect_time\", ' '\"upstream_response_time\": \"$upstream_response_time\", ' '\"upstream_status\": \"$upstream_status\", ' '\"status\": \"$status\"}'; } Filebeat配置文件编写filebeat配置文件，收集Nginx的access.log和error.log，并且添加自定义字段和标签存储到redis cat /etc/filebeat/filebeat-nginx.yml filebeat.inputs: - type: log enabled: true json.keys_under_root: true paths: - /usr/local/nginx/logs/access.log tags: [\"access\"] fields: server: nginx type: nginx-access fields_under_root: true - type: log enabled: true json.keys_under_root: true paths: - /usr/local/nginx/logs/error.log tags: [\"error\"] fields: server: nginx type: nginx-error fields_under_root: true processors: - drop_fields: fields: [\"input_type\", \"ecs.version\", \"host.name\", \"agent\", \"log.offset\"] #output.console: output.redis: hosts: [\"10.10.110.194:56379\"] password: \"123456\" key: \"nginx\" db: 0 datatype: list 控制台调试Filebeat输出的日志数据通过drop_fields去控制我们想要输出的字段，得到精简的日志数据 { \"@timestamp\": \"2020-09-07T18:08:49.000Z\", \"@metadata\": { \"beat\": \"filebeat\", \"type\": \"_doc\", \"version\": \"7.9.0\" }, \"server\": \"nginx\", \"ecs\": {}, \"host\": {}, \"log\": { \"file\": { \"path\": \"/usr/local/nginx/logs/access.log\" } }, \"json\": {}, \"input\": { \"type\": \"log\" }, \"type\": \"nginx-access\", \"message\": \"10.10.110.194 - - [08/Sep/2020:02:08:41 +0800] \\\"GET /848dd HTTP/1.1\\\" 404 153 \\\"-\\\" \\\"curl/7.29.0\\\"\", \"tags\": [\"access\"] } Logstash读取Redis中的日志数据logstash读取redis中的日志数据，并且在Kibana展示Nginx日志 # logstash配置文件通过我们定义的fields字段和标签匹配数据,将不同的数据存储到不同的index input { redis { host => \"10.10.110.194\" port => 56379 password => \"123456\" db => \"0\" data_type => \"list\" key => \"nginx\" } } output { # 通过字段和标签判断日志数据,存储到不同的index if [type] == \"nginx-access\" { if [tags][0] == \"access\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-nginx-access%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } if [type] == \"nginx-error\" { if [tags][0] == \"error\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-nginx-error%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Kibana展示Nginx日志我们可以在kibana上创建索引，查看Nginx日志，通过字段去统计和展示日志数据","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic 引入Filebeat(7)","slug":"Elastic 引入Filebeat(7)","date":"2020-08-20T03:58:57.000Z","updated":"2020-09-09T09:13:03.139Z","comments":true,"path":"post/9482a90c.html","link":"","permalink":"https://www.missf.top/post/9482a90c.html","excerpt":"","text":"引入Filebeat架构简介filebeat代替logstash去收集日志数据，然后将收集到的日志数据存储到redis或者kafka，再由logstash去消费数据。filebeat是非常轻量级单用途的日志采集器，属于Beats家族。早期的elk架构使用logstash收集、解析日志，但是logstash对内存、CPU、IO等资源消耗比较高(因为logstash是使用java语言编写的)，后来出现了使用golang编写的filebeat日志收集器，可以不依赖任何环境安装即可使用，同时对资源的占用可以忽略不计，使用filebeat替代logstash去收集日志是非常好的方案 安装Filebeat# 下载filebeat wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.9.0-x86_64.rpm # 安装 yum install -y filebeat-7.9.0-x86_64.rpm 编写Filebeat配置文件filebeat配置文件负责收集日志，然后将数据存到redis cat /etc/filebeat/filebeat.yml filebeat.inputs: - type: log enabled: true paths: - /var/log/messages tags: [\"messages\",\"syslog\"] #include_lines: ['sometext'] Filebeat仅导出与列表中的正则表达式匹配的行 #exclude_lines: ['^DBG'] Filebeat会删除列表中与正则表达式匹配的所有行 fields: # 可以指定字段向输出添加附加信息 type: system # fields_under_root: true # 如果为true,则自定义字段将作为顶级字段而不是作为fields字段的子字典 - type: log enabled: true paths: - /var/log/audit/audit.log tags: [\"audit\",\"syslog\"] fields: type: system # fields_under_root: true output.console: # 将收集到的日志数据输出到控制台,可以查看fields定义的字段 output.redis: # filebeat将收集到的日志存储到redis hosts: [\"10.10.110.194:56379\"] password: \"123456\" key: \"filebeat\" db: 0 timeout: 5 查看Filebeat输出的Json数据我们在调试日志格式时使用命令去启动filebeat，使用systemctl的方式去调试会出现很多转义符，不便于查看 /usr/bin/filebeat -c /etc/filebeat/filebeat.yml # 这里需要将控制台输出的数据json格式化 { \"@timestamp\": \"2020-09-07T16:17:42.615Z\", \"@metadata\": { \"beat\": \"filebeat\", \"type\": \"_doc\", \"version\": \"7.9.0\" }, \"ecs\": { \"version\": \"1.5.0\" }, \"host\": { \"name\": \"localhost.localdomain\" }, \"agent\": { \"ephemeral_id\": \"660a2bfb-9a56-43a8-ae93-788060f5d243\", \"id\": \"6a8ff370-52b5-4f89-ad9c-b6feecf938a9\", \"name\": \"localhost.localdomain\", \"type\": \"filebeat\", \"version\": \"7.9.0\", \"hostname\": \"localhost.localdomain\" }, \"log\": { \"offset\": 997322, \"file\": { \"path\": \"/var/log/messages\" } }, \"message\": \"Sep 8 00:01:01 localhost systemd: Started Session 7 of user root.\", \"tags\": [\"messages\", \"syslog\"], \"fields\": { # 这里由于filebeat配置文件中没有开启fields_under_root: true这个选项,所以我们定义的字段会在fields里面 \"type\": \"system\" }, \"input\": { \"type\": \"log\" } } 定义Filebeat输出的Json数据我们除了可以自己自定义字段，还可以删除一些filebeat默认输出的字段，让日志数据更加易于查看 # 定义filebeat配置文件,过滤不需要的json数据 filebeat.inputs: - type: log enabled: true # json.keys_under_root: true 开始json解析,不是json格式的日志不要开启此选项 paths: - /var/log/messages tags: [\"messages\",\"syslog\"] fields: type: system fields_under_root: true - type: log enabled: true paths: - /var/log/audit/audit.log tags: [\"audit\",\"syslog\"] fields: type: system fields_under_root: true processors: - drop_fields: fields: [\"input_type\", \"ecs.version\", \"host.name\", \"agent\", \"log.offset\"] # 将这些字段丢弃 output.console: 查看自定义之后的json数据 { \"@timestamp\": \"2020-09-07T17:37:59.500Z\", \"@metadata\": { \"beat\": \"filebeat\", \"type\": \"_doc\", \"version\": \"7.9.0\" }, \"tags\": [\"messages\", \"syslog\"], \"input\": { \"type\": \"log\" }, \"type\": \"system\", # fields_under_root: true 将作为顶级字段 \"ecs\": {}, \"host\": {}, \"log\": { \"file\": { \"path\": \"/var/log/messages\" } }, \"message\": \"Sep 8 01:35:28 localhost systemd-logind: Removed session 4.\" } Logstash消费Redis中的数据filebeat将日志数据存储到redis之后，logstash从redis读取日志数据就是非常简单的事情了 cat /etc/logstash/conf.d/sys-from-redis.conf input { redis { host => \"10.10.110.194\" port => 56379 password => \"123456\" db => \"0\" data_type => \"list\" batch_count => \"1\" key => \"filebeat\" } } filter { } output { if [type] == \"system\" { # 这里的匹配由filebeat输出的json数据格式来定义 if [tags][0] == \"messages\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-fromredis-messages-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } else if [tags][0] == \"audit\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"filebeat-fromredis-audit-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Elasticsearch查看数据索引的命名根据我们在logstash处理数据时的定义格式","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic 引入Redis(6)","slug":"Elastic 引入Redis(6)","date":"2020-08-17T10:48:56.000Z","updated":"2020-09-07T10:45:28.472Z","comments":true,"path":"post/23bc2fbc.html","link":"","permalink":"https://www.missf.top/post/23bc2fbc.html","excerpt":"","text":"引入Redis架构简介logstash分为shipper(负责收集日志数据)和indexer(负责对日志做过滤存储到ES)两个角色。当日志量达到一个量级之后，我们就不能继续使用logstash去收集和处理数据，由于ES的HTTP API处理能力有限，在日志写入频繁的情况下可能会超时、丢失，所以用队列来做缓冲在两个logstash角色之间可以引入redis或者kafka。使用消息队列的方式可减少ES压力，队列起到缓冲作用，也可以一定程度保护数据不丢失。同时我们还能将所有收集到的日志统一在logstash indexer进行处理 环境准备logstash 10.10.110.195 # logstash shipper生产数据,将获取到的数据存到redis logstash + redis 10.10.110.194 # logstash indexer消费redis中的日志数据 生产日志数据编写logstash pipeline配置文件，将收集到的日志数据存储到redis input { file { path => [\"/var/log/messages\"] type => \"syslog\" tags => [\"messages\",\"log\"] start_position => \"beginning\" } file { path => [\"/var/log/audit/audit.log\"] type => \"syslog\" tags => [\"audit\",\"log\"] start_position => \"beginning\" } } filter { } output { redis { host => [\"10.10.110.194:56379\"] password => \"123456\" db => \"0\" data_type => \"list\" key => \"logstash\" } } 启动logstash进行收集日志存储到redis /usr/share/logstash/bin/logstash -rf /etc/logstash/conf.d/syslog-toredis.conf Redis查看日志数据logstash在收集到日志数据并且添加上标签和类型然后存储到redis，我们可以返回列表的长度来得知日志数据是否被存储到redis {% image https://pic.imgdb.cn/item/5f55cd21160a154a674bc848.jpg '' '' %} 消费日志数据编写logstash pipeline配置文件，将redis中的日志数据存储到ES input { redis { host => \"10.10.110.194\" port => 56379 password => \"123456\" db => \"0\" data_type => \"list\" key => \"logstash\" } } filter { } output { if [type] == \"syslog\" { if [tags][0] == \"messages\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"syslog-fromredis-messages-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } else if [tags][0] == \"audit\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"syslog-fromredis-audit-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Redis查看消费的数据日志数据被消费完之后就代表已经写入到ES # redis中的key会全部存到ES中(日志数据被消费完) 127.0.0.1:56379> llen logstash (integer) 7041 127.0.0.1:56379> llen logstash (integer) 5791 127.0.0.1:56379> llen logstash (integer) 4541 127.0.0.1:56379> llen logstash (integer) 3041 127.0.0.1:56379> llen logstash (integer) 1666 127.0.0.1:56379> llen logstash (integer) 0 127.0.0.1:56379>","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Kibana展示系统日志(5)","slug":"Elastic Kibana展示系统日志(5)","date":"2020-08-16T10:39:44.000Z","updated":"2020-09-09T09:08:46.601Z","comments":true,"path":"post/c802a07c.html","link":"","permalink":"https://www.missf.top/post/c802a07c.html","excerpt":"","text":"编写logstash pipeline配置文件定义日志收集、过滤、存储的方式 input { file { path => [\"/var/log/messages\"] type => \"syslog\" tags => [\"messages\",\"log\"] start_position => \"beginning\" # 从文件开头读取 } file { path => [\"/var/log/audit/audit.log\"] type => \"syslog\" tags => [\"audit\",\"log\"] start_position => \"beginning\" } } filter { } output { if [type] == \"syslog\" { if [tags][0] == \"messages\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] # 存储带ES index => \"syslog-messages-%{+YYYY.MM.dd}\" # index的命名格式 } stdout { codec=> rubydebug } } else if [tags][0] == \"audit\" { elasticsearch { hosts => [\"http://10.10.110.191:9200\",\"http://10.10.110.192:9200\",\"http://10.10.110.193:9200\"] index => \"syslog-audit-%{+YYYY.MM.dd}\" } stdout { codec=> rubydebug } } } } Logstash收集日志存储到ES# 启动logstash,systemctl启动方式可以指定配置文件 /usr/share/logstash/bin/logstash -rf /etc/logstash/conf.d/syslog.conf # logstash常用参数 -n 指定logstash实例的名称,默认为当前主机名 -f 指定启动配置文件 -e 指定直接执行的配置文件内容,可以不指定-f参数了 -r 检测配置文件变化,自动重新加载 -t 检查配置的语法是否正确并退出 Elasticsearch查看数据索引的命名格式按日期去分割 将ES的日志索引到KibanaKibana的配置文件指定ES的地址，使用正则匹配去创建索引 配置时间过滤器字段 Kibana展示日志数据可以根据日志数据的字段去查看指定的信息","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Kibana(4)","slug":"Elastic Kibana(4)","date":"2020-08-14T07:56:54.000Z","updated":"2020-09-09T09:04:44.171Z","comments":true,"path":"post/e26112db.html","link":"","permalink":"https://www.missf.top/post/e26112db.html","excerpt":"","text":"Kibana简述Kibana是一个针对Elasticsearch的开源分析及可视化平台，用来搜索、查看交互存储在Elasticsearch索引中的数据。使用Kibana，可以通过各种图表进行高级数据分析及展示。Kibana让海量数据更容易理解，它操作简单，基于浏览器的用户界面可以快速创建仪表板(dashboard)实时显示Elasticsearch查询动态。设置Kibana非常简单，无需编码或者额外的基础架构，就可以完成Kibana安装并启动Elasticsearch索引监测 Kibana安装配置# 下载Kibana wget https://artifacts.elastic.co/downloads/kibana/kibana-7.8.1-x86_64.rpm # 安装 shasum -a 512 kibana-7.8.1-x86_64.rpm rpm --install kibana-7.8.1-x86_64.rpm # 修改Kibana配置文件 grep -v \"^#\" /etc/kibana/kibana.yml server.port: 5601 server.host: \"127.0.0.1\" elasticsearch.hosts: [\"http://10.10.110.191:9200\"] i18n.locale: \"zh-CN\" # 启动Kibana systemctl start kibana.service 配置Nginx代理Kibana配置Nginx反向代理实现鉴权 vim /usr/local/nginx/conf/nginx.conf server { listen 9090; server_name localhost; location / { auth_basic \"Restricted Access\"; auth_basic_user_file /usr/local/nginx/conf/passwd.db; # 账号密码文件 proxy_pass http://127.0.0.1:5601; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 配置验证登录账号密码 # 需要安装httpd-tools工具,文件里的密码是密文的 htpasswd -c /usr/local/nginx/conf/passwd.db admin # 连续输入两次密码 # 测试本机kibana能否连接,如果本机都不能连接,那么Nginx代理就没有意义 curl -L -u admin:12345678 http://127.0.0.1:5601 登录Kibana登录kibana的地址 http://10.10.110.194:9090/ Nginx账号密码 kibana web页面","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Logstash(3)","slug":"Elastic Logstash(3)","date":"2020-08-11T07:04:57.000Z","updated":"2020-09-01T07:00:22.418Z","comments":true,"path":"post/fe947601.html","link":"","permalink":"https://www.missf.top/post/fe947601.html","excerpt":"","text":"Logstash概述logstash是elasticsearch的数据管道，负责对数据源进行处理。工作原理分别是输入、过滤、输出。其中input(负责从数据源采集数据)和output(将数据传输到目的地)是必要的，filter(将数据修改为你指定的格式或内容)是非必要的。logstash是插件式管理模式，在输入、过滤、输出以及编码过程中都可以使用插件进行定制，Logstash社区有超过200种可用插件 Logstash安装这里使用yum是因为二进制安装的jdk，在Logstash启动时会报could not find java # 安装jdk yum install -y java-11-openjdk java-11-openjdk-devel java-11-openjdk-headless # 下载logstash wget https://artifacts.elastic.co/downloads/logstash/logstash-7.8.1.rpm # 安装logstash yum install -y logstash-7.8.1.rpm # 修改启动分配内存 vim /etc/logstash/jvm.options -Xms512m -Xmx512m # 第一个logstash示例 cd logstash Installation directory bin/logstash -e 'input { stdin { } } output { stdout {} }' 执行结果如下 Logstash配置详解Logstash的配置有两个必须元素(input和output)和一个可选元素(filter) input { # 输入 stdin { ... # 标准输入 } } filter { # 过滤 ... # 对数据进行分割、截取等处理 } output { # 输出 stdout { ... # 标准输出 } } 输入 采集各种样式、大小和来源的数据，数据往往以各种各样的形式，或分散或集中地存在于不同的系统中 Logstash支持各种输入选择 ，可以在同一时间从众多常用来源捕捉事件 能够以连续的流式传输方式，轻松地从您的日志、指标、Web 应用、数据存储以及各种AWS服务采集数据 过滤 实时解析和转换数据，Logstash过滤器能够解析各个事件 识别已命名的字段以构建结构，并将它们转换成通用格式，以便更轻松更快速地分析和实现商业价值 输出 Logstash提供众多输出选择，你可以将数据发送到指定的地方，并且能够灵活地解锁众多下游用例 输入插件Stdin示例从标准输入读取数据输出到标准输出 input { stdin { } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 mwj { \"host\" => \"localhost.localdomain\", \"@timestamp\" => 2020-08-12T18:36:32.683Z, \"message\" => \"mwj\", \"@version\" => \"1\" } test data { \"host\" => \"localhost.localdomain\", \"@timestamp\" => 2020-08-12T18:36:47.691Z, \"message\" => \"test data\", \"@version\" => \"1\" } 输入插件File示例从文件中读取数据，输出到标准输出 input { file { # 调用file这个插件,logstash社区有非常多的插件可以供我们使用 path =>\"/var/log/messages\" # 数据源来自这个文件的内容 tags =>\"messages\" # 打标签 type =>\"syslog\" } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 { \"type\" => \"syslog\", \"@timestamp\" => 2020-08-13T11:41:45.031Z, \"@version\" => \"1\", \"path\" => \"/var/log/messages\", \"host\" => \"localhost.localdomain\", \"tags\" => [ [0] \"messages\" ], \"message\" => \"Aug 13 19:41:44 localhost yum[86466]: Installed: 1:nginx-mod-http-image-filter-1.16.1-1.el7.x86_64\" } { \"type\" => \"syslog\", \"@timestamp\" => 2020-08-13T11:41:45.032Z, \"@version\" => \"1\", \"path\" => \"/var/log/messages\", \"host\" => \"localhost.localdomain\", \"tags\" => [ [0] \"messages\" ], \"message\" => \"Aug 13 19:41:44 localhost yum[86466]: Installed: 1:nginx-all-modules-1.16.1-1.el7.noarch\" } 输入插件TCP示例logstash从本机端口读取数据，其他机器通过nc工具发送数据到logstash指定的端口 input { tcp { port =>12345 # 监听12345端口 type =>\"nc\" # 通过nc工具使用tcp/udp连接去发送网络数据给logstash } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 { \"@version\" => \"1\", \"type\" => \"nc\", \"@timestamp\" => 2020-08-13T06:28:13.448Z, \"host\" => \"10.10.110.191\", \"port\" => 35228, \"message\" => \"we\" # logstash接收到其他机器nc工具发送过来的信息(nc 10.10.110.194 12345) } { \"@version\" => \"1\", \"type\" => \"nc\", \"@timestamp\" => 2020-08-13T06:28:40.148Z, \"host\" => \"10.10.110.191\", \"port\" => 35228, \"message\" => \"test\" } 编解码插件Json示例只有输入json格式的数据才会被成功编解码，不是json格式的数据logstash不处理 input { stdin { codec => json { charset => [\"UTF-8\"] } } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 {\"name\":\"孙七\",\"age\": 24,\"mail\": \"555@qq.com\",\"hobby\":\"听音乐、看电影\"} { \"hobby\" => \"听音乐、看电影\", \"name\" => \"孙七\", \"mail\" => \"555@qq.com\", \"age\" => 24, \"@version\" => \"1\", \"host\" => \"localhost.localdomain\", \"@timestamp\" => 2020-09-01T14:27:24.066Z } 编解码插件Multline示例multline会将不是以字母开头的行合并到上一行(next是合并到下一行)，下面模拟java日志报错 input { stdin { codec => multiline { pattern => \"^\\s\" what => \"previous\" } } } filter { } output { stdout { codec => rubydebug } } 执行结果如下 [INFO] 2020-08-13 15:56:53,195 --AsyncResolver-bootstrap-executor-0-- # 模拟java报错信息 at com.curre at org.sprin at org.sprin { \"@timestamp\" => 2020-09-01T14:36:50.642Z, \"tags\" => [ [0] \"multiline\" ], \"@version\" => \"1\", \"message\" => \"[INFO] 2020-08-13 15:56:53,195 --AsyncResolver-bootstrap-executor-0--\\n at com.curre\\n at org.sprin\\n at org.sprin\", \"host\" => \"localhost.localdomain\" } 过滤插件Json示例将json数据做过滤放在content字段里面 input { stdin { } } filter { json { source => \"message\" target => \"content\" } } output { stdout { codec => rubydebug } } 执行结果如下 {\"request\":\"get\", \"status\":\"404\", \"bytes\":\"563\"} # 数据源 { \"host\" => \"localhost.localdomain\", \"@timestamp\" => 2020-08-13T09:28:26.702Z, \"content\" => { \"request\" => \"get\", \"bytes\" => \"563\", \"status\" => \"404\" }, \"message\" => \"{\\\"request\\\":\\\"get\\\", \\\"status\\\":\\\"404\\\", \\\"bytes\\\":\\\"563\\\"}\", \"@version\" => \"1\" } 过滤插件Kv示例以&amp;和?作为分隔符，得到key=value形式的数据 input { stdin { } } filter { kv { field_split => \"&amp;?\" # 以&amp;和?作为分隔符,得到key=value的形式 field_split_pattern => \":+\" # 以一个或者多个:作为分隔符 } } output { stdout { codec => rubydebug } } 执行结果如下 pin=12345~0&amp;d=123&amp;e=foo@bar.com&amp;oq=bo?oi=bo&amp;ss=12345: # 数据源 { \"d\" => \"123\", \"pin\" => \"12345~0\", \"ss\" => \"12345:\", \"oq\" => \"bo\", \"oi\" => \"bo\", \"e\" => \"foo@bar.com\", \"@timestamp\" => 2020-08-13T09:31:41.881Z, \"host\" => \"localhost.localdomain\", \"message\" => \"pin=12345~0&amp;d=123&amp;e=foo@bar.com&amp;oq=bo?oi=bo&amp;ss=12345:\", \"@version\" => \"1\" } 输出插件ES示例logstash将日志输出到ES节点，存储到missf这个index并且以时间去命名 output { elasticsearch { hosts => \"localhost:9200\" index => \"missf-%{+YYYY.MM.dd}\" } }","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Elasticsearch(2)","slug":"Elastic Elasticsearch(2)","date":"2020-08-05T10:26:09.000Z","updated":"2020-09-09T08:57:44.414Z","comments":true,"path":"post/1abc58c4.html","link":"","permalink":"https://www.missf.top/post/1abc58c4.html","excerpt":"","text":"Elasticsearch简介Elasticsearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java语言开发，并作为Apache许可条款下的开放源代码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索、稳定、可靠、快速、使用方便 我们建立一个网站或应用程序，并要添加搜索功能，但是想要完成搜索工作的创建是非常困难的。我们希望搜索解决方案要运行速度快，我们希望能有一个零配置和一个完全免费的搜索模式，我们希望能够简单地使用JSON通过HTTP来索引数据，我们希望搜索服务器始终可用，我们希望能够从一台开始并扩展到数百台，我们要实时搜索，我们要简单的多用户，我们希望建立一个云的解决方案。因此我们利用Elasticsearch来解决所有这些问题及可能出现的更多其它问题 Elasticsearch集群部署Elasticsearch的发展是非常快速的，所以在ES5.0之前，ELK的各个版本都不统一，出现了版本号混乱的状态，所以从5.0开始，所有Elastic Stack中的项目全部统一版本号。目前最新版本是7.8.1 # 环境准备 ES1 10.10.110.191 ES2 10.10.110.192 ES3 10.10.110.193 # 下载elasticsearch和校验文件 wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.1-x86_64.rpm wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.1-x86_64.rpm.sha512 # 安装elasticsearch shasum -a 512 -c elasticsearch-7.8.1-x86_64.rpm.sha512 yum install -y elasticsearch-7.8.1-x86_64.rpm # 修改jvm启动参数,根据自己机器决定 vim /etc/elasticsearch/jvm.options -Xms512m # 确保Xmx和Xms的大小是相同的，其目的是为了能够在java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源 -Xmx512m # 修改进程在VMAs(虚拟内存区域)创建内存映射最大数量 echo \"vm.max_map_count=655360\" >> /etc/sysctl.conf &amp;&amp; sysctl -p # 修改elasticsearch配置文件 grep -v '^#' /etc/elasticsearch/elasticsearch.yml cluster.name: elk-cluster # 集群名称,所有节点一样 node.name: node-1 # 不同节点,分别用node-1/node-2/node-3... path.data: /var/lib/elasticsearch # 数据目录,如果加入集群失败可以清空数据目录再重启服务 path.logs: /var/log/elasticsearch # 日志目录 network.host: 10.10.110.191 # 不同节点,分别用10.10.110...... http.port: 9200 # 监听端口 discovery.seed_hosts: [\"10.10.110.191\", \"10.10.110.192\", \"10.10.110.193\"] # 集群发现,可以写成10.10.110.191:9200 cluster.initial_master_nodes: [\"node-1\", \"node-2\", \"node-3\"] # 指定可以成为master的节点,此参数只有在初始化集群时生效 # 启动elasticsearch服务 systemctl start elasticsearch.service Elasticsearch集群常用查询查看集群状态 curl -X GET http://10.10.110.191:9200/_cluster/health?pretty # 响应 { \"cluster_name\" : \"elk-cluster\", \"status\" : \"green\", # 集群状态红绿灯,绿:健康,黄:亚健康,红:病态 \"timed_out\" : false, \"number_of_nodes\" : 3, \"number_of_data_nodes\" : 3, \"active_primary_shards\" : 0, \"active_shards\" : 0, \"relocating_shards\" : 0, \"initializing_shards\" : 0, \"unassigned_shards\" : 0, \"delayed_unassigned_shards\" : 0, \"number_of_pending_tasks\" : 0, \"number_of_in_flight_fetch\" : 0, \"task_max_waiting_in_queue_millis\" : 0, \"active_shards_percent_as_number\" : 100.0 } 查看节点状态 curl -X GET 'http://10.10.110.191:9200/_cat/nodes?v' ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name 10.10.110.191 62 93 0 0.00 0.01 0.05 dilmrt - node-1 10.10.110.193 62 74 0 0.00 0.01 0.05 dilmrt * node-3 # *代表当前节点是master 10.10.110.192 70 75 0 0.00 0.01 0.05 dilmrt - node-2 查询节点所有索引 curl -X GET 'http://10.10.110.191:9200/_cat/indices?v' health status index uuid pri rep docs.count docs.deleted store.size pri.store.size green open data njHuT0XvSOa2NHPJM3Aj-g 1 1 3 0 19.5kb 9.7kb 查询一个索引所有数据 curl -X GET 'http://10.10.110.191:9200/data/_search/?pretty' Elasticsearch-head安装由于ES官方并没有为ES提供界面管理工具，仅仅是提供了后台的服务。elasticsearch-head是一个为ES开发的一个页面客户端工具，其源码托管于GitHub，地址为：https://github.com/mobz/elasticsearch-head elasticsearch-head提供了四种安装方式： 源码安装通过npm run start启动(不推荐) 通过docker安装(推荐) 通过chrome插件安装(推荐) 通过ES的plugin方式安装(不推荐) 通过docker安装 # 拉取镜像 docker pull mobz/elasticsearch-head:5 # 启动容器 docker run -itd --name \"elasticsearch-head\" -p 9100:9100 -v elasticsearch_head:/usr/src/app --restart always mobz/elasticsearch-head:5 # 由于前后端分离开发,所以会存在跨域问题,需要在服务端做CORS的配置 vim /etc/elasticsearch/elasticsearch.yml http.cors.enabled: true http.cors.allow-origin: \"*\" # Web访问 http://10.10.110.191:9100/ Elasticsearch Head数据浏览不显示数据，使用浏览器按F12查看发现406 Not Acceptable错误，出现这个错误是因为后台返回的数据是json格式前台无法解析，解决方法如下： # 找到docker数据卷在宿主机上的目录 docker volume inspect elasticsearch_head # 修改数据卷目录下_site/vendor.js文件 contentType: \"application/x-www-form-urlencoded\" 修改为 contentType: \"application/json;charset=UTF-8\" var inspectData = s.contentType === \"application/x-www-form-urlencoded\" &amp;&amp; 修改为 var inspectData = s.contentType === \"application/json;charset=UTF-8\" &amp;&amp; Elasticsearch基本概念索引(index)是Elasticsearch存放数据的地方，可以理解为关系型数据库的数据库。我们的数据被存储和索引在分片(shards)中，索引只是一个把一个或多个分片分组在一起的逻辑空间。索引的结构是为快速有效的全文索引准备的，索引名称必须是小写，并且不能用下划线开头 类型(type)用于区分同一个索引下不同的数据类型，相当于关系型数据库中的表。在Elasticsearch中，我们使用相同类型的文档表示相同的”事物”，因为他们的数据结构也是相同的。每个类型都有自己的映射(mapping)或者结构定义，就像传统数据库表中的列一样。所有类型下的文档被存储在同一个索引下，但是类型的映射会告诉Elasticsearch不同的文档如何被索引(ES6.0之后一个索引只能存在一种类型) 文档(document)是ElasticSearch中存储的实体数据，一个文档相当于数据库表中的一行记录。在Elasticsearch中，文档这个术语有着特殊含义。它特指最顶层结构或者根对象(root object)序列化成的JSON数据(以唯一ID标识并存储于Elasticsearch中) 关系型数据库与Elasticsearch的概念类比如下 Relational DB Databases Tables Rows Columns Elasticsearch Indices Types Documents Fields RESTful API在Elasticsearch中，提供了功能丰富的RESTful API的操作，包括基本的CRUD、创建索引、删除索引等操作。RESTful是统一规范的http接口，任何语言都可以使用。我们可以直接使用web客户端(postman)来测试，甚至还可以使用Linux上的curl工具测试，不需要自己写程序来调用Elasticsearch服务 # Elasticsearch RESTful操作数据的风格 curl -X &lt;verb> '&lt;protocol>://&lt;host>:&lt;port>/&lt;path>?&lt;query_string> -d &lt;body>' verb: HTTP方法，如GET、POST、PUT、HEAD、DELETE host: ES集群中的任意节点主机名 port: ES HTTP服务端口默认9200 path: 索引路径 query_string: 可选的查询请求参数，例如?pretty参数将格式化输出JSON数据 -d: 一个GET的JSON格式请求主体 body: 自己写的JSON格式的请求主体 创建索引在Lucene中创建索引是需要定义字段名称以及字段的类型，在Elasticsearch中提供了非结构化的索引，就是不需要创建索引结构，即可写入数据到索引中，实际上在Elasticsearch底层会进行结构化操作，此操作对用户是透明的 # 创建一个data的空索引 curl -X PUT '10.10.110.191:9200/data' # 删除索引 curl -X DELETE '10.10.110.191:9200/data' 插入数据URL规则：POST /索引/类型/id # 往data这个索引下的user类型中插入一条ID为1的数据,?pretty是以json格式返回数据 curl -X POST '10.10.110.191:9200/data/user/1?pretty' -H \"Content-Type:application/json\" -d ' { \"name\": \"mowenjie\", \"job\": \"DevOps\", \"base\": \"sz\" }' # 响应 { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"1\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : { \"total\" : 2, \"successful\" : 1, \"failed\" : 0 }, \"_seq_no\" : 0, \"_primary_term\" : 1 } # 不指定ID插入数据会自动生成ID curl -X POST '10.10.110.191:9200/data/user/?pretty' -H \"Content-Type:application/json\" -d ' { \"name\": \"missf\", \"job\": \"linux\", \"base\": \"sz\" }' # 响应 { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"-J1PMXQBkHjO2vDovLJx\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : { \"total\" : 2, \"successful\" : 2, \"failed\" : 0 }, \"_seq_no\" : 1, \"_primary_term\" : 1 } 更新数据在Elasticsearch中可以通过覆盖的方式对数据进行更新 # 对ID为1的这条数据进行更新 curl -X PUT '10.10.110.191:9200/data/user/1?pretty' -H \"Content-Type:application/json\" -d ' { \"name\": \"fan\", \"job\": \"java\", \"base\": \"bj\" }' # 查询更新结果 curl -X GET '10.10.110.191:9200/data/user/1?pretty' { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"1\", \"_version\" : 2, # 更新之后的数据版本进行了+1 \"_seq_no\" : 2, \"_primary_term\" : 1, \"found\" : true, \"_source\" : { \"name\" : \"fan\", \"job\" : \"java\", \"base\" : \"bj\" } } # 上面是更新整条数据,下面是局部更新一条数据的某些字段,需要使用_update标识 curl -X POST '10.10.110.191:9200/data/user/1/_update?pretty' -H \"Content-Type:application/json\" -d ' { \"doc\":{ \"name\": \"aaa\" } }' 删除数据在Elasticsearch中，删除文档数据只需要发起DELETE请求即可 # 删除ID为1的这条数据 curl -X DELETE 'http://10.10.110.191:9200/data/user/1?pretty' # 响应,看到返回\"result\" : \"deleted\"就表示删除成功,如果删除一条不存在的数据会返回404 { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"1\", \"_version\" : 2, \"result\" : \"deleted\", \"_shards\" : { \"total\" : 2, \"successful\" : 2, \"failed\" : 0 }, \"_seq_no\" : 1, \"_primary_term\" : 1 } 删除一个文档也不会立即从磁盘上移除，它只是被标记成已删除。Elasticsearch将会在你之后添加更多索引的时候才在后台进行删除内容的清理 搜索数据根据id搜索数据 curl -X GET '10.10.110.191:9200/data/user/003?pretty' 搜索全部数据 curl -X GET '10.10.110.191:9200/data/user/_search?pretty' # 响应默认只返回10条数据 关键字搜素数据 # 查询base等于sz的用户数据 curl -X GET '10.10.110.191:9200/data/user/_search?q=base:sz' DSL搜索Elasticsearch提供基于JSON的完整查询语言DSL(Query DSL)来定义查询，它允许你构建更加复杂、强大的查询 # 查询base等于sz的用户 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { # 请求体 \"query\" : { \"match\" : { \"base\" : \"sz\" } } } ' # 查询age大于16且job等于Linux的用户 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"bool\": { \"filter\": { \"range\": { \"age\": { \"gt\": 16 } } }, \"must\": { \"match\": { \"job\": \"Linux\" } } } } } ' # 全文搜索 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"match\": { \"name\": \"miss lisi\" } } } ' 高亮显示查询得到需要高亮的数据，再使用highlight将需要高亮的字段写在fields里面 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"match\": { \"name\": \"miss lisi\" } }, \"highlight\": { \"fields\": { \"name\": {} } } } ' 聚合在Elasticsearch中支持聚合操作，类似SQL中的group by操作 # 根据字段值分组聚合 curl -X POST '10.10.110.191:9200/data/user/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"aggs\": { \"age_terms\": { \"terms\": { \"field\": \"age\" } } } } ' # 响应,age字段值为16的有1条数据,age字段值为25的有2条数据 \"aggregations\" : { \"age_terms\" : { \"doc_count_error_upper_bound\" : 0, \"sum_other_doc_count\" : 0, \"buckets\" : [ { \"key\" : 16, \"doc_count\" : 1 }, { \"key\" : 25, \"doc_count\" : 2 }, { \"key\" : 36, \"doc_count\" : 1 } ] } } 文档一个文档不只有数据，它还包含了元数据(metadata)——关于文档的信息。三个必须的元数据节点是 节点 说明 _index 文档存储的地方 _type 文档代表的对象的类 _id 文档的唯一标识 索引(index)类似于关系型数据库里的”数据库”——它是我们存储和索引关联数据的地方 _type(类型)，在关系型数据库中，我们经常将相同类的对象存储在一个表里，因为它们有着相同的结构。同理，在Elasticsearch中我们使用相同类型(type)的文档表示相同的”事物”，因为他们的数据结构也是相同的 id仅仅是一个字符串，它与_index和_type组合时，就可以在Elasticsearch中唯一标识一个文档。当创建一个文档时你可以自定义_id ，也可以让Elasticsearch帮你自动生成 响应查询指定响应字段 # 只响应_source下的name,job字段 curl -X GET '10.10.110.191:9200/data/user/001/?_source=name,job' 不返回元数据，仅仅返回原始数据 curl -X GET '10.10.110.191:9200/data/user/001/_source' 判断文档存在如果我们只需要判断文档是否存在，而不查询文档内容 # 如果文档存在,Elasticsearch将返回HTTP/1.1 200 OK,如果不存在就返回HTTP/1.1 404 Not Found curl -i -X HEAD 'http://10.10.110.191:9200/data/user/001' 当然，这只表示你在查询的那一刻文档不存在，但并不表示几毫秒后依旧不存在，另一个进程在这期间可能创建新文档 批量操作有些情况下可以通过批量操作以减少网络请求，如：批量查询、批量插入数据 # 批量查询 curl -X POST '10.10.110.191:9200/data/user/_mget?pretty' -H \"Content-Type:application/json\" -d ' { \"ids\": [\"001\", \"002\"] }' # 响应 { \"docs\" : [ { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"001\", \"_version\" : 1, \"_seq_no\" : 0, \"_primary_term\" : 1, \"found\" : true, \"_source\" : { \"name\" : \"lisi\", \"job\" : \"Python\", \"base\" : \"sh\", \"age\" : 16 } }, { \"_index\" : \"data\", \"_type\" : \"user\", \"_id\" : \"002\", \"_version\" : 1, \"_seq_no\" : 1, \"_primary_term\" : 1, \"found\" : true, \"_source\" : { \"name\" : \"mowenjie\", \"job\" : \"Linux\", \"base\" : \"sz\", \"age\" : 36 } } ] } 分页和SQL使用LIMIT关键字返回只有一页的结果一样，Elasticsearch接受from和size参数 size: 结果数,默认10 from: 从第n条数据之后开始,默认0 查询一个区间的数据 # 导入官方测试数据 curl -H \"Content-Type: application/x-ndjson\" -XPOST \"10.10.110.191:9200/bank/account/_bulk?pretty\" --data-binary @accounts.json # 将数据的account_number字段进行排序之后再取数据 curl -X GET \"http://10.10.110.191:9200/bank/account/_search?pretty\" -H \"Content-Type:application/json\" -d ' { \"query\": {\"match_all\": {} }, \"sort\": [{\"account_number\": \"asc\"}], \"from\": 10, # 从第10条数据之后开始 \"size\": 30 # 一共返回30条数据,就是account_number为10-39的数据 }' # 取1000到2000这个区间的随机数据 curl -X GET \"http://10.10.110.191:9200/bank/account/_search?pretty\" -H \"Content-Type:application/json\" -d' { \"query\": { \"bool\": { \"must\": { \"match_all\": {} }, \"filter\": { \"range\": { \"balance\": { \"gte\": 1000, \"lte\": 2000 } } } } } }' 映射前面我们创建的索引以及插入数据，都是由Elasticsearch进行自动判断类型，有些时候我们是需要进行明确字段类型的，否则自动判断的类型和实际需求是不相符的。每个字段都有一个数据类型，可以是一个简单的类型：text、keyword、date、long、double、boolean、ip，或者一个支持JSON层次结构的类型：例如object、nested，或者是一种特殊的类型：geo_point、geo_shape、completion 创建明确类型的索引 curl -X PUT '10.10.110.191:9200/itcast' -H \"Content-Type:application/json\" -d ' { \"settings\": { \"index\": { \"number_of_shards\": \"2\", \"number_of_replicas\": \"0\" } }, \"mappings\": { \"properties\": { \"name\": { \"type\": \"text\" }, \"age\": { \"type\": \"integer\" }, \"mail\": { \"type\": \"keyword\" }, \"hobby\": { \"type\": \"text\" } } } }' 查看索引映射 curl -X GET '10.10.110.191:9200/itcast/_mapping' # 响应 { \"itcast\" : { \"mappings\" : { \"properties\" : { \"age\" : { \"type\" : \"integer\" }, \"hobby\" : { \"type\" : \"text\" }, \"mail\" : { \"type\" : \"keyword\" }, \"name\" : { \"type\" : \"text\" } } } } } 批量插入数据 # 如果插入的数据类型与我们字段定义的类型不同,那么就无法插入 curl -X POST '10.10.110.191:9200/itcast/_bulk' -H \"Content-Type:application/json\" --data-binary @itcast.json {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"1\"}} {\"name\":\"张三\",\"age\": 20,\"mail\": \"111@qq.com\",\"hobby\":\"羽毛球、乒乓球、足球\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"2\"}} {\"name\":\"李四\",\"age\": 21,\"mail\": \"222@qq.com\",\"hobby\":\"羽毛球、乒乓球、足球、篮球\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"3\"}} {\"name\":\"王五\",\"age\": 22,\"mail\": \"333@qq.com\",\"hobby\":\"羽毛球、篮球、游泳、听音乐\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"4\"}} {\"name\":\"赵六\",\"age\": 23,\"mail\": \"444@qq.com\",\"hobby\":\"跑步、游泳\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"_doc\",\"_id\":\"5\"}} {\"name\":\"孙七\",\"age\": 24,\"mail\": \"555@qq.com\",\"hobby\":\"听音乐、看电影\"} 查询插入的数据 curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' 结构化查询term主要用于精确匹配某些值，比如数字、日期、布尔值或not_analyzed的字符串(未经分析的文本数据类型) curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\" : { \"term\" : { \"age\" : 20 } } }' range过滤允许我们按照指定范围查询一批数据 # 查询age大于等于20小于等于22范围的数据(gt:大于,gte:大于等于,lt:小于,lte:小于等于) curl -X POST '10.10.110.191:9200/bank/account/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\" : { \"range\": { \"age\": { \"gte\": 20, \"lte\": 22 } } } }' exists查询可以用于查找文档中是否包含指定字段或没有某个字段，类似于SQL语句中的IS_NULL条件 # 查询原始数据中含有address字段的文档 curl -X POST '10.10.110.191:9200/bank/account/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\" : { \"exists\": { \"field\": \"address\" } } }' match是一个模糊查询，需要指定字段名，但是会进行分词(中英文分词不一样) # 查询hobby字段是乒乓球的记录,在查询之前会进行分词(只要记录包含[乒/乓/球]都会被匹配成功) curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"match\": { \"hobby\": \"乒乓球\" } } }' bool查询可以用来合并多个条件查询结果的布尔逻辑，它包含以下操作符： must: 多个查询条件的完全匹配，相当于and must_not: 多个查询条件的相反匹配，相当于not should: 至少有一个查询条件匹配，相当于or filter: 必须匹配，但它不会对匹配的数据进行评分 # 只要包含\"乒乓 游泳\"的数据都会被匹配 curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"bool\": { \"must\": [ { \"match\": { \"hobby\": \"乒乓 游泳\" } } ] } } }' # hobby包含乒乓但是age不等于21的数据 curl -X POST '10.10.110.191:9200/itcast/_doc/_search?pretty' -H \"Content-Type:application/json\" -d ' { \"query\": { \"bool\": { \"must\": [ { \"match\": { \"hobby\": \"乒乓\" } } ], \"must_not\": [ { \"match\": { \"age\": \"21\" } } ] } } }' 中文分词中文分词的难点在于在汉语中没有明显的词汇分界点，如在英语中空格可以作为分隔符，如果分隔不正确就会造成歧义。常用中文分词器有IK、jieba、THULAC等，推荐使用IK分词器 IK Analyzer是一个开源的，基于java语言开发的轻量级的中文分词工具包。从2006年12月推出1.0版开始，IKAnalyzer已经推出了3个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。新版本的IK Analyzer 3.0则发展为面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。采用了特有的”正向迭代最细粒度切分算法”，具有80万字/秒的高速处理能力 采用了多子处理器分析模式，支持：英文字母（IP地址、Email、URL）、数字（日期，常用中文数量词，罗马数字，科学计数法），中文词汇（姓名、地名处理）等分词处理。 优化的词典存储，更小的内存占用 安装ik中文分词器 # 下载对应es版本的ik分词器 https://github.com/medcl/elasticsearch-analysis-ik # 创建目录 cd your-es-root/plugins/ &amp;&amp; mkdir ik # 解压 unzip plugin to folder your-es-root/plugins/ik # 重启es(集群环境每一台都要配置) 分词测试 curl -X POST '10.10.110.191:9200/_analyze?pretty' -H \"Content-Type:application/json\" -d ' { \"analyzer\": \"ik_max_word\", \"text\": \"我是中国人\" }' 结果 { \"tokens\" : [ { \"token\" : \"我\", \"start_offset\" : 0, \"end_offset\" : 1, \"type\" : \"CN_CHAR\", \"position\" : 0 }, { \"token\" : \"是\", \"start_offset\" : 1, \"end_offset\" : 2, \"type\" : \"CN_CHAR\", \"position\" : 1 }, { \"token\" : \"中国人\", \"start_offset\" : 2, \"end_offset\" : 5, \"type\" : \"CN_WORD\", \"position\" : 2 }, { \"token\" : \"中国\", \"start_offset\" : 2, \"end_offset\" : 4, \"type\" : \"CN_WORD\", \"position\" : 3 }, { \"token\" : \"国人\", \"start_offset\" : 3, \"end_offset\" : 5, \"type\" : \"CN_WORD\", \"position\" : 4 } ] }","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Elastic Stack(1)","slug":"Elastic Stack(1)","date":"2020-08-05T06:19:27.000Z","updated":"2020-09-03T09:26:42.011Z","comments":true,"path":"post/cb83e724.html","link":"","permalink":"https://www.missf.top/post/cb83e724.html","excerpt":"","text":"Elastic Stack简介ELK日志收集分析平台相信所有的运维工程师都听说过，实际上ELK不是一门技术，而是三个软件的简称。它们分别是由Elasticsearch、Logstash、Kibana组成，在ELK发展的过程中，又有新成员Beats的加入，所以就形成了Elastic Stack Elastic Stack的组成 ElasticsearchElasticsearch基于java语言开发，是个开源分布式搜索引擎，它的特点有:分布式、零配置、自动发现、索引自动分片、索引副本机制、RESTful风格接口、多数据源、自动搜索负载等 LogstashLogstash基于java语言开发，是一个开源的用于收集，分析和存储日志的工具 KibanaKibana基于nodejs，也是一个开源和免费的工具，Kibana可以为 Logstash和ElasticSearch提供的日志分析的友好Web界面，可以汇总、分析和搜索重要数据日志 BeatsBeats是elastic公司开源的一款采集系统监控数据的代理agent，是在被监控服务器上以客户端形式运行的数据收集器的统称，可以直接把数据发送给Elasticsearch或者通过Logstash发送给Elasticsearch，然后进行后续的数据分析活动 Beats由如下组成： Packetbeat：一个网络数据包分析器，用于监控、收集网络流量信息，Packetbeat嗅探服务器之间的流量，解析应用层协议，并关联到消息的处理，其支持ICMP(v4 and v6)、DNS、HTTP、Mysql、PostgreSQL、Redis、MongoDB、Memcache等协议 Filebeat：用于监控、收集服务器日志文件，其已取代logstash forwarder Metricbeat：可定期获取外部系统的监控指标信息，其可以监控、收集 Apache、HAProxy、MongoDB、MySQL、Nginx、PostgreSQL、Redis、System、Zookeeper等服务 Winlogbeat：用于监控、收集Windows系统的日志信息","categories":[{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"}]},{"title":"Prometheus pushgateway工具(8)","slug":"Prometheus pushgateway工具(8)","date":"2020-08-04T10:05:33.000Z","updated":"2020-09-11T11:23:37.195Z","comments":true,"path":"post/5cf39589.html","link":"","permalink":"https://www.missf.top/post/5cf39589.html","excerpt":"","text":"PushGateway部署prometheus基于http的pull方式去采集时间序列数据，但是由于业务需求，prometheus和exporter可能不在一个子网或者防火墙原因，导致Prometheus无法直接拉取各个target数据，或者需要将不同的数据进行汇总，这时候就可以使用prometheus的自带组件pushgateway进行数据的汇总，将默认的pull方式改为push方式进行数据的采集 # 下载pushgateway wget https://github.com/prometheus/pushgateway/releases/download/v1.2.0/pushgateway-1.2.0.linux-amd64.tar.gz # 解压 tar xf pushgateway-1.2.0.linux-amd64.tar.gz &amp;&amp; mv pushgateway-1.2.0.linux-amd64 /usr/local/pushgateway # 创建pushgateway启动文件 vim /usr/lib/systemd/system/pushgateway.service [Unit] Documentation=pushgateway exporter After=local-fs.target network-online.target network.target Wants=local-fs.target network-online.target network.target [Service] Restart=on-failure ExecStart=/usr/local/pushgateway/pushgateway # 需要修改监听端口可以自行添加参数 [Install] WantedBy=multi-user.target # 启动pushgateway systemctl start pushgateway.service Prometheus添加PushGateway在我们的prometheus配置文件添加pushgateway的地址 vim /usr/local/prometheus/prometheus.yml scrape_configs: - job_name: 'pushgateway' static_configs: - targets: ['49.233.200.185:9091'] # 这个是安装了pushgateway的服务器地址 labels: instance: pushgateway 重启prometheus服务 systemctl restart prometheus.service pushgateway其实是一个中转站，我们可以使用任何高级语言发送post请求到pushgateway，然后对数据进行增加删除等操作，pushgateway再把数据实时推送到prometheus 推送数据到PushGatewayecho \"missf 123456\" | curl --data-binary @- http://49.233.200.185:9091/metrics/job/prometheus # 数据:missf,值:123456 # --data-binary 表示发送二进制数据(post方式) # http://49.233.200.185:9091 pushgateway的地址 查看pushgateway推送到prometheus上的数据，这可以看到有exported_job=”prometheus”和job=”pushgateway”两个指标，我们推送数据时指定的job是prometheus，为什么这里的job会显示pushgateway呢？这里需要修改一个honor_labels的参数 修改prometheus的配置文件，开启honor_labels参数(默认为false) scrape_configs: - job_name: 'pushgateway' honor_labels: true static_configs: - targets: ['49.233.200.185:9091'] labels: instance: pushgateway 重启prometheus 再次推送数据到pushgateway，然后查看prometheus上的数据 echo \"mwj 123456\" | curl --data-binary @- http://49.233.200.185:9091/metrics/job/prometheus/instance/missf 这里说明一下honor_labels的作用:因为prometheus配置pushgateway的时候，也会指定job和instance，但是它只表示pushgateway实例本身，不能真正表达收集数据的含义。所以配置pushgateway需要添加honor_labels:true参数，避免收集到的数据本身的job和instance被覆盖。具体参考官网 在PushGateway删除数据curl -X DELETE http://49.233.200.185:9091/metrics/job/prometheus/instance/missf","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus 业务监控(7)","slug":"Prometheus 业务监控(7)","date":"2020-08-03T02:26:26.000Z","updated":"2020-09-11T11:23:54.225Z","comments":true,"path":"post/f261c617.html","link":"","permalink":"https://www.missf.top/post/f261c617.html","excerpt":"","text":"Blackbox_exporter部署Blackbox_exporter是prometheus官方提供的exporter之一，可以提供http、dns、tcp、icmp 的监控数据采集 # 下载 wget https://github.com/prometheus/blackbox_exporter/releases/download/v0.17.0/blackbox_exporter-0.17.0.linux-amd64.tar.gz # 解压 tar xf blackbox_exporter-0.17.0.linux-amd64.tar.gz &amp;&amp; mv blackbox_exporter-0.17.0.linux-amd64 /usr/local/blackbox # 创建blackbox启动文件 vim /usr/lib/systemd/system/blackbox.service [Unit] Documentation=Blackbox exporter After=local-fs.target network-online.target network.target Wants=local-fs.target network-online.target network.target [Service] Restart=on-failure ExecStart=/usr/local/blackbox/blackbox_exporter --config.file=/usr/local/blackbox/blackbox.yml [Install] WantedBy=multi-user.target # 启动blackbox systemctl daemon-reload systemctl restart blackbox.service 配置TCP端口检测及告警传统的端口检测方式，调用命令的方式去实现 ncat -vz 47.100.107.121 80 # 返回seconds而不是timeout那么端口就是通的 telnet ...... zabbix监控端口可以通过模板或者自定义key写脚本实现 修改prometheus配置文件，配置TCP端口检测 vim /usr/local/prometheus/prometheus.yml scrape_configs: - job_name: 'nginx_port_check' metrics_path: /probe params: module: [tcp_connect] file_sd_configs: - files: - check/port/nginx.json relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 47.100.107.121:9115 # 这个是blackbox所在主机以及端口 编写监控TCP端口的告警规则 vim /usr/local/prometheus/rules/nginx_port_check.yml groups: - name: nginx port check rules: - alert: nginx_port_check failed for: 5s expr: probe_success{job=\"nginx_port_check\"} == 0 labels: serverity: critical annotations: description: \"{{ $labels.group }} port connection fail,{{ $labels.group }} value is:{{ $value }}\" summary: \"{{ $labels.group }} port connection failed\" 修改prometheus配置文件需要重启prometheus服务 systemctl restart prometheus.service 关闭Nginx测试当80端口无法访问之后的告警结果 业务接口检测及告警基于现在Java + Vue前后端分离的开发模式下，我们很多时候需要去检测Java的接口是否正常。传统的手动检测可以使用postman，或者写shell脚本也可以实现，但是prometheus可以通过blackbox去更好的检测业务接口 修改prometheus配置文件，添加监控业务接口的job scrape_configs: - job_name: 'get_mysite' scrape_interval: 5s metrics_path: /probe params: module: [http_2xx] file_sd_configs: - files: - check/url/*.json relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 47.100.107.121:9115 编写监控url链接的告警规则文件 vim /usr/local/prometheus/rules/get_mysite.yml groups: - name: get mysite check rules: - alert: get_mysite_check failed for: 5s expr: probe_success{group=\"get_mysite\",instance=\"https://www.missf.top\",job=\"get_mysite\"} == 0 labels: serverity: critical annotations: description: \"{{ $labels.group }} failed, {{ $labels.group }} value is:{{ $value }}\" summary: \"{{ $labels.group }} website not accessible\" 修改prometheus配置文件之后记得重启prometheus服务 systemctl restart prometheus.service 如果https://www.missf.top这个链接的http请求不是返回2xx的状态码就会告警 {% image https://pic.imgdb.cn/item/5f28fbe914195aa5944ce74b.jpg '' '' %} 我们在监控业务接口时，只监控到接口的返回状态(2xx状态码)，假如我们想要监控业务接口的返回内容该如何实现呢？那就需要修改blackbox的配置文件 modules: http_2xx: prober: http # 下面这段是需要添加的内容 http: method: GET headers: Host: www.missf.top Accept-Language: en-US Origin: missf.top fail_if_body_matches_regexp: # 如果我get的url地址返回的正文中有\"apache\",那么就会失败,则probe_success值为0 - \"apache\" fail_if_body_not_matches_regexp: - \"nginx\" # 如果我get的url地址返回的正文中没有\"nginx\",那么就会失败,则probe_success值为0 http_post_2xx: prober: http http: method: POST tcp_connect: prober: tcp pop3s_banner: prober: tcp tcp: query_response: - expect: \"^+OK\" tls: true tls_config: insecure_skip_verify: false ssh_banner: prober: tcp tcp: query_response: - expect: \"^SSH-2.0-\" irc_banner: prober: tcp tcp: query_response: - send: \"NICK prober\" - send: \"USER prober prober prober :prober\" - expect: \"PING :([^ ]+)\" send: \"PONG ${1}\" - expect: \"^:[^ ]+ 001\" icmp: prober: icmp 修改了blackbox配置文件需要重启blackbox服务 systemctl restart blackbox.service 上面所配置的匹配返回内容是在http_2xx这个模块下添加的，我们需要修改prometheus配置文件对应的http_2xx模块的规则文件，配置我们监控业务接口的返回内容的url地址 vim /usr/local/prometheus/check/url/get_mysite.json [ { \"targets\": [ \"47.100.107.121\" # 这个url返回的是默认的Nginx页面,对应我上面的匹配规则(nginx/apache) ], \"labels\": { \"group\": \"get_mysite\" } } ] 查看blackbox的采集数据 probe_success的值是根据我们在blackbox配置文件的正则去决定的 这时候我们get_mysite.json这个规则文件的job的probe_success值就是通过get获取一个url的返回值去确定的，我们这样就可以去监控接口的返回内容了 配置网络监控我们可以让服务器使用icmp协议去请求www.baidu.com或者是一个公网IP，测试服务器的网络是否正常 修改prometheus配置文件，添加网络监控的job scrape_configs: - job_name: 'icmp_check_network' scrape_interval: 5s metrics_path: /probe params: module: [icmp] file_sd_configs: - files: - check/icmp/*.json relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 47.100.107.121:9115 编写网络监控的规则文件 vim /usr/local/prometheus/rules/check_network.yml groups: - name: icmp check network rules: - alert: icmp check network failed for: 10s expr: probe_success{group=\"icmp_check_network\",instance=\"www.baidu.com\",job=\"icmp_check_network\"} == 0 labels: serverity: critical annotations: description: \"{{ $labels.group }} icmp connection failed, {{ $labels.group }} value is: {{ $value }}\" summary: \"{{ $labels.group }} connection failed, instance: {{ $labels.instance }}\" 修改prometheus配置文件之后记得重启prometheus服务 systemctl restart prometheus.service","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus 告警(6)","slug":"Prometheus 告警(6)","date":"2020-07-23T03:53:03.000Z","updated":"2020-09-11T11:23:41.126Z","comments":true,"path":"post/615f0093.html","link":"","permalink":"https://www.missf.top/post/615f0093.html","excerpt":"","text":"Alertmanager概述prometheus发出告警时分为两部分，首先prometheus按告警规则(rule_files配置)向alertmanager发送告警，即告警规则是在prometheus上定义的，然后由alertmanager去管理这些告警，包括去重(deduplicating)、分组(grouping)、静音(silencing)、抑制(inhibition)、聚合(aggregation)，最终通过丰富的告警通知渠道(电话、微信、短信、邮件)将告警通知路由给对应的联系人。prometheus的大部分组件都是go语言开发的，zabbix到4.4之后的客户端才是go编写 Alertmanager二进制安装# 下载 wget https://github.com/prometheus/alertmanager/releases/download/v0.21.0/alertmanager-0.21.0.linux-amd64.tar.gz # 解压 tar xf alertmanager-0.21.0.linux-amd64.tar.gz &amp;&amp; mv alertmanager-0.21.0.linux-amd64 /usr/local/alertmanager # 创建alertmanager启动文件 vim /usr/lib/systemd/system/alertmanager.service [Unit] Documentation=alertmanager [Service] Restart=on-failure ExecStart=/usr/local/alertmanager/alertmanager --config.file=/usr/local/alertmanager/alertmanager.yml --storage.path=/usr/local/alertmanager/data [Install] WantedBy=multi-user.target # 启动 systemctl daemon-reload systemctl start alertmanager.service Alertmanager配置文件详解vim /usr/local/alertmanager/alertmanager.yml global: resolve_timeout: 5m # 恢复的超时时间,这个跟告警恢复通知有关,此参数并不是说在这个时间没有收到告警就会恢复 route: group_by: ['alertname'] # 默认以告警名进行分组,就是rule文件的alert值进行分组 group_wait: 10s # 发送警报前，至少等待多少秒才会发送(为了收集同组更多的警报信息一起发送) group_interval: 10s # 如果警报1已经发送,这时又出现同组的警报2,由于组状态发生变化,警报会在group_interval这个时间内发送,不会被repeat_interval这个时间收敛 repeat_interval: 20m # 报警信息已发送，但事件并没有恢复,则等待多久时间再重新发送(生产环境一般设成20min或者30min) receiver: 'web.hook' # 发送警报的接收者名称,如果一个报警没有被一个route匹配,则发送给默认的接收器 receivers: # 发送告警信息给那个接收者 - name: 'web.hook' # 这个需要和上面定义的接收者名称一致 webhook_configs: - url: 'http://127.0.0.1:5001/' inhibit_rules: # 抑制规则,防止告警风暴 - source_match: severity: 'critical' target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] 检查Alertmanager配置文件# 提示SUCCESS,则配置文件没有问题 ./amtool check-config alertmanager.yml # 修改配置文件之后重启alertmanager systemctl restart alertmanager.service 配置邮件告警修改alertmanager配置文件，填写邮箱的验证信息，定义路由的收件人，配置发送告警邮件到那个邮箱 cat /usr/local/alertmanager/alertmanager.yml global: resolve_timeout: 3m smtp_smarthost: 'smtp.qq.com:465' smtp_from: '1173354099@qq.com' smtp_auth_username: '1173354099@qq.com' smtp_auth_password: '' # 授权码 smtp_require_tls: false route: group_by: ['alertname'] group_wait: 10s group_interval: 10s repeat_interval: 20m receiver: 'devops.mail' receivers: - name: 'devops.mail' email_configs: - to: 'mf_2013@163.com' headers: { Subject: \"[WARN] Prometheus 报警邮件\" } send_resolved: true # 发送告警恢复通知 #inhibit_rules: # - source_match: # severity: 'critical' # target_match: # severity: 'warning' # equal: ['alertname', 'dev', 'instance'] 配置prometheus与alertmanager通信，设置规则文件的路径和正则匹配 # 修改prometheus配置文件 vim /usr/local/prometheus/prometheus.yml alerting: alertmanagers: - static_configs: - targets: - 127.0.0.1:9093 # 这里由于alertmanager是和prometheus部署在同一台机器上,所以写本机地址 rule_files: - \"rules/*.yml\" # rules这个目录是在prometheus上的,指当前配置文件的同级目录,这个目录需要自己创建 # 检查prometheus配置文件 ./promtool check config prometheus.yml systemctl restart prometheus.service 编写rules文件，根据rules文件中的表达式去告警，这个规则文件的路径是prometheus配置文件中定义的 # 监控节点的状态 cat /usr/local/prometheus/rules/node.yml groups: - name: node_alert rules: - alert: Node_InstanceDown expr: up == 0 # 表达式 for: 5s labels: serverity: error annotations: summary: \"Instance {{ $labels.instance }} down\" description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes\" 在prometheus的web控制台查看配置的规则 关闭node_exporter.service节点，查看告警邮件 配置微信告警修改alertmanager配置文件，定义路由规则 cat /usr/local/alertmanager/alertmanager.yml global: resolve_timeout: 3m smtp_smarthost: 'smtp.qq.com:465' smtp_from: '1173354099@qq.com' smtp_auth_username: '1173354099@qq.com' smtp_auth_password: '' # 授权码 smtp_require_tls: false templates: - /usr/local/alertmanager/template/wechat.temp route: group_by: ['alertname'] group_wait: 10s group_interval: 10s repeat_interval: 20m #receiver: 'devops.mail' receiver: 'devops.mailwechat' routes: # 为node_exporter、docker、mysqld_exporter定义匹配路由,每个路由有自己的分组在微信告警时信息就会单独发送 - receiver: 'devops.mailwechat' # 每个服务可以定义自己的接收者,这样在发送时就可以发送给不同的人,不同的服务对应不同的处理人员 group_wait: 10s group_by: ['node_exporter'] match_re: job: node_exporter - receiver: 'devops.mailwechat' group_wait: 10s group_by: ['docker'] match_re: job: docker - receiver: 'devops.mailwechat' group_wait: 10s group_by: ['mysqld_exporter'] match_re: job: mysqld_exporter receivers: - name: 'devops.mailwechat' # 将这个告警同时发送到邮件和微信 email_configs: - to: 'mf_2013@163.com' headers: { Subject: \"[WARN] Prometheus 报警邮件\" } send_resolved: true wechat_configs: - api_secret: '' agent_id: '' corp_id: '' to_party: '' send_resolved: true #inhibit_rules: # - source_match: # severity: 'critical' # target_match: # severity: 'warning' # equal: ['alertname', 'dev', 'instance'] 编写rules文件，为了每个服务单独报警，这里将node_exporter、docker、mysqld_exporter分开去写匹配规则 cat /usr/local/prometheus/rules/node.yml groups: - name: node_exporter rules: - alert: node_exporter_Down expr: up{job=\"node_exporter\"} == 0 for: 5s labels: serverity: error annotations: summary: \"Instance {{ $labels.instance }} down\" description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes\" - name: mysqld_exporter rules: - alert: mysqld_exporter_Down expr: up{job=\"mysqld_exporter\"} == 0 for: 5s labels: serverity: error annotations: summary: \"Instance {{ $labels.instance }} down\" description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes\" - name: docker rules: - alert: docker_Down expr: up{job=\"docker\"} == 0 for: 5s labels: serverity: error annotations: summary: \"Instance {{ $labels.instance }} down\" description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes\" 配置完成之后重启alertmanager systemctl restart alertmanager.service 关闭node_exporter和docker_cadvisor服务，这时候会每个服务单独发送告警信息，由于将全部服务group_by在一个组里面，在发送恢复信息时会出现服务混乱的情况，所以我将每个服务做了路由，每一个服务都有自己的group_by，这样在发送信息时才会单独去发送 配置钉钉告警先去创建一个钉钉机器人，具体过程这里就不详细说明了 prometheus配置钉钉告警需要使用到prometheus-webhook-dingtalk插件，我们先使用二进制安装钉钉插件，dingtalk服务默认启动的端口是8060 prometheus-webhook-dingtalk插件下载地址 # 下载prometheus-webhook-dingtalk wget https://github.com/timonwong/prometheus-webhook-dingtalk/releases/download/v1.4.0/prometheus-webhook-dingtalk-1.4.0.linux-amd64.tar.gz # 解压prometheus-webhook-dingtalk tar xf prometheus-webhook-dingtalk-1.4.0.linux-amd64.tar.gz &amp;&amp; mv prometheus-webhook-dingtalk-1.4.0.linux-amd64 /usr/local/dingtalk # 编写dingtalk启动文件 vim /usr/lib/systemd/system/dingtalk.service [Unit] Description=prometheus-webhook-dingtalk After=network-online.target [Service] Restart=on-failure ExecStart=/usr/local/dingtalk/prometheus-webhook-dingtalk \\ --ding.profile=Prometheus告警=https://oapi.dingtalk.com/robot/send?access_token=xxxxxx [Install] WantedBy=multi-user.target # 启动dingtalk.service systemctl daemon-reload systemctl restart dingtalk.service # 查看dingtalk的webhook地址 journalctl -fu dingtalk.service Jul 29 18:38:01 iZuf6fpaicz5jt7kep555qZ prometheus-webhook-dingtalk[5504]: ts=2020-07-29T10:38:01.655Z caller=main.go:133 component=configuration msg=\"Webhook urls for prometheus alertmanager\" urls=http://localhost:8060/dingtalk/Prometheus告警/send 修改prometheus的alertmanager配置，更改告警的路由和接收者 route: receiver: 'devops_dingtalk' # 接收者必须和下面的一致 receivers: - name: 'devops_dingtalk' webhook_configs: - url: 'http://localhost:8060/dingtalk/Prometheus告警/send' # 这个URL是dingtalk的webhook地址 send_resolved: true 关闭docker收集器查看告警效果 告警状态prometheus的告警状态有三种，我们可以在prometheus的控制台页面上查看告警的状态 inactive没有触发任何阈值，这个是根据scrape_interval参数(采集数据周期)和evaluation_interval参数(对比规则周期)去决定的 pending已触发阈值但未满足告警持续时间，告警进入pending状态之后，需要等待规则配置的for时间，如果在这个时间内触发阈值的表达式一直成立，才会进入firing状态 firing已触发阈值且满足告警持续时间，将告警从prometheus发送给alertmanager，在alertmanager收到告警之后并不会立刻发送，还需要等待一个group_wait时间，直到某个计算周期表达式为假，告警状态变更为inactive，发送一个resolve给altermanger，说明此告警已解决 告警收敛alertmanager在收到prometheus发送的告警之后，并不是把收到的信息简单的直接发送出去，而是通过一系列的收敛机制(分组、抑制、静默)去筛选出需要发送的信息，如果alertmanager收到信息就直接发送出去，会导致告警信息过多，运维人员会被告警信息淹没，错过重要的告警信息 分组将类似性质的告警分类为单个通知，减少告警消息数量 将类似性质的告警进行聚合发送，帮助运维更好的排查问题 抑制当告警发出后，停止重复发送由此告警而引起的其他告警，帮助运维第一时间掌握最核心的告警信息 inhibit_rules: - source_match: severity: 'critical' # 当发生critical级别的告警时,就会抑制下面warning级别的告警 target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] # 已发送的告警与新产生的告警中equal定义的标签完全相同,则启动抑制机制 静默是一种简单的特定时间静音的提醒机制，在发布新版本时我们需要停掉某些进程，这时候告警肯定会触发的，由于这是我们已经预知的现象，我们可以打开prometheus主机的9093端口暂时将告警设置成静音 Prometheus一条告警是怎么触发的1.采集数据 scrape_interval: 15s 2.比对采集到的数据是否触发阈值 evaluation_interval: 15s 3.判断是否超出持续时间(在这个时间内一直处于触发阈值状态)for: 5s 4.告警到达alertmanager然后进行分组、抑制、静默 5.通过分组、抑制、静默一系列机制的信息将会被发送，但是会延迟发送group_wait: 10s 编写告警规则案例groups: - name: general.rules rules: - alert: node_FileSystemUsage # 监控磁盘使用率 expr: 100 - node_filesystem_free_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"} / node_filesystem_size_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"} * 100 > 80 for: 5s labels: serverity: warning annotations: summary: \"Instance {{ $labels.instance }} : {{ $labels.mountpoint }} Partition utilization is too high\" description: \"{{ $labels.instance }} : {{ $labels.mountpoint }} Partition utilization is greater than 80% (Currently: {{ $value }})\" - alert: node_MemoryUsage # 监控内存使用率 expr: 100 - (node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) / node_memory_MemTotal_bytes * 100 > 80 for: 5s labels: serverity: warning annotations: summary: \"Instance {{ $labels.instance }} High memory usage\" description: \"{{ $labels.instance }} Memory usage greater than 80% (Currently: {{ $value }})\" - alert: node_cpuUsage # 监控CPU使用率 expr: 100 - irate(node_cpu_seconds_total{mode=\"idle\",job=\"node_exporter\",instance=\"47.100.107.121:9100\"}[5m]) * 100 > 80 for: 5s labels: serverity: warning annotations: summary: \"Instance {{ $labels.instance }} High cpu usage\" description: \"{{ $labels.instance }} Memory usage greater than 60% (Currently: {{ $value }})\"","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus 监控案例(5)","slug":"Prometheus 监控案例(5)","date":"2020-07-16T07:43:16.000Z","updated":"2020-09-11T11:23:43.745Z","comments":true,"path":"post/ba827699.html","link":"","permalink":"https://www.missf.top/post/ba827699.html","excerpt":"","text":"监控Linux服务器部署node_exporterprometheus官方提供Node_exporter来让我们收集机器的系统数据，除node_exporter外，官方还提供consul、memcached、haproxy、mysqld等exporter。exporter类似于zabbix写好的监控模板，但是这些exporter都是需要在被监控节点安装 # 下载node_exporter wget https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz # 解压 tar xf node_exporter-1.0.1.linux-amd64.tar.gz &amp;&amp; mv node_exporter-1.0.1.linux-amd64 /usr/local/node_exporter # 编写启动文件 vim /usr/lib/systemd/system/node_exporter.service [Unit] Description=prometheus [Service] Restart=on-failure ExecStart=/usr/local/node_exporter/node_exporter [Install] WantedBy=multi-user.target # 启动node_exporter systemctl daemon-reload systemctl start node_exporter.service # 访问node_exporter的数据接口 http://10.10.110.23:9100/metrics # 默认端口是9100,默认接口是metrics 配置监控# 修改prometheus配置文件 vim /usr/local/prometheus/prometheus.yml - job_name: 'node_exporter' file_sd_configs: - files: ['/usr/local/prometheus/sd_config/node/*.yaml'] refresh_interval: 5s # 创建服务发现的文件 vim /usr/local/prometheus/sd_config/node/*.yaml - targets: - '10.10.110.23:9100' # 这个地址是被监控节点的IP地址 promSQL监控CPU、内存、硬盘CPU监控# 计算CPU五分钟内平均的使用率表达式 100 - irate(node_cpu_seconds_total{mode=\"idle\",instance=\"10.10.110.23:9100\",job=\"node_exporter\"}[5m]) * 100 # node_cpu_seconds_total{mode=\"idle\",instance=\"10.10.110.23:9100\",job=\"node_exporter\"}[5m]:取CPU五分钟之内的空闲值 # irate函数:将会用于计算某个指标在一定时间间隔内的变化速率 # 将得到的空闲值乘以100再得到CPU百分比的空闲值,再以100减去CPU百分比的空闲值,就得到CPU五分钟内平均的使用率 内存监控# 计算内存使用率表达式 100 - (node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) / node_memory_MemTotal_bytes * 100 # (node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes)是内存剩余的总量 在系统层面来考虑:buff和cache是已经被使用的内存 在程序层面来考虑:buff和cache是剩余的内存 # 内存剩余的总量除以内存总量得到内存剩余率,再以100减去内存剩余率得到内存使用率 硬盘监控# 计算硬盘使用率表达式 100 - node_filesystem_free_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"} / node_filesystem_size_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"} * 100 # node_filesystem_free_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"}是根分区硬盘剩余容量,只计算ext4|xfs类型的文件系统 # node_filesystem_size_bytes{mountpoint=\"/\",fstype=~\"ext4|xfs\"}是根分区的硬盘总量 # 根分区硬盘剩余容量除以根分区的硬盘总量得到根分区硬盘的剩余率,再以100减去硬盘的剩余率得到硬盘使用率 监控系统服务状态修改node_exporter的启动参数vim /usr/lib/systemd/system/node_exporter.service [Unit] Description=prometheus [Service] Restart=on-failure ExecStart=/usr/local/node_exporter/node_exporter --collector.systemd --collector.systemd.unit-whitelist=(docker|sshd).service # 利用正则匹配监控systemd的docker|sshd这三个服务 [Install] WantedBy=multi-user.target 重启node_exportersystemctl daemon-reload systemctl restart node_exporter.service 查看监控服务的数据指标node_systemd_unit_state{name=\"docker.service\"} 在activating、active、deactivating、failed、inactive五个状态中value为1的状态，就是服务当前的状态 {% image https://pic.imgdb.cn/item/5f1fa26414195aa5947438c7.jpg '' '' %} 使用Grafana图表展示监控数据安装Grafana# 下载软件包 wget https://dl.grafana.com/oss/release/grafana-7.1.0-1.x86_64.rpm # 安装 yum install grafana-7.1.0-1.x86_64.rpm -y # 启动 systemctl enable grafana-server.service systemctl start grafana-server.service # Grafana默认端口为3000,账号密码都为admin,初次登录会提示需要修改密码 Grafana配置数据源填写prometheus主机的地址，在配置数据源时我们还可以配置验证、定义HTTP头部、以及其他的一些信息 Grafana导入仪表盘我们可以自己编写仪表盘，也可以使用官方网站上别人已经写好的仪表盘模板直接导入使用，这里我们没有必要自己去编写(重复造轮子而且还没有人家专业…)。我们先去Grafana Labs上找到监控Linux主机的仪表盘，然后将仪表盘的ID号导入到Grafana 查看仪表盘Grafana监控Linux主机的仪表盘数据是从prometheus的数据源获取的，就是被监控主机上的node_exporter获取到的数据 监控Docker服务器部署cadvisor想要监控Docker容器，需要在被监控主机安装cadvisor插件，暴露一个HTTP端口，为prometheus提供容器的监控数据 # 由于国内无法连接到gcr.io,这里使用张馆长仓库的镜像地址 docker run \\ --volume=/:/rootfs:ro \\ --volume=/var/run:/var/run:ro \\ --volume=/sys:/sys:ro \\ --volume=/var/lib/docker/:/var/lib/docker:ro \\ --volume=/dev/disk/:/dev/disk:ro \\ --publish=8080:8080 \\ --detach=true \\ --name=cadvisor \\ --privileged \\ --device=/dev/kmsg \\ registry.aliyuncs.com/k8sxio/cadvisor:latest 配置Prometheus监控cadvisorcadvisor可以搜集一台机器上所有运行的容器信息，还提供基础查询界面和http接口，供其他组件如prometheus拉取数据 vim /usr/local/prometheus/prometheus.yml # 在prometheus配置文件加入监控主机的cadvisor端口(拉取容器数据) - job_name: 'docker' static_configs: - targets: ['10.10.110.23:8080'] systemctl daemon-reload systemctl restart prometheus.service Grafana导入仪表盘我们去Grafana Labs网站寻找一个监控Docker主机的仪表盘，在Grafana进行导入 查看Docker主机仪表盘 监控MySQL服务器监控MySQL主机和监控Linux主机一样，都是需要导出器去获取数据，这里我们去prometheus官网下载mysqld_exporter，然后在mysql主机上安装(监控那台mysql主机就在那台主机安装mysqld_exporter) MySQL主机安装mysqld_exporter# 下载 wget https://github.com/prometheus/mysqld_exporter/releases/download/v0.12.1/mysqld_exporter-0.12.1.linux-amd64.tar.gz # 解压 tar xf mysqld_exporter-0.12.1.linux-amd64.tar.gz &amp;&amp; mv mysqld_exporter-0.12.1.linux-amd64 /usr/local/mysqld_exporter # 创建启动文件 vim /usr/lib/systemd/system/mysqld_exporter.service [Unit] Documentation=https://prometheus.io/ [Service] Restart=on-failure Environment=DATA_SOURCE_NAME=exporter:Missf.top123@(localhost:3306)/ # 连接数据库的账号密码,也可以指定.my.cnf文件 ExecStart=/usr/local/mysqld_exporter/mysqld_exporter [Install] WantedBy=multi-user.target # 被监控数据库添加mysql用户及监控权限 CREATE USER 'exporter'@'localhost' IDENTIFIED BY 'Missf.top123' WITH MAX_USER_CONNECTIONS 3; GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'exporter'@'localhost'; FLUSH PRIVILEGES; # 启动mysqld_exporter systemctl start mysqld_exporter # 获取监控数据 curl [IP]:9104/metrics 配置Prometheus监控mysqld_exporter# 修改配置文件 vim /usr/local/prometheus/prometheus.yml - job_name: 'mysqld_exporter' # 添加监控mysqld_exporter static_configs: - targets: ['47.100.107.121:9104'] # 重启 systemctl restart prometheus.service 导入MySQL仪表盘导入ID为7362的MySQL仪表盘，查看MySQL的监控数据","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus 配置文件与核心功能(4)","slug":"Prometheus 配置文件与核心功能(4)","date":"2020-07-15T11:06:15.000Z","updated":"2020-09-11T11:23:57.019Z","comments":true,"path":"post/521f1005.html","link":"","permalink":"https://www.missf.top/post/521f1005.html","excerpt":"","text":"全局配置文件介绍global: # 全局默认的数据拉取间隔,默认每隔1m拉取一次监控数据 [ scrape_interval: &lt;duration> | default = 1m ] # 全局默认的单次数据拉取超时 [ scrape_timeout: &lt;duration> | default = 10s ] # 对告警规则做定期计算的间隔时间,每隔1m对比一次我采集到的数据跟我设置的告警规则,符合告警规则的事件就会被发送到alertmanager,由alertmanager做路由匹配然后进行告警处理 [ evaluation_interval: &lt;duration> | default = 1m ] # 监控告警的规则设置 rule_files: [ - &lt;filepath_glob> ... ] # 配置被监控指标 scrape_configs: [ - &lt;scrape_config> ... ] # 指定告警和告警管理器相关的设置 alerting: alert_relabel_configs: [ - &lt;relabel_config> ... ] alertmanagers: [ - &lt;alertmanager_config> ... ] scrape_configs配置数据源，拉取数据的对象称为Targets，每个Targets用job_name命名，添加数据源又分为静态配置和服务发现 # 定义job名称,是一个拉取单元,每个job_name都会自动引入默认配置如: # scrape_interval 依赖全局配置 # scrape_timeout 依赖全局配置 # metrics_path 默认为'/metrics' # scheme 默认为'http' job_name: &lt;job_name> # 数据拉取间隔 [ scrape_interval: &lt;duration> | default = &lt;global_config.scrape_interval> ] # 数据拉取超时时间 [ scrape_timeout: &lt;duration> | default = &lt;global_config.scrape_timeout> ] # 拉取数据指标的地址 [ metrics_path: &lt;path> | default = /metrics ] 基于文件的服务发现基于文件的服务发现不需要依赖其他平台与第三方服务，用户只需将要更新的target信息以yaml或json文件格式添加到target文件中，prometheus会定期的从指定文件中读取target信息并更新。给我们带来的好处就是不需要一个个target去添加，只需要一个yaml或者json文件，便于管理 编写配置文件vim prometheus.yml # my global config 全局配置文件 global: scrape_interval: 5s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration 告警管理 alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093 # Load rules once and periodically evaluate them according to the global 'evaluation_interval'. rule_files: # - \"first_rules.yml\" # - \"second_rules.yml\" # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs: # The job name is added as a label `job=&lt;job_name>` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. # scrape_interval: 5s # static_configs: # - targets: ['localhost:9090'] file_sd_configs: # 文件服务发现 - files: ['/usr/local/prometheus/sd_config/*.yaml'] # 指定服务发现的文件路径 refresh_interval: 5s # 每过5秒动态发现服务配置 创建目录及文件vim /usr/local/prometheus/sd_config/test.yaml # 需要监控那一台主机就在那一台主机上创建 - targets: - '10.10.110.150:9090' # 这个是填写prometheus主机的地址,如果prometheus启动时监听的是8080端口,那么这里就需要和prometheus端口一致,不然获取不到数据 labels: group: prometheus 重载配置文件ps -ef | grep prometheus root 1774 1 0 Jul15 ? 00:02:21 /usr/local/prometheus/prometheus --config.file=/usr/local/prometheus/prometheus.yml root 2741 1702 0 14:13 pts/1 00:00:00 grep --color=auto prometheus kill -hup 1774","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus 部署(3)","slug":"Prometheus 部署(3)","date":"2020-07-15T09:11:11.000Z","updated":"2020-09-11T11:25:47.510Z","comments":true,"path":"post/d26dfcbe.html","link":"","permalink":"https://www.missf.top/post/d26dfcbe.html","excerpt":"","text":"二进制部署# 下载二进制安装包 wget https://github.com/prometheus/prometheus/releases/download/v2.19.2/prometheus-2.19.2.linux-amd64.tar.gz # 解压 tar xf prometheus-2.19.2.linux-amd64.tar.gz &amp;&amp; mv prometheus-2.19.2.linux-amd64 /usr/local/prometheus # 创建启动文件 cp /usr/lib/systemd/system/sshd.service /usr/lib/systemd/system/prometheus.service # 编写启动文件 tee /usr/lib/systemd/system/prometheus.service &lt;&lt; EOF [Unit] Description=http://prometheus.io [Service] Restart=on-failure ExecStart=/usr/local/prometheus/prometheus --config.file=/usr/local/prometheus/prometheus.yml [Install] WantedBy=multi-user.target EOF # 启动prometheus systemctl daemon-reload systemctl restart prometheus.service 修改配置文件vim /usr/local/prometheus/prometheus # my global config global: scrape_interval: 5s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093 # Load rules once and periodically evaluate them according to the global 'evaluation_interval'. rule_files: # - \"first_rules.yml\" # - \"second_rules.yml\" # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs: # The job name is added as a label `job=&lt;job_name>` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['127.0.0.1:9090'] Docker部署docker run -d --name \"prometheus\" -p 9090:9090 \\ --mount src=prometheus,dst=/etc/prometheus \\ --mount type=bind,src=/prometheus/prometheus.yml,dst=/etc/prometheus/prometheus.yml prom/prometheus 启动常用命令行参数./prometheus -h --config.file=\"prometheus.yml\" # 指定配置文件 --web.listen-address=\"0.0.0.0:9090\" # 指定端口 --log.level=info # 指定日志级别","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus 概述(2)","slug":"Prometheus 概述(2)","date":"2020-07-14T06:48:33.000Z","updated":"2020-09-11T11:23:39.189Z","comments":true,"path":"post/ef0b21f0.html","link":"","permalink":"https://www.missf.top/post/ef0b21f0.html","excerpt":"","text":"Prometheus简介Prometheus(普罗米修斯)是一个最初在SoundCloud上构建的监控系统。自2012年成为社区开源项目，拥有非常活跃的开发人员和用户社区。为强调开源及独立维护，Prometheus于2016年加入云原生云计算基金会(CNCF)，成为继Kubernetes之后的第二个托管项目 可能有些运维小伙伴不知道Prometheus，但是你们一定用过zabbix。现在由于Docker和Kubernetes的兴起，zabbix渐渐的失去了监控的优势，现在Prometheus是用来监控容器的最好实现，只有用到Docker和Kubernetes就离不开Prometheus提供监控支持。以前刚接触zabbix时，配置的微信告警让我开心了一整天，那时候觉得zabbix是世界上最好的监控软件，但是现在却觉得Prometheus才是。可能人总是需要不断向前看、不断向前奔跑的吧！ prometheus官网 Prometheus特点 多维数据模型(由时序列数据metric和一组key/value组成) 使用多维度数据完成复杂的语言查询，为prometheus的后期发展奠定基础(PromSQL) 不依赖分布式存储，单个服务器节点可直接工作 通过pushgateway进行时序列数据推送(pushing) 可以通过服务发现或者静态配置去获取要采集的目标服务器 多种可视化图表及仪表盘支持 基于HTTP的pull方式采集时间序列数据 Prometheus 组成及架构Prometheus根据配置定时去拉取各个节点的数据，默认使用的拉取方式是pull，也可以使用pushgateway提供的push方式获取各个监控节点的数据。将获取到的数据存入TSDB(时序型数据库)，此时prometheus已经获取到监控数据，可以使用内置的promSQL进行查询。它的报警功能使用alertmanager提供，alertmanager是prometheus的告警管理和发送报警的一个组件。prometheus原生的图表结构过于简单，prometheus的图表展示功能一般由grafana进行统一管理 Prometheus数据模型Prometheus将所有数据存储为时间序列，具有相同度量名称以及标签属于同一个指标。每个时间序列都由度量标准名称和一组键值对(也成为标签)唯一标识 # 时间序列格式示例 &lt;metric name>{&lt;label name>=&lt;label value>, ...} api_http_requests_total{method=\"POST\", handler=\"/messages\"} Prometheus指标类型Counter: 递增的计数器 Gauge: 可以任意变化的数值 Histogram: 对一段时间范围内数据进行采样，并对所有数值求和与统计数量 Summary: 与Histogram类似 不同的指标类型用于渲染不同的图表 Prometheus作业和实例实例: 可以抓取的目标称为实例(Instances) 作业: 具有相同目标的实例集合称为作业(Job) scrape_configs: - job_name: 'prometheus' # prometheus这个job作用于localhost:9090这个目标 static_configs: - targets: ['localhost:9090'] - job_name: 'node' # node这个job作用于192.168.1.10:9090这个目标 static_configs: - targets: ['192.168.1.10:9090']","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Prometheus 监控的意义(1)","slug":"Prometheus 监控的意义(1)","date":"2020-07-13T17:28:39.000Z","updated":"2020-09-11T11:23:45.870Z","comments":true,"path":"post/ded057ed.html","link":"","permalink":"https://www.missf.top/post/ded057ed.html","excerpt":"","text":"监控目的监控分为白盒监控和黑盒监控。白盒监控: 通过监控内部的运行状态及指标判断接下来可能会发生的问题，从而做出预判或应对的方法。黑盒监控: 监控系统或服务，在发生异常时做出相应的措施。prometheus属于黑盒监控，是在服务发生异常时，我们通过告警信息得知，才去处理异常问题 监控的目的主要分为以下方面: 根据历史监控数据，对未来做出预测 发生异常时即使告警，或做出相应措施 根据监控报警及时定位问题根源，记录问题出现的证据(记录网络波动) 通过可视化图表展示，便于直观获取信息 领导查看数据图表(PV、UV、订单趋势图) 运维人员能够提前预知风险，避免故障的产生或者在故障发生时能够迅速处理 怎么监控使用传统监控工具，直接调用Linux系统命令去获取服务状态和信息 # free # vmstat # df # top # ss # iftop ... 使用监控系统去监控系统和服务，能够整体监控每一项数据 # zabbix # nagios # prometheus # open-falcon 监控流程监控的大概流程分为:数据采集、数据存储、数据分析、以及展示和告警 监控什么 监控类型 具体参数 硬件监控 硬件参数、温度、故障等 系统监控 CPU，内存，硬盘，网卡流量，TCP状态，进程数 应用监控 Nginx、Tomcat、PHP、MySQL、Redis等 日志监控 系统日志、服务日志、访问日志、错误日志 安全监控 WAF，敏感文件监控 API监控 可用性，接口请求，响应时间 业务监控 例如电商网站，每分钟产生多少订单、注册多少用户、多少活跃用户、推广活动效果 流量分析 根据流量获取用户相关信息，例如用户地理位置、某页面访问状况、页面停留时间等","categories":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Docker Compose 单机编排利器(9)","slug":"Docker Compose 单机编排利器(9)","date":"2020-07-10T06:27:09.000Z","updated":"2020-09-11T11:22:27.422Z","comments":true,"path":"post/34699079.html","link":"","permalink":"https://www.missf.top/post/34699079.html","excerpt":"","text":"Docker Compose 概述Compose是用于定义和运行多容器的工具，通过Compose可以使用YAML文件来配置容器。然后使用一个命令就可以从配置中创建并启动所有服务。其实在刚学习Docker时我就想过，如果我是LNMP架构容器化项目，因为每次都要一个个容器的启动，是否有必要将启停多个容器的命令写成一个shell脚本呢。现在学到Docker Compose，才知道根本没有这个必要，我们现在所有能想到的东西，其实早就有人帮我们实现了。这里不得不敬佩那些为开源项目做出贡献的伟大开发者们 使用Compose大概分为三个步骤: 定义Dockerfile，以便可以在任意环境运行 定义应用程序启动配置文件 docker-compose.yml docker-compose启动并管理整个应用程序生命周期 Linux 安装 Compose其实前面我们在学习Harbor时已经安装过docker-compose，这是一个使用python开发的编排工具，国内下载可能会比较慢(你应该知道怎么做了吧…) curl -L \"https://github.com/docker/compose/releases/download/1.26.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/bin/docker-compose chmod +x /usr/bin/docker-compose docker-compose.yaml配置文件参数build使用docker-compose启动容器服务除了可以基于指定的镜像，还可以基于一份Dockerfile，在使用up启动时执行构建镜像的任务，这个构建标签就是build。Compose将会利用它自动构建这个镜像，然后使用这个镜像启动服务容器 version:\"3.7\" services: web: context:./web dockerfile:Dockerfile contextcontext选项可以是Dockerfile的文件路径，也可以是到链接到git仓库的url。当提供的值是相对路径时，它被解析为相对于撰写文件的路径，此目录也是发送到Docker守护进程的context build: context:./dir dockerfile使用此dockerfile文件来构建，必须使用context指定构建路径 build: context:. # 知道dockerfile必须要有构建路径,.表示当前路径 dockerfile:Dockerfile-alternate image指定docker-compose启动容器服务的镜像，可以是存储仓库、标签以及镜像ID，如果镜像不存在，Compose会自动拉去镜像 image: redis image: ubuntu:14.04 image: tutum/influxdb image: example-registry.com:4000/postgresql image: a4bc65fd command覆盖容器启动后默认执行的命令 command:bundle exec thin -p 3000 command:[\"bundle\",\"exec\",\"thin\",\"-p\",\"3000\"] container_name指定容器名称，由于容器名称是唯一的，如果指定自定义名称，则无法使用scale container_name:my-web-container environment添加环境变量，可以使用数组或字典。这个标签的作用是设置镜像变量，它可以保存变量到镜像里面，类似ENV指令一样会把变量一直保存在镜像、容器中 environment: RACK_ENV:development SHOW:'true' SESSION_SECRET: environment: -RACK_ENV=development -SHOW=true -SESSION_SECRET networks加入指定网络 networks: - lnmp ports映射端口 ports: -\"3000\" -\"3000-3005\" -\"8000:8000\" -\"9090-9091:8080-8081\" -\"49100:22\" -\"127.0.0.1:8001:8001\" -\"127.0.0.1:5000-5010:5000-5010\" # 指定IP+端口的话只会监听ipv4的地址 -\"6060:6060/udp\" expose暴露端口，但不映射到宿主机，只被连接的服务访问。这个标签与Dockerfile中的EXPOSE指令一样，用于指定暴露的端口，实际上docker-compose.yml的端口映射还得ports这样的标签 extra_hosts添加主机名的标签，就是往/etc/hosts文件中添加一些记录，与Docker客户端中的–add-host类似 extra_hosts: -\"www.missf.top:124.156.205.241\" -\"mf_missf.gitee.io:212.64.62.174\" volumes挂载一个目录或者一个已存在的数据卷容器 volumes: - /opt/data:/var/lib/mysql # 挂载宿主机的/opt/data目录到容器的/var/lib/mysql - datavolume:/var/lib/mysq # 将容器的/var/lib/mysq挂载到datavolume数据卷 restart默认值为 no ，即在任何情况下都不会重新启动容器。当值为 always 时，容器总是重新启动。当值为on-failure时，当出现on-failure报错容器退出时，容器重新启动。 restart: \"no\" restart: always restart: on-failure restart: unless-stopped hostname定义容器主机名 hostname: foo Compose 常用选项与命令up该命令十分强大，它将尝试自动完成包括构建镜像，创建服务，启动服务，并关联服务相关容器的一系列操作 up选项如下: -d: 在后台运行服务容器 –force-recreate: 强制重新创建容器，不能与–no-recreate同时使用 –no-recreate: 如果容器已经存在了，则不重新创建，不能与–force-recreate同时使用 -no-build: 不自动构建缺失的服务镜像 –no-deps: 不启动服务所链接的容器 build可以随时在项目目录下运行docker-compose build来重新构建服务 build选项如下: –force-rm: 删除构建过程中的临时容器 –no-cache: 构建镜像过程中不使用cache(这将加长构建过程) –pull: 始终尝试通过pull来获取更新版本的镜像 ps列出项目中目前的所有容器 ps选项如下: -q: 只打印容器的ID信息 logs查看服务容器的输出，默认情况下，docker-compose将对不同的服务输出使用不同的颜色来区分 docker-compose logs [选项] rm删除所有(停止状态的)服务容器，推荐先执行docker-compose stop命令来停止容器 rm选项如下: -f/–force: 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项 -v: 删除容器所挂载的数据卷 scale设置指定服务运行的容器个数 docker-compose scale web=3 db=2 down删除容器、网络 start/stop/restart启动/停止/重启服务 docker-compose编排lnmp容器docker-compose目录设计tree /docker-compose_lnmp/ /docker-compose_lnmp/ ├── docker-compose.yaml ├── mysql │ └── start ├── nginx │ ├── Dockerfile │ ├── nginx-1.16.1.tar.gz │ ├── nginx.conf │ ├── php.conf │ └── start └── php ├── Dockerfile ├── php-7.4.0.tar.gz ├── php-fpm.conf ├── php.ini ├── start └── www.conf docker-compose.yamlversion: '3' services: php: hostname: php build: context: ./php dockerfile: Dockerfile networks: - \"lnmp\" volumes: - \"nginx:/usr/local/nginx/html\" nginx: hostname: nginx build: context: ./nginx dockerfile: Dockerfile ports: - \"80:80\" - \"443:443\" networks: - \"lnmp\" volumes: - \"nginx:/usr/local/nginx/html/\" mysql: hostname: mysql image: mysql:5.7 ports: - \"53306:3306\" networks: - \"lnmp\" volumes: - \"mysql:/var/lib/mysql/\" command: --character-set-server=utf8mb4 environment: MYSQL_ROOT_PASSWORD: mwj123456 MYSQL_DATABASE: wordpress networks: lnmp: {} volumes: nginx: {} # 把php代码放到这个数据卷的目录下 mysql: {} docker-compose编排nginx反向代理tomcat集群docker-compose目录设计tree /docker-compose_lnmt/ /docker-compose_lnmt/ ├── docker-compose.yaml ├── nginx │ ├── Dockerfile │ ├── nginx-1.16.1.tar.gz │ ├── nginx.conf │ ├── start │ └── tomcat.conf └── tomcat ├── apache-tomcat-8.5.57.tar.gz ├── Dockerfile ├── jdk-8u211-linux-x64.tar.gz └── start docker-compose.yamlcat docker-compose.yaml version: '3' services: nginx: hostname: nginx build: context: ./nginx dockerfile: Dockerfile ports: - \"80:80\" - \"443:443\" networks: - \"lnmt\" volumes: - \"webapps:/usr/local/tomcat/webapps/\" tomcat1: hostname: tomcat1 build: context: ./tomcat dockerfile: Dockerfile networks: - \"lnmt\" volumes: - \"webapps:/usr/local/tomcat/webapps/\" tomcat2: hostname: tomcat2 build: context: ./tomcat dockerfile: Dockerfile networks: - \"lnmt\" volumes: - \"webapps:/usr/local/tomcat/webapps/\" tomcat3: hostname: tomcat3 build: context: ./tomcat dockerfile: Dockerfile networks: - \"lnmt\" volumes: - \"webapps:/usr/local/tomcat/webapps/\" mysql: hostname: mysql image: mysql:5.7 ports: - \"53306:3306\" networks: - \"lnmt\" volumes: - \"mysql:/var/lib/mysql/\" command: --character-set-server=utf8mb4 environment: MYSQL_ROOT_PASSWORD: mwj123456 MYSQL_DATABASE: test volumes: webapps: {} # 把war包放到这个数据卷的目录下,就会自动解压 mysql: {} networks: lnmt: {} 监听Nginx容器访问日志tail -f /usr/local/nginx/logs/access.log # 点击浏览器刷新页面,可以看到upstream_addr的IP变化,这样就实现了反向代理Tomcat集群 {\"@timestamp\": \"2020-07-14T08:03:19+08:00\", \"clientRealIp\": \"10.10.110.1\", \"scheme\": \"http\", \"method\": \"GET\", \"host\": \"10.10.110.150\", \"url\": \"/\", \"size\": 1056, \"referrer\": \"-\", \"agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36\", \"upstream_addr\": \"192.168.16.3:8080\", \"request_time\": 0.323, \"request_length\": 450, \"upstream_connect_time\": \"0.003\", \"upstream_response_time\": \"0.324\", \"upstream_status\": \"200\", \"status\": \"200\"} {\"@timestamp\": \"2020-07-14T08:03:28+08:00\", \"clientRealIp\": \"10.10.110.1\", \"scheme\": \"http\", \"method\": \"GET\", \"host\": \"10.10.110.150\", \"url\": \"/\", \"size\": 1056, \"referrer\": \"-\", \"agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36\", \"upstream_addr\": \"192.168.16.6:8080\", \"request_time\": 0.345, \"request_length\": 450, \"upstream_connect_time\": \"0.000\", \"upstream_response_time\": \"0.345\", \"upstream_status\": \"200\", \"status\": \"200\"} {\"@timestamp\": \"2020-07-14T08:03:29+08:00\", \"clientRealIp\": \"10.10.110.1\", \"scheme\": \"http\", \"method\": \"GET\", \"host\": \"10.10.110.150\", \"url\": \"/\", \"size\": 1056, \"referrer\": \"-\", \"agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36\", \"upstream_addr\": \"192.168.16.4:8080\", \"request_time\": 0.355, \"request_length\": 450, \"upstream_connect_time\": \"0.000\", \"upstream_response_time\": \"0.354\", \"upstream_status\": \"200\", \"status\": \"200\"}","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker 图形化页面管理(8)","slug":"Docker 图形化页面管理(8)","date":"2020-07-10T02:03:55.000Z","updated":"2020-09-11T11:21:56.944Z","comments":true,"path":"post/92368be2.html","link":"","permalink":"https://www.missf.top/post/92368be2.html","excerpt":"","text":"Docker图形化页面管理Portainer概述Portainer是Docker的图形化管理工具，portainer通过连接/var/run/docker.sock文件去管理容器，可让你轻松管理不同的Docker环境(Docker主机或Swarm群集)。Portainer提供状态显示面板、应用模板快速部署、容器镜像网络数据卷、事件日志显示、容器控制台操作、登录用户管理和控制等功能。Docker图形化管理界面有很多实现的工具，但生态一直不温不火，这是由于Docker的很多操作都是直接在命令行进行，再加上Docker的操作也比较简单。一般这样的图形化管理平台都是交给开发和测试人员去使用的 Portainer安装docker run -d -p 8000:8000 -p 9000:9000 --name \"portainer\" --restart=always \\ -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer # 这里portainer通过连接/var/run/docker.sock文件去管理容器,所以需要把宿主机的docker.sock文件挂载到portainer 登录Portainer页面 Portainer连接容器的方式Local:管理Portainer所在主机上的Docker主机，需要将宿主机的docker.sock文件挂载到Portainer容器内 Remote:管理远程主机上的Docker主机，但是要开启远程的Docker主机的Docker API，允许Portainer通过TCP连接 Agent:直接连接到在Swarm集群中运行的Portainer代理 Azure:连接到Microsoft Azure 这里我们先使用Local的方式连接到Portainer所在的主机 Portainer管理界面通过下图可以看到Portainer提供了对容器、镜像、网络、数据卷、变量、主机的操作，App templates是一些供我们下载的公共镜像，我们还可以看到正在运行的容器状态、日志、基于镜像、创建时间、映射端口等 Portainer连接远程Docker主机首先需要在远程Docker主机上开启Docker API vim /usr/lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 # 表示所有地址都能连接到Docker API,也可以指定IP连接,默认端口是2375 systemctl daemon-reload systemctl restart docker.service 然后在Portainer再创建一个连接远程Docker主机API的节点 这时候我们可以使用Portainer去管理本地和远程主机上的Docker资源了","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker 企业级镜像仓库Harbor(7)","slug":"Docker 企业级镜像仓库Harbor(7)","date":"2020-07-08T05:33:50.000Z","updated":"2020-09-11T11:22:05.041Z","comments":true,"path":"post/d46af348.html","link":"","permalink":"https://www.missf.top/post/d46af348.html","excerpt":"","text":"Harbor 概述Harbor是由VMWare公司开源的容器镜像仓库。事实上，Harbor是在Docker Registry上进行了相应的企业级扩展，从而获得了更加广泛的应用，这些新的企业级特性包括：管理用户界面，基于角色的访问控制 ，AD/LDAP集成以及审计日志等，足以满足基本企业需求 Harbor 官网 Harbor GitHub 地址 Harbor 部署条件服务器硬件配置最低要求:CPU2核/内存4G/硬盘40GB 推荐:CPU4核/内存8G/硬盘160GB 软件Docker 17.06版本+ Docker Compose 1.18版本+ 安装方式在线安装:从Docker Hub下载Harbor相关镜像，因此安装软件包非常小 离线安装:安装包包含部署的相关镜像，因此安装包比较大 docker-compose安装下载二进制文件https://github.com/docker/compose/releases # docker-compose下载地址 # 下载docker-compose-Linux-x86_64这个二进制文件 配置二进制文件mv docker-compose-Linux-x86_64 /usr/bin/docker-compose chmod +x /usr/bin/docker-compose docker-compose --help # 安装完成 Harbor HTTP部署下载Harbor安装包wget https://github.com/goharbor/harbor/releases/download/v2.0.1/harbor-offline-installer-v2.0.1.tgz 解压安装包tar xf harbor-offline-installer-v2.0.1.tgz 修改配置文件cp harbor.yml.tmpl harbor.yml vim harbor.yml hostname: reg.missf.com # 修改Harbor默认域名 https: # 先注释https相关配置 harbor_admin_password: MF-yihan # 修改Harbor的密码 部署Harbor./prepare # 做一系列的准备工作 ./install.sh # 利用docker-compose拉取一系列的镜像,安装好之后就会直接启动 访问Harbor# 通过本地电脑配置hosts,然后在浏览器访问我们的域名reg.missf.com {% image https://pic.imgdb.cn/item/5f05980114195aa5940c513f.jpg '' '' %} 登录Harborvim /etc/hosts # 添加解析,登录时可以直接访问域名 10.10.110.151 reg.missf.com vim /etc/docker/daemon.json # 配置域名可信任,因为现在没有配置https,而docker默认是使用https协议去连接的,不配置不能登录成功 { \"registry-mirrors\": [\"https://265wemgl.mirror.aliyuncs.com\"], \"insecure registries\": [\"reg.missf.com\"] } systemctl restart docker.service # 修改了daemon.json需要重启docker docker-compose down &amp;&amp; docker-compose up -d # 重启docker之后容器有些会退出,重启harbor重启把容器拉起来 docker login reg.missf.com # 登录成功 Username: admin Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded 推送镜像到Harbor仓库docker tag nginx:1.0 reg.missf.com/library/nginx:1.0 # 推送之前修改镜像的标签(镜像中心/项目/镜像:标签) docker push reg.missf.com/library/nginx:1.0 # 推送镜像，pull拉取镜像也是使用这个标签去拉取 The push refers to repository [reg.missf.com/library/nginx] b1b653ec37ba: Pushed fe503a975c26: Pushed 60165efe909a: Pushed e098d2f9f0dd: Pushed ae9b67129281: Pushed d2039520c249: Pushed 034f282942cd: Pushed 1.0: digest: sha256:a4c155ecb6b7eee5d332764057c29a74d8965de19f9d739f1792cf479c2bf030 size: 1786 查看Harbor上推送成功的镜像 Harbor HTTPS部署由于Harbor不附带任何证书，它默认使用HTTP来提供注册表请求。但是强烈建议为生产环境配置ssl证书。这里我们由于是实验测试，使用自签名证书，到时候生产环境配置可以去阿里云购买ssl证书。 生成自签名ssl证书由于kubernetes使用cfssl自签证书,这里我们也使用cfssl生成自签证书 # 执行这个脚本,安装cfssl并将命令放到/usr/bin/下供我们直接使用 cat cfssl.sh wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 chmod +x cfssl* mv cfssl_linux-amd64 /usr/bin/cfssl mv cfssljson_linux-amd64 /usr/bin/cfssljson mv cfssl-certinfo_linux-amd64 /usr/bin/cfssl-certinfo # 执行这个脚本,生成两个json的ca配置文件并自动生成证书,cfssl是根据json的配置文件去生成ca证书的 cat certs.sh cat > ca-config.json &lt;&lt;EOF { \"signing\": { \"default\": { \"expiry\": \"87600h\" }, \"profiles\": { \"kubernetes\": { \"expiry\": \"87600h\", \"usages\": [ \"signing\", \"key encipherment\", \"server auth\", \"client auth\" ] } } } } EOF cat > ca-csr.json &lt;&lt;EOF { \"CN\": \"kubernetes\", \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"Beijing\", \"ST\": \"Beijing\" } ] } EOF cfssl gencert -initca ca-csr.json | cfssljson -bare ca - # 初始化ca配置文件 cat > reg.missf.com-csr.json &lt;&lt;EOF { \"CN\": \"reg.missf.com\", \"hosts\": [], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"BeiJing\", \"ST\": \"BeiJing\" } ] } EOF cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes reg.missf.com-csr.json | cfssljson -bare reg.missf.com # 生成ca证书 # 执行完上面两个脚本之后我们会得到下面这两个文件 reg.missf.com-key.pem reg.missf.com.pem Harbor启用HTTPShttps: # https port for harbor, default is 443 port: 443 # The path of cert and key files for nginx certificate: /root/ssh/reg.missf.com.pem private_key: /root/ssh/reg.missf.com-key.pem 重新配置并部署Harborsystemctl restart docker.service ./prepare docker-compose down docker-compose up –d # 重新打开Harbor页面会自动跳转到https,但是由于是自签证书,所以仍会显示不安全 其他Docker主机连接Harbor仓库一般Harbor仓库都是自己公司内部使用,但是有时候也会开放给别的Docker主机去pull镜像，如果其他的Docker主机需要连接Harbor，必须要有证书才能连接 # 复制Harbor主机的证书到需要连接Harbor仓库的Docker主机上 mkdir -p /etc/docker/certs.d/reg.missf.com/ # 在Docker主机上创建目录 cp reg.missf.com.pem /etc/docker/certs.d/reg.missf.com/reg.missf.com.crt # 将Harbor主机的证书复制到Docker主机 echo \"10.10.110.151 reg.missf.com\" >> /etc/hosts # 这里由于是实验环境,需要配置域名解析 docker login reg.missf.com # 在其他的docker主机登录到Harbor,就可以pull拉取Harbor仓库的镜像了 Username: admin Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded Harbor主从复制Harbor主从复制的三种方式学习过MySQL主从的同学可以看出，其实Harbor的主从复制和MySQL的主从复制方式非常相似 主节点的仓库管理新建目标新建一个目标，就代表本地Harbor可以连接到这个远程Harbor，当我们配置复制管理的目的Registry时，可以从新建目标里面填写复制镜像到那个Harbor节点 主节点的复制管理新建规则配置复制模式和目的Registry，将本地Harbor主节点上的镜像(可以使用过滤器进行选择性推送)推送到备用Harbor节点上 推送验证这时候只有有镜像被推送到Harbor的主节点，那么Harbor主节点就会把镜像push到Harbor的备用节点，可以查看复制记录 Harbor运行维护Harbor容器功能介绍 容器 功能 harbor-core 配置管理中心 harbor-jobservice 负责镜像复制 harbor-log 记录操作日志 harbor-portal Web管理页面和API harbor-db PG数据库 registryctl 镜像存储 nginx 前端代理，负责前端页面和镜像上传/下载转发 redis 会话 Harbor容器数据持久化目录:/data(这个目录需要定时备份) 日志文件目录:/var/log/harbor","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Dockerfile 定制容器镜像(6)","slug":"Dockerfile 定制容器镜像(6)","date":"2020-06-30T05:33:50.000Z","updated":"2020-09-11T11:21:54.298Z","comments":true,"path":"post/44241b5a.html","link":"","permalink":"https://www.missf.top/post/44241b5a.html","excerpt":"","text":"Dockerfile 介绍Dockerfile是由一行一行的命令语句组成，并且从上到下执行，支持以#注释行。一般Dockerfile的内容分为四个部分，基础镜像信息、维护者信息、镜像操作指令、容器启动时执行指令 Dockerfile 常用指令 指令 描述 FROM 指定构建新镜像时是基于那个镜像，Dockerfile的第一条指令必须为FROM指令，如果在同一个Dockerfile中创建多个镜像可以使用多个FROM指令 LABEL 为镜像添加标签 RUN 每条RUN指令将在当前镜像的基础上执行指定shell命令，并提交为新的镜像 COPY 拷贝宿主机(Dockerfile所在目录的相对路径)的文件或目录到镜像中 ADD 复制指定的&lt;src&gt;到容器中的&lt;dest&gt;，&lt;src&gt;可以是Dockerfile所在目录的文件或目录，可以是一个URL，还可以是一个tar文件(自动解压缩) ENV 指定一个环境变量，会被后续RUN指令使用，并在容器运行时保持 USER 指定运行容器时的用户名或UID，后续的RUN也会使用指定用户 EXPOSE 声明容器运行的服务端口，启动容器时可以将这些端口转发到宿主机或者指定宿主机那个端口映射过来 WORKDIR 为后续的RUN、CMD、ENTRYPOINT指令配置工作目录 VOLUME 在镜像中创建挂载点，这样只要通过该镜像创建的容器都有了挂载点，查看容器详细信息可以看到容器挂载点映射到宿主机的目录 CMD 容器启动时执行指令，每个Dockerfile只能有一条CMD指令，如果有多个CMD指令只有最后一个生效 ENTRYPOINT ENTRYPOINT如果与CMD一起使用，CMD将作为ENTRYPOINT的默认参数，如果有多个ENTRYPOINT指令只有最后一个生效 构建镜像Dockerfile demo# This dockerfile demo for project build to docker images FROM centos:7 LABEL maintainer www.missf.top USER root RUN yum install -y nginx EXPOSE 80 443 VOLUME [\"/usr/local/nginx/\"] CMD [\"/usr/local/nginx/bin\"] Docker build构建镜像# 在Dockerfile所在的目录下构建镜像,后面的\".\"表示当前目录 docker build -t demo:1.0 . # 构建过程如下 Sending build context to Docker daemon 2.048kB Step 1/8 : FROM centos:7 7: Pulling from library/centos 524b0c1e57f8: Pull complete Digest: sha256:e9ce0b76f29f942502facd849f3e468232492b259b9d9f076f71b392293f1582 Status: Downloaded newer image for centos:7 ---> b5b4d78bc90c Step 2/8 : LABEL maintainer mownejie ---> Running in 7dbcab7ef3ce Removing intermediate container 7dbcab7ef3ce ---> 4db1e9da6977 Step 3/8 : ENV JAVA_HOME /usr/local/java ---> Running in b896cedee458 Removing intermediate container b896cedee458 ---> f8991838d97e Step 4/8 : USER root ---> Running in 8252457198f0 Removing intermediate container 8252457198f0 ---> 96ef213928ad Step 5/8 : RUN yum install -y nginx ---> Running in 8807973810c5...... # -t 指定这个镜像的tag # -f 指定这个Dockerfile文件的位置 CMD 与 ENTRYPOINT 区别CMD用法# exec形式,首选形式,传参不支持引用变量 CMD [\"executable\", \"param1\", \"param2\"] # CMD作为ENTRYPOINT的默认参数 CMD [\"param1\", \"param2\"] # Shell形式 CMD command param1 param2 ENTRYPOINT用法ENTRYPOINT [\"executable\", \"param1\", \"param2\"] # 假如配合CMD一起使用,那么[\"param1\", \"param2\"]可以写在CMD作为ENTRYPOINT的默认参数 ENTRYPOINT command param1 param2 总结1. CMD和ENTRYPOINT指令都可以用来定义运行容器时所使用的命令 2. Dockerfile至少指定一个CMD或ENTRYPOINT 3. CMD可以用作ENTRYPOINT默认参数，或者用作容器的默认命令 4. docker run启动容器时指定&lt;command>，将会覆盖dockerfile定义的CMD 构建Nginx容器镜像dockerfile内容FROM centos:7.7.1908 LABEL maintainer www.missf.top RUN yum install -y gcc gcc-c++ make \\ openssl-devel pcre-devel gd-devel \\ iproute net-tools telnet wget curl && \\ yum clean all && rm -rf /var/cache/yum/* ADD nginx-1.16.1.tar.gz / RUN cd nginx-1.16.1 && \\ ./configure --user=nginx --group=nginx \\ --prefix=/usr/local/nginx \\ --with-http_stub_status_module \\ --with-http_ssl_module \\ --with-http_gzip_static_module \\ --with-http_sub_module && \\ make -j4 && make install && \\ mkdir /usr/local/nginx/conf/vhost && \\ cd / && rm -rf nginx* && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime RUN useradd -s /sbin/nologin nginx ENV PATH $PATH:/usr/local/nginx/sbin ENV LANG=\"en_US.utf8\" COPY nginx.conf /usr/local/nginx/conf/nginx.conf COPY php.conf /usr/local/nginx/conf/vhost/php.conf WORKDIR /usr/local/nginx EXPOSE 80 443 CMD [\"nginx\", \"-g\", \"daemon off;\"] 目录结构[root@localhost /Dockerfile/nginx]# ll total 1028 -rw-r--r-- 1 root root 890 Jul 6 18:58 Dockerfile -rw-r--r-- 1 root root 1032630 Jan 14 09:53 nginx-1.16.1.tar.gz -rw-r--r-- 1 root root 3297 Jul 6 18:46 nginx.conf -rw-r--r-- 1 root root 362 Jul 6 20:13 php.conf -rw-r--r-- 1 root root 128 Jul 6 18:51 start 构建PHP容器镜像dockerfile内容FROM centos:7.7.1908 LABEL maintainer www.missf.top RUN yum install -y epel-release && \\ yum install -y sqlite-devel libmcrypt-devel mhash-devel libxslt-devel \\ libjpeg-devel libpng libpng-devel freetype freetype-devel \\ libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel libjpeg \\ glib2 glib2-develbzip2 bzip2-devel ncurses ncurses-devel \\ curl-devel e2fsprogs e2fsprogs-devel krb5 gcc krb5-devel libidn \\ openssl-devel libsqlite3x-devel oniguruma-devel openssl libidn-devel \\ iproute net-tools telnet wget curl && \\ yum clean all && rm -rf /var/cache/yum/* ADD php-7.4.0.tar.gz / RUN cd /php-7.4.0 && \\ ./configure --prefix=/usr/local/php \\ --with-config-file-path=/usr/local/php/etc \\ --enable-opcache --with-curl --enable-fpm \\ --enable-gd --with-iconv --enable-mbstring \\ --with-mysqli --with-openssl --enable-static \\ --enable-sockets --enable-inline-optimization \\ --with-zlib --disable-ipv6 --disable-fileinfo \\ --with-mcrypt --enable-hash --with-jpeg-dir --with-png-dir \\ --with-freetype-dir --with-pdo-mysql --disable-debug && \\ make -j 4 && make install && \\ cp /php-7.4.0/php.ini-production /usr/local/php/etc/php.ini && \\ cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf && \\ cp /usr/local/php/etc/php-fpm.d/www.conf.default /usr/local/php/etc/php-fpm.d/www.conf && \\ sed -i \"90a \\daemonize = no\" /usr/local/php/etc/php-fpm.conf && \\ mkdir /usr/local/php/log && \\ cd / && rm -rf php* && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime ENV PATH $PATH:/usr/local/php/sbin ENV LANG=\"en_US.utf8\" COPY php.ini /usr/local/php/etc/ COPY php-fpm.conf /usr/local/php/etc/ COPY www.conf /usr/local/php/etc/php-fpm.d/ WORKDIR /usr/local/php EXPOSE 9000 CMD [\"php-fpm\"] 目录结构[root@localhost /Dockerfile/php]# ll total 16144 -rw-r--r-- 1 root root 1758 Jul 6 18:53 Dockerfile -rw-r--r-- 1 root root 16418792 Jul 1 10:39 php-7.4.0.tar.gz -rw-r--r-- 1 root root 5394 Jul 1 21:51 php-fpm.conf -rw-r--r-- 1 root root 72953 Jul 1 22:09 php.ini -rw-r--r-- 1 root root 93 Jul 6 18:56 start -rw-r--r-- 1 root root 19616 Jul 6 18:53 www.conf 容器化搭建个人博客自定义网络docker network create lnmp # 将多个容器加入到一个自定义网络 创建MySQL容器docker volume create mysql docker run -e MYSQL_ROOT_PASSWORD=mwj123456 -e MYSQL_DATABASE=wordpress -p 53306:3306 --name \"mysql\" --network lnmp --mount src=mysql,dst=/var/lib/mysql/ -d mysql:5.7 # 将MySQL数据库的数据持久化到mysql这个数据卷 创建PHP容器docker volume create nginx docker run --name php --network lnmp --mount src=nginx,dst=/usr/local/nginx/html/ -d php:1.0 # 这里先启动PHP容器再启动Nginx容器,因为Nginx要去连接PHP容器,如果PHP容器没有启动,那Nginx就因为无法连接到PHP所有退出了 # 这里需要把Nginx代码也挂载到PHP容器内,而且容器内的路径要与Nginx配置文件路径一致 # 因为Nginx配置文件将所有*.php的请求都通过fastcgi_pass代理到PHP容器去处理,所有需要把代码也挂载到PHP容器内,不然访问php文件会提示未找到文件 创建Nginx容器docker container run --name \"nginx\" --mount src=nginx,dst=/usr/local/nginx/html --network lnmp -p 80:80 -p 443:443 -d nginx:1.0 部署WordPress代码docker volume inspect nginx # 先查看数据卷在宿主机上的目录,然后把代码解压到对应的目录下 tar xf wordpress-5.4.2-zh_CN.tar.gz -C /var/lib/docker/volumes/nginx/_data/ # 这时候通过访问宿主机的IP就能看到WordPress的安装页面了,如果无法对wp-config.php文件写入,就手动创建并写入 构建Tomcat容器镜像dockerfile内容FROM centos:7.7.1908 LABEL maintainer www.missf.top ADD jdk-8u211-linux-x64.tar.gz /usr/local/ ADD apache-tomcat-8.5.57.tar.gz /usr/local/ RUN mv /usr/local/jdk1.8.0_211 /usr/local/jdk && \\ mv /usr/local/apache-tomcat-8.5.57 /usr/local/tomcat && \\ rm -rf /usr/local/tomcat/webapps/* ENV JAVA_HOME /usr/local/jdk ENV CLASSPATH ${JAVA_HOME}/lib/dt.jar:${JAVA_HOME}/lib/tools.jar ENV CATALINA_HOME /usr/local/tomcat ENV PATH $PATH:${JAVA_HOME}/bin:${CATALINA_HOME}/lib:${CATALINA_HOME}/bin RUN sed -i '1a JAVA_OPTS=\"-Djava.security.egd=file:/dev/./urandom\"' ${CATALINA_HOME}/bin/catalina.sh && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime WORKDIR ${CATALINA_HOME} EXPOSE 8080 CMD [\"catalina.sh\", \"run\"] 目录结构[root@localhost /Dockerfile/tomcat]# ll total 200568 -rw-r--r-- 1 root root 10379806 Jul 7 11:19 apache-tomcat-8.5.57.tar.gz -rw-r--r-- 1 root root 728 Jul 7 19:41 Dockerfile -rw-r--r-- 1 root root 194990602 Jul 2 2019 jdk-8u211-linux-x64.tar.gz 部署测试代码docker volume inspect tomcat # 查看Tomcat容器代码目录持久化到宿主机的目录 ll /var/lib/docker/volumes/tomcat/_data # 放到这个目录的war包会被自动解压 total 17840 drwxr-x--- 4 root root 37 Jul 7 21:34 ROOT -rw-r--r-- 1 root root 18265402 Jun 20 13:08 ROOT.war 构建java微服务项目镜像dockerfile内容# 一个容器内只跑一个jar包 FROM java:8-jdk-alpine LABEL maintainer www.missf.top ENV JAVA_OPTS=\"$JAVA_OPTS -Dfile.encoding=UTF8 -Duser.timezone=GMT+08 -Xms128m -Xmx128m\" RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories && \\ apk add -U tzdata && \\ mkdir /projects && \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime COPY hello.jar /projects/ EXPOSE 8888 CMD [\"/bin/sh\", \"-c\", \"java -jar $JAVA_OPTS /projects/hello.jar\"] Dockerfile 最佳实践减少镜像层一次RUN指令形成新的一层镜像，shell命令尽量写在一行，减少镜像层 优化镜像大小在形成新的一层镜像之后，如果没有在同一层删除缓存或者没用的文件，那么这些文件都会被带到下一层，所有要在每一层清理对应的残留数据，减少镜像大小 减少网络传输例如镜像所需要下载的软件包，mvn仓库 多阶段构建代码编译、部署在一个Dockerfile完成，只会保留部署阶段产生的数据 选择最小的基础镜像例如alpine","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker 容器网络(5)","slug":"Docker 容器网络(5)","date":"2020-06-23T01:49:44.000Z","updated":"2020-09-11T11:21:58.871Z","comments":true,"path":"post/bc1d2f66.html","link":"","permalink":"https://www.missf.top/post/bc1d2f66.html","excerpt":"","text":"容器的四种网络模式bridge 模式当启动docker进程之后，docker会默认创建一个名为docker0的虚拟网桥，创建容器时如果不指定网络，默认就是添加到这个网桥中。这样docker主机上的所有容器都可以通过交换机的方式连接在一个二层网络中。创建容器时，docker会先创建容器的虚拟网卡，容器的虚拟网卡去连接docker主机的docker0虚拟网桥，相当于用一根网线将容器和docker主机连接起来。虚拟网卡连接到docker0子网后，由docker0虚拟网桥分配IP给容器的虚拟网卡使用，并设置docker0虚拟网桥的IP地址为容器的默认网关。除了docker启动时默认创建的bridge默认网络，我们还可以自定义bridge网络。相比默认的具备内部DNS发现，bridge网络模式还可以通过容器名去实现容器之间的网络通信 查看docker宿主机上的docker0虚拟网桥，默认网段是172.17.0.1，安装docker之后默认创建的 ip a s docker0 3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default link/ether 02:42:9f:dc:ee:74 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:9fff:fedc:ee74/64 scope link valid_lft forever preferred_lft forever 查看默认定义好的网络模式,这里没有container模式是因为container是启动容器时直接指定的 docker network ls NETWORK ID NAME DRIVER SCOPE a42d2b0e12ec bridge bridge local 168bbf4b0447 host host local ec481d03e2a1 none null local 21be62f7b97e webserver bridge local 查看bridge网络模式的详细信息 docker network inspect bridge [ { \"Name\": \"bridge\", \"Id\": \"a42d2b0e12ec0e039e7c4686099468585b88c8df8b639eaa780700980adb9e1b\", \"Created\": \"2020-06-23T17:16:25.717600267+08:00\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [ { \"Subnet\": \"172.17.0.0/16\", \"Gateway\": \"172.17.0.1\" } ] }, \"Internal\": false, \"Attachable\": false, \"Ingress\": false, \"ConfigFrom\": { \"Network\": \"\" }, \"ConfigOnly\": false, \"Containers\": { \"253d0d8f196182eccaa52238068513cebfbf2abe69d2a7980e40d8c136b53960\": { \"Name\": \"nginx\", \"EndpointID\": \"7fd4576f90bc1d0fd966ed5794710dd43461d077ea32f99e54a8b3c56ba1de08\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" }, \"8652448b6f9a99d9b9a6c70277ea23924b21df57289d4deb29a146974ad4c4dd\": { \"Name\": \"centos7\", \"EndpointID\": \"e112927463f07a606a3a019f3af7400c711b9a903fec19c130b27c7d5f53d359\", \"MacAddress\": \"02:42:ac:11:00:03\", \"IPv4Address\": \"172.17.0.3/16\", \"IPv6Address\": \"\" } }, \"Options\": { \"com.docker.network.bridge.default_bridge\": \"true\", \"com.docker.network.bridge.enable_icc\": \"true\", \"com.docker.network.bridge.enable_ip_masquerade\": \"true\", \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\", \"com.docker.network.bridge.name\": \"docker0\", \"com.docker.network.driver.mtu\": \"1500\" }, \"Labels\": {} } ] 安装网桥管理工具包 yum install -y bridge-utils.x86_64 查看虚拟网桥上的接口信息 brctl show docker0 bridge name bridge id STP enabled interfaces docker0 8000.02429fdcee74 no veth81bdc19 vetha8f66a7 创建类型为bridge的自定义网桥 docker network create webserver 21be62f7b97ebfc9ce6f6a1aaaffd59a4a220c6b778f36a98c72162023b5c5e5 启动容器时指定使用自定义创建的webserver网桥(具备DNS发现) docker container run -itd --name \"app1\" --network webserver centos:7.7.1908 98efd7fb3c63c0bd487039b7ef00925d786e0499f10d76003afa2277cc93b404 docker container run -itd --name \"app2\" --network webserver centos:7.7.1908 c81e58db50ca74111d46f460ff322378b45414a36804738597559ec3c06cf542 docker container run -itd --name \"app3\" --network webserver centos:7.7.1908 41fb1a7dd161c03a158a104da54dcfa3b226035feceecabd003f7a18e91bff61 查看容器的IP地址 docker inspect --format='{{.NetworkSettings.Networks.webserver.IPAddress}}' app1 172.18.0.2 docker inspect --format='{{.NetworkSettings.Networks.webserver.IPAddress}}' app2 172.18.0.3 docker inspect --format='{{.NetworkSettings.Networks.webserver.IPAddress}}' app3 172.18.0.4 容器之间的通信测试，自定义的bridge网桥相比默认的bridge网桥具备内部DNS发现， IP和主机名都是可以PING通 ping 172.18.0.2 PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data. 64 bytes from 172.18.0.2: icmp_seq=1 ttl=64 time=0.203 ms 64 bytes from 172.18.0.2: icmp_seq=2 ttl=64 time=0.085 ms ping 98efd7fb3c63 # 如果启动容器时不指定自定义的网桥,那就会使用默认的bridge模式,这样是不能PING通主机名的 PING 98efd7fb3c63 (172.18.0.2) 56(84) bytes of data. 64 bytes from app1.webserver (172.18.0.2): icmp_seq=1 ttl=64 time=0.402 ms 64 bytes from app1.webserver (172.18.0.2): icmp_seq=2 ttl=64 time=0.100 ms host模式如果启动容器时指定host模式，那么这个容器将不会获得一个独立的Network namespace，而是和宿主机共用一个Network namespace。容器不会虚拟出自己的网卡，而是使用宿主机的IP和端口。这种无需NAT转换的网络模式无需再映射容器与宿主机之间的端口，在提高网络传输性能的同时，造成了网络环境隔离性弱化。容器之间不再拥有隔离独立的网络，docker host上已使用的端口就不能再用了 启动一个nginx容器，再查看宿主机上的80端口是否被使用 docker container run -itd --name \"host_nginx\" --network=host nginx:1.1 查看宿主机上的80端口是否被nginx容器所使用 netstat -lntup | grep 80 tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 7358/nginx: master 查看宿主机上nginx进程的父进程是否为docker ps -afx | grep containerd -A 1 1100 ? Ssl 1:18 /usr/bin/containerd 7341 ? Sl 0:00 \\_ containerd-shim -namespace moby -workdir /var/lib/containerd/io.containerd.runtime.v1.linux/moby/adf66250b1fcd95c2531f04f8504bea614dd90903f4f074e150ce6202895a023 -address /run/containerd/containerd.sock -containerd-binary /usr/bin/containerd -runtime-root /var/run/docker/runtime-runc 7358 pts/0 Ss+ 0:00 \\_ nginx: master process nginx -g daemon off; # 这个nginx进程是容器中启动的nginx进程,这也正如我们前面所说,使用host模式启动容器,容器会和宿主机共用一个Network namespace 进入容器中查看网卡信息，可以看到宿主机上的网卡也会显示，这就是共用了一个Network namespace的结果 ifconfig br-21be62f7b97e: flags=4099&lt;UP,BROADCAST,MULTICAST> mtu 1500 inet 172.18.0.1 netmask 255.255.0.0 broadcast 172.18.255.255 inet6 fe80::42:6fff:fe77:c9f0 prefixlen 64 scopeid 0x20&lt;link> ether 02:42:6f:77:c9:f0 txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 docker0: flags=4099&lt;UP,BROADCAST,MULTICAST> mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:9fff:fedc:ee74 prefixlen 64 scopeid 0x20&lt;link> ether 02:42:9f:dc:ee:74 txqueuelen 0 (Ethernet) RX packets 3 bytes 114 (114.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 8 bytes 677 (677.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ens32: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 10.10.110.150 netmask 255.255.255.0 broadcast 10.10.110.255 inet6 fe80::20c:29ff:fec4:cbac prefixlen 64 scopeid 0x20&lt;link> ether 00:0c:29:c4:cb:ac txqueuelen 1000 (Ethernet) RX packets 91694 bytes 118390130 (112.9 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 41857 bytes 2875558 (2.7 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73&lt;UP,LOOPBACK,RUNNING> mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host> loop txqueuelen 1000 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 none模式容器启动时指定none模式是获取独立的Network namespace，但不为容器进行任何网络配置。容器内部只有loopback网络设备不会再有其他的网络资源，将网络创建的责任完全交给用户。作为 Docker 开发者，才能在这基础做其他无限多可能的网络定制开发，这种方式可以实现更加灵活复杂的网络，同时也体现了Docker设计理念的开放 启动一个none模式的容器 docker container run -itd --name \"none_centos\" --network=none centos:7.7.1908 进入容器查看网卡设备信息 docker container exec -it none_centos /bin/bash ifconfig # 这里只有一个回环口地址,因为none模式不会对容器进行任何网络配置 lo: flags=73&lt;UP,LOOPBACK,RUNNING> mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host> loop txqueuelen 1000 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 container模式创建新的容器时指定和已存在的容器共享一个Network namespace，这些容器之间共享IP、端口范围等网络配置，容器之间传输效率高。两个容器除了网络资源共享之外，其他资源还是隔离的。虽然多个容器共享网络环境，但是多个容器形成的整体依然与宿主机以及其他容器形成网络隔离 启动一个名为server1的容器 docker container run -itd --name \"server1\" centos:7.7.1908 再启动两个容器，把它们加入到server1这个容器的Network namespace docker container run -itd --name \"server2\" --network=container:server1 centos:7.7.1908 docker container run -itd --name \"server3\" --network=container:server1 centos:7.7.1908 查看各个容器的IP地址 docker inspect --format='{{.NetworkSettings.Networks.bridge.IPAddress}}' server1 172.17.0.3 docker inspect --format='{{.NetworkSettings.Networks.bridge.IPAddress}}' server2 &lt;no value> docker inspect --format='{{.NetworkSettings.Networks.bridge.IPAddress}}' server3 &lt;no value> 这里我们在查看server2和server3容器IP时，显示为&lt;no value&gt;，其实它们是和server1共用一个Network namespace的 docker container exec -it server2 /bin/bash [root@41436b0be6f7 /]# ifconfig eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 172.17.0.3 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:03 txqueuelen 0 (Ethernet) RX packets 10969 bytes 20985758 (20.0 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 6234 bytes 344851 (336.7 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 docker container exec -it server3 /bin/bash [root@41436b0be6f7 /]# ifconfig eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 172.17.0.3 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:03 txqueuelen 0 (Ethernet) RX packets 10969 bytes 20985758 (20.0 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 6234 bytes 344851 (336.7 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 # 两个容器的IP、主机名都相同 容器虚拟网卡和docker0网桥的veth pair配对veth是成对出现的虚拟网络设备， 发送到veth一端虚拟设备的请求会从另一端的虚拟设备中发出。创建一个容器的同时会为这个容器创建一对虚拟网卡veth pair，这个成对出现的虚拟网卡veth pair，分别放到宿主机和容器中，宿主机一端桥接到默认的docker0或者自定义的网桥上，容器一端放到新创建容器的Network namespace中，并把名字修改为eth0。虚拟网卡veth pair就像是一根网线，将宿主机的docker0和容器连接起来 docker container run -itd --name \"server1\" centos:7.7.1908 # 创建容器 brctl show docker0 # 查看宿主机上的docker0网桥 bridge name bridge id STP enabled interfaces docker0 8000.02429fdcee74 no veth7459cf7 ip a s veth7459cf7 # 这是虚拟网卡veth pair在宿主机上的一端 34: veth7459cf7@if33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 86:54:3c:c6:70:6b brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::8454:3cff:fec6:706b/64 scope link valid_lft forever preferred_lft forever [root@ec94bfbd724f /]# ifconfig # 容器内部的eth0网卡是虚拟网卡veth pair在容器中的一端 eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 172.17.0.2 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:02 txqueuelen 0 (Ethernet) RX packets 5495 bytes 10346440 (9.8 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 3386 bytes 186731 (182.3 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 容器网络访问原理图 容器网络实现的核心技术: iptablesdocker容器的跨网络隔离与通信，是使用iptables去实现的 源IP地址变换规则docker在安装完成后，将默认在宿主机上增加一些iptables规则，以用于docker容器和容器之间的隔离与通信，可以使用使用iptables-save命令查看 iptables-save | grep docker -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE 参数说明: -s:源地址172.17.0.0/16 -o:指定数据报文流出接口为docker0 -j:动作为MASQUERADE(地址伪装) 上面这条规则关系着docker容器和外界的通信，含义是源地址为172.17.0.0/16的数据包(即docker容器发出的数据)，当不是从docker0网卡发出时做SNAT(源地址转换)。这样使得docker容器访问外网的流量，在外界看来就是从宿主机上发出的，外界感觉不到docker容器的存在 目标IP地址变换规则从docker容器访问外网的流量，在外部看来就是从宿主机上发出的，外部感觉不到docker容器的存在。其实这也是由相应的iptables规则去实现的 docker container run -itd --name \"nginx\" -p 80:80 nginx:1.17 查看创建容器之后生成的iptables规则 iptables-save | grep docker -A DOCKER ! -i docker0 -p tcp -m tcp --dport 80 -j DNAT --to-destination 172.17.0.2:80 -A DOCKER -d 172.17.0.2/32 ! -i docker0 -o docker0 -p tcp -m tcp --dport 80 -j ACCEPT 这两条规则将访问宿主机的80端口的流量转发到了172.17.0.2的80端口上(即真正提供服务的docker容器的IP+端口)，所以外界访问docker容器是通过iptables做DNAT(目的地址转换)实现的 etcd 和 flannel 实现 docker 跨主机通信flannel是一种基于overlay网络的跨主机容器网络解决方案，也就是将TCP数据包封装在另一种网络包里面进行路由转发和通信，flannel是CoreOS团队针对Kubernetes设计的一个网络规划服务，让集群中的不同节点主机创建的容器都具有全集群唯一的虚拟ip地址，flannel使用go语言编写 实现原理flannel为每个host分配一个subnet，容器从这个subnet中分配ip，这些ip可以在host间路由，容器间无需使用nat和端口映射即可实现跨主机通信。每个subnet都是从一个更大的ip池中划分的，flannel会在每个主机上运行一个叫flanneld的agent，其职责就是从池子中分配subnet。etcd相当于一个数据库，flannel使用etcd存放网络配置、已分配的subnet、host的IP等信息 实验环境 节点 安装软件 系统 内核版本 docker版本 10.10.110.150(master) etcd、flannel、docker CentOS7.7.1908 3.10.0-1062.el7.x86_64 19.03.12 10.10.110.151(slave) flannel、docker CentOS7.7.1908 3.10.0-1062.el7.x86_64 19.03.12 master节点配置安装配置etcd yum install -y etcd # 安装etcd,由于不配置etcd集群,所以只在10.10.110.150节点安装etcd就行了 sed -i \"s/localhost/10.10.110.150/g\" /etc/etcd/etcd.conf # 修改etcd配置文件 systemctl start etcd.service # 启动etcd 安装配置flannel yum install -y flannel sed -i \"s/127.0.0.1/10.10.110.150/g\" /etc/sysconfig/flanneld # flannel连接到etcd,slave连接也是填写master的IP etcdctl --endpoints=\"http://10.10.110.150:2379\" set /atomic.io/network/config '{ \"Network\":\"172.17.0.0/16\", \"Backend\": {\"Type\": \"vxlan\"}} ' # 配置etcd的子网,如果这一步不配置,那么etcd无法启动 systemctl start flanneld.service # 启动flannel slave节点配置安装配置flannel yum install -y flannel sed -i \"s/127.0.0.1/10.10.110.150/g\" /etc/sysconfig/flanneld # 这里是填写master节点的IP,让slave连接到master的etcd,多slave也一样 systemctl start flanneld.service # 确保slave节点能连接到master节点的etcd,如果不关闭防火墙,那必须打开2379端口 配置docker使用flannel的网络master节点 vim /usr/lib/systemd/system/docker.service EnvironmentFile=/run/flannel/docker # 加载这个文件里面的变量,这个文件记录了flannel分配给master节点的子网信息(slave也会有自己的子网) ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock $DOCKER_NETWORK_OPTIONS # 这个变量是上面文件中定义的,意思是在启动容器时指定使用flannel分配的子网去配置容器的网络 iptables -P FORWARD ACCEPT # 开启iptables转发,如不开启即使配置成功也不能通信 systemctl daemon-reload systemctl restart flanneld.service # 这里必须先重启flannel再重启docker,这时候启动容器就会使用flannel去配置容器的网络 systemctl restart docker.service slave节点配置 vim /usr/lib/systemd/system/docker.service EnvironmentFile=/run/flannel/docker # 查看slave节点上这个文件,网段是和master节点不一样的 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock $DOCKER_NETWORK_OPTIONS iptables -P FORWARD ACCEPT systemctl daemon-reload systemctl restart flanneld.service systemctl restart docker.service 查看宿主机的IP变化master节点 ip a 3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:e3:89:96:4e brd ff:ff:ff:ff:ff:ff inet 172.17.98.1/24 brd 172.17.98.255 scope global docker0 valid_lft forever preferred_lft forever 4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default link/ether 02:6f:fa:71:67:f7 brd ff:ff:ff:ff:ff:ff inet 172.17.98.0/32 scope global flannel.1 valid_lft forever preferred_lft forever inet6 fe80::6f:faff:fe71:67f7/64 scope link valid_lft forever preferred_lft forever # docker0虚拟网卡和flannel虚拟网卡已经在同一网段，这时候说明配置成功 slave节点 ip a 3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:f2:30:ba:34 brd ff:ff:ff:ff:ff:ff inet 172.17.75.1/24 brd 172.17.75.255 scope global docker0 valid_lft forever preferred_lft forever 4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default link/ether f6:ae:d1:c0:e1:a7 brd ff:ff:ff:ff:ff:ff inet 172.17.75.0/32 scope global flannel.1 valid_lft forever preferred_lft forever inet6 fe80::f4ae:d1ff:fec0:e1a7/64 scope link valid_lft forever preferred_lft forever 在两个节点创建容器相互ping验证master节点 docker run -it busybox sh / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:62:02 inet addr:172.17.98.2 Bcast:172.17.98.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1450 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:656 (656.0 B) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # ping 172.17.75.2 PING 172.17.75.2 (172.17.75.2): 56 data bytes 64 bytes from 172.17.75.2: seq=0 ttl=62 time=0.492 ms 64 bytes from 172.17.75.2: seq=1 ttl=62 time=0.353 ms 64 bytes from 172.17.75.2: seq=2 ttl=62 time=0.342 ms slave节点 docker run -it busybox sh / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:4B:02 inet addr:172.17.75.2 Bcast:172.17.75.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1450 Metric:1 RX packets:6 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:516 (516.0 B) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # ping 172.17.98.2 PING 172.17.98.2 (172.17.98.2): 56 data bytes 64 bytes from 172.17.98.2: seq=0 ttl=62 time=1.945 ms 64 bytes from 172.17.98.2: seq=1 ttl=62 time=0.344 ms 64 bytes from 172.17.98.2: seq=2 ttl=62 time=0.384 ms 注意:如果不能ping通，先重启flannel再重启docker试试","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker 容器数据持久化(4)","slug":"Docker 容器数据持久化(4)","date":"2020-06-19T02:14:10.000Z","updated":"2020-09-11T11:22:00.807Z","comments":true,"path":"post/a7b8d397.html","link":"","permalink":"https://www.missf.top/post/a7b8d397.html","excerpt":"","text":"容器数据持久化的三种方式由于容器的镜像分层机制，我们在容器里面创建文件或者修改文件，结果都会保存在容器的可读写层中，一旦容器被销毁，那么这个读写层也会随着容器销毁而消失。而且当一个容器需要和其他容器的读写层进行数据交互时，也会显得非常困难。于是在将容器数据持久化到宿主机方面，docker为我们提供了三种持久化的方式 volumesvolumes由docker负责创建、管理。用户可以显式的调用命令docker volume create创建volume，也可以通过container、service的启动隐式创建 docker创建的volumes本质上还是宿主机文件系统中的一个目录，一个volumes可以供多个容器使用，即使没有容器使用此volumes，它也不会自动删除，除非用户明确删除它 如果用户显式创建volumes则需要给它一个名称，如果是隐式创建volumes则docker会为它分配一个在宿主机范围内唯一的名字 通过使用第三方提供的volume driver，用户可以将数据持久到远程主机或者云存储中，也就是说存储空间可以不由宿主机提供 # 创建volumes docker volume create nginx_volumes # 查看volumes docker volume ls # 查看卷详细信息 docker volume inspect nginx_volumes [ { \"CreatedAt\": \"2020-06-19T18:47:49+08:00\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/nginx_volumes/_data\", # 这是volumes在宿主机上的真实路径 \"Name\": \"nginx_volumes\", \"Options\": {}, \"Scope\": \"local\" } ] # 清理volumes docker volume rm nginx_volumes 将nginx容器的html目录映射到宿主机的nginx_volumes目录 # 创建数据持久化的容器,如果卷不存在则自动创建 docker container run -itd --name \"nginx1\" -p 80:80 -v nginx_volumes:/usr/share/nginx/html nginx:1.17 # -v方式 docker container run -itd --name \"nginx1\" -p 80:80 --mount src=nginx_volumes,dst=/usr/share/nginx/html nginx:1.17 # --mount方式 # 查看nginx_volumes在宿主机的真实目录 ll /var/lib/docker/volumes/nginx_volumes/_data total 8 -rw-r--r-- 1 root root 494 Apr 14 22:19 50x.html # 这时候nginx容器内部的文件已经被映射到宿主机上了 -rw-r--r-- 1 root root 612 Apr 14 22:19 index.html # 修改宿主机上的index.html文件 echo \"nginx_volumes test\" > /var/lib/docker/volumes/nginx_volumes/_data/index.html # 访问宿主机的80端口(前面启动容器时将容器的80端口绑定到宿主机的80端了) curl 10.10.110.150 nginx_volumes test # nginx容器内的文件确实被修改成功 bind mountsbind mounts本质上是容器共享宿主机文件系统，比如docker将宿主机的/etc/resov.conf文件bind mount到容器里，两者会使用相同的dns服务器 # 创建容器,将宿主机的/nginx/app绑定到容器的/usr/share/nginx/html目录 docker container run -itd --name \"nginx1\" --mount type=bind,src=/nginx/app,dst=/usr/share/nginx/html nginx:1.17 docker container run -itd --name \"nginx1\" -v /nginx/app:/usr/share/nginx/html nginx:1.17 # 查看宿主机和容器的目录 ls /nginx/app docker exec -it nginx1 ls /usr/share/nginx/html # 两个目录都为空,这是因为bind mounts是将宿主机的目录绑定到容器的目录,容器目录已有的内容会被隐藏(bind mounts以宿主机目录为主) 注意: 如果源文件或源目录不存在，则不会自动创建。如果容器目录为非空目录，则容器目录现有内容会被宿主机目录内容所隐藏。 tmpfs出于安全原因，或者容器性能优化的原因有时候不需要容器的数据长久保存时可以使用这种方式。将容器数据挂载存储在宿主机的内存中，避免写入容器可写层，提高容器性能 volumes 和 bind mounts 的使用场景和区别volumes适合多个容器需要共享数据、将数据保存到远程主机或云上等场景。bind mounts适合将宿主机的系统配置文件共享给容器。volumes是将容器内部的数据映射到宿主机对应的volumes目录，如果容器内部是一个非空目录，volumes目录也是一个非空目录，那么两个目录的文件会合并。而bind mounts是将宿主机上任意位置的目录或文件挂载到容器中，如果宿主机的目录非空，那么容器目录的数据将会被宿主机目录的数据隐藏，容器内的数据要卸除挂载后才会恢复 Bind mounts和volumes都可以通过使用标志-v或–volume来挂载到容器中，只是格式有些许不同。然而，在Docker17.06及其以上版本中，我们推荐使用–mount来对容器或服务进行这三种方式的挂载，因为这种格式更加清晰","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker 容器管理(3)","slug":"Docker 容器管理(3)","date":"2020-06-17T08:23:38.000Z","updated":"2020-09-11T11:22:03.024Z","comments":true,"path":"post/39a5b294.html","link":"","permalink":"https://www.missf.top/post/39a5b294.html","excerpt":"","text":"创建容器常用选项 选项 描述 -i, –interactive 交互式 -t, –tty 分配一个伪终端 -d, –detach 运行容器到后台 -e, –env 设置环境变量 -p, –publish list 发布容器端口到主机 -P, –publish-all 发布容器所有EXPOSE的端口到宿主机随机端口 –name string 指定容器名称 -h, –hostname 设置容器主机名 –ip string 指定容器IP,只能用于自定义网络 –network 连接容器到一个网络 –mount mount 将文件系统附加到容器 -v, –volume list 绑定挂载一个卷 –restart string 容器退出时重启策略,默认no,可选值:[always|on-failure] 创建容器示例# 启动一个nginx容器,指定名字、映射端口、设置重启 # 如果不加-it分配一个交互式的伪终端,容器就会直接退出了,容器内的第一个程序必须一直处于前台运行(必须hang住) docker container run -itd --name \"nginx\" -p 80:80 --restart always nginx:1.17 容器资源限制 选项 描述 -m，–memory 容器可以使用的最大内存量 –memory-swap 允许交换到磁盘的内存量 –memory-swappiness=&lt;0-100&gt; 容器使用SWAP分区交换的百分比(0-100，默认为-1) –oom-kill-disable 禁用OOM Killer –cpus 可以使用的CPU数量 –cpuset-cpus 限制容器使用特定的CPU核心，如(0-3, 0,1) –cpu-shares CPU共享(相对权重) 内存限额示例# 允许容器最多使用500M内存和600M的swap,并禁用OOM Killer docker container run -d --name \"nginx1\" --memory=\"500M\" --memory-swap=\"600M\" --oom-kill-disable nginx:1.17 CPU限额示例# 允许容器最多使用两个的CPU docker container run -d --name \"nginx2\" --cpus=\"2\" nginx:1.17 # 允许容器最多使用50%的CPU docker container run -d --name \"nginx3\" --cpus=\".5\" nginx:1.17 容器资源配额扩容# 容器资源可更新选项 docker update --help Usage: docker update [OPTIONS] CONTAINER [CONTAINER...] Update configuration of one or more containers Options: --blkio-weight uint16 Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0) --cpu-period int Limit CPU CFS (Completely Fair Scheduler) period --cpu-quota int Limit CPU CFS (Completely Fair Scheduler) quota --cpu-rt-period int Limit the CPU real-time period in microseconds --cpu-rt-runtime int Limit the CPU real-time runtime in microseconds -c, --cpu-shares int CPU shares (relative weight) --cpus decimal Number of CPUs --cpuset-cpus string CPUs in which to allow execution (0-3, 0,1) --cpuset-mems string MEMs in which to allow execution (0-3, 0,1) --kernel-memory bytes Kernel memory limit -m, --memory bytes Memory limit --memory-reservation bytes Memory soft limit --memory-swap bytes Swap limit equal to memory plus swap: '-1' to enable unlimited swap --pids-limit int Tune container pids limit (set -1 for unlimited) --restart string Restart policy to apply when a container exits # 更新正在运行中的容器内存限额 docker update --memory=\"400M\" --memory-swap=\"500M\" --restart=\"on-failure\" 4e860294d239 管理容器常用命令 选项 描述 ls 列出容器 inspect 查看一个或多个容器详细信息 exec 在运行容器中执行命令 commit 创建一个新镜像来自一个容器 cp 拷贝文件/文件夹到一个容器 logs 获取一个容器日志 port 列出或指定容器端口映射 top 显示一个容器运行的进程 stats 显示容器资源使用统计 stop/start/restart 停止/启动一个或多个容器 rm 删除一个或多个容器 prune 移除已停止的容器 管理容器示例# 列出真正运行的所有容器 docker container ls -a # 获取一个容器日志 docker container logs --tail=\"5\" nginx # 仅列出最新N条容器log信息 docker container logs -f nginx # 跟踪log信息输出 docker logs --since=\"2020-06-18\" --tail=\"10\" nginx # 显示某个时间之后的最新十条log信息 # 进入正在运行的容器中执行命令 docker container exec -it nginx /bin/bash # 显示一个容器运行的进程 docker container top nginx # 删除一个或删除全部容器 docker container rm -f nginx docker container rm -f $(docker container ls -q) 容器实现核心技术: Namespace在容器化中，一台物理计算机可以运行多个不同操作系统(一个容器就类似于一个系统)，那就需要解决”隔离性”，让彼此感知不到对方的存在，出现问题也互不影响 Linux内核从2.4.19版本开始引入了namespace概念，其目的是将特定的全局系统资源通过抽象方法使得namespace中的进程看起来拥有自己隔离的资源。Docker就是借助这个机制实现了容器资源隔离 Linux的namespace机制提供了6种不同的命名空间: IPC: 隔离进程间通信 MOUNT: 隔离文件系统挂载点 NET: 隔离网络协议栈 PID: 隔离进程号，容器命名空间对父进程空间可见 USER: 隔离用户 UTS: 隔离主机名和域名 容器实现核心技术: CGroupsDocker利用namespace实现了容器之间资源隔离，但是namespace不能对容器资源限制，比如CPU、内存。如果某一个容器属于CPU密集型任务，那么会影响其他容器使用CPU，导致多个容器相互影响并且抢占资源。如何对多个容器的资源使用进行限制就成了容器化的主要问题。所以容器引入了Control Groups(简称CGroups)，限制容器资源 CGroups 以某种标准讲一组进程为目标进行资源分配和控制，例如CPU、内存、带宽等，并且可以动态配置: 限制进程组使用的资源数量(Resource limitation ):可以为进程组设定资源使用上限，例如内存 进程组优先级控制( Prioritization):可以为进程组分配特定CPU、磁盘IO吞吐量 记录进程组使用的资源数量(Accounting ):例如使用记录某个进程组使用的CPU时间 进程组控制(Control ):可以将进程组挂起和恢复 查看cgroups可控制的资源 资源 描述 blkio 对块设备的IO进行限制 cpu 限制CPU时间片的分配，与cpuacct挂载同一目录 cpuacct 生成cgroup中的任务占用CPU资源的报告，与cpu挂载同一目录 cpuset 给cgroup中的任务分配独立的CPU(多核处理器)和内存节点 devices 允许或者拒绝 cgroup 中的任务访问设备 freezer 暂停/恢复 cgroup 中的任务 hugetlb 限制使用的内存页数量 memory 对cgroup中任务的可用内存进行限制，并自动生成资源占用报告 net_cls 使用等级识别符(classid)标记网络数据包，这让 Linux 流量控制程序(tc)可以识别来自特定从cgroup任务的数据包，并进行网络限制 net_prio 允许基于cgroup设置网络流量的优先级 perf_event 允许使用perf工具来监控cgroup pids 限制任务的数量 资源控制在容器中的实际位置ll /sys/fs/cgroup/\"资源名\"/docker/\"容器ID\"/ Docker核心组件之间关系我们使用docker client运行一个容器，其实容器运行时底层是需要依赖一系列组件的，我们完全可以通过调用这些组件去启动一个容器，而不使用docker引擎的方式去启动。主要的组件有docker client、docker daemon、containerd、container-shim、runC docker clientdocker客户端程序，负责发送用户的请求给docker daemon docker daemondocker daemon守护进程，也称docker engine，负责处理docker client的请求，并返回处理结果 containerdcontainerd是一个工业级标准的容器运行时，它强调简单性、健壮性和可移植性。Containerd可以在宿主机中管理完整的容器生命周期:容器镜像的传输和存储、容器的执行和管理、存储和网络等。为docker daemon提供接口去管理容器，docker对容器的管理和操作基本都是通过containerd完成的。但是要注意的是:containerd被设计成嵌入到一个更大的系统中，而不是直接由开发人员或终端用户使用 container-shimcontainer-shim是containerd的组件，是容器的运行时载体，我们在docker宿主机上看到的shim也正是代表着一个个通过调用containerd启动的docker容器 ps axf | grep docker -A 1 10191 ? Sl 0:01 \\_ containerd-shim -namespace moby -workdir /var/lib/containerd/io.containerd.runtime.v1.linux/moby/4dffa5d5861899400770d6470618e4e051c5f1bf0c53034999b13821fc3fe93f -address /run/containerd/containerd.sock -containerd-binary /usr/bin/containerd -runtime-root /var/run/docker/runtime-runc 10208 ? Ss 0:00 \\_ nginx: master process nginx -g daemon off; -- 4215 ? Ssl 2:06 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock runCRunC 是一个轻量级的工具，它是用来运行容器的。我们可以认为它就是个命令行小工具，可以不用通过 docker 引擎，直接运行容器。事实上runC 是标准化的产物，它根据 OCI 标准来创建和运行容器。而 OCI(Open Container Initiative)组织，旨在围绕容器格式和运行时制定一个开放的工业化标准","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker 镜像管理(2)","slug":"Docker 镜像管理(2)","date":"2020-06-16T07:00:10.000Z","updated":"2020-09-11T11:22:07.069Z","comments":true,"path":"post/ce2c2968.html","link":"","permalink":"https://www.missf.top/post/ce2c2968.html","excerpt":"","text":"镜像概述镜像是一个分层存储的文件 镜像就是一个软件的运行环境 一个镜像可以重复使用，创建无数个容器 一个不包含Linux内核而又精简的Linux操作系统 镜像是一种标准化的交付，镜像内包含代码以及软件的运行环境 配置镜像加速阿里云为每一个开通容器镜像服务的用户免费提供一个镜像加速地址 # 配置镜像加速 tee /etc/docker/daemon.json &lt;&lt; EOF { \"registry-mirrors\": [\"https://265wemgl.mirror.aliyuncs.com\"] } EOF systemctl daemon-reload systemctl restart docker.service 拉取镜像我们拉取镜像一般是默认从Docker Hub拉取的，但是国内访问Docker Hub速度很慢，所以我们在前面配置了阿里云的镜像加速。在拉取镜像时，直接从阿里云的docker镜像仓库拉取。我们假如要拉取一个镜像，但是不知道仓库中是否有这个镜像时，我们可以先搜索这个镜像名字，看是否有对应的镜像 # 搜索镜像 docker search nginx # 拉取镜像,如果不指定版本号,默认拉取最新(latest) docker pull nginx:1.17 镜像拉取到宿主机本地之后，会以分层的文件形式存储，下面是镜像的存放目录 [root@localhost ~]# ll /var/lib/docker/overlay2/ total 0 drwx------ 4 root root 55 Jun 17 19:04 5f4badc01c88554e78d4aaec269a84fb5e2028d42278d5f131dda81c4209622c drwx------ 3 root root 47 Jun 17 19:04 658e3b564ce9017b0bd507f1853702f6cdda4642fdc6fbf4b4d06e34cf9a8c25 drwx------ 3 root root 30 Jun 17 19:09 6d57028d1a60a66afc6959b02e0005ea424182908fadf6aa5ac90f3868c014f7 brw------- 1 root root 253, 0 Jun 17 18:31 backingFsBlockDev drwx------ 4 root root 72 Jun 17 19:04 d56648ebd71c9bdb68226b4021ec008db3ed537072b3c4f9e77afc51f8108c07 drwx------ 2 root root 142 Jun 17 19:09 l 镜像与容器的联系当启动一个新容器时，docker只加载只读镜像，并在这个只读镜像上面添加一个读写层，即容器层。但我们需要修改容器里面的文件时，会先从镜像层把这个文件拷贝到读写层，然后再执行修改操作 镜像存储核心技术:联合文件系统(UnionFS)联合文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(uniteseveral directories into a single virtual filesystem)。联合文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。另外，不同 Docker 容器就可以共享一些基础的文件系统层，同时再加上自己独有的改动层，大大提高了存储的效率 Docker 中使用的 AUFS（AnotherUnionFS）就是一种联合文件系统。 AUFS 支持为每一个成员目录（类似 Git 的分支）设定只读（readonly）、读写（readwrite）和写出（whiteout-able）权限, 同时 AUFS 里有一个类似分层的概念, 对只读权限的分支可以逻辑上进行增量地修改(不影响只读部分的) Docker 目前支持的联合文件系统包括 OverlayFS , AUFS , Btrfs , VFS , ZFS 和 DeviceMapper 镜像存储核心技术:写时复制(COW)docker镜像由多个只读层叠加而成，启动容器时，docker会加载只读镜像层并在镜像层顶部添加一个读写层。如果运行中的容器修改了一个已存在的文件，那么该文件将会从只读层复制到读写层，该文件的只读版本任然存在，只是已经被读写层中该文件的副本所隐藏，这就是写时复制机制 镜像常用管理命令# 列出镜像,-a显示所有镜像 docker image ls # 在当前目录通过Dockerfile构建镜像 docker build -t \"nginx_tomcat\" . # 查看镜像历史 docker image history nginx:1.17 # 显示镜像的详细信息 docker inspect nginx:1.17 # 从镜像仓库拉取镜像 docker pull nginx:1.17 # 推送镜像到镜像仓库 docker pull centos:7.6.1810 # 移除一个或多个镜像 docker image rm centos docker image rm $(docker image ls -q) # 删除全部镜像 # 删除没有被标记或没有被任何容器引用的镜像 docker image prune -af # 创建一个引用源镜像标记目标镜像 docker tag centos:latest coentos:v1 # 为centos:latest这个镜像打一个标签为coentos:v1 # 导出容器文件系统为tar归档文件 docker export -o centos-export.tar [CONTAINER ID] # 导入容器文件系统tar归档文件来创建镜像 docker import centos-export.tar # 保存一个或多个镜像到一个tar归档文件 docker save -o database.tar redis mysql # 加载镜像来自tar归档或标准输入 docker load -i database.tar 相信许多的初学者看到这里肯定有疑问，这里说明一下export &amp; import和save &amp; load的区别在哪里 export &amp; importexport的应用场景主要用来制作基础镜像，比如你从一个centos镜像启动一个容器，然后安装一些软件和进行一些设置后，使用docker export保存为一个基础镜像。然后把这个镜像分发给其他人使用，比如作为基础的开发环境 export:将容器导出为tar归档文件,生成的是该容器的快照，复刻了容器当前的Linux系统环境 import:将tar归档文件导入为镜像 整个过程即:容器-->tar归档文件-->镜像 save &amp; load如果你的应用是使用docker-compose.yml编排的多个镜像组合，但你要部署的客户服务器并不能连外网。这时，你可以使用docker save将用到的镜像打个包，然后拷贝到客户服务器上使用docker load载入 save:将镜像导出为tar归档文件,该命令也可以作用于容器,但导出的是容器背后的images load:将tar归档文件导入为镜像 注意: save命令生成的tar包比export命令生成的tar包大很多，两组命令不可交叉互用","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Docker 核心概念与安装(1)","slug":"Docker 核心概念与安装(1)","date":"2020-06-15T02:56:03.000Z","updated":"2020-09-11T11:22:33.299Z","comments":true,"path":"post/f7aff4ce.html","link":"","permalink":"https://www.missf.top/post/f7aff4ce.html","excerpt":"","text":"为什么使用容器提供简单轻量的建模方式，非常容易上手，运行速度非常快 使开发和运维的职责分离，开发只需要关心容器中的程序，运维只需要管理容器 快速高效的开发生命周期，开发环境和生产环境一致，避免了额外的调试有效缩短上线时间 鼓励使用面向服务的架构，docker推荐单个容器只运行一个应用程序，使分布式扩展和调试变得简单 Docker 是什么容器技术想要了解docker，首先要知道什么是容器。最早的容器技术来自于BSD的jail技术(jail一词是监狱的意思，这个技术的隔离思想来源于监狱的启发)，目的就是为了实现进程隔离，使得一个进程被攻陷后不会影响到其他进程，这是出于安全的目的。 使用最为广泛的开源容器引擎在近几年来，docker是一个非常火的名词。事实上docker只是众多容器引擎其中一款优秀的容器引擎，但是它却几乎成为了容器的代名词。许多业外人士觉得docker就是容器，这里大家要明白，docker只是属于容器技术的一种。 容器是一种操作系统级别的虚拟化技术使用docker创建的容器，以特殊进程的方式在宿主机上运行，运行一个容器就像运行一个进程一样，宿主机上可以运行多个容器，容器间的资源是互相隔离的。 依赖于Linux内核特性 Namespace &amp; Cgroups容器之间运行的是一个隔离的环境，也可以理解类似于一个沙盒，使用Namespace进行资源的隔离，使用Cgroups进行资源的控制。 Docker 基本组成Docker Client 客户端docker采用C/S架构 docker客户端和docker服务器之间的通信访问可以是本地方式也可以是远程方式 docker客户端向守护进程发送请求，守护进程的执行结果会传回给客户端 Docker Daemon 守护进程docker采用C/S架构 docker客户端和docker服务器之间的通信访问可以是本地方式也可以是远程方式 docker客户端向守护进程发送请求，守护进程的执行结果会传回给客户端 Docker Image 镜像 镜像是容器的基石，镜像包含了容器启动的一切条件，容器基于镜像去启动。镜像是层叠的只读文件系统，底层是bootfs引导文件系统，rootfs文件系统永远是只读状态，使用同一个镜像无论启动多少个容器，或者容器被如何修改，镜像都不会被改变。一个镜像可以放到一个镜像的顶部，最下面的镜像称为基础镜像，就是图中的centos/Ubuntu层。这里使用了写时复制技术(copy on write)，即通过一个镜像启动一个容器实例，这个镜像是以只读形式挂载的，即不允许任何修改操作，当在容器实例中修改一个文件时，会首先从镜像里把这个文件拷贝到可写层，然后执行更新操作。 Docker Container 容器容器通过镜像启动 docker守护进程执行命令就是在容器实例中执行 应用部署在容器中 在启动容器时会在镜像的最上层创建一个读写层，读写层加上下面的多个只读层从而构成一个容器 Docker Registry 仓库随着我们项目的增加，我们构建的镜像也会越来越多。而镜像也是像代码一样的，需要一个镜像仓库来进行管理的，镜像仓库里面保存着我们构建的镜像。镜像仓库还分为公有仓库和私有仓库。公有仓库一般指Docker Hub，Docker Hub 是一个由 Docker 公司运行和管理的基于云的存储库，它是一个在线存储库，Docker 镜像可以由其他用户发布和使用。而私有仓库一般是我们公司的组织内部拥有的一个私有仓库，仅允许公司内部用户使用。 容器的关系图 容器 VS 虚拟机虚拟机是系统级别的虚拟化，而容器是进程级别的虚拟化，这是虚拟机和容器最核心的区别。虚拟机提供了物理机硬件级别的操作系统隔离，使用虚拟机部署应用，除了应用和应用依赖的库文件，还需要虚拟完整的操作系统，每个虚拟机拥有自己独立的内核，这会大量占用系统的硬件资源。而容器是进程级别的虚拟化，当我们运行docker容器时，此时容器本身只是操作系统中的一个进程，利用了Linux系统的内核特性(Namespace &amp; Cgroups)实现了进程之间网络、空间、权限等隔离，使多个容器进程互相不知道彼此的存在。在这个追求速度的互联网时代，容器在许多方面要比虚拟机优秀。但是不意味着传统的虚拟机技术就过时了，虚拟机的操作系统级别隔离是容器无法替代的，容器的意义在于运行单个应用，如果在容器里面添加越来越多的功能，那不如一开始就直接使用虚拟机。 虚拟技术的核心区别 容器 VS 虚拟机详细对比 Container VM 启动速度 秒级 分钟级 运行性能 接近原生 5%左右损失 磁盘占用 MB GB 数量 成百上千 一般几十台 隔离性 进程级 系统级(更彻底) 操作系统 主要支持Linux 几乎所有 封装程度 只打包项目代码和依赖关系，共享宿主机内核 完整的操作系统 Docker应用场景应用程序打包和发布 应用程序环境隔离 持续集成 部署微服务 快速搭建测试环境 提供Pass产品(平台即服务) Linux 安装 Docker# 安装依赖包 yum install -y yum-utils device-mapper-persistent-data lvm2 # 添加Docker软件源 yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo # 安装Docker CE yum install -y docker-ce # 启动Docker服务并设置开机启动 systemctl start docker systemctl enable docker # 查看docker版本 docker --version Docker version 19.03.11, build 42e35e61f3 # 查看更详细的信息 docker info","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"CODING持续集成Java项目","slug":"CODING 持续集成Java项目","date":"2020-05-18T07:42:59.000Z","updated":"2020-09-11T11:06:47.230Z","comments":true,"path":"post/1b979c3e.html","link":"","permalink":"https://www.missf.top/post/1b979c3e.html","excerpt":"","text":"CODING介绍在说到持续集成这方面，相信所有做运维的小伙伴都知道Jenkins，就是那个拿着托盘的老头子。但是说到coding，可能很多人都没听说过。什么是coding呢？coding涵盖了软件开发从构想到交付的一切所需，使研发团队在云端高效协同，实践敏捷开发与 DevOps，提升软件交付质量与速度。这是来自官网的介绍，下面就让我们一起学习coding吧 注册CODINGcoding所有的东西都是在这个云平台上实现的，所谓的使研发团队在云端高效协同说的就是这个吧 创建项目选择DevOps项目模板 填写项目基本信息 下载若依的源码若依源码gitee地址 配置若依数据库将若依自带的两个SQL文件导入到ry数据库 初始化本地仓库git init git add . git commit -m \"第一次提交\" 配置coding SSH秘钥在Windows电脑生成ssh密钥对，然后将id_rsa.pub公钥添加到coding SSH公钥 推送本地仓库到coding 注意: 如果已经在coding配置了ssh秘钥，git添加远程仓库的时候不要使用https的地址，不然还是会提示需要输入coding的账号密码 git remote add origin git@e.coding.net:missf/RuoYi.git # 配置了SSH秘钥的，一定要填写项目的git地址 git push -u origin master # 这样推送时就不需要输入账号密码啦 持续集成创建持续集成任务 新建构建计划 录入项目凭据在服务器生成SSH秘钥对，将私钥录入到coding的凭据管理，coding就能持续集成部署代码到服务器 编写静态配置的 Jenkinsfile 配置环境变量 这里附上完整Jenkinsfile pipeline { agent any stages { stage('检出') { steps { checkout([$class: 'GitSCM', branches: [[name: env.GIT_BUILD_REF]], userRemoteConfigs: [[url: env.GIT_REPO_URL, credentialsId: env.CREDENTIALS_ID]]]) } } stage('构建') { steps { echo '构建中...' sh 'java -version' sh 'mvn package' echo '构建完成.' } } stage('压缩jar包') { steps { echo '压缩中...' sh 'cd /root/workspace/ruoyi-admin/target/ &amp;&amp; tar -zcf /tmp/ruoyi-admin.tar.gz ruoyi-admin.jar' echo '压缩完成.' } } stage('部署') { steps { echo '部署中...' script { def remote = [:] remote.name = 'java-server' remote.allowAnyHosts = true remote.host = \"${env.REMOTE_HOST}\" remote.port = 50312 remote.user = \"${env.REMOTE_USER_NAME}\" // 把「CODING 凭据管理」中的「凭据 ID」填入 credentialsId，而 id_rsa 无需修改 withCredentials([sshUserPrivateKey(credentialsId: \"${env.REMOTE_CRED}\", keyFileVariable: 'id_rsa')]) { remote.identityFile = id_rsa // SSH 上传文件到服务器 sshPut remote: remote, from: '/tmp/ruoyi-admin.tar.gz', into: '/tmp/' // 解压缩 sshCommand remote: remote, sudo: false, command: \"tar -zxf /tmp/ruoyi-admin.tar.gz -C /home/ruoyi/\" // 执行Java应用启停脚本 sshCommand remote: remote, sudo: true, command: \"sh /home/ruoyi/start.sh stop &amp;&amp; sh /home/ruoyi/start.sh start\" } } echo '部署完成' } } } } 触发规则本地仓库推送代码到master分支时就会自动触发持续集成任务 开启缓存目录开启缓存目录后可以大大提升构建的速度 立即构建 查看构建过程构建失败可以查看完整日志分析失败原因 服务器的启停脚本[root@java-server ~]# cd /home/ruoyi/ [root@java-server ruoyi]# ll total 65080 drwxr-xr-x 2 root root 4096 May 18 10:18 logs -rw-r--r-- 1 root root 67 May 18 17:04 nohup.out -rw-r--r-- 1 root root 66627886 May 18 17:04 ruoyi-admin.jar -rwxr-xr-x 1 root root 760 May 18 14:29 start.sh [root@java-server ruoyi]# cat start.sh #!/bin/bash WORKSPACE=/home/ruoyi if [ -d \"${WORKSPACE}\" ]; then cd ${WORKSPACE} else echo \"${WORKSPACE} directory does not exist\" exit 1 fi APP_NAME='ruoyi-admin.jar' USE_JAVA_HOME='/usr/local/jdk1.8.0_211' JVM_OPTS='-Xms512m -Xmx512m' CONFIG_OPTS='' if [ $1 == 'start' ]; then echo 'start service '$APP_NAME nohup java -jar ${JVM_OPTS} ${APP_NAME} > ${WORKSPACE}/nohup.out 2>&amp;1 &amp; elif [ $1 == 'stop' ]; then echo 'stop service '$APP_NAME PID=$(ps -ef | grep -v grep | grep ${APP_NAME} | awk '{print $2}') if [ -z ${PID} ]; then echo ${APP_NAME} ' had stopped' else kill ${PID} sleep 2 if [ $? -ne 0 ]; then echo ${APP_NAME} ' stop failed' exit 1 fi fi fi 查看持续集成的效果","categories":[{"name":"CODING","slug":"CODING","permalink":"https://www.missf.top/categories/CODING/"}],"tags":[{"name":"CODING","slug":"CODING","permalink":"https://www.missf.top/tags/CODING/"},{"name":"持续集成","slug":"持续集成","permalink":"https://www.missf.top/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"}]},{"title":"Python基础day07","slug":"Python基础day07","date":"2020-04-28T11:42:45.000Z","updated":"2020-06-09T01:36:26.399Z","comments":true,"path":"post/44a3d96e.html","link":"","permalink":"https://www.missf.top/post/44a3d96e.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 闭包一般情况下，如果一个函数结束，函数的内部所有东西都会释放掉，还给内存，局部变量都会消失。但是闭包是一种特殊情况，如果外函数在结束的时候发现有自己的临时变量将来会在内部函数中用到，就把这个临时变量绑定给了内部函数，然后自己再结束。 # 闭包 def outer(): a = 6 def inner(): b = 8 print(a) print(b) return inner if __name__ == '__main__': res = outer() res() 可迭代对象我们分析对可迭代对象进行迭代使用的过程，发现每迭代一次（即在for…in…中每循环一次）都会返回对象中的下一条数据，一直向后读取数据直到迭代了所有数据后结束。那么，在这个迭代过程中就应该有一个“记录员”去记录每次访问到了第几条数据，以便每次迭代都可以返回下一条数据。我们把这个能帮助我们进行数据迭代的“记录员”称为迭代器(Iterator)。可迭代对象的本质就是可以向我们提供一个这样的“记录员”即迭代器帮助我们对其进行迭代遍历使用 转化成迭代器# 内部含有\"__iter__\"并且含有\"__next__\"方法的就是迭代器，遵循迭代器协议 s2 = \"cdfv\" ol = s2.__iter__() # 可迭代对象通过__iter__或者iter()方法转化成迭代器 # print(ol) print(ol.__next__()) # 一个next对应一个值，一一对应 print(ol.__next__()) print(ol.__next__()) print(ol.__next__()) c d f v 判断对象是否为迭代器# 判断一个对象是否是可迭代对象，方法一 s1 = 'asdf' jo = iter(s1) # 将可迭代对象转化成迭代器 print(jo) print(\"__iter__\" in dir(jo) and \"__next__\" in dir(jo)) # 判断是否同时含有这两个方法 &lt;str_iterator object at 0x000000FE3E7E0898> True # 判断一个对象是否是可迭代对象，方法二 from collections.abc import Iterable,Iterator # 导入Iterable,Iterator方法 so = 'asdf' print(isinstance(so,Iterable)) # 判断对象是否是可迭代 print(isinstance(so,Iterator)) # 判断对象是否是迭代器 生成器生成器本质上是迭代器，生成器是自己用Python代码写的迭代器，平时我们用iter将一个迭代对象转化成迭代器，是调用iter方法底层的C代码实现的。 # 将一个函数变成生成器函数 def fun(): print(123) print(456) yield 789 fun() s = fun() # 将函数赋值使用next打印，不能使用fun()调用函数进行打印 print(next(s)) # 一个next去取一个yield的值，之所以打印三个值是函数内部打印的，next(s)只打印了789 123 456 789 生成器的send方法一个send对应一个yield，但是如果send中有传值，就会将这个值发送给上一个yield def func(): # 1.定义函数 a = yield 123 print(a) yield '有志青年' yield '好好学习' yield '天天向上' genor = func() # 2.函数赋值 print(genor.send(None)) # 3.取一个yield，打印123 print(genor.send('Alex')) # 4.取下一个yield，并将Alex赋值给上一个yield，先执行的a = Alex;print(a),再打印有志青年 生成器的yield fromdef func(): lst = ['努力','奋斗','向上','乐观'] yield lst # 将列表当成一个整体 genor = func() print(next(genor)) ['努力', '奋斗', '向上', '乐观'] def func(): lst = ['努力','奋斗','向上','乐观'] yield from lst # 将列表中的每个元素逐个输出 genor = func() # print(next(genor)) for i in genor: print(i) 努力 奋斗 向上 乐观 列表所有值+1info = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] for index,i in enumerate(info): # info[0] = 0 + 1 info[index] += 1 print(info) 列表推导式和生成器表达式列表推导式列表推导式就是用一行代码构建一个简单或者复杂的列表，减少代码量的同时又可以装逼 print([i for i in range(1,26)]) # 构建一个1 - 25的列表 print(['python%s期' % i for i in range(1,26)]) # 构建一个稍微复杂的列表 print([i for i in range(1,31) if i % 3 == 0]) # 构建一个30以内所有能被3整除的数 print([i ** 2 for i in range(1,31) if i % 3 == 0]) # 所有能被3整除的数的平方 print(['青年%s号' % i for i in range(1,31,2)]) print(['*' if i % 3 == 0 else i for i in range(1,21)]) # 如果i能被3整除就为*，否则从range里面取值 # 将列表中至少含有两个e的字符串放到一个列表中 names = [['Tefe','oIred','Edvl','fgte','vfeke','vfd'],['dcvr','vfer','vfree']] ll = [] for i in names: for name in i: if name.count('e') >= 2: ll.append(name) print(ll) print([name for i in names for name in i if name.count('e') >= 2]) # 列表推导式能一行代码完成 生成器表达式生成器表达式与列表推导式几乎一模一样，就是[]换成了(),但是生成器在内存方面更占优势，列表推导式是一次性将数据加载到内存，而生成器则是取一点生成一点，更加节省内存 genor = ('python%s期' % i for i in range(1,26)) print(genor) for i in genor: print(i) 字典推导式print({i:None for i in range(1,11)}) # 值为None，key从range(1,11)取 am = {'s':'cd','wf':10,'r5':'km'} print({value:key for key,value in am.items()}) # 将字典的键值对换 集合推导式lp = {12,-9,75} print({i ** 2 for i in lp}) 匿名函数# 匿名函数 def func(x,y): return x + y print(func(2,78)) # 针对这种自有返回值的函数，可以写成简化的匿名函数 func = lambda x,y:x * y # 只能写成一行 print(func(3,56)) suf = lambda x,y,z:x * y * z print(suf(45,4,2))","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day06","slug":"Python基础day06","date":"2020-04-27T05:45:29.000Z","updated":"2020-06-30T07:04:01.442Z","comments":true,"path":"post/33a4e9f8.html","link":"","permalink":"https://www.missf.top/post/33a4e9f8.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 函数思考:不能使用len方法去统计一个字符串的长度 s = 'cdvfdcmkcd' count = 0 for i in s: count += 1 print(count) d = [1,2,3,4,5,] count = 0 for i in d: count += 1 print(count) 可以实现，但如果我在多处使用就会有重复性的代码。初学者一定要培养一种对代码完美的偏执，其实这也是面向过程编程的缺点:代码重复性较多，代码的可读性差。 函数初识一个函数就是封装一个功能 d = [1,2,3,4,5,] def my_len(): # 定义函数名my_len count = 0 for i in d: count += 1 print(count) my_len() # 调用函数，不调用不会执行代码 函数返回值函数中遇到return直接结束，给函数的调用者返回一个值，不写默认为None def date(): print('我叫荒原饮露') print('我在学习Python') print('我在让自己变得更加优秀') return # 直接结束函数 print('我以后要...') # return后面的不会输出 date() print('加油') 我叫荒原饮露 我在学习Python 我在让自己变得更加优秀 加油 # 如果不写返回值，默认返回一个None df = date() print(df) 我叫荒原饮露 我在学习Python 我在让自己变得更加优秀 None # 返回多个值 def date(): return 'faker','doinb','jacklove' skt,fpx,ig = date() print(skt) print(fpx) print(ig) faker doinb jacklove 函数的参数def date(a,b): # 函数的定义:形式参数 print('faker') print(a,b) x = 2 y = 3 date(x,y) # 函数的执行者:实际参数,将实参x,y传递给形参a,b faker 2 3 位置参数def date(positon,sex): # 实参和形参的位置必须要对应 print('%s附近的%s' % (positon,sex)) date('深圳','女性') # 调用函数时，传入两个参数 深圳附近的女性 键值对参数def date(tq,name,dc): # 形式参数与实际参数的键对应，位置不需对应 print('我叫%s,我喜欢的季节是%s,我学习%s已经一个月了' % (name,tq,dc)) date(name=\"小马哥\",tq=\"秋季\",dc=\"Python\") # 以键值对的方式传入实际参数 混合参数# 注意:位置参数必须在关键字参数的前面，不然会报错 def date(cs,home,tq,name,dc): print('我叫%s,我喜欢的季节是%s,我学习%s已经一个月了' % (name,tq,dc)) print('%s赚钱%s花,一分别想带回%s' % (cs,cs,home)) date('深圳','家',name=\"小马哥\",tq=\"秋季\",dc=\"Python\") 默认参数def date(soft,posi,sex=\"女\"): # 默认参数需要放置位置参数的后面 print('打开%s软件,搜索%s附近的%s' % (soft,posi,sex)) date('约会',posi='深圳南山区') 万能参数# 万能参数：两个形式参数，接收所有的位置参数，关键字参数 def date(*args,**kwargs): print(args) # 位置参数 print(kwargs) # 关键字参数 date('南山区','18',posi='深圳',sex='laddyboy') ('南山区', '18') # 将位置参数返回为一个元组 {'posi': '深圳', 'sex': 'laddyboy'} # 将关键字参数返回为一个字典 *的魔性用法# *的魔性用法 def fun(*args,**kwargs): print(args,kwargs) fun(*(1,2,'alex'),*('mk,j'),**{'ed':'12'},**{'cds':'lkj'}) # 在调用函数时*是将多个元组的元素整合成一个元组，**是将多个字典整合成一个字典 (1, 2, 'alex', 'm', 'k', ',', 'j') {'ed': '12', 'cds': 'lkj'} 形参的顺序问题def fun(a,b,*args,sex='女',**kwargs): print(a) print(b) print(args) print(sex) print(kwargs) fun(1,2,3,'oi','cd',sex=\"男\",name=\"alex\") 1 2 男 (3, 'oi', 'cd') {'name': 'alex'} # 按照位置参数 *args 默认参数 **kwargs的顺序 判断数值大小def sum(a,b): # 定义两个形式参数，用来接收实际参数 if a > b: return a else: return b print(sum(1,5)) 三元运算符dc = \"A\" if 6 > 3 else \"B\" # 如果条件成立dc就等于A，否则等于B print(dc) A def max(a,b): return a if a > b else b # 如果a大于b，就return a否则return b df = max(150,48) print(df) 150 函数的命名空间# 函数的命名空间 name = 'alex' age = '23' def fun(): sex = '女' print(sex) fun() # 变量赋值时会在内存中开辟一个名称空间用来存放变量名和对应的值 # 定义函数时会在内存中开辟一个函数内存地址，但不会存放函数体的内容 # 但函数调用时会再开辟一个临时名称空间，存放函数体的内容，并且临时名称空间随着函数的调用结束而消失 在python解释器开始执行之后, 就会在内存中开辟一个空间, 每当遇到一个变量的时候, 就把变量名和值之间的关系记录下来, 但是当遇到函数定义的时候, 解释器只是把函数名读入内存, 表示这个函数存在了, 至于函数内部的变量和逻辑, 解释器是不关心的. 也就是说一开始的时候函数只是加载进来, 仅此而已, 只有当函数被调用和访问的时候, 解释器才会根据函数内部声明的变量来进行开辟变量的内部空间. 随着函数执行完毕, 这些函数内部变量占用的空间也会随着函数执行完毕而被清空 我们给这个存放名字与值的关系的空间起了一个名字——命名空间 全局名称空间:存放的是py文件中变量与值的对应关系 局部名称空间:存放的是函数体里面的变量与值的对应关系 内置名称空间:内置函数，关键字等 加载到内存的顺序内置名称空间 —&gt; 全局名称空间 —&gt; 局部名称空间(当函数执行时) 取值顺序# 取值顺序，就近原则 # 局部名称空间 ---> 全局名称空间 name = 'mwj' def fun(): name = 'lok' print(name) fun() lok globals和localsname = 'li' def fun(): name = 'alex' def inner(): name = 'qw' print(globals()) # 返回一个字典：包含全局作用域的所有内容 print(locals()) # 返回一个字典：当前作用域的所有内容 inner() fun() {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': &lt;_frozen_importlib_external.SourceFileLoader object at 0x0000009D39BA5860>, '__spec__': None, '__annotations__': {}, '__builtins__': &lt;module 'builtins' (built-in)>, '__file__': 'C:/Python3.7/Python_Scripts/t5.py', '__cached__': None, 'name': 'li', 'fun': &lt;function fun at 0x0000009D39B5C1E0>} {'name': 'qw'} 高阶函数# 高阶函数 def fun1(): print(111) def fun2(): print(222) fun1() def fun3(): print(333) fun2() print(555) fun3() print(666) # 555 333 222 111 666,代码从上至下执行，函数调用函数 def fun(): print(1) def inner(): print(2) def inner2(): print(3) print(4) inner() print(5) fun() # 1 4 2 5,从上至下执行，函数定义之后不调用则不会被输出 global nonlocal# global nonlocal def fun(): global name name = \"alex\" fun() print(name) # 可以在局部声明一个全局变量，如果不声明为全局变量，print(name)不输出alex # 原本内层函数不能对外层函数的变量只能引用不能修改 def war(): name = \"alex\" def inner(): nonlocal name # 使用nonlocal 可以使内层函数对外层函数进行修改 name += \"b\" print(name) inner() war() 局部作用域不能引用全局作用域变量count = 1 def fun(): count += 1 # 执行报错 print(count) # 可以打印 fun() # 执行会报错，是因为局部作用域不能对全局作用域的变量只能引用不能修改 # 通过global在局部作用域声明，可以进行修改 count = 1 def fun(): global count count += 1 print(count) fun() 函数名作为函数的参数def fun(x): print(x) print(\"in fun\") def fun1(): print(\"in fun1\") fun(fun1) # 调用fun函数并且将fun1作为参数，输出的是fun1函数的内存地址，fun1函数被作为参数时是一个变量 &lt;function fun1 at 0x00000055024C9620> in fun 函数名可以当做函数的返回值# 函数名可以当做函数的返回值 def fun(x): print(\"in fun\") return x def fun1(): print(\"in fun1\") re = fun(fun1) print(re) in fun &lt;function fun1 at 0x00000030B6739620>","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day05","slug":"Python基础day05","date":"2020-04-26T05:21:29.000Z","updated":"2020-06-02T07:51:22.011Z","comments":true,"path":"post/aaadb842.html","link":"","permalink":"https://www.missf.top/post/aaadb842.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 Python文件操作全部读取file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") # 文件路径，文件编码，操作方式 content = file1.read() # 将读取到文件的内容复制给content print(content) # 打印文件的内容 读取n个字符file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") content = file1.read(11) print(content) 按行读取file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") content = file1.readline() print(content) 返回列表file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") content = file1.readlines() print(content) # 返回一个列表，用原文件的每一行作为列表的每一个元素 for循环读取# 读取大文件时逐行读取防止内存崩溃，涉及到迭代器 file1 = open(r\"d:\\java_restart2.sh\",encoding=\"utf-8\",mode=\"r\") for line in file1: print(line.strip()) file1.close() 读取文件的方式 read() 全部读取 read(n) 读取n个字符 readline() 按行读取 readlines() 返回一个列表，列表的元素是原文件的每一行数据 for循环读取 读取大文件时逐行读取防止内存崩溃 写入文件的方式写入空文件f1 = open(\"file1\",encoding=\"utf-8\",mode=\"w\") # 打开文件句柄 content = f1.write(\"我也不知道写什么啊\") # 写入操作 f1.close() # 关闭文件句柄 # 如果写入文件不存在，open()将自动创建它 # 如果文件已存在已有内容，会清空再写入 写入多行f1 = open(\"file1\",encoding=\"utf-8\",mode=\"w\") f1.write(\"我也不知道写什么啊\") f1.write(\"我也不知道写什么啊\") f1.write(\"我也不知道写什么啊\") f1.close() # 加换行符 f1 = open(\"file1\",encoding=\"utf-8\",mode=\"w\") f1.write(\"我也不知道写什么啊\\n\") f1.write(\"我也不知道写什么啊\\n\") f1.close() # 在打开一个文件句柄后，可以重新写入多次而不被清空，只有在文件句柄被关闭后，下一次写入才会被清空 追加文件内容# 没有文件创建文件追加内容，有此文件则在原文件的末尾追加新内容 f1 = open(\"file1\",encoding=\"utf-8\",mode=\"a\") f1.write(\"我也不知道写什么啊\\n\") f1.write(\"我也不知道写什么啊\\n\") f1.close() 读写非文字类文件# 音视频或者图片类型的文件，以bytes读取和写入 f3 = open(\"tr.jpg\",mode=\"rb\") # 用rb模式打开一张图片 content = f3.read() # 以bytes读取原图片数据 f4 = open(\"ting.jpg\",mode=\"wb\") f4.write(content) # 将数据写到一个新文件图片 f3.close() f4.close() 读写模式先读后写f1 = open(\"file1\",encoding=\"utf-8\",mode=\"r+\") content = f1.read() # 读取内容 print(content) f1.write(\"alex\") # 写入内容，这里是以追加的方式写入，不会清空文件内容 f1.close() 调整光标写入f1 = open(\"file1\",encoding=\"utf-8\",mode=\"r+\") f1.seek(0) # 将光标调整到最前 f1.write(\"jkl\") # 在最前面写入jkl，会将原来前面的三个字符替换掉 f1.close() f1.seek(0,2) # 将光标调到最后面 f1.write(\"ooo\") # 在下一行写入ooo f1.close() 强制保存f1 = open(\"file1\",encoding=\"utf-8\",mode=\"r+\") f1.write(\"TES.123\") f1.flush() #强制保存，相当于Crtl + s f1.close() 判断文件句柄是否可读可写# readable writeable f2 = open(\"file\",encoding=\"utf-8\",mode=\"w\") # 写入模式 print(f2.read()) # 读取会报错 print(f2.readable()) # 由于是写入模式不能读 False print(f2.writable()) True 按照字节调整光标位置# tell seek f1 = open(\"file2\",encoding=\"utf-8\") ret = f1.read() # 读取文件，光标会移动到下一行 print(f1.tell()) # 获取当前文件指针的位置 f1.seek(3) # 移动指针到指定的位置 print(f1.read()) # 从指针位置往后读取 f1.close() 截取文件# truncate 只能在可写的模式下截取原文件，只能从头截取 f1 = open(\"file1\",encoding=\"utf-8\",mode=\"r+\") ret = f1.truncate(12) # 截取文件的前12个字节,文件其他内容会被清空，只保留截取到的字节 print(f1.read()) f1.close() 中华人民 # utf-8编码下，一个中文字符等于三个字节，如果是截取4个字节会报错 with open操作方式# 1.自动关闭文件句柄 with open(\"file4\",encoding=\"utf-8\") as f1: content = f1.read() print(content) # 2.同一语句可操作创建多个文件句柄 with open(\"file1\",encoding=\"utf-8\") as f1,open(\"file2\",encoding=\"utf-8\",mode=\"w\") as f2: print(f1.read()) # 对file1进行读取操作 f2.write(\"777\") # 对file2进行写入操作 # 3.with open 可能引起IO错误的操作 with open(\"file1\",encoding=\"utf-8\") as f1: f1.read() # 打开文件句柄f1进行读取操作，文件句柄自动关闭 with open(\"file1\",encoding=\"utf-8\",mode=\"w\") as f2: f1.write(\"777\") # 又打开文件句柄f2进行写操作，如果文件句柄f1没有及时关闭又打开了f2文件句柄程序就会报错 关于文件的修改文件的数据都是存放在硬盘上的，因此只存在覆盖，不存在修改一说，我们平时看到的修改文件，都是模拟出来的效果，修改file5文件中的Alex字符为Sb，并且将原文件复制为新文件file.bak，删除原文件，修改新文件的名字为file5，修改速度非常快，根本看不到生成的file5.bak文件，具体的说有两种实现方式 将硬盘存放的该文件的内容全部加载到内存，在内存中是可以修改的，修改完毕后，再由内存覆盖到硬盘 # file5文件内容 Alex是个屌丝，即使Alex有特斯拉也还是屌丝 你们真逗，Alex再牛逼，也掩饰不了资深屌丝的气息 import os with open(\"file5\",encoding=\"utf-8\") as f1,open(\"file5.bak\",encoding=\"utf-8\",mode=\"w\") as f2: # 打开两个文件句柄，f1只读，f2可写 old_content = f1.read() # 将f1内容赋值给old_content new_content = old_content.replace(\"Alex\",\"Sb\") # 将Alex替换为Sb的数据赋值给new_content f2.write(new_content) # 将新数据写入f2 os.remove(\"file5\") # 删除文件file5 os.rename(\"file5.bak\",\"file5\") # 将新文件命名为file5 # 这样有一个不好的地方，old_content = f1.read()这里是一次性将文件加载到内存中的 将硬盘存放的该文件的内容一行一行地读入内存，修改完毕就写入新文件，最后用新文件覆盖源文件 import os with open(\"file5\",encoding=\"utf-8\") as f1,open(\"file5.bak\",encoding=\"utf-8\",mode=\"w\") as f2: for line in f1: new_line = line.replace(\"Sb\",\"Alex\") # 将一行的数据替换完成赋值给新的一行 f2.write(new_line) # 逐行写入 os.remove(\"file5\") os.rename(\"file5.bak\",\"file5\") # 不会将文件一次加载到内存","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day04","slug":"Python基础day04","date":"2020-04-25T10:21:29.000Z","updated":"2020-06-02T07:51:22.006Z","comments":true,"path":"post/ddaa88d4.html","link":"","permalink":"https://www.missf.top/post/ddaa88d4.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 基础数据类型补充判断数值是否相等top1 = 'alex' top2 = 'alex' print(top1 == top2) True 内存地址# 打印mem会先找到mem的内存地址，然后再找到内存地址指向的数据 mem = 'mk' print(id(mem)) 170332332864 判断内存地址是否相同f = [1,2,3] g = [1,2,3] print(f == g) # True print(f is g) # False # 判断的是两个对象的内存地址是否相同,虽然f的值等于g，但是内存地址却不是指向同一个 数据类型 可变/不可变 整型 不可变 字符串 不可变 元组 不可变 列表 可变 集合 可变 字典 可变 代码块# 代码块 代码全都是基于代码块去运行的，一个文件就是一个代码块，不同的文件就是不同的代码块 # 代码块的缓存机制 Python在执行同一个代码块的初始化对象的命令时，会检查其值是否已经存在， 如果存在，会将其重用，如果有同样的记录那么它会重复使用这个字典中的值， 但是要注意的是，只有在同一个代码块下，才会实现这个缓存机制 满足此机制的数据类型:int str bool 优点：节省内存，提升性能 小数据池Python自动将-5~256的整数进行了缓存，当你将这些整数赋值给变量时，并不会重新创建对象，而是使用已经创建好的缓存对象。python会将一定规则的字符串在字符串驻留池中，创建一份，当你将这些字符串赋值给变量时，并不会重新创建对象， 而是使用在字符串驻留池中创建好的对象。 小数据(又称驻留机制、驻存机制) 能够应用于不同的代码块 适应的数据类型:int str bool int:-5 ~ 256 str:一定条件下的str满足小数据池 bool:全部 优点:节省内存 提升性能 编码进阶不同的编码之间不能互相识别（会出现报错或者乱码），文字通过网络传输，或者硬盘存储不能使用Unicode编码方式。 ASCII早期的密码本，英文字母，数字，特殊字符 8位(bit) == 1byte 在ascll码中,8位bit表示一个字节表示一个字符 hello = 01101000 01100101 01100111 0110011 01100101 Unicode万国码包含全世界所有的文字 32位bit表示4个字节表示一个字符 a:10001000 00010010 00100000 00010010 中:00000000 10010010 00000000 10010010 utf-8最少用8位表示一个字符 a:01000010,8位bit表示一个字节表示一个字符 欧洲文字:00000010 00100000 16位bit表示两个字节表示一个字符 中国文字:00000010 00000010 00000010 24位bit表示三个字节表示一个字符 gbk最包含英文和自己国家的语言 a:00000010 8位bit表示一个字节表示一个字符 中:00000010 0000001016 16位bit表示两个字节表示一个字符 在Python3x环境下，唯独str类型的内部编码方式是Unicode， 所以Python3x中的字符串不能用于直接的网络传输和文件存储 补充一个数据类型：bytes类型，与str类型是海尔兄弟， bytes内部编码方式为非Unicode，bytes类型能用于网络传输和文件存储，还拥有str的其他特性 但是bytes中文是16进制表示，看不懂，所以常用的还是str类型 bytes类型b1 = 'alex' b2 = b'alex' print(b1,type(b1)) alex &lt;class 'str'> print(b2,type(b2)) b'alex' &lt;class 'bytes'> 数据类型转换# str ---> gbk s0 = '荒原饮露' b1 = s0.encode('gbk') # 编码，将字符串转换为gbk print(b1) b'\\xbb\\xc4\\xd4\\xad\\xd2\\xfb\\xc2\\xb6' # 可以看到 一个中文两个字节 y2 = b1.decode('gbk') # 解码 print(y2) 荒原饮露 # str ---> utf-8 s2 = '努力奋斗' b2 = s2.encode('utf-8') print(b2) b'\\xe5\\x8a\\xaa\\xe5\\x8a\\x9b\\xe5\\xa5\\x8b\\xe6\\x96\\x97' # 一个中文三个字节 b3 = b2.decode('utf-8') print(b3) 努力奋斗 # gbk ---> utf-8 si = '编码' s1 = si.encode('gbk') print(s1) b'\\xb1\\xe0\\xc2\\xeb' # 得到gbk编码的bytes类型 1 = s1.decode('gbk') # 解码再加密 b2 = b1.encode('utf-8') print(b2) b'\\xe7\\xbc\\x96\\xe7\\xa0\\x81' # utf-8编码的bytes类型 深浅拷贝# 赋值运算 jk = [1,2,3] yu = jk # yu变量和jk变量都指向同一个内存地址 yu.append(789) # 修改这个列表的时候，两个变量的值都被修改 print(jk,yu) [1, 2, 3, 789] [1, 2, 3, 789] 浅拷贝lo = ['de',15,['er',4,2]] ko = lo.copy() # ko拷贝lo的列表，得到一样的数据，但是浅copy只会拷贝内存中的第一层数据 lo.append('lp') # lo往列表追加一个元素lp print(id(lo),lo) print(id(ko),ko) 205292790408 ['de', 15, ['er', 4, 2], 'lp'] 205293284808 ['de', 15, ['er', 4, 2]] # 可以看到两个列表的内存地址都是不一样的，往lo列表追加lp元素，ko列表是没有跟随lo列表追加lp元素的 lo[2].append('io') # 往lo列表的小列表里面追加io元素 print(lo,ko) ['de', 15, ['er', 4, 2, 'io'], 'lp'] ['de', 15, ['er', 4, 2, 'io']] # 可以看到，lo和ko列表的小列表都被追加了io元素，简而言之，列表里面的小列表里面的元素是共用的。ko拷贝lo的列表，只会拷贝lo外层列表，而不会拷贝lo的内层列表，lo外层列表发生改变ko不会跟随，但是lo内层列表发生改变ko会跟随，复制一个列表时，lo = ['de',15,['er',4,2]]，de和15元素的地址发生改变，['er',4,2]小列表的元素还是指向原来的地址 # 全切片是浅copy ki = ['cf',['ijni','678',15],90] ji = ki[:] ki[1].append('mk') print(ki,ji) ['cf', ['ijni', '678', 15, 'mk'], 90] ['cf', ['ijni', '678', 15, 'mk'], 90] 深拷贝# 深copy会在内存中对原列表以及列表里面的可变的数据类型重新创建一份，而列表中不可变得数据类型还是沿用原来的 import copy lo = ['fr','ty',['rt','km',12],45] ko = copy.deepcopy(lo) print(lo,ko) lo[2].append('test') print(lo,ko) ['fr', 'ty', ['rt', 'km', 12], 45] ['fr', 'ty', ['rt', 'km', 12], 45] ['fr', 'ty', ['rt', 'km', 12, 'test'], 45] ['fr', 'ty', ['rt', 'km', 12], 45] # 往lo小列表追加元素，ko的小列表的元素不是指向原来的地址，ko的小列表元素没有被改 深拷贝和浅拷贝的区别# 以下所有的内容都是基于内存地址来说的。 # 可变数据类型：当该数据类型的对应变量的值发生了改变，那么它对应的内存地址不发生改变，对于这种数据类型，就称可变数据类型 # 不可变数据类型：当该数据类型的对应变量的值发生了改变，那么它对应的内存地址也会发生改变，对于这种数据类型，就称不可变数据类型 # 总结：不可变数据类型更改后地址发生改变，可变数据类型更改地址不发生改变 深拷贝和浅拷贝的需要注意的点# 在浅拷贝时，拷贝出来的新对象的地址和原对象是不一样的，但是新对象里面的可变元素（如列表）的地址和原对象里的可变元素的地址是相同的，也就是说浅拷贝它拷贝的是浅层次的数据结构（不可变元素），对象里的可变元素作为深层次的数据结构并没有被拷贝到新地址里面去，而是和原对象里的可变元素指向同一个地址，所以在新对象或原对象里对这个可变元素做修改时，两个对象是同时改变的，但是深拷贝不会这样，这个是浅拷贝相对于深拷贝最根本的区别","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day03","slug":"Python基础day03","date":"2020-04-24T10:14:29.000Z","updated":"2020-06-02T07:51:22.009Z","comments":true,"path":"post/43ce1d77.html","link":"","permalink":"https://www.missf.top/post/43ce1d77.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 验证码# 代入验证码项目，输入姓名密码之后有空格也不会报错 username = input(\"请输入姓名:\").strip() passworrd = input(\"请输入密码:\").strip() code = 'AeTrd'.upper() your_code = input(\"请输入验证码:\").upper() if your_code == code: if username == 'alex' and passworrd == 'sb': print('登录成功') else: print('用户名或者密码错误') else: print('验证码不正确') 将一行字符串竖着打印# while循环 t = '荒原饮露cchkskhdiqwuey' s = len(t) # 先统计字符串的长度 # print(s) index = 0 # 设定一个索引值 while index &lt; s: # 如果索引值小于变量s则进入循环 print(t[index]) # 从0开始打印字符串的索引，直到index&lt;s不成立退出循环 index += 1 # index每次自增1 # for循环 t = '荒原饮露cchkskhdiqwuey' for i in t: print(i) # 还可以进行拼接，print(i+'lo') 猜数字# 猜数字,只有猜对了才会退出 num = 66 while True: cai = int(input(\"请输入你要猜的数字:\")) if cai > num: print(\"猜的数字大了！\") elif cai &lt; num: print(\"猜的数字小了\") else: print(\"猜对了！\") break # 三次猜测不对就退出 num = 66 i = 0 while i &lt; 3: j = int(input(\"请输入数字:\")) if j > num: print(\"数字大了!\") elif j &lt; num: print(\"数字小了!\") else: print(\"猜对了!\") break i += 1 计算器# 方式一 content = input(\"请输入内容:\").strip() # 将输入的字符串，去掉前后两端的空格 plus_index = content.find('+') # 找到加号位置，并返回加号的索引数 num1 = content[:plus_index].strip() # 取加号前面的区域并且去掉空格 num2 = content[plus_index+1:] # 取加号后面的区域也去掉空格 sum3 = int(num1) + int(num2) # 将取到的无空格值相加 print(sum3) # 方式二 content = input(\"请输入内容:\").strip() # 将输入的字符串，进行去前后两端的空格 li = content.split('+') # 将字符串转换为列表，指定以+进行分割 print(li) ['15 ', ' 16'] # 将得到的元素相加 sum1 = int(li[0]) + int(li[1]) # 将字符串类型的两个元素强制转换为int，会去掉空格 print(sum1) 列表为什么需要列表 字符串如果长度过于长取值时会很费劲，取出来的数据是字符串类型，使用不方便 字符串有长度限制(只能存储少量的字符串类型的数据) 基于以上原因Python提供了一个另外的数据类型:容器类数据类型 什么是列表 列表能存储大量的、不同的数据类型，列表存放什么数据类型，取出来之后还是什么数据类型 列表可以存放的数据类型:数字，字符串，布尔值，小列表，元组，字典，集合，对象 32位Python的限制是 536870912 64位Python的限制是 1152921504606846975 列表是有序的、有索引值的、可切片、方便取值 列表取值# 取第一个元素 sl = ['alex','荒原','154'] sl1 = print(sl[0],type(sl)) # 输出索引和索引类型 print(sl1) # alex &lt;class 'list'> 定义列表时是字符串 sl = ['alex','荒原','154'] sl1 = print(sl[0:2]) # 0 1 2，顾首不顾尾，只取前两个元素 print(sl1) # ['alex', '荒原'] # 反向取值 sl = ['alex','荒原','154'] sl1 = print(sl[-1:-4:-1]) print(sl1) # ['154', '荒原', 'alex'] 列表的增加sl.append(\"abc\") # 增加abc元素 print(sl) sl.append(True) # 增加布尔值 print(sl) name_list = [] # 空列表 while True: # 如果不执行break,则一直执行while True username = input(\"请输入姓名:\").strip() # 用户输入字符串 if username.upper() == 'Q':break # 如果输入是q，无论大小写都执行break name_list.append(username) # 判断到不是q则增加到列表 print(name_list) # 插入 lk = ['mjk','ctr','tpo',100] lk.insert(1,'yu') # 在索引1的位置，插入'yu',索引从零开始 print(lk) ['mjk', 'yu', 'ctr', 'tpo', 100] # 迭代者追加 lk = ['mjk','ctr','tpo',100] lk.extend('abc') print(lk) ['mjk', 'ctr', 'tpo', 100, 'a', 'b', 'c'] lk = ['mjk','ctr','tpo',100] lk.extend(['asd','cvf','cdd']) print(lk) ['mjk', 'ctr', 'tpo', 100, 'asd', 'cvf', 'cdd'] 列表的删除# 按照索引去删除 lk = ['mjk','ctr','tpo',100] ret = lk.pop(1) # 删除索引为1的元素 print(lk) ['mjk', 'tpo', 100] # 按照元素去删除 lk = ['mjk','ctr','tpo',100] lk.remove('tpo') # 指定删除那个 print(lk) ['mjk','ctr',100]. # 清空列表 lk = ['mjk','ctr','tpo',100] lk.clear() print(lk) [] # del 1.按照索引删除单个元素 lk = ['mjk','ctr','tpo',100] del lk[0] print(lk) ['ctr','tpo',100] 2.按照切片删除一部分元素 lk = ['mjk','ctr','tpo',100] del lk[:2] print(lk) ['tpo', 100] 3.按照切片（步长）删除一部分元素 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] s = lk[:5:2] # 取区域为0-5，步长为2 print(s) ['mjk', 'tpo', 'cff'] del lk[:5:2] # 取区域为0-5，步长为2，这些元素全部删除 print(lk) ['ctr', 100, 'ioo', 'tyy'] 列表的修改# 利用索引修改 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] lk[0] = 'we' # 利用索引定义要修改的元素的位置 print(lk) # 利用切片修改 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] lk[:2] = 'op' print(lk) ['o', 'p', 'tpo', 100, 'cff', 'ioo', 'tyy'] # 利用切片+步长修改 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] lk[:4:2] = 'op' # 注意步长的个数和修改后的字符串个数 print(lk) ['o', 'ctr', 'p', 100, 'cff', 'ioo', 'tyy'] 列表的查询# 按照索引查询 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy'] print(lk[1]) # 打印一个 # for 循环 for i in lk: print(i) # 输出列表所有元素 列表的其他操作# 计算列表元素的总个数 lk = ['mjk','ctr','tpo',100,'cff','ioo','tyy','cff'] print(len(lk)) 8 # 计算某个元素出现的个数 print(lk.count('cff')) 2 # 通过元素找索引，找到第一个返回，找不到就报错 print(lk.index('ctr')) 1 # 从小到大排列 fg = [2,9,4,6,7,1,8] fg.sort() print(fg) [1, 2, 4, 6, 7, 8, 9] # 从大到小排列 fg.sort(reverse=True) print(fg) [9, 8, 7, 6, 4, 2, 1] # 列表翻转 fg = [2,9,4,6,7,1,8] fg.reverse() print(fg) # 英文字符排序，按照元素首字母的ASCLL码的大小排序 fg = ['dfg','arfd','wer','fgv'] fg.sort() print(fg) ['arfd', 'dfg', 'fgv', 'wer'] 列表的嵌套ll = [1,2,'taibai',[1,'alex',3,]] # 列表里面有嵌套的小列表 # 将taibai改成大写 ll[2] = ll[2].upper() print(ll) # 往小列表追加元素'老男孩教育' ll[3] = ll.append('老男孩教育') print(ll) # 将alex改成alexsb ll[3][1] = ll[3][1] + 'sb' print(ll) # 打印嵌套列表元素 lj = ['wedi','lko','cjd',['dkd','oto'],'top'] for i in lj: if type(i) == list: # 加个判断如果某个元素类型为list，则再循环一遍，打印出来 for o in i: print(o) else: # 否则正常打印 print(i) 元组用来存放一些重要的信息，放在列表中不安全，需要一个容器类的数据类型，比如：个人信息，密码等。元组不能修改，但是元组里面的列表可以修改。 tu = (1,'alex',True,[1,2,3]) # 定义一个元组 tu[-1][2] = '12' # 往列表里面追加元素 print(tu) (1, 'alex', True, [1, 2, '12']) # 存放一些重要数据时，需要用元组存放 字典列表如果存储大量的数据，查询速度相对较慢，因为列表存储的数据一般没有什么关联性。针对这个问题，Python提供了一个基础数据类型：字典(dict) 回顾数据类型 分类 数据类型 容器型数据类型 list，tuple，dict，set 非容器型数据类型 str，bool，int 可变数据类型（不可哈希） list，dict，set 不可变数据类型（可哈希） str，bool，int，tuple 字典是由键值对形式存储的数据类型，字典的键必须是不可变的数据类型，唯一不重复的，字典的值可以是任意数据类型或者对象。基于字典的键是不可变的，字典的键会通过一种哈希算法，将键的值换算成内存地址，所以字典的查询速度非常快。字典在Python3.6之前是无序的，在3.6及以后字典会按照字典创建时的顺序排列。字典可以存储大量关联性数据。 字典的增加dic = {'name':'barry','age':18,'sex':'man'} # 用字典定义三个键值对 dic['dfgh'] = 150 # 没有则添加这个键值对 dic['age'] = 28 # 有age这个键就将值覆盖为28 print(dic) {'name': 'barry', 'age': 28, 'sex': 'man', 'dfgh': 150} dic.setdefault('port') # 没有这个键值对就会添加并赋值为空 dic.setdefault('name','yiyi') # 有name这个值则不修改，没有则增加 print(dic) {'name': 'barry', 'age': 18, 'sex': 'man', 'port': None} 字典的删除# pop 通过键去删除键值对 dic = {'name':'barry','age':18,'sex':'man'} ret = dic.pop('sex') print(dic) {'name': 'barry', 'age': 18} # 删除一个不存在的键就会报错 dic = {'name':'barry','age':18,'sex':'man'} ret1 = dic.pop('name2') # 为了程序能执行下去，想要不报错的话，可以添加一个返回值 dic = {'name':'barry','age':18,'sex':'man'} ty = dic.pop('re','没有此键') print(ty) 没有此键 # clear 清空 dic = {'name':'barry','age':18,'sex':'man'} dic.clear() print(dic) {} # popitem 删除最后一个键值对，3.5之前是随机删除，3.6删除最后一个键值对 dic = {'name':'barry','age':18,'sex':'man'} lo = dic.popitem() print(dic) {'name': 'barry', 'age': 18} # 删除整个字典 dic = {'name':'barry','age':18,'sex':'man'} del dic print(dic) 字典的修改# 改 dic = {'name':'barry','age':18,'sex':'man'} dic['age'] = 28 #重新定义age键的值 print(dic) # update 更新 dic1 = {'name':'barry','age':18,'sex':'man'} dic2 = {'name':'nji','age':'18','id':'001'} dic2.update(dic1) #将dic1字典中的键值对覆盖添加到dic2，dic1不变 print(dic2) {'name': 'barry', 'age': 18, 'id': '001', 'sex': 'man'} # update 正常添加 dic = {'name':'barry','age':18,'sex':'man'} dic.update(weight=150,high=175) #一次添加多个键值对 print(dic) {'name': 'barry', 'age': 18, 'sex': 'man', 'weight': 150, 'high': 175} 字典的查询# 查 dic = {'name':'barry','age':18,'sex':'man'} print(dic['name']) # 按键查对应的值，没有此键会报错 barry tr = dic.get('age1','没有此键') # 定义没有此键时的返回值 print(tr) 没有此键 字典的其他操作dic = {'name':'barry','age':18,'sex':'man'} print(dic.keys()) dict_keys(['name', 'age', 'sex']) print(dic.values()) dict_values(['barry', 18, 'man']) print(dic.items()) dict_items([('name', 'barry'), ('age', 18), ('sex', 'man')]) # for循环得到的是keys值 for i in dic: print(i) name age sex 字典的嵌套联系# 字典的嵌套练习 dic = { 'l1':['alex', '太白'], 'id':3, 1:{ 'data': 20181225, 'place': '深圳校区', 'class': 'python3期', 'name_list': ['awq', 'xx'], } } # 1.给小列表['alex', '太白'] alex后面插入一个字符串，'aaa' dic['l1'].insert(1,'aaa') print(dic) # 2.将id对应的3变成1 dic['id'] = 1 # 3.将1对应的字典的data的值变成20181224 dic[1]['data'] = 20181224 print(dic) # 4.将name_list对应的awq全部变成大写 dic[1]['name_list'][0] = dic[1]['name_list'][0].swapcase() print(dic) # 5.将name_list对应的xx删除 dic[1]['name_list'].pop(1) print(dic) 将字典数据格式化输出# 格式化输出 msg = '我叫%s,我身高%s，年龄%s' % ('ed',180,23) print(msg) # 将字典数据格式化输出 dic = {'name':'barry','age':18,'sex':'男'} mk = '我叫%(name)s,今年%(age)s,性别%(sex)s' % dic print(mk) 返回一个新的字典# 返回一个新的字典，键从可迭代对象里面获取，值不变 dic1 = dict.fromkeys('top','ed') dic2 = dict.fromkeys(['lop'],'努力') print(dic1) {'t': 'ed', 'o': 'ed', 'p': 'ed'} print(dic2) {'lop': '努力'} dicu = dict.fromkeys([1,2,3],['alex']) print(dicu) {1: ['alex'], 2: ['alex'], 3: ['alex']} # 坑:值如果是一个可变的数据类型，那么所有的值都是一个内存地址 dicu[1].append(000) print(dicu) {1: ['alex', 0], 2: ['alex', 0], 3: ['alex', 0]} # 给dicu[1]这个列表赋值000，所有列表的值都是000，因为列表所有的值都指向一个内存地址 数据类型的补充# 数据类型的补充 str ---> list split list ---> str join 0,'',[],{},(),set() ---> bool:false # 列表和元组的互换 # list &lt;---> tuple jk = [1,2,3] yu = tuple(jk) print(yu) uy = list(yu) print(uy) # dict ---> list dico = {'name':'kasha','ui':'io'} print(list(dico)) ['name', 'ui'] # dict ---> tuple dich = {'name':'yu','age':15} print(tuple(dich)) ('name', 'age') # 元组中只有一个元素并且没有逗号，则它不是元组，它与元素数据类型相同 t1 = (1,) t2 = ('al',) t3 = ([1,2,3],) print(t1,t2,t3) (1,) ('al',) ([1, 2, 3],) t1 = (1) t2 = ('al') t3 = ([1,2,3]) print(t1,t2,t3) 1 al [1, 2, 3] 将索引为奇数位的元素删除# 将索引为奇数位的元素删除,列表是不等长的 # 方法一 li = [11,36,56,48,79,45,21,65] del li[1::2] # 1-所有，步长为2 print(li) # 方法二 li = [11,36,56,48,79,45,21,65] new_li = [] # 定义一个空列表 for index in range(len(li)): # 循环 if index % 2 == 0: # 如果能被2整除 new_li.append(li[index]) # 如果能整除，就加入到new_li列表里面，这样索引是奇数位的元素就被删除了 li = new_li print(li) # 方法三 li = [11,36,56,48,79,45,21,65] for index in range(len(li)-1,-1,-1): if index % 2 == 1: li.pop(index) print(li) 将字典中键含有k元素的键值对删除# 将字典中键含有k元素的键值对删除 dict = {'ko':'ty','df':54,'13k':'hu','jl':'lp'} # 循环列表时不能改变字典的大小 lo = [] # 定义一个空的列表 for i in dict: # 将字典循环给i，赋值时是只将key赋值 if 'k' in i: # 如果k存在于i中 lo.append(i) # 则把这些有k元素的键值对添加到lo这个空字典 for y in lo: # 将lo字典循环给y dict.pop(y) # 通过键去删除键值对 print(dict) enumerate()# enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中 s1 = \"Hello\" for i,y in enumerate(s1,start=1): print(i,y) 1 H 2 e 3 l 4 l 5 o s2 = [\"top\",\"jun\",\"mid\",\"adc\",\"sup\"] for i,j in enumerate(s2,start=1): print(i,j) 1 top 2 jun 3 mid 4 adc 5 su 集合集合创建# 集合的创建 set1 = {\"er\",\"mk\",\"lk\"} print(set1) set2 = ('lk','oi',\"er\") # 不一定要{}或者(),只要是迭代对象就行 print(set2) 集合的无序特点# 集合是无序的 set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.add(\"fpx\") print(set1) {'rng', 'top', 'skt', 'fpx', 'we'} #增加一个元素，不会按照顺序添加，每一次执行代码，顺序都会改变 集合的迭代增加set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.update(\"fpx\") #迭代增加会把整个字符串拆分为多个字符进行增加 print(set1) {'skt', 'x', 'rng', 'top', 'f', 'p', 'we'} 集合的删除set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.remove(\"skt\") # 指定删除元素 print(set1) {'top', 'we', 'rng'} set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.pop() # 随机删除一个元素 print(set1) set1 = {\"we\",\"rng\",\"skt\",\"top\"} set1.clear() # 清空集合 print(set1) set() 集合的元素是不可变类型set1 = {\"we\",\"gb\",[\"rf\",\"gb\"]} print(set1) # 集合里面存在列表元素，执行会报错 set1 = {\"we\",\"gb\",(\"vf\",\"jin\",1)} print(set1) # 集合里面存在元组元素可以执行，因为元组是不可变类型 面试必考# 面试必考 list1 = [1,2,3,4,5] list2 = [2,3,4,5,6] # 将list1和list2的元素集合起来并去重 new_list = list1 + list2 print(new_list) new_set = list(set(new_list)) #将new_list转换为集合，再转换为list print(new_set) [1, 2, 3, 4, 5, 2, 3, 4, 5, 6] [1, 2, 3, 4, 5, 6] 电影投票# 电影投票:程序先给出几个目前正在上映的电影列表. 由用户给每个电影投票. # 最终将该用户投票信息公布出来 lst = ['北京遇上西雅图', '解救吴先生', '美国往事', '西西里的美丽传说'] lst = ['北京遇上西雅图', '解救吴先生', '美国往事', '西西里的美丽传说'] # print(lst) dic = dict.fromkeys(lst,0) #定义一个字典，key来自lst列表，值是0 while True: for num,name in enumerate(lst,start=1): #定义电影序号和电影来自lst列表 print('{}\\t{}'.format(num,name)) #列出电影序号和电影 name_num = input('请输入你喜欢的电影序号，或者q/Q退出:').strip() #记录用户所喜欢的电影序号 if name_num.isdigit(): #如果用户输入的是数字则进入，否则输出206行的：你输入有误，请重新输入 name_num = int(name_num) #用户输入的必须是整数 if 0 &lt; name_num &lt; len(lst): #控制用户输入数字的范围必须是比0大，比列表总长度小 dic[lst[name_num-1]] += 1 #将用户输入的值记录到dic空字典，lst[name_num-1] == dic字典的第一元素，是0 print('已成功为%s投票' %(lst[name_num-1])) #提示用户投票成功 else: print(\"没有该序号的电影，请重新输入\") #如果输入的范围不对，提示没有这个序号的电影 elif name_num.upper() == 'Q': #如果用户输入q就退出 break else: print(\"你输入有误，请重新输入\") for movie_name,total_num in dic.items(): #以列表返回可遍历的键值 print(\"%s电影的总得票数%s\" %(movie_name,total_num))","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day02","slug":"Python基础day02","date":"2020-04-24T04:14:29.000Z","updated":"2020-06-02T07:51:22.008Z","comments":true,"path":"post/34c92de1.html","link":"","permalink":"https://www.missf.top/post/34c92de1.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 格式化输出# 格式化输出 name = input(\"请输入姓名：\") age = input(\"请输入年龄：\") job = input(\"请输入职业：\") hobby = input(\"请输入爱好\") msg = \"\"\"------ info of %s ------ Name : %s Age : %s job : %s Hobbie : %s ------ end ------\"\"\" % (name,name,age,job,hobby) print(msg) # 坑:单个%号默认被当成一个占位符，如果想单纯的表示%号，请使用%% msg = '我叫%s,今年%s岁,python入门1%%.' % ('荒原饮露','23') print(msg) 运算符 运算符 描述 实例 = 简单的赋值运算符 c = a + b 将 a + b 的运算结果赋值给c += 加法赋值运算符 c += a 等效于 c = c + a -= 减法赋值运算符 c -= a 等效于 c = c - a *= 乘法赋值运算符 c *= a 等效于 c = c * a /= 除法赋值运算符 c /= a 等效于 c = c / a %= 取模赋值运算符 c %= a 等效于 c = c % a **= 幂赋值运算符 c *= a 等效于 c = c * a //= 取整赋值运算符 c //= a 等效于 c = c // a and “与”，如果 x 为False，x and y 返回False，否则返回y的计算值 两边为True才为True or “或”， 如果 x 为True，返回True，否则它返回y的计算值 一边为True则为True not “非”， 如果 x 为True，返回False，如果 x 为False，返回True True则False，反之 逻辑运算符的优先级() > not > and > or and 两个条件必须同时成立才为True or 两个条件有一个成立则为True not 条件为True则结果为False，条件为False则结果为True 运算符的不等式计算print(2 > 1 and 3 > 4) 两边式子同时成立，才会为True，否则为False print(2 > 1 and 3 > 4 or 4 &lt; 5 and 6 &lt; 7) 先计算and，式子为False or True，结果则为True print(1 > 2 and 3 &lt; 4 or 4 > 5 and 2 > 1 or 9 &lt; 8) 先计算and，式子为False or False or False，结果为False 运算符数字计算x or y # if x is True，return x else return y.如果x为True则返回X，否则返回y print(1 or 2) 1 print(3 or 2) 3 print(0 or 2) 2 # x and y和x or y是相反的 print(1 and 2) 2 print(8 and 0) 0 print(-100 and 2) 2 print(1 and 2 or 3 and 5) == print(2 or 5) 2 编码初识ASCII ASCII:早期的密码本，只包含英文字母，数字，特殊字符与01的对应关系 采用 8位比特（bit） == 1byte（字节） 在ascll编码中 8位比特表示一个字节表示一个字符 h e l l o = 01101000 01100101 01100111 0110011 01100101 缺点:只为英文使用者考虑，不能处理中文和其他国家的文字 GBK 由于ASCII编码，于是每个国家都提出了不同的编码来适应自己的语言 GBK 只包含本国文字（以及英文字母，数字，特殊字符）与01对应关系 GBK是采用单双字节变长编码，英文使用单字节编码，完全兼容ASCII字符编码，中文部分采用双字节编码 a 太 白 = 01101000 01100101 01100111 0110011 01100101 # 1个英文占1个字节，1个中文字符占2个字节，共5字节 UNICODE 由于ASCII编码的局限性，unicode应运而生 unicode:万国码，将全世界所有的文字都统一到一套编码里面 采用32位比特(bit)== 4byte 在unicode编码中 32位比特表示4个字节表示一个字符 a：00000000 00010010 00000000 00010010 中：00000000 10010010 00000000 10010010 缺点:如果使用unicode编码来存储英文，这会大量浪费空间，因为我们知道一个英文字符只占一个字节，而另外三个字节就浪费掉了，这样在存储和传输上非常不划算 UTF-8 utf-8:包含全世界所有的文字与二进制01的对应关系,最少用8位表示一个字符 utf-8是一种针对Unicode的可变长度字符编码,是对Unicode编码的压缩和优化，将所有的字符和符号进行分类 英文: 00000010 8位表示一个字节表示一个字符 欧洲文字: 00000010 00100000 16位表示两个字节表示一个字符 中国(亚洲): 00000010 00000010 00000010 24位表示三个字节表示一个字符 例子 'old男孩' GBK:7个字节 utf-8:9个字节 十进制转换为二进制关键要点:除二取余，倒序排列，高位补零。 将十进制数42不断除以2，得到的余数非别是:010101，然后倒序排列，42所对应的二进制就是101010，然后高位补零就是:00101010 负整数转换为二进制，以-42为例，先得到42的二进制，然后取反(0变1，1变0)再加一，就是11010101 + 1，结果为11010110 二进制转换成十进制 1 0 0 1 0 1 1 0 1 * 2^7 0 * 2^6 0 * 2^5 1 * 2^4 0 * 2^3 1 * 2^2 1 * 2^1 0 * 2^0 将这些数相加，得到的就是10010110这个二进制数的十进制数 128 + 0 + 0 + 16 + 0 + 4 + 2 + 0 = 150 数据类型之间的转换int（整数） --> bool（布尔值） 非零即True bool（布尔值） --> int（整数） True 1 False 0 str（字符串） --> bool（布尔值） 非空即True str（字符串） --> int（整数） str（13 ）转换为整数，会强制去掉空格变成int（13） bool（布尔值） --> str（字符串） 还是True，但是str类型的True，失去True的意义 y = True u = str(y) print(u,type(u)) True &lt;class 'str'> # 由于是str数据类型的True，下面的3 + u会报错，如果是bool数据类型的True可以与数字相加 print(3 + u) 字符串的切片字符串索引示意图请记住切片原则:顾首不顾尾 按照索引取值s = 'python骑士计划第三期' s1 = s[0] s2 = s[-1] print(s1) # p print(s2) # 期 按照切片取值s = 'python骑士计划第三期' # 照切片取值，顾首不顾尾，s5 = s[6:-3] 6就是第六个字符以后，-3就是倒数第三个字符以前 s3 = s[0:6] # 是从零开始数。取整个字符串可以写成s3 = s[:6],取整个字符串是s3 = s[:] print(s3) # python s4 = s[:6] # 相当于s[0:6]，0可以不写，默认从零开始 print(s4) # python s5 = s[6:-3] print(s5) # 骑士计划 s6 = s[6:10] print(s6) # 骑士计划 切片加步长取值# 步长就是每一步的长度，取pto字符串，要先划分区域，再定义隔几个字符去取 s = 'python骑士计划第三期' s7 = s[:6:2] # 划分区域为 0-6（区域为:python，从首个字符串开始取），步长为2 print(s7) # pto s8 = s[7::2] # 划分区域为 7-最后（区域为:士计划第三期，从第七个字符之后开始取），步长为2 print(s8) # 士划三 s9 = s[-1:-4:-1] # 倒叙取值要加上反向步长 print(s9) # 期三第 print(s[:5:-1]) # 后面是-1所以是反向取值，区域定义为 0-5（python），但是区域也是反向的，所以是从期到n的区域里面取 骑士计划第三期 字符串的常用操作capitalize() 首字母大写s = 'faker' s1 = s.capitalize() print(s) # faker print(s1) # Faker center() 将字符串居中s = 'missf.top' s1 = s.center(50) print(s1) missf.top # 设置50的长度并把字符串居中 s2 = s.center(50,'*') print(s2) ********************missf.top********************* # 设置50的长度定义填充物并把字符串居中 swapcase() 大小写翻转sr = 'KubeRnEteS' print(sr.swapcase()) kUBErNeTEs title() 非字母隔开单词的首字母大写s = 'tpshow9nohup@mid' # 注意：第一个字母也会变成大写 print(s.title()) Tpshow9Nohup@Mid upper() 不区分大小写# 用途:验证码不区分大小写 username = input(\"请输入姓名:\") passworrd = input(\"请输入密码:\") code = 'AeTrd'.upper() your_code = input(\"请输入验证码:\").upper() if your_code == code: if username == 'alex' and passworrd == 'sb': print('登录成功') else: print('用户名或者密码错误') else: print('验证码不正确') startswich() endswith() 判断以什么为开头和结尾s = 'mowenjieadcarry' print(s.startswith('o')) False # 字符串不是以o开头，结果为False print(s.startswith('mo')) True # 字符串以mo开头，结果为True print(s.startswith('j',5)) # 切割五个字符之后是否是j开头，结果为True True print(s.endswith('ry')) # 判断以什么为结尾 True find() index() 通过元素找索引s = 'mowenjieadcarry' print(s.find('a')) 8 # 返回a元素前面的索引数 print(s.find('a',9,)) 11 # 从第九个字符后面开始找，找到的是第二个a # find和index功能几乎一样，区别只有find找不到会返回-1,index会报错 strip() 默认去除字符串前后的空格/换行符/制表符# strip() 默认去除字符串前后两端的空格，换行符，制表符 s = '\\n barry \\t \\n' print(s.strip()) # barry # strip 去除字符串两边的字符 s = 'kkohuang yuan yin lure' print(s.strip('kore')) # 会把kore切割成最小单位，从前后两边逐个去除 huang yuan yin lu # lstrip 只从前面去除 print(s.lstrip('k')) ohuang yuan yin lure # rstrip() 只从后面去除 print(s.rstrip('re')) kkohuang yuan yin lu split() 将字符串转化为列表s = 'kkohuang yuan yin lure' print(s.split()) # 默认以空格分割元素 ['kkohuang', 'yuan', 'yin', 'lure'] t = 'top:mid:adc' print(t.split(':')) # 指定以冒号进行分割 ['top', 'mid', 'adc'] print(t.split(':',1)) # 指定以冒号进行分割,分割一次 ['top', 'mid:adc'] t = ':mid:adc' # 只有两个分割符，但是转换成列表之后参数个数是n+1 print(t.split(':')) ['', 'mid', 'adc'] join() 列表转化为字符串t = ':mid:adc' s9 = '-'.join(t) # 将每个字符通过指定的连接符连接在一起 print(s9) :-m-i-d-:-a-d-c t1 = ['liz','zsd','awa'] s10 = ' '.join(t1) # 以空格为分隔符 print(s10) liz zsd awa # 将列表的多个元素转换回字符串 replace() 字符串替换t = 'faker是世界第一中单，faker也是一个屌丝，faker' s11 = t.replace('faker','55开',2) # 可以指定替换的次数，不指定次数则全部替换 print(s11) 55开是世界第一中单，55开也是一个屌丝，faker format() 格式化输出# 第一种 s = '我叫{}，我玩{}，我主玩的位置是{}'.format('bang','英雄联盟','adc') print(s) # 我叫bang，我玩英雄联盟，我主玩的位置是adc # 第二种 s = '我叫{0}，今年{1}，性别{2}，我依然叫{0}'.format('小明','20','女') print(s) # 我叫小明，今年20，性别女，我依然叫小明 # 第三种 s = \"\"\" 我叫{name}，今年{age}，性别{sex}，我依然叫{name} \"\"\".format(age=20,sex='女',name='小明') print(s) # 我叫小明，今年20，性别女，我依然叫小明 is 判断字符串和数字组成name ='huanyuan135' print(name.isalnum()) # 判断字符串由字母或数字组成 True print(name.isalpha()) # 判断字符串只由字母组成 False print(name.isdigit()) # 判断字符串只由数字组成 False count 计算字符串中某个字符出现的次数s = 'cdcdcdcdcdjvnjfnvjfn:jsvnsvpojwpd' print(s.count('f')) # 计算这个字符串f字符出现的次数 2 print(s.count('d')) 6 print(s.count('d',0,8)) # 切片，顾首不顾尾，从零开始到第八个字符的前面截断 4 print(s.count('d',8)) # 从零开始数，第八个字符到结束 2 len 统计字符串长度s = 'cdcdcdcdcdjvnjfnvjfn:jsvnsvpojwpd' print(len(s)) # 内置函数 33","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Python基础day01","slug":"Python基础day01","date":"2020-04-23T04:14:29.000Z","updated":"2020-06-30T07:03:45.687Z","comments":true,"path":"post/adc07c5b.html","link":"","permalink":"https://www.missf.top/post/adc07c5b.html","excerpt":"","text":"我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 ​ ——塔里克 Python发展史 创始人:Guido，国人叫龟叔，在1989年的圣诞节写出来的 2005 - 2012，龟叔去了谷歌工作，谷歌大量使用Python 2005年国内第一家使用Python的公司—豆瓣 2012年国内兴起云计算的热潮，Python借助OpenStack又火了一把 2014年AI兴起，大量的公司使用Python去写算法 直到2017年Python才真正进入大众的视野 Python的应用领域 WEB开发:最火的Python web框架Django，还有支持异步高并发的Tornado，短小精悍的flask 网络编程:支持高并发的Twisted网络框架 爬虫:Python在爬虫领域几乎是霸主地位，具有非常多的爬虫模块支持 云计算:著名的云计算框架OpenStack就是用Python写的 人工智能和数据分析:Python是目前人工智能和数据分析领域公认的必备语言 自动化运维:在Linux运维领域，Python能做很多事情，特别是处理数据的能力非常出色 游戏开发:Python能做游戏开发，但是使用Python开发游戏的公司可能没有这么多 编译型语言核心:通过编译器将人类写出来的代码一次性全部编译成机器语言让计算机可以识别和执行 代表语言：c，c++，golang，java 优点:执行效率高 缺点:开发效率低，不可以跨平台 一般多用于研究所、研究院，对执行效率要求高，大数据的计算、底层的开发 解释型语言核心:解释器逐行解释代码，再逐行执行（python是解释器，java中叫虚拟机） 代表语言:Python，php，Java，ruby 优点:开发效率高，可以跨平台，可移植性强 缺点:执行效率相对编译型语言慢 Python的优缺点优点 Python是一门高级语言，不用关心底层内存指针等等 由于Python开源的本质，Python已经被移植到许多平台，具备非常高的可移植性 Python可以嵌入c语言的代码，c语言也可以嵌入Python的代码，具备可嵌入性 大量现有的第三方库和模块的支持，使得开发效率大大提高 缺点 执行速度比编译型语言慢，如果运行Python花了0.1s，同样的代码c语言花了0.01秒，这样c就比Python快了十倍 Python源码是以明文形式存放的，如果项目要求源代码必须是加密的，一开始就不应该选择Python 线程不能利用多核CPU的问题，这也是Python被人诟病最多的一个缺点 变量官方解释:将程序中一些中间结果暂时存到内存中，供后面程序调用 变量命名规则 变量必须由数字，字母，下划线任意组合 不能是数字开头 不能使用Python中的关键字（具体关键字后面再介绍） 变量要具有描述性 变量不能过长 变量不能使用中文 尽量使用驼峰体 定义Python变量age1 = 12 age2 = age1 age3 = age2 age2 = 24 print (age1,age2,age3) 12 24 12 # 注意：程序中会大量的出现和使用变量，变量中会暂存一些少量的数据，给其他变量代指 Python常量常量，用于定义不变的值。例如:身份证号，圆周率，历史记载，新中国成立时间:1949101 使用常量Python中的常量可以改变（不像c改变常量会报错），但约定俗成Python中将变量全部变成大写，就是表示常量，将一些不想让别人改变的量设置成常量，放在文件最上面 Python注释对某一段代码做解释说明，一般是精简的代码，别人可能看不懂，需要做简单的解释 单行注释#好好学习，天天向上 多行注释'''被注释的内容''' \"\"\" 被注释的内容 \"\"\" 基础数据类型初识int 整型i1 = 10 i2 = 20 print (i1 * i2) # 200 str 字符串python中凡是用引号引起来的内容就是字符串数据类型 ret1 = '荒原饮露' ret2 = \"荒原饮露\" ret3 = \"\"\"荒原饮露\"\"\" ret4 = '''荒原饮露''' print (ret1,ret2,ret3,ret4) bool 布尔值true # 真 false # 假 用于判断条件，逻辑语句真假 单双引号搭配使用msg = \"I' m huangyuanyinlu,18 year\" print (msg) # I' m huangyuanyinlu,18 year 字符串相加相乘a1 = 'Alex' a2 = 'sb' print (a1 + a2) # Alexsb print (a1 * 10) # AlexAlexAlexAlexAlexAlexAlexAlexAlexAlex input 用户交互让用户输入用户名密码，得到用户输入的数据，起到了人与程序的交互作用 name = input(\"请输入你的名字：\") age = input(\"请输入你的年龄：\") sex = input(\"请输入你的性别：\") print (name,age,sex) # 这里注意一点:凡是input得到的值，都是字符串数据类型 将用户输入的变量进行拼接name = input(\"请输入你的名字：\") age = input(\"请输入你的年龄：\") sex = input(\"请输入你的性别：\") msg = '我的姓名是' + name + ',' + '我的年龄是' + age + ',' + '我的性别是' + sex + '.' print (msg) # 我的姓名是荒原饮露,我的年龄是23,我的性别是男 if 流程控制语句if 单分支age = input (\"请输入年龄:\") age = int(age) # Python3x之后，input得到的数据都是字符串类型 print (age,type(age)) # 输出变量的数据类型 if age > 10: print('你已经不是10岁的小孩了'） if 多分支jineng = input('请输入你的技能:') if jineng == '三分球': print('可以参加三分球大赛') elif jineng == '中投': print('可以参加中距离投篮') elif jineng == '突破': print('可以参加1V1对抗赛') else: print('买票进场吧') if 嵌套# 登陆示例 username = input('请输入用户名：') password = input('请输入密码：') if username == '荒原饮露': if password == '123': print('登录成功') else: print('密码错误') else: print('用户名不存在') # 买票示例 has_ticket = int(input('请输入车票号码:')) knife_length = int(input('请输入刀的长度:')) if has_ticket == 23: print('车票检查通过，准备开始安检') if knife_length &lt; 20: print('刀不超过20厘米，允许上车') else: print('刀超过20厘米，不允许上车') else: print(\"没有车票\") while 循环单次循环flag = True while flag: print('麦迪') print('科比') print('杜兰特') flag = False print('詹姆斯') # flag = False后面的依然会输出，因为运行到最后才会重新回到while 打印1到100# 方法一 count = 1 flag = True while flag: print(count) count = count + 1 if count == 101: flag = False # 方法二 count = 1 while count &lt; 101: print(count) count = count + 1 # 不要见方法二代码少就不去理解方法一，因为方法一包含flag = True的编程思想 计算1加到100count = 1 sum = 0 while count &lt;= 101: sum = sum + count count = count + 1 if count == 101: break print(sum) # break是直接终止循环 continue打印1到10，但是跳过7 count = 0 while count &lt; 10: count = count + 1 if count == 7: continue # continue是跳出本次循环，继续执行下一个循环 print(count) count = 0 while count &lt; 10: count = count + 1 if count == 7: # 判断count的值，直接+1 count = count + 1 print(count) 打印100以内的偶数# 利用对2取余去判断是否偶数 count = 0 while count &lt; 101: if count % 2 == 0: print(count) count = count + 1 # 每次自加2去打印偶数，虽然这样的做法不专业，但是也是体现灵活编程思维的一种方式 count = 0 while count &lt; 101: print(count) count = count + 2 while else# while else :只有在while循环被break打断时，才不会执行else程序，否则循环完之后一定会执行else程序 count = 0 while count &lt;= 5: count = count + 1 if count == 3:break print(\"Loop\",count) else: print(\"循环正常执行\") count = 0 while count &lt;= 5: count = count + 1 print(\"Loop\",count) else: print(\"循环正常执行\") # while循环没有被打断，打印完Loop1-6之后还是会打印循环正常执行","categories":[{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"}],"tags":[{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"}]},{"title":"Hello World","slug":"Hello World","date":"2019-03-28T04:14:29.000Z","updated":"2020-06-02T07:51:22.003Z","comments":true,"path":"post/4a17b156.html","link":"","permalink":"https://www.missf.top/post/4a17b156.html","excerpt":"","text":"所有无法深入问题本质的那些人，最终都将离开这个行业。","categories":[{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/categories/Hello-World/"}],"tags":[{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/tags/Hello-World/"}]},{"title":"我在人间凑数的日子","slug":"我在人间凑数的日子","date":"2019-03-28T04:14:29.000Z","updated":"2020-09-09T07:27:24.829Z","comments":true,"path":"post/world.html","link":"","permalink":"https://www.missf.top/post/world.html","excerpt":"","text":"语言这东西，在表达爱意的时候如此无力，在表达伤害的时候，却如此锋利。 你住的城市下雨了，想问你有没有带伞，可我不敢。因为我怕你说没带，而我又无能为力，就像是我爱你，却给不了你想要的。 十年太长，什么都会变。一辈子太短，一件事也有可能做不完。回忆永远站在背后，你无法抛弃，只能拥抱。 没有回音的山谷不值得纵身一跃。 世界上只有一种英雄、看透了生活的真相，却依然热爱生活。 你联系我，我就听你说，你不联系我，我就顺其自然；实不相瞒，我很想你，但我能控制，因为这样很酷。 我不知道凌晨五点该说晚安还是早安，也不知道这个年龄是该说爱还是喜欢。 曾经我发誓要把生命献给爱情，后来我没死，只是青春替我偿了命。 我与春风皆过客，你携秋水揽星河。 我曾踏足山巅，也曾进入低谷，二者都让我受益良多。 从此无心爱良夜，任他明月下西楼。 仅一夜之间，我的心判若两人。 真正的离别没有长亭古道，也没有劝君更尽一杯酒，只是在一个和往常一样的清晨，有的人留在昨天了。 我吹过你吹过的晚风，那我们算不算相拥。 明智的放弃胜过盲目的执着，去吹吹风吧，能清醒的话，感冒也没关系。 以后不见面的日子要按年算了。 没有特别挚爱的东西，没有一定要得到的人，也没有非做不可的事。 艺术，值得为之痛苦。 我于杀戮之中盛放，亦如黎明中的花朵。 生如蝼蚁，当立鸿鹄之志，命薄如纸，应有不屈之心。 好像什么都还来得及，又好像什么都无能为力。 旧时王谢堂前燕，飞入寻常百姓家。 越过山丘，才发现无人等候。 没有好好告别的人一定会重逢。 如果不是刻意相见，原来真的不会遇见。 有时候生活没那么好，有时候生活也没那么坏。 可能给不了你世间所有温柔，但有个词叫尽我所能。 真正爱你的人会督促你变的优秀，而不是蹉跎你的青春。 人间忽晚，山河已秋。 人间度日，何缘其身。我喜欢这种孤身只影的感觉，它让我孤独得像一个死去多年的人。 我原本可以接受所有的黑暗，如果我不曾见过光明。 我最遗憾的是，从未拥有过一个女孩的青春。 逢人不必言深，孤独本是常态。 种下一棵树最好的时间是十年前，其次是现在。 巅峰产生虚伪的拥护，黄昏见证真正的使徒。 所有命运馈赠的礼物，都早已在暗中标好了价格。 如不抽出时间来创造自己想要的生活，你最终将不得不花费大量的时间来应付自己不想要的生活。 往往最简单的东西里面，藏着最深刻的道理。 俄罗斯方块让我明白，成功会消失，错误会积累；贪吃蛇让我明白，越到后面越危险，最大的敌人是自己。 从来没有什么岁月静好，只不过是有人在替你负重前行！ 书上说，如果有一天你梦见了一个很久没见的人，代表她正在遗忘你。 虽然分手是我提的，但我很清楚是谁要走。 真实发生在身边的事情，让我瞬间明白了许多道理。 Make me feel the warmth,Make me feel the cold. 总有人会洗去生来的泥土，站在云端与诸神共舞。 等人是会上瘾的，因为等着等着，你会发现，如果你不等了，不是放弃了对方，而是背叛了自己。 人难免天生有自怜情绪，唯有时刻保持清醒，才能看清真正的价值在哪里。 可能是未来的架构师，也可能送外卖。 永恒燃烧的羽翼，带我脱离凡间的沉沦。 这世人的喧嚣之上，我追寻着荣光飞翔。 我拿起了母亲的剑，还有她的决心。 无意者烈火焚身，悲索者该当死罪，欺诈者判你无能，忤逆者烈焰加身，堕落者不可饶恕。","categories":[{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/categories/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"}],"tags":[{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/tags/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"},{"name":"记忆","slug":"记忆","permalink":"https://www.missf.top/tags/%E8%AE%B0%E5%BF%86/"},{"name":"语录","slug":"语录","permalink":"https://www.missf.top/tags/%E8%AF%AD%E5%BD%95/"}]}],"categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.missf.top/categories/MySQL/"},{"name":"Elastic Stack","slug":"Elastic-Stack","permalink":"https://www.missf.top/categories/Elastic-Stack/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/categories/Prometheus/"},{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/categories/Docker/"},{"name":"CODING","slug":"CODING","permalink":"https://www.missf.top/categories/CODING/"},{"name":"Python","slug":"Python","permalink":"https://www.missf.top/categories/Python/"},{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/categories/Hello-World/"},{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/categories/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.missf.top/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"ELK","slug":"ELK","permalink":"https://www.missf.top/tags/ELK/"},{"name":"企业级日志系统","slug":"企业级日志系统","permalink":"https://www.missf.top/tags/%E4%BC%81%E4%B8%9A%E7%BA%A7%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"},{"name":"数据收集分析","slug":"数据收集分析","permalink":"https://www.missf.top/tags/%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90/"},{"name":"云计算","slug":"云计算","permalink":"https://www.missf.top/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://www.missf.top/tags/Prometheus/"},{"name":"监控","slug":"监控","permalink":"https://www.missf.top/tags/%E7%9B%91%E6%8E%A7/"},{"name":"Docker","slug":"Docker","permalink":"https://www.missf.top/tags/Docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://www.missf.top/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"CODING","slug":"CODING","permalink":"https://www.missf.top/tags/CODING/"},{"name":"持续集成","slug":"持续集成","permalink":"https://www.missf.top/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"name":"Python基础","slug":"Python基础","permalink":"https://www.missf.top/tags/Python%E5%9F%BA%E7%A1%80/"},{"name":"Hello World","slug":"Hello-World","permalink":"https://www.missf.top/tags/Hello-World/"},{"name":"荒原饮露","slug":"荒原饮露","permalink":"https://www.missf.top/tags/%E8%8D%92%E5%8E%9F%E9%A5%AE%E9%9C%B2/"},{"name":"记忆","slug":"记忆","permalink":"https://www.missf.top/tags/%E8%AE%B0%E5%BF%86/"},{"name":"语录","slug":"语录","permalink":"https://www.missf.top/tags/%E8%AF%AD%E5%BD%95/"}]}